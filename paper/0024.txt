NBER WORG PAPER SERIES

OPTIMAL ADAPTIVE CONTROL METHODS
FOR STRUCTURALJ.JY VARYING SYSTEIS

Alexander H. Sar'ris
Michael Athans
Working Paper No.

2t.

COMPUTER RESEARCH CENTER FOR ECONO{LCS AND 11ANAGEMENT SCIENCE

National Bureau of Economic Research, Inc.
575 Tecbno1oi Square

Canridge, Massachusetts 02139

Deceiiüer 1973

Preliminary: not for quotation
NBER working papers are distributed infoniully and in limited ni.rrbers
for corrments only. They should not be quoted without written permission.
This report has not undergone the review acccrded official NBER

publications; in particular, it has not yet been submitted for approval by
the Board of Directors.

Massachusetts Institute of Technoioj and NBER Computer Research Center.
Research supported in part by National Science Foiidation Grant GJ-ll54X2
to the National Bureau of Economic Research, Inc.

*'CMassachusetts Institute of Technoloj. Research supported in part by
NASA Grant NGL- 22 0091214 to

MIT.

Abstract

The problem of simultaneously identifying arid controlling a timevarying, perfectly-observed linear system is posed. The parameters are
assumed to obey a Markov structure and are estimated with a Kalman filter.
The problem can be solved conceptually by dynamic programning, but even
with a quadratic loss function the analytical computations cannot be
carried out for rrcre than one step because of the dual nature of the
optimal control law. All approximations to the solution that have been
proposed in the literature, and two approximations that are presented

here for the first time, are analyzed. They are classified into dual
and non-dual methods. ialytical comparison is untractable; hence
Monte Carlo siirailations are used. A set of experiments is presented in
which five non-dual methods are compared. The numerical results indicate
a possible ordering anong these approximations.

Acloiowledgement

The authors would li]ce to thank Ms. Sophia A. Zalk for her excellent
typing work.

.3-

.

Contents

1. Introduction

1

.

2. Statement of the Problem

Estirrtion of the Varying Parameters

3.

Bayesian

.

Solution via Dynamic Pro'arrriing

8

10

5. Optirrul Control with Perfectly Known Parameters

13

6. Non-Dual Suboptirru.1 Methods

16

6.1 Wouters' Mininn Variance Controls

17

6.2 Wieslander s and Wittenrrurk' S Control

17

6.3 Sequential Stochastic Control

18

6. L

7.

Dual

Open

Loop Feedback Optima]. (OLFO) Control

Suboptirnal Methods

22
26

7.1 One-Measurement-Optimal Feedback Control

26

7.2 Adaptive Covariance Method

29

7.3 Two-Step Optimal Adaptive Control

3

8. Numerical Comparisons

38

9. Sunrry and Conclusions

5L

Appendix

A. Solution of the Adaptive Covariance Control Problem

Appendix B. Soma Useful Matrix Irivatives
Appendix C.

Computation

of the Two-step Adaptive Control

References

Tables

Table 1. List of Monte Carlo Experimants
Table

2. List of Average Cost in Experints

39

39

Figures

Figure 1.

Control Gains for El

Figure 2.

t3

Figure 3.

Estirrates of at in El
in El
Estimates of

Figure

Control Gains for E2

L5

Figure 5.

Estirrates of at in E2

Figure 6.

Estirrates of bt in E2

L7

Figure 7.

Control Gains for E3

Lt8

Figure 8.

Estiirtes of at -' E3

L9

Figure 9.

Estiirates of

50

Figure 10.

Control Gains for ES

51

Figure 11.

Estirrates of at in ES

52

Figure 12.

Estimates of

in E5

53

in E3

LL

/

1. INTRODUCTION

Economic science attempts to ui-iderstand the economic behaviour of

individual units like the household and the finn as well as their aggregates.
There is huge diversity in the ways of people and firTrs, hence there is a

lot of uncertainty inherent in any economic system. The difficulty of
understanding economic behaviour is compounded by the fact that attitudes

change, and technological innovations and political factors tend to always
change the status quo. We live in a changing wcirld and we rrn.ist find ways

to understand, describe, and deal with these changes.
To date nost quantitative economic res.earch has dealt with system

no1e1s in which the structure is completely fixed and is
change.

not allzed to

There has been a lot of worc, under the name of econometrics,

that has dealt with constant parameter estirrtion of econometric rrcdels.

A very good indicator of the state of the art is the book by Theil (1971).
Recently there has been some research into the development of
methods of describing and estimating changing parameters. The work of
Rosenberg

(1968), Cooley (1971) and

the research

to

date.

This paper

uncertainty as

Sarris (1973) are representative of

deals

with

policy in the presence

of structLa'al

evidenced by parameter variations. There

research

into

constant

but unknocin

the problem

of policy forrmilation

system parameters.

has been

some

in the presence of

Prescott (1967)

was

the

first

—2—

economist to deal with such an "adaptive" problem. Since then McRai
(1972), Poporic

(1972), Rauser

and Freebairn (1973), and Chc.z (1973)

have also dealt with the same problem.
The problem of controlling a plant with unknown parameters is

not new to engineers. Fel'dbaum (1960 a, b, 1961 a, b) was the first
one to analyze the complexities of "learning while controlling," i. e. the

dual nature of control.

Since then there have been rnnnerous bcoks

(Sworder (1966), Fel 'dbaum (1966), Poki (1967) ) and papers (see ref. 16

for an extensive bibliography) dealing with policy in the presence of
uncertain parameters. Hciever, there have been very few papers,

addressing therrselves specifically to the problem of controlling a system
whose parameters are varying in a random fashion. Exceptions are the
papers by Wieslander and Wittenmerk (1971) and Wouters (1972), in which

some nirical results were given. The papers by Bar-Shalom and S ivan

(1969), Tse and Athans (1972), Tse et. al. (1973 a,b) also treated time

varying parameters althou the nunerical results reported were for
systeirs with constant parameters.

In this paper we attempt to unify inst of the methods available
for controlling systerrs with parameter adaptation. To this end we shall
consider only systeirs with perfect state inforrration. We shall extend

the

methods

that have been developed for the constant parameter case, to

include the varying parameter case. We shall also propose some new

—3—

methods. In section 2 we present the problem to be tackled. Section
3 analyzes the estintion technique for the time varying parameters.
Section '4 presents the general method of solution and indicates the

difficulties of applying it to our problem. In section 5, we present
the ideal case of )cn parameters and one control technique based on
it. In section 6 we present four non-dual control methods and try
to indicate their shortcomings. In section 7 we present three dual
methods, one of which is presented here for the first time. Section
8 presents some Monte Carlo comparisons of the non-dual methods, and

in secdon 9 we sunimerize the results and indicate directions for

further research.

-2. STATEMENT OF TI-I PBLIEM

Our purpose is to analyze and compare various methods so we

shall try to keep the complexity of the systerr to be analyzed, miniiral.
Generalizations of the methods to nre complicated probleirs are straight

forward in rrcst cases. We shall confine ourselves to discrete time linear

systeme described by the folling equations.

xt+iAtxt+Btut+CtZt+€t

Hx

+

Vt

(1)
(2)

where

is the niobservable state vector at time t
Ut - is a vector of policy or control variables at time
-

z-

'

t

is a vector of exogenous variables

- is the vector of state measurements at time t

v - are vectors of system and measurement noises respectively.

The rrodel as stated in (1) and (2) is general enough to include
many engineering ncdels of interest and also reduced form econometric

nodels. Hiever, it is still too general for our purposes. Therefore,
we shall consider the folliing nodel composed of the rrost elementary
building blocks.

y+iat+btut+t
where

(3)

- is the perfectly observed scalar state
-

is

a scalar

control

- is scalar system noise.
The irodel in (3) is a special case of airrost every nodel that has been

dealt with in the literature.
level.

Hence we can compare many methods at this

— 5—

The state

will be measured exactly. Let us denote by yt
u the foUcdng quantities

ut-.
=
•

The controls

ut's.

(y,u )

is

the state at

Then

{ut} will be restricted to the follcwing form.

t t-l

u
where

a function

(6)

to be

chosen. Let Y denote the set in which

time t is restricted to lie, and V the set of allcxjable
is a function from Y0 x Y1.. .x Y V x V1 . . .V1 -'

V. For the purses of
At

(5)

u}

{u0,u1

this

tine zero we

paper Y =

shall assusne

V

R for all

that the

i.

folling quantities

are ]CKWn;

N
y0,

, e)

p(c0, C1
N

p(a0,b0)

Lo
The

N(O,a 2)*

0

obj ective is to chaos e the functions

such that the folliing cost criterion is minimized.
V(y0) =

* p(.)
with

{

:

y?

+

a probability density and N (a ,b)
a and variance b.

denotes

mean

E

y, l•.' 1N-l
(6a)

denotes a norl density

—6—

Notice that the problem is still not completely forjnilated because
shall impese the
we do not kncii hci a and bt are going to vary. We
follciiflg a-priori probabilistic structure on the pararrterS.
ati [at
btj

+

[0

Lbtlj

or if we denote by Pt
+

(7)

j

[a bt' *

and

w=

n

(8)

w1

s is the stcture propes ed by s eerg (1968) and S ais (1973).
In order for the problem to be completely specified the joint
must be given. Since we do not
WN
probability density of W0,
know a-priori how the parameters vary it is not trivial to specify this
quantity. For the purposas of this paper we shall ke the following
assumption

N

p(W0, W1

w)

E N(O,R)

(9)

1=1

where

(10)

R

o\
The choice

It

of appropriate R will not be

is discussed

sorrjhat by Sarris (1973).

The problem can

*

discussed

now be stated in full.

(') denotes transposition

in this paper.

—7—

Find the optirrnn V*(y0) where

E { 'E

mm

V*(y0) =

1

subject

0

yj +

+ r'u

)

}

(11)

to the stochastic constraints,
+

+

btut +

(12)

-i

(13)

Pt =

where

1

c}

+

are series of white nonr1 random variables with the

and

properties

p( ct) =

(1')

N(O,a)

(15)

N(O, R)

p(Wt)

= ç(

(16)

c)P(w)

and the system initial conditions are,
-

y0

kncn

p(p0)

l

N (

(17)
(17a)

, M0)

In the sequel we will

abuse the notation a little by writing

UN_i in place of Io,Yi
wiU be done for the reader's convenience.
,

1N-i 1Ii

(ii).

—8—

3. BAYESIPN

TIMAITON OF THE VAR'ING PARAMFE

As

will be seen scon, the solution of the prthlem stated in

section 2 will require the kn.iiedge of the joint conditional distribution
of the parameters at and bt, conditioned on the data up to the time t.
In this section we shall examine a way of obtaining this distribution,
which we shall denote
The

by p( P1Y ,ut_l).

distribution at time zero is nonmal as seen in (17 a). Assir
ut_i) is nonral with mean

that the conditional distribution p(

and symmetric covariance matrix denoted by Mt_itt_i.

denoted by

The relevant equations for the next stage are
+

Pt

w1

(18)

(19)

zp +
where

we have denoted

z N'We can use

u

(20)

standard Bayesian

analysis to find the density

'

,u

p(p /yt41,ut)

p(pt/yt+,ut)
(21)

[p(y/p,y ,u )p(p/y ,u )cpt
m (18) we see that the density
is

normel with mean

Mt,t_i

=

p(p/ytut) = p(pttyt,ut)
and covariance matrix

equal to P-i--.

Nt_itt_i

(22)

+ R

yt Ut) is also nonrl

from (19).

The

density

in

(21) is there-

fore normal. Its mean and coyariance matrix, after some calculations,

—9—

are

given by the fo11ing fonnulas.

tit

+

Mt,t [M_1

1z

+ 1z' z

(23)
(24)

t

The

folliing imatrix inversion lemma will help us render (23) and (24)

identical

to the standard Kalmen filter equations.

Lemma 1. (Matrix Inversion Lenma). If

s
S

+

M-

MA

AR 1B]

—

[R + BMAJ

then

-l

BM.

Proof. The proof is by direct compctation and is omitted.

With the help of this len (24) can be rewritten.
Mt,t

=

I—i,r2
Mt,ti - Mt,t iZt L + ZtMt,tiZtJ ztMt,t_i (25)

This along with (22) are the well kncwn updating equations for the

ovariances of the Kalmen filter adapted to our problem. We notice

that since Mt,t_i is symmetric then Mt is also srtric. We nai
substitute in (23) the expression for Mtit foiffld in (25). We obtain
after some menipulation

t,t

+

Pt,t-i

Nt,tiz( + ztMt,tizTt)_l(yt÷i -

Which is the standard KaJ.jman updating formula. Equations (23)
will

be useful later.

zpi1)
and

(24)

(26)

—10—

4. SOLIJftON VIA DYNAMtC PROGR1ING

The problem that was stated in section 2 can in principle be
solved via dynamic programming. We state nci the form that the stochastic

dynamic prograiming uations take. We can write:

V*(y0)

u0,

N-i

E'

min

E

i

u11

u1

0

(y2
1+1

+ ru/yN_l,uN_
1

(27)

We shall ni state a theorem, which can be found in strm (1970, oh. 8),

that will be crucial.
Theorem 1.

Let E [./y denote the conditional mean given y. Assune

that the function f(y,u)
respect

E[l(x,y,u)/y') has a unique miniam with
to ucV for all ycY. Let u°(y) denote the value of u for which
=

the minimum is achieved. Then

n El(x,y,u)
u(y)

E1(x,y,u°(y))

E' in E [1(x,y,u)/y]
yu

N-i
Using this theorem and noticing that E [ E (y? + + ru2) N-i ,u
i/y N-2
i= 0

is quadratic with respect to

therefore having a uuque minimi.ni we

can write
N-i

V*(y0)

mm

U0,U1,... UN2

E' nin E[

UN2

i=l

(y?
0

i"

ru' N—l N_23
}(28)
,u

—11—

we invoke the principle of optimality, and noticing that the first
N-i texirs in the si.mtion of (28) do not involve UN1 , we write:
NcM

N-2

V*(y0)

=

E { E (y1 + ru?) + mm EJ + ruNlIy,uJ}

mm

UOUi,...UN_2

1=0

it

(y?1 +

E' { E

ntin

Uo,Ul,...UN2

UN_i

ru) + v*yN_l)

(29)

}

where we have denoted:
V*(yt)

E{

mm

N-i
+

E

ru)/yt,ut_l}

Ut,Ut+l,...UN_l

By the reasoning used above it is quite straightforward ncw

to prove the folling recursive relation:
V*(yt) =

E

'{ y÷1 + ru + V*(yt)/yt,ut_l}

(30)

Ut

Equation (30) is the well kricwn recursive relation of stochastic dynamic

programming. If we can solve it then our problem will be solved.
At time N-i (30) becomes:
V.. (yN—l) =

.

mm

E

2

2
N—i N—2
+ r1/y
,u

}

UN-i

min E {(_1y_1 + b 1u21 +

+ 2a lbN iUN

l'Nl +

UN_i

N-i + 2_lUN_icN_l) + 1iN_i,N_2}

=

—12—

-

.

nun

+

The

r

2

N—i N—2

2

LYN_1E(_lh1' U

) +

2

2

N—i N—2

uiE(bNi/y

+ 2lyNiE(lbN_iIyN_i,uN_2)

+

,U

) +

_]

(31)

miniiami of the above expression is easy to find since the

quantity

inside

the brackets is a quadratic in UN1•
=

r
— 1r +

2

N-i N—2 i —i

E(bNl/y

,u

)j

N—i N-2

E(aNibNi/y

U

N1

(32)

(33)

v*(y) KN1 'N1 +
where

KN_i

E(1/yN_l,u2)

-

[r + E(b/y',u2)J _(11/yN_i,uN2)2

(3)

(35)

Equation

(33) might icok like a quadratic y but a quick iook at (3t4.)

will convince the reader that KN1 is a quite complicated function of

(c.f.

uations (25)(26)). It thus

becomes impossible to carry the

backward induction any further than already done.

It is our purpose in this paper to examine and compare sioptirr1
techniques to solve the problem posed in section 2. This will be done in

the

next

fei sections.

0

—13—

5.

OF1IMAL CONTROL WITH PEFFECLY KMCI4N PARAMETEI

In this sectial we shall assi.nne that the parameters a ,bt are
kricn with certainty during the whole interval tO,NJ. Equation (30) at
time N-i becomes:
N—i

V*(y

mm

N—i N—2
2
) mm. E "N2+ ruNl/y
,u

E' {

1y1 + b11 + 2_1bN_l_iyN_1

21N1N1 + 2b _1CN_i + 1iN_i,N_2
+

b11 + 21bNi1yN1 +

+

}

+

J

(36)

The above equation is a quadratic in UN1 so its minimum is easily foumd.

r
- [I'
+

2 1—1
-1i
_1bN_1yN_1

HNy

(38)

+ FN_l

where
2

HN1 aNl

2
i—i 2 2
r
L
r
+
bNl
j
aNlbNl
-

FNl 0
Let V*(y) H+121 +
progr'armiing recursion becomes

Then at time tj the dynairdc

— 14-

V*(yJ)

mm [ci

The

mm

+

ru

E[y?÷1 +

H.1)(a?y?

+

+ b?u?

+

2ab.uY

+

+ ru J

('tO)

miniraim of the above equation is again easily fomd:

u-

Cr + (1 +

V*(yj)

+

H+1)b]

-l

(1

+Hj+1)abY

(141)

(142)

where

H

(1 +

-

H.1)a

F1 +

H1)b J -1(1 + H1)2ab

[r +

(1 +

(1 +

H1)cm

(43)
(144)

The equations (141)-.(4Lt) along with the initial conditions FN:O and
H :0 are the solution to the problem.

N

A suboptiil technique of solving the original problem is
based on (4l)-(144) and is usually referred to in the literate by the
name of certainty equivalence or enforced separation (from here on
abbreviated as CE).

It is the

follring,

a) At time k we are given the data and k_l hence the folling
section 3:
quantities can be computed via the results of

k-1 I /k-l ,bkli

'

and

Ik-l

—15—

b)

Equation ('+3) is solved bac]<ward

from

time N until time

k+l

with

the

fo1ling conventions:
1)

a ak/k_i)

forallk4 <j<

j - /k-l)

b

N-i

2)

Denote the solution by

c) The control at time k is found by the follci..ing equation:
+

This
people

(1

)b,kiJ _l(l

+

('+

soptiirl technique is usually the one against which

rrst

compare their suboptim1 methods. It is one of the simplest and

fastest suboptinal techniques and therefore it is attractive. It will
be compared with other suboptini1 methods at a later section. It is
interesting to see that if the parameters are ]<ncwn exactly CE reduces to

the true ntrol

l (141).

—16—

6. NON-DUAL SUBOPTIMAL MEIHOt6.

In this section we shall examine various suboptima]. techniques

that have been suggested in the literature. All these techniques will be

non-dual, in the sense that they calculate the control la.i at

t k under

the assumption that there will be no further measurements after tinie k.

There are three rrain elements of a dual control. The first
which can be called the controlling element has to do with the effect of

the control on the criterion function and is the element that characteriz
all optimLnn controls, dual or not. The second characteristic is a
learning one, namely the infoxration that is accumulated over past controlling

stages is utilized to ijirove the present }aledge of the system. In
section 3 we analyzed the way that optimel learning will be achieved

in our problem. The third element, which we shall term the dual effect,
has to do with the experimental nature of the control. Choices of present
controls affect the futine probability densities of the urijczncwn parameters.

Hence a dual control can affect not only the present but also the
future learning of the system. It will be this element that will be
missing from the suboptimel methods presented in this

section. In all

subsequent methods, learning will occur via the method descrised in

section 3.

—17—

6.1

Wouters' Minirr&nrt Variance Control.

This method was proposed by Wouters (1972). It is quite simple.

The logic is the following. Suppose that the objective is to minimize
the index;
him

N
1 E

N-'° Nkl
then

(146)

y2(k)

the control suggested by Wouters (to be denoted by the letter W) is
—

ak/]<]

(147)

bk/K_1
Notice that (146) is quite different than our objective (6).

It

does not,

used

for example, include penalty for the

control.

Wouters

this technique to control systerrs with tirr varying parameters.

He showed via Monte Carlo experiments that the method is better than

no control
6.2

at

all.

Wies lander's and Wittenmerk
This method

(hereby

's Control.

denoted as WW) was proposed by Wieslander

and Witterumrk (1971). Their idea is the following. Since the reciasive
equation (30) cannot be solved analytically for rrre than one step,

assume that the next step is the final one. The index to be minimized
in their paper was Ey2(t). The control that they derived is the same

—18—

one

as in (32) with r 0

-

_(bk/yk,(u)k_l)yk

the experiments that they did they

In

law

[Eb,yk,(u) k_i)]

compared this control

to no control at all, and it performed better. Since it is not

obvious that any control will perform better than no control, their
method deserves some attention. This as well as the previous method

ignores penalty in the control. Hever, in this case it is quite easy
to introduce control penalty. In fact the rrdified control law (to be
denoted by WM) is identical to the one in (32).

u

[r + E(/yk,(u)k_l)

-

It

E(ab/yk,( )k_l)y (9)

is interesting to notice that none of the previous three

methods reduce to the true control law, derived in section 5 (equation
(l)), when the pararrters are krown exactly. We nc examine a method

that has this desirable property.
6.3 Sequential Stochastic Control.

The logic for this method is that at time k all future

infortion is neglected. Hcwever, it is recognized that the pararrters
will be changing. The assiunption then is that the distribution of the
future values of the parameters will not be affected by the future
measurements. This assumption is similar to the one that assumes the•
future

parameters to be random drawings from a distribution which

depends only on inforniation up to time k. The difference here is that

-19-

the

distribution is different at every point in time. This method has

been mentioned by Yoshida and

it carefully.

We nc.i derive

Nakamura (1973),

but they have not analyzed

it in detail (the method will be abbreviated

by Si).
Assume that

kk-l
we are at time k and we have observed y ,u

Hence we have computed /k1 and MK,.kl with the help of the Bayesian
foniniias

developed in section 3. The problem ncw is the foflcx'zing.

. . u1

(loose

N-i

k

E' { E

V(y )

so as to

2

+

(y

minimize
k

2

ru.)Iy

k

1

(50)

jk j+l
subject to

yi+l zP
p.

+

j >k

=p.
j-l+w.j—i

(Si)

The assumption that we are iiking can na. be stated precisely.
The vector p of parameters at time j > k will be assumed to be a random

dr'iing from a

Gaussian

j/k-l
and

density with mean
=

j-l/k-l

(52)

(/k-1

covariance matrix
Mj,k_l

Mj_l/k_l

+

R

•..

Mk/kl

+ (j—k)R

(53)

—20—

k k—i

j—l )

j

Thus we approxirrte p (P /y ,u

by p( p /y ,u

).

The dynaniic

prograrrining

recursion nci can be analyzed. At the fisial tiir (30) becomes
+

V*(YN_1)

E {

N-i
a-1y2
+

-i
2

N-i N-i }
,u

/

2
+
+ b2
N_1UN_l

2bNiicN_i
2

k k-i )

m [y1 E(aNlIy ,u
k

k-i
,u

N i

+

+

Ni'

+

1E(1/yk,ui) + a

N-i N—2

2

U

}

+

i'i2

) +

Let us nci decorripos e the

+ 2_ibN_1_iyN_i

matrix N.
as foiiais:
J/k—l

Nj/ki

Referring to

(55)

(10) and

V(y1)

(bl,kl

(55),

(5'4) reduces

to

[y2Ni(a2Nl/ki +
+

+ a2

+

-iIk-i

+

u1[r +

2iYNi(i/kibNl/kl

(56)

+

-i/k- J

—21—

The

control minimizing the above expression is

- [r +

(b11 -l/k-lJ -l (& llbNl_l + -lc-lN-l
(58)

+

V*(yN_1) =
where

N1fkl +
N-l/k-l-l-l + _1_l)2

(aNlfk.l *

N-l/k-l

—

Lr +

N-1/k-1
(59)
(60)

=

C

If we nci assm that
then by

(61)

v*(yL)

H.1y2.÷1 +

an analysis

identical to that of section 5 we derive the following:

u

{r +

-

(1
+

V*(yj)

=

Hy

+

H41)(bp_1

+

/k-lJ

-l

(1 +

/k1 y

(62)

+

(63)

H÷1).

where
(1 +

+ (1:4

H+l)(a,kl

FN

M(k_l)

H+l)(b,kl +
+

=

+

(1 +
0

H÷1)

c

-1

(1 +

H1)2(a 1b + jIk-l
(65)

(66)

—22—

The

optimal

control

at

time

k is chosen as folics:
(67)

*

u is derived recursively as above. After this control is applied
and so on
k+l is observed and the cycle is repeated to choose
until time N-i. It is interesting to note that when the parameters

where

are knc.in exactly the control derived by this method is reduced to

the true optimal control described in section 6. When R =

0

or

equivalently when we assume that the parameters are constant, then

Si reduces to a method that has been analyzed anng others by oki
(1967),
6.

Bar-Shalom

(1969), and

Prescott (1967).

Feedback Opt irral (OLEO) Control.

Open Loop

This

and Sivan

method has been analyzed by Tse and Athans (1972) and

Ku and Athans (1973). The assumption under which the control at tune
k is found is that the sequence Uk ,Uk+l

UN1 will not depend

on any future data and hence can be found at time k by solving an
open loop control problem. Let us make this assunrption inure precise.

The problem to be solved at time k' is the following.
V (y )

'{

irdn

Uk,Uk+l
subject

E(
j4z

UN_i

y.1/y

,u

- +r

E
j:k

u2. 1 (68)

to
zip.
=

+
+

c

2

k

(69)

—23—

that the expectation in (68) does not include the control teni.

Notice

This is because they are to be chosen in an open loop fashion. The

solution to this prcblem is quite complicated. We shall present here

an outline of it and we shall irntion the simplifications that were
employed by Tse and Athans, and Ku and Athans.

The problem in (68) and (69) can be solved via detenrilnistic

dynamic proarrming as folls. Denote by V (J) the quantity
E { Nl (v?+l +

Vy)
E{

mm

uu+1
Then

1-J

,UN1

UU4.1

ij

(y?÷1+

ru}Ik—l}

(70)

the dynamic pr graming recursion is
V*(yj)

mm

E

+

ru

+

V(yIk—l )

(71)

Uj•
Notice

that since E(.Ik—l) is kricwn at time k, (71) is a deterministic

dynamic prograning recursion.

At the final step we obtain

*N_l )

V (y

=

mm

2

E(yN +

2

—24—

+ 2lbNlUN1yNi

E(1y1 +

min
UN-i

+ r1/k-l)
rnin{ E(a1y1/k-1) + u1 [r

+

UNl

E(b1/k-l)J

}

2uN1E(aNibNlyNl/k_i) +

+2_lYN_iCN_l +

+

(72)

The optin.i OLFO uNl is
*
UN_i

—1

EN-i

N-l

(73)

where
r +

E(b1/k-l)

(74)

N-1 = E(aNlbNlyNl/k)
=

Notice
(69) a, b, and

y

(75)

1/k-i) -

E(a2N

D1 f1

+

(76)

an interesting phenomenon. Since in the state equations
are coupled in a nonlinear rrnner one cannot separate

E(a_1y1/k-l) for example into E(a1/k-l)E(y1/k-l). Hence no
interesting

cancellations will occur in the

steps prior to the last.

To illustrate this paint we will shi without proof (which is straightforwani) the OLFO control and the cost at time N-2.
—D N—2N—2

r + E(b2
N-2

+

12/k-l) DlE2(llbN2_l) (78)
-

E(2bN2yN2 + l2bN2yN2/k_1) E(aMlbNlbN2fk_l )

(79)

—25—

*N._2

V (y

t:

2

2

) E(aN2yN2

+

2

2

2

a1a2y2/k_l)

—12

- D

ibM laN 2N 2/k-l) -

(80)

f_2
Thus

N_1E (aN

we can see that the exact solution for the 0120 control

at time k becomes increasingly laborious as we proceed in the bac3iards

induction. The problem arises because we have assiied that aj as well

as b are random, and this introduces the nonlinearity in (69). Tse
and Athans (1972) assumed that only b is random while a is not. In such
a case

aE(Ik—l)

E(÷1/k—l)
E(b. /k-i)
J+1

+

uE(b/k)

(81)

E(b.Ik-1)

J

therefore the conditional expectations evolve linearly, rrking the

and

bac1.iards induction of. reproducible form from step to step. Ku and
Athans (1973) on the other hand have used the approximation

E(Y+1Ik1)
Their

(82)

+
E(a./k-i)E(Ik-1)

uE(bIk-1)

(82)

extensive 1bnte Carlo results shed that OLFO in conjifflction with

performed

slightly better than CE (or enforced separation, as they

called CE), for stable systerrs, but considerably worse than CE for uistable

aies.

—26—

7.

DUAL SUBOPINAL MEIHOLS.

Dual methods assume explicitly that the choice of the present

control will affect the future probability densities of the parameters.
Hence the control is inevitably a nonlinear fumction of the present state
and in rrcst cases quite a conplicatéd one too. We shall analyze three
quite different dual methods, the last one appearing here for the first
time.
7.1 One-Measurement-Optime]. Feedback Control.
This

has been
Iausser

measurement

was developed

by Curry (1969-1970), and

recently used by Tse et.al. (1973), Tse and Bar—Shalom (1973),

and Freebaim (1973),

and

further analyzed

by Early and

Early

(1973). The idea is the fol1cxiing.

Suppese

we chose uk

k given {k ,k_i

.

Then we could find the

covariance

via (25). We could also assert that the

average value of k+1 would be

k+i
We could

k—,

then consider

V(y ,y1)

a/_i

k+l/k-l

iian

Uk+l

bk/k 1

(83)

the problem

N-i
-

+

E

,UN1

{

2

2 k—

k-i—

(y11 + ru)/y Yk+lU ,uk}
ik+l
E

of

—27—

with initial conditions
(8k)

"k+l/k-l
k/k
M—l

(85)

k/k—l
—

—l

M

k/k-i

k/k

,

+

(86)

,

ZkZk

where

(87)

LYk']

The above problem is solved via the OLFO rrthod and the following ninther
is computed.

V(yk,)
Now

+

a n value for

ri

+

VoLFO(yk,k÷l)

(88)

is chosen and the whole procedure is

repeated. The usual procedure is to start with the CE control and then

search in the neighborhood so as to find a better control. The control
minimizing V(yk ,) is applied and the nthod is started an&i in the ne'c

tine step.
The nthod has at least one advantage, namely that it guarantees
a better control than the starting one which can be the CE one. Tse and
Bar-Shalom (1973) have shown numerical results in which this method was

better than CE by one order of magnitude.

—28—

The rrin disadvantage of it is that in general it involves a
search in a rn-dimensional space, where m is the dtrrnsi-i of the ccntrol

vector. Unless the control space is bounded, this search will result
in a local rrn mum of V(yk) with respect to Uk. In addition, as was
seen in section 6. 4, the exact OLFO control is hanl to find and approxi-

n.tions might be used. In such cases the quantity V0 in (88) is
substituted by an approxinute one. Therefore, the minimization of (88)

with respect to

will be an approxite one.

Modifications of this method are easy to visualize. One which

seens to us particularly appealing is to substitute for VOLFO in (88) the
quantity V1, namely the cost computed with the Si method analyzed in

section 6. 3. Without some numerical studies it is quite difficult to
assert a-priori which method would perform better.
The dual nature of the one-measurement-optimal feedback method

is menifested by the fact that the covariances of the parameters at time

k+l are explicit functions of the control applied at time k. The dependence
of the future covariances on the present control is nonlinear and quite
complicated. Thus since it is hard to compute the explicit dependence

analytically numerical evaluations have to be made. For on line

applications this can be quite costly.

—29—

7.2

Adaptive Covariance thod.
This quite interesting rrthod was proposed by McRae (1972).

Here we shall present the mJn idea, and we shall extend her results
to our problem, and give them a shape suitable for ninrrical computation,
which she has not done.

Suppose we are at tirr k and we have observed

and k_1.

We would like to choose u ,uk,... ,uNl so as to rninize the
quantity
N-i
E {

V(yk)

N-i
E{

2

(y11
ik

/yk,Uk_l}

+

E (y1 + r4)/k—l

}

(89)

i=k
subject

to
+

zp
=

p(pk/k_i)

g

N(pk/kl,M,k

j> k

l

(90)

(91)

Our fut 1aledge of the parameters p will be governed by the posterior
density of p given future data. From section 3 we kncw that the future
posterior densities of p will be norrr.l with means and covariances
evolving by the formulas:

—30—

M1 [M-,_1P,_1

N'

N'

=

+

lz!y1J

(92)

(93)

+ 1 ZTZ

GC

i/i

pj/j_1

N..
J/J_l

=

(9k)

P_l/_l

=11.

+R

.

Ji/J'l

(95)

for j > k with initial conditions given in (91).

In vi of (90) the constraints (92)-(93) are stochastic. We
mike the folling appro±rtion similar to McRae '5, that renders the.m
deterministic.

We asstune that the evolution of means and covariances

will be deterministic and given by the fo11iing formulas.

pj,j M1 [M_1p,_1 + E(lzty/k-l)]
j/j
N. .
Jim.-1

N'

+

=

p.1151

= M.

E[1 z'z
j j/k_1J

.

J—l/Jl

(96)
(97)
(98)

+R

(99)

Thus the future means and covariances are fiiictions of quantities that

are to be calculated at time k, i.e. Uk,Uk÷1...

—31—

us analyze (96)

Let

jj

E(1 z'y

2£

a little further.

1 Ez'E( /y,u)/k-l

/k-i)

c

1 E 1z'zE(p/yJuJ)/k_1]
E
(ye

p

JJJ/J_i

p.,.1

Since

(100)

1k—i]

is deterministic it can be factored out of (100).

Therefore, (96) becomes

+
p.,.

Equation

pj/j

M5,5 [1/j_1

(97) nci

E(lztz/k_l)J

(101)

implies that

Pi/il

Pu/u

= •• k/k-1

(102)

Thus implicit in assumptions (96)-(99) is the fact that the future
mean is not affected by the controls but the future covariance is via
(97).

The problem that we solve is

the foi1cing.

Minimize V(yk) in(89) with respect to
subject

to the

stochastic

constraints (90), and given that the

future

densities of the parameters have means given by (102) and covariances

—32—

by

(97). The problem that we pose is both stochastic and deterministic

because half the constraints are stochastic, namely (90), and half

deterministic, naily (97). We solve it, foUaiing McRae, by applying
dynamic proairoiii.ng to a criterion which is (89) aunted by products

of the deterministic constraints and deterministic Laange multipliers.
The complete analysis is given in appendix A.

The result is

,uMl are linear fiuictions of k

that the controls u, ,u

'N-l respectively with gains given by the solution of a two-pointboundry-value (TPBV) problem. The complete set of equations is the folliing
(For prcof see appendix A).
u.
J
G.

ii

—G1F

j

(103)

y

J

K.

+

(1 +

)

+

i/i—i

i/i—i

j+1

(1

b

)(b 2

r + (1 + K

K.

j+l

)(a?

.

jlj—l

+

—
-

+

K.1)(a.1 1b.1.

J

1 L

.

3/3—1

)

- —1

j

j

1L

- GT1F

j j

(lOLt)

(105)

(106)

C

L.

J

P.

- M. .P. N. .x.
(I + M1.R)1
(I + RN3/3•)1 L.
3/] 3+1 J/] j+l
j/j
j+1

(107)

-GF.

1

(108)

—GF.

3]

GT2F2
J

I

—33—

x.

E(y?/k—l) + x

ti'

P (p

+

p'

j—1 j—1/j—2 j—l/j—2

j—1

[a] jiji

pjl/jl

=

M

)}

(109)

j—l/j—2

/k-1

(110)

3/3

=

N.,.1

+1

M.11.1 +

Px

(111)

R

(112)

The bounda contions are

0, l 0,

/k1 and

The solutions of the above equations must be carried at each
step k and only uk applied to the system. Then a nz measurement is

taken and the procedure must be repeated. What is interesting about

this method is that the future controls are linear and influence all the
future covariances. We have not as yet examined nnnerical ways to
solve the above TPBV problem.

7.3 o—Step Optirrl Adaptive Control.

This method, to o kncledge has not been suggested before. The

idea is the follci.dng. Msir that we are at time k having observed
k,k_l. Then assune that optimization is to be done only for two rrcre
periods. Also assiniie that the one future value of the parameter b is
and equal to bk/k l Then carry out the two-step backward dynamic
pxgranining recursion. The assi.niiption that bk+l is constaiit and equal

to bk/k is sufficient to render the minimization with respect to
to minizatim of a quadratic function of Uk.
Uk equivalent

v(yk)

=

min E

+

ru + v*(yk),k_l]

(113)

Uk

where

V*(y)

rain

E [+2 + ru1/k

(114)

At time k+l the minimization (ll'l) is straightforward. We obtain
(115)
where

(116)

Cr +
!c

V(y

+

k+l

117

CY

—35—

where

H ak+1/k +

+1/k

- (r + b+)

(118)

+lak+l/k

(119)

C

At tine

mm

(y )

From

k we

section 3 we

have
2

E [(1 +
H)yk+i+

r 2 + F/k_i]

(120)

kncw that

c/k s/k-i

+

/k-1kkk/k-1

+

aE)

k+1

-

k-ik

-bk/k_K)

(121)

-

+1/k /k

/kT1
in (12!) the innovation becomes

If we substitute for

a]</)y]
We

(122)

+

(b<

—

bk/k 1)Uk +

Ck

(123)

nake the assl2llption
(bk

which

—

bk/k_i)

is what

=

(12'4)

0

will render

the prob1n tractable.

—36—

Of course,

if bk

a true fact,

and

is a—priori kncn then

not

an

the

assumption (12'-i.) will

be

approximation.

(12l)-(122)

By substituting for ak+l/k,M+i/k in H, via

and

substituting for k+1 in (120) we arrive at an expression whose conditional expectation is easy to take. In addition the resulting
expression is quadratic in uk. The calculations are lengthy but
straightforward and they. are shcwn in appendix C. The optimizing

is

-l

*

(125)

-D kk

Uk
where

r+

(1 +

+i/k/k-l /k-l
+

r

+
r +

/k-l

(bkl +

+

()
{a2k,kl

bk/k

1

X{E E(ak - K/k_l)hJ y +

+ /k-1
=

k

{ (1 +

(126)

÷l,k1kP

L yE [akbk(ak - ak/kl)/klJ

2l)kE

r

+

r + /k1
+

- akfl)k1}

L/k_1akbk_1)

E(ak/k_l)]
+

+

+

—37-.

r +

k/k_l)/k_Jc

+

2ak/k_lbk/k_lX1o)

2

bk/k_i

where

c—lk>'k/k—i +

Xk

The control Uk
We can also

see

is

that even

thus

2)l
a highly nonlinear function of

if we rrke the assuntion that bk

it is impossible to carry out one rrre recursive

to bkl/12

dynamic pro'anining step because of the

of

(127)

complex nonlinear

dependence

V (y ) on

This

control 1 is

dual

not the

and it takes into account futi.ae
variance

of

a. It is quite

simple

adaptation

of the mean but

to

since it does not involve the solution of any iterative

compute

system of

equations

like the previous methods.

(126)

—38—

8. NUMERICPJJ COIARISONS

In this section we sh the results of some initial Monte Carlo
comparisons of all the non-dual methods mentioned before except the
OLFO one, for which exact corrtputations are tedious as seen in section 6. Li.
and

inexact computations give strange results (cf. Ku and Athans (1973)).
The methods compared are denoted by the fo11aiing initials:

T - Control with perfectly kricwn parameters (cf. section 5)
CE - Certainty equivalence method (cf. section 5)
W —

-

For all

WM —

f'bdified WW

Si

Sequential

the

parameter

(cf. section 6.1)
Wieslander's and Wittennrk's method

Wouters' method

—

methods

(cf. section 6.2)

(cf. equation (L1.9))

stochastic control

except

T, which

updating was done

(cf.

section 6.3)

does not involve learning, the

with the Kalman

filter analyzed

in

section

3.

We n state the results for four experiments that were
conducted. Table 1 simrizes the conditions of each experiment. The
first colunui denotes a code name for the experiment. The second coli.nrn

denotes a code name for the tn.ie parameters used in generating the data.

The third coluun lists the covariances of the system error. The random
nibers that were created had the indicated covariances and were normal.

The N0 colurrm lists the initial covariance nitrix of the parameters. For
every run the

initial

values of the parameters were chosen by random

sampling from a normal density with mean p0, listed in the last colnm,
and covariance matrix

M0.

The colunn labeled R lists the covariance

ntrices used for the error ter in the parameter equations (cf. (7) and

0

MErHOD:

E5

E3

E2

E1

EXPERIMENT

3

20

io_2i

93.444

5185.37

272.849

47.485

625.557

20.921

17.99

29.524

19.661

16.412

W

27.421

31.333

23584.1

61.258

Wv1

WM

(.6,—.2)

.3

20.76

18.257

20.552

64009.4

21.997

3.386 X

20.189

Si

(.8,.3)

(—.63,.083)

(.8,.2)

.3

.3

.3

r

20.507

3

3

20

Y0
3

RUNS

20

of

20

No.

io_2i

20.237

CE

0

[o .01

[.09

l0I

R

List of Average Cost in Experirrents

lo_212

10212

lo_212

1o_212

M

List of Monte Carlo Experinnts

20.158

T

.25

AB'4

E5

Table 2.

.25

.25

.25

J33

AB1

TRUE COEF.

E3

E1

EXPERIMENT

Table 1.

fl

CA)

(0

—[10—

(10)). The rerrining three coluirns list the nuither of runs, the initial
value of y0 and the control penalty r respectively. All runs were for
30 periods.

In

experiment

El the true parameter at was constant and the

bt was a sl.i trend. In E2 the true at and bt were generated
using equation (7) with initial values (-.63,.083), as shn in the
true

last column of Table 1, and normel random errors with zero

covariances o .09 and

means

and

.01. In E3 the true parameters were

both tine varying with some trends and sudden jumps. In E5 both
the parameters were constant with at equal to .7 and bt equal to - 4•

In Table 2 we shc the average cost for the 20 runs. The

first thing that we notice is that the

method performe quite well,

surpassed at some experiments only by Sl. We see that the W and WW
methods which are minimum variance ones involve excessively high

control cost. In experiment E2 the parameter at was umstable for
half of the controlling period, and we see that all suboptiinal methods

perfonn poorly. This is a disturbing fact and was also observed by
Ku and Athans (1973) in their simulations of the OLFO method.

Figures 1-12 shi the average control gains and the
average parameter estirrted resulting from the 20 Monte Carlo rums

of each experiment. it is interesting to notice that for E2 in
which, as seen in Table 2, none of the methods gave good controls,

U

—tl—

nevertheless the estirrates of the parameters are quite satisfactory.
In general W, M, and WM give the worst results with CE and Si aays

superior to those three. The experiments, hcever, did not result
in a distinct ordering of CE and Si.

There is still a lot of work to be done in arrtparing these
methods and corrparing them with the dual methods described in section 8.

The dual methods should give better results than the non-dual ones.

On the other hand the dual ones are all, with the exception of the
one described

in section 7.3, quite costly.

0.0

—1.5

16

TIME Bout IC'S:
SYMBOL

.•

'

I TO O

.A.LE I44ME
E1_TG
*1

#1

E1_C;G

*1

El

*1

El_LJG

-cj.

—0.

—0.70

— .90

1

TItlE E:OIJt11r

1 TO O

SYMBOL .CkLE

I.
U

*1
*1
*1

ELIC

El .1iC
El

1C

-)
Figure 1. Control Gains for El.

...t. 3—.

o 780

o 74Ct
I IME EOIJtl[i:-

1 Iii ?."

SVt1E)L .I. HLE tIHME

•
•

*1
W1

*1

*1

El _':F':_ci

F. _WC...C I
E I ._LUIFCJ 1

0

0.

TItlE F:riI.I,lCr

(tiEOL
••

•

LE

1 T'' )
fr ir1E

$1

*1
*1

F _1.11FC....C 1

E1_:IrC1

Figure 2. Estirra-tes of

in El.

_1.ltl-.

rU.

0. 1'
1 TO 13

I tilE E:OIJt t'
SYT1EIL

iLE PIHIIE

0

01

•

*1

•

*1

E1_'F'C_C2

*1

£ 1 _LJLJP:_C

E t_NFC•_C2

0. 220

0.1951
TIME

''IC'

I TO

SYMBOL SC L.E

••
•

01

HE1.C.

*1

E1_IFC_C2

*1

Cl _WUFC_C2

Fig'e 3. Estin±es of bt in El.

—'t 5—

2t3.

0.

-20.

I TO 3

TIME

SYOL ';CLE
S

••

U-iIiE

*1

E2_TG

*1

E.WL.ii..

*1
*1

ECG
E_W(

4.0

i.e

t.

I

It

21

TIME 6OIJtID 1 TO O
S?I1EOL kLE

••
•

*1

*1
*1

£ ...WflG

Figure . Control Gains for E2.

26

31

—'46—

U

6

11

26

16

31

I TO

Ti ME E:Ot [t:

smEi:'L JHLE tIiME
iF:2_Ct
Ui
#1
E..iPC_C1
6
$ 1.
L JJFI_C I

.

'

II

E_MWFC_C

3.0

1.0

-1.0

6

TIME EOU(iS

I

11

IC'

16

21

0

S'/I1EOL SCLE IIktlE

a

•
•

*1

In

Ejn1P':_CI
E..1p1:_c1

Figure 5. EstimateS of at in E2.

26

31

-0.20

—0.60

1

TIME EOut•40S 1 TO

SYMBOL iLE

••
•

Li

tlHr1E

E2.C 2

*1

E:_C FC _C2
E2_WFCC 2
E2_WIIPC.C2

$1

$1

Ii

-0.20

-o.,0

11

TItlE EClIHC,.
SYMPJ)L

•
•
•

16

21

1 10 31)

LE NH1E
41

,.4F;:_c2

E2_1fliFI_C.
E2_S I FC_0

Figure 6.

Estimates of bt in E2.

26

31

— 8—

1.0

—4.0

31

1 TO 30

I I ME ROUt
SYMBOL
S

a

C:LE

4H1E

E_TG

*1
*1
*1

ECG
E3JIG
EJMG

—0.25

-€1.75

—1 .25

TIME E;C'IJlCS

1 TO 30

SYTIBOL .Cr-I.E N-r1E

•
•
•

1 E3_TG
*1

Ii

ETJr1G
E?_S1G

Figure 7. Control Gains for E3.

—t 9—

I . (it)

0.50

0.

11

16

21

TIME E:01IHD 1 TO O
SYMBOL !LE

•
•
•
N

*1

*1

*1

E:3...C I
E_CFC_C 1
E3_WPC_C

E3_wI•IP':...: i

.00

(i50

@13

-0.50
TIME

E;OIJUOS

SYMBOL cc.,LE

••
•

III
*1
*1

1 TO
I h-i? E

E3.1FC_C1

Figure 8. Estimates of at in E3.

26

31

—50—

Ci.

0.40

-

—0.40

D

1

TIME BOIJnO,

11

16

26

21

1 TO 30

SYMBOL SCALE I1-fiE

i.E:_C2
E_C:PC_C2

.

$1

a

*1

U

*1
*1

E3_IIPC_C2

E_fl4PC_C

0

0.40

ci .00

TIME flIJpciS
S\IIBOL SCALE
U

.

*1
*1
*1

1

TO 30

B_C2

E.3...UMPC_C2
E3_S1PC_C2

Figure 9. Estintes of bt in

E3.

31

—51—

2.

*

- --

4- -S 4 I- -5- .- -b

6

1

TIME EUL:L3

1 TO

11

-S 4 •

4

21

O

SYMBOL
S

$1

U

E5_TG
E5.. I.UG

S

hi

E5_S 1 G

3.25

2.25

I 25

8.251
TIME BOUHOS 1 TO 30
SYMBOL SCALE MAfIE

°

•

*1
*1

1

E5_T

E_CG
E5_t1G

Figure 10. Cono1 Gains for E5.

3'

—52—

0.600

TIME fiJ,:

1.10 .3i

SYPOL SCLE t1t1E

••

84_C 1

*1

*1

•
•

E5..CF'C_C 1

E_LPC.C I

*1

*1

E5..L'4WPC_C 1

0. 72

0. 625

0.5?5

TI ME jJc:

1 TO 10

SY?IBOL SCALE W4ME

o

$1

•

#1

•

E5J1PC:_ r t

*1

E5_SIFC_C 1

Figure II. Estiirates of at in E5.

—& 3—

—O 2S0

—6. •350

—6.450

6

1

11

16

21

26

I TO 30

TIME BOUNDS

SYMBOL SCALE t1ME

4_C2

o

•

E3_CPC_C2

#1
*1

E5_kJPC_C2
E5_WWPC_C:2

—0.100

—0. 200

-e.:3e0

..

U

TIME BOUNDS
SYME:OL

••

•

b

11

16

21

1 10 30

£CLE MME
*1
*1
*1

E5...I4MF'C_C2
ES_S 1PC_C2

Figure 12. Estimates of

in ES.

26

31

— 5i—

9.

SUMMARY AND CONCLW IONS.

In this paper we have examined the problem of controlling a

system with parameters varying in a fashion unkncin to the controller.
We have surveyed all methods available for the solution of such problems
and we have extended some to fit our framework. We have also suggested

and analyzed two methods for the first time. One is a non-dual one (Si)
and the

a

other is a dual

one (see section 7.3). We have

also

presented

numerical comparison of the non-dual methods, in which Sl was

along

foumd,

with enforced separation, superior to other non-dual methods

that have been suggested elsewhere.

A mejor problem with all the methods is that a-priori there is
complete ignorance about the evolution of the parameters.

figures 5 and 6

it was

From

seen that if the parameter variation happens to

be of the same form as the one assumed, then these parametErs are

estinted satisfactorily. Otherwise, we do not have large hope of
identifying them. This raises the whole issue of robust estintion for
some particular kind of parameter variation, it is not clear whether

it will give good results if the parameters evolve according to a

different structure. The ultirate goal, of course, is to optimize
the criterion. The interaction between identification and control might
be somewhat umderstood in the case of constant but urJin parameters,

—55—

but it is not at all clear in the case of time varying parameters.

There is still a lot of research to be done in this area beginning with
mDre ecterisive comparisons of the dual and the non-dual methods,

extens ions to higher order systen, and examination of the interaction
between identification and control.

APPENDIX A

SOLUTION OF ThE ADAPTIVE COVARIANCE CONOL PROBLEM

In this appendix we present the solution to the problem posed

in

The solution procedure foilcs the analysis of McRaé
(1972). The problem is the foilcx.ing.
section 7.2.

Find

uk,... ,UN1 where

*k

N-1

V (y )

mm

E' {

UkU]c+l14N_i
subject

to
=

zp

independent

+

Z
(y1 + ru)/Jc-l}
ik

.

(A.1)

j>k

(A.2)

zero mean white noise with covariance
(A.3)

- 1/1

Ms,.

M,.1+ Eji z'z/k_l]
+R

z

=

[y,u

(A.)

kIk-1

j

>k

(A.5)

i

k

(A.6)

j >k

(A.7)

We define a set of N-k+1 matrix Lange multipliers

k-i <j

<N-i where L are all symmetric 2x2 matrices. We n form

the foiling Hamiltonian quantity.

-A2-

N-i

E{ (y1

H(yk)

E

ru?)/k—i}

+

+

1k

t{ L1

-

E[y ru
+

(M.1111

+

RY1

- E( 1 z'z/k—l)] I

.

ltr(L1zz)/k-l] +

11

-

}

+

Lk1M1/k1]

where

- L(M1111
We

+

R)]

(A.9)

shall apply stochastic dynamic prograiruiing to the augented

criterion (A. 8). We shall be careful, hcwever, to simultaneously irripose

the constraints
aH(y') =

0

k

<j

<N—i

(A.lO)

0

k <j

<N—i

(A.ll)

3/3
3Hyk)

(A. 10)

and (A. ii) correspcnd to the state-costate equations for
The dynamic proaJTming recursion can now be written as follows
H*(yj)

min { E fw.
Ui

for

k

<j <N—i

+

H*(y)/j_iJ +

(A.12)

-A3-

with
* N
H (y

—1

—1

-i-l/k-l1

E-1-i/N_i

w y1 + ru?

—

(A.l'4)

1tr(Lz'z)

tr[L1M111

-

+

L. (N.

(A.15)

(A.16)

E

E {.ii_iJ

The interesting thing about this arrangement is that we shall
be able to satisfy (A.iO) recursively as we proceed backwards.
At time N we have the cost H(yN) given in (A.13). We can

differentiate it with respect to Ml/Nl since this quantity will
appear only in H* (N)• Using (B. ) of appendix B, we have

H(y )

3H(y )

L1 +

- DIAG(LN1)

0

(A.17)

N—i/N—i

since the

are synetric (A. 17) is equivalent to
(A.18)
*

N

H (y )

-

trlk

-l

1M k-i/k-i

(A.19)

At time N-i the recs ion (A. 12) becomes

H(y1)

mm '{ E

[y +

- 1tr(Ll1NizNl) +
cl

UN_i

I_2MN_2/N_2

-

-1-2/N-2 + R)'J}

(A.2o

-A4-

We paxtition the

Only the first three terns in (A.20) in1ve
ntrices L. and N. as follows

L

L

L

LJ

LJ
J

1

1M.

J/J

3]

N.,.

(A.21)

J/J

(A.22)

I

M1).I?.
3/]
J/J

We nc expand (A. 20)

N-l-l/N2 +

-l/N-2

+

2yNl1(aN1/N_2bN_1/N_2+

UNl
+

1(r

+

b2Nl,I2

+

-l/N-2

1 (1y1 +

+

(A.23)

6

2L1y1_1 +

+

H(yN)

+

By differentiation we find

*

[_2M_2/N_2

(A.2L)

N_lFN_l7N_1

where

r + -l/N-2

+

-l-2/N-2 +

that the minimizing UN1 is

—l

-G

-

-l/N-2 -

1

(A.25)

p

-AS-

_l/N_2bN_1/N_2 +

-1/N-2 -

(A.26)

1

a2

C

We nc.i write H(yk) in

with respect to
H(yk)

a form that will help the differentiation

dictated by (A.lO)

[

E y/k_l] +

2M

2/N 2

-

+ R)_1] +

(ter not involving L2/N2)
+

+

tr [2M2/N2 - -l-2/N-2 + R)J

(te without -2/N-2 E-l/N-2N-l/N-2 + -2/N-2

• E(11/k-l) +

tr

-

-l-2-2

+

(tern without M2/N2)
With the help of (B. 5) and

o

RY'J

(A.27)

(B. 6) we have

_22/N2E(l_l/k_l)2/N2

+

ThN2/N2

DIAG {_2/N_2E 11 2/N2] _22 + DIAG(2)

+

R)

+

-A6-

N-2/N-2 -l +

2(1 +

DIAG

[1 +

Since

N-2/N-2 -l + M2/N_2R)'J

(A.28)

all the ritrices are synutric, (A. 28) is equivalent to

the foflciing

N-2/N-2 -l + K_2/N_2R) - 2/N_2E

+

[1c_i)
(A.29)

MN

2/N 2

*

The st H (yN—i ) becous
H*(yN_l)

2

H*(yN) + 2M2/N2 -l2-2 R) (A. 30)

where

-l/N-2 + -l/N-2 2

_i

-

(A.31)

G1F1

So H(yM_l) is a quadratic in N1 and the recursion can continue.
Notice that the nonlinear dependence of

on UN2

Uk

has

dissappeared

with the introduction of the multiplier matrices. it is easy ncxi to

ite the eress ions for u.

u -GFy

(A. 32)

-A7-

where

r + (1 + K+1)(b,_1 + /j—1
+

(1 +

(1 + K.

K.

)(a?

(I +

L
The initial

+

.

)

j/j—l

—

(A.33)

I

1 L —
—
j
a

RM,.)L.1(I

—

M,,51)

.

j/j—l

j+1

:

—

GF
jj

(A.35)

C

- M1.E(z.1z.÷1/k-1)M.1. (A.36)

+

nditions are
(A.37)

'h1I—1°
Along with (A. 4),

a

(A.3't)

(A. 5) and (A. 6) the above equations define

complicated two-çxint-boundary-value (TPBV) problem. In order to define

the problem completely we need a way to evaluate

We non

for alik —
E(z:z./k-1
<j —<N-i
JJ
provide such a recursion.

E(z.z.fk—1)

1

G1F
ii

2

E (y.Ik—l) E

—i
—22
-G .F. G. F.

3] 3

E(y/k-1) a +

3

2

P.E(y.Ik-l)

(A.38)

+

[P 1( l/j 2j

+

E(y1/k-l)

Since E(y/k-l) y (A,39) is a well defined recursion. The TPBV
problem is now complete.

(A.39)

APPENDIX B

SOFT USEFUL MiTRIX DERIVATIVES

In this appendix we develop certain matrix derivatives that are
useful in the proofs of appendix A. Many formulas for matrix derivatives
have been rexr'ted by Athans and Schweppe (1965), and Athans (1967).

Hcever, those derivatives were applicable only to matrices whose elerents
are independent. Here we derive sorre formulas for synTnetric matrices.
Define the operator DIAG which operates on a square matrix A

and creates the fo11iing matrix

0

a11

DIAG (A)

o

a22

(B.1)

0

Let X be a ni matrix and let f(X) denote a scalar valued function of
the

.
.
n2elements of X. Then the matrix
derivative
of f is defined by

af(X) =

f(X) 1
{

(B.2)

3X)

so the matrix derivative of f is a matrix. We n state the fofldng
thorerr.
Theorem. Let X,B be synuietric nxi matrices. Then the foUing equalities

are tie

-B2—

atrX =
a

trAX

I

(B.3)

= A

- DIAG(A)

A

+

(B.'4)

ax

a trA(X

ax

B)1

+

DIAG [cx +

atrA

ax

[x' +

B]

-1

BYA(X

+

DIAG [(I +
Before

B)1A(X

-(X +

B) - (X

+

+

B)A(X +

B)']

BX)A(I

BX)A(I

+

+

))_1

B)

+

(B.5)

+

(I + BX)'A (I + )_1

-

(B.6)

+

we proceed with the proofs we state for corrarison the corresponding

formulas for rr.trices whose elements are independent

3trX I

(B.7)

a tx =

(B.8)

ax

A'

atrA(X + BY1

3trA( X1

=

-X

+ B) 1

+

aA(X +

B)]

fci + BXY1A(I

+

)Y'7

(B.9)
(B.1Q)

'A

—B3—

Proof.

is trivial and we omit

(B.3)

(B.4):

trAX trA

its
0

trA

X

xij

(B.5):

+ B)

0

Q.E.D.

Ji

13

trA(X

1..
31

a..

a.. +

proof.

trA

Xij

(X +

B)

1

-trA(X +

BY

Xij

aXij

-trA'

(

+

X(X +

{j,i}

1.2.,. .,n.)

where

xx+ B)_1]
-tr'A'

-

E

<jkx1i

—

1l kl

a(X'

{cx + B)1A(X

+

+

BY

+ Cx +

BY-i A(X + B)_1]

Q.E.D.

-B'-

(8.6):

DtrA(X1

+

B)_1 = trA a (X1

+ B)'

ax..

ax..

1J

1J

-trA(X + B)1ax1(x + BYax..
1]

+ B)XXX(X + B)
ax..

1J

trA(I
the

+

XB)' X(I +
ax..
1J

prf of (B.5) carries over.

BXY1

and the analysis of

APPENDIX C

COUTATION OF ThE IWO-STEP ADPFI'IVE CONTROL

In this appendix we carry out the
section 7.3. The problem is
mm E

V (y )

2

+

We substitute (121) and

2

2

r'u + Hyk+l

(122)

calculations

+

called for in

1

F/k-i j

(C. 1)

into (118) keeping in mind

the

assi.n-ription

(12'4). We obtain

22a
____
2 /k-l + '' k/k-lkk'/k-1
2

H

1k+1

2

2

+

k]

+

2ir

G€

+ -21
L -lk +
-

+ Iv+1/k

(C.2)

We notice from (122) that
a function of
the

+

+

+1/k

does

not

depend on

and

is

kk-1 ) so we will not expand it further. To facilitate
(y ,u

notation we shall define the quantity

Xk_ /k-lkk/k-1 + 2)-1
Xk is a function of
V(yk) ncw becorrs

k k-i

(y ,u

).

(C.3)

-C2-

E'{ru + F

V(yk)

+(aqY +

+ 2c k
r

[(ak

-

/k-1k

+F

bk/k-i +

{

(1 +

2

'+1/kk/k-i

+

/k-i1

+

+

+

r
+

/k-i

+

+

/k-i

+

ak_1)(_1 +

-

+

r

+

r + b1

y
[a_i +

ja(ak

+

- /k_l_1 }

2ak,klykE [(ak

[E

r

£k]

fyE

-

(i + +l/k)a +

2

+

-

+1/kk/k-i
+

+

c/k-1k

Ik-i
L_1_1

r+

2abkykuk +

k k-i } }Iy,u

{ (1 +

r2

r

a

-

+

+

+1(

+

+

bu +c +

+

[a2k,klb,k1

(b/kl ÷

t/k-ik

+

/k-iJ +

+

-C3-

{ (1 +

+l,k)E(akbk/k_1)

X fy [ak1ak -

ak/k_i)

2aK/klXKYkE tk(ak -

r

2(r

where

=

+

(C. if) is

b1÷1

GE(akbk/k_1)

ak/k_i_1J

} +

- ak/k_i)_hics

a quadratic

+

in u,

k +

+

+

2ak/k1bk/kla

so its minimization

-D 1

k

(1 +

/k-1

+

(C.)

is

We find

(C.5)

(remembering that

r+

[,k_lE(abk1k_1) +

b+i

straightforward.

u

1k-i] +

>kE

Equation

*

r

+

[2E [ak(ak - ak/k_i)Ik_1Jae

2Ykt r +

(r +

r

+

was assd equal to bk,,kl)

+i,k)(bk_l +

[E

-

k-1

ak/k-i

2

r

+

ak/kl(bk/kl

r+

/k-iy

+

ccIk-1 +

/k-1J

(C.6)

_CL-

2
r + bk/k
1

X2k fyE kbk<

1)2,k_il

+

+

2,klykE [akbk( - ak/k 1)/k_1] }
ykE [bkak -

r

1)_i]a

+

ak

lbk_lXk (C.7)

k/k-i

The expectations appearing in

from

[1E/k-i) +

r

+

fk: k {(i +

the

and

k

joint gaussian density of ak

are straightforward to compute

and

bk given (k ,k_1.

REFERENCES

1.

Aoki, M. (1967), "Optimization of Stochastic Systerrs," Academic
Press, 1967.

2. strSni, K. J. (1970), Introduction to Stochastic Control
Academic Press, 1970.

Theory,

3. Athans, M. (1967), "The Matrix Minimum Principle," Infontion
and Control, Vol. II, Nos. 5 and 6, Novejrber-Decernber 1967.

4. Athans, M. and F. C. Schweppe (1965), "Gradient

Matrices
and Matrix Calculations ," IffT Lincoln Lab. Technical Note
1965-53, Lexington, Massachusetts.

5.

Bar-Shalom,

Y. and S ivan, R. (1969), "On the Optfral Control of

IE

Discrete-Time Linear Systesrs with Random Parameters ,'
Trans actions on Autorratic Control, Vol. AC- 1L, No. 1, February 1969.
6.

Chc.i, G. C. (1973),

Private Corrmunication.

of Sequential
Parameter Variation," Ph. D. Thesis, Department of Economics,
University of Pennsylvania, 1971.

7. Cooley, T. F. (1971), "Estirration in the Presence

8. Curry, R. E. (1969), "A N.i Algorithm for Suboptimal Stochastic
Control ," IEEE Transactions on Automatic Control, Vol. AC_1L,
No. 5, October 1969.
9.

10.

I

Curry, R. E. (1970), Estirration and Control with Quantized
Measurements, IffT Press 1970.
Early, R. H. and B. M. Early (1973), "On the Relative Perfonrance of
the Optirral Control System with N Measurements ,"
Transactions on Automatic Control, Vol. AC-l7, No. 1, August, 1973.

A. A. (1960a), "Dual Control Theory 1," Automation
and Resrote Control, Vol. 21, No. 11, September 1960.

U. Fel'dbaum,

12.

A. A. (1960b), "Dual Control Theory 2,"
and Rencte Control, Vol. 21, No. 11, November 1960.
Fel'dbaum,

Automation

—2—

13.

3," Autorrtiofl
Pel'dbaum, A. A. (1961a), "Dual Control Theory
1961.
and Rerrote Control, Vol. 22, No. 1, January

Automation

,"
Fel' dbaurn, A. A. (196Th), "Dual Control Theory
1961.
No.
2,
February
and Rerrcte Control, Vol. 22,
Academic
15. Fel'dbaUrfl, A. A. (1966), "Optimal Control Systens,"

itt.

Press, N.i York, 1966.
16. IEEE Transactions on Automatic Control, "Special Issue on

LneaQuaatiC_Gauan Problem,"

Vol. AC—l6, December 1971.

Control of Linear
17. Ku, R. and M. AthanS (1973), "On the Adaptive
0ptBraJ- Approach," IEEE
Systens Using the Open_L op—Feedba Vol.
AC-l8, No. 5, October
Transactions on Automatic Control,
1973.

18. McRae, E. C. (1972), "Linear Decision with Experimentation,"
1972.
Annals of Economic and Social Measurement, October
(1972), "Analytic Solutions to Some Stochastic
19.

Popevic, B.

20.

Prescott,

ProbleiTs for Economic
Adaptive, and Dual Optima]- ControlUniversity
of Illinois,
Decision Making," Ph. D. Thesis,

Decision Rules for Macro
E. C. (1967), "Adaptive
Economic Planning," Ph. D. Thesis, Graduate School of 1967.

Industrial Aninistrati0n, Carnegie-Mellon UniversitY,

of
J. W. Freebai-rn (1973), "Comparison
Control Solution to U. S. Beef Trade
Approximate Adaptive
second NBER Conference on Stochastic
Policy," Presented at the
1973.
Control and Economics, University of Q-iicago, June 7-9,

21. Rauss er,

G. C. and

22. jsenberg,

B. (1968), uVarying_Parameter

Thesis, Department of

23. Sarris, A. H. (1973),

Estimation," Ph. I).

Economics, Harvari University 1968.
Estimation of
"A Bayesian Approach to

Coefficients," Annals of Economic and

Time-Varying ReesS ion
Social Measurement, October 1973.

2LL Theil,

H. (1971), Principles

of Econometr. John Wiley, 1971.

I

—3—

25. Tse, E. and M. Athans (1972),_"Adaptive Stochastic Control for a
Class of Linear SysteriE ," IIk Transaction on Airtorratic Control,
Vol.

AC-17, No. 1, February 1972.

26.

Tse,

27.

Tse, E. and Y. Bar-Shalom (l973b), 'Wi Activity Adaptive Control
for Linear Systems with Random Parameters via the Dual Control
Approach," IEEE Transaction on Automatic Control, Vol. AC-18

E., Y. Bar—Shalom and L. Meier, III (1973a), "Wide Sense
Adaptive Dual Control for Nonlinear Stochastic Systerrs," IEEE
Transactions on Automatic Control, Vol. AC-l8, No. 2, April 1973.

No.

2, April 1973.

28. Wieslander, J. and B. Wittenrrrk (1971), "An Approach to Adaptive
Control Using Real Time Identification," Autorratica, Vol. 7,
May 1971.

29. Wouters, W. (1973), "Adaptive Minimum Variance Control for
Linear Discrete Time Systems," Proceedings of the 1972 IEEE
Conference on Decision and Control, December 13-15, 1972.
30. Yoshida, Y. and Nakarnura, K., (1973), "Learning Dual Control
with Complete State Infonmation," Research Reports of Automatic
Control Laboratory Faculty of Engineering, Nagoya Lhiversity,

Japan, Vol. 20, June 1973.

