NBER WOFCNG PAPER SERIES

INTERPRETING SPECTRAL ANALYSES

IN TERMS OF TIME-DOMAIN MODELS

Robert F. Engle

Working Paper No.

37

COUTER RESEARCH CTER FOR ECONOCS AND MANAGEMENT SCIDCE

National Bureau of Economic Research, Inc.
575 Technolo,i Square
Cambridge,

Massachusetts

02139

April l97

Preliminary:

NBER working

papers

not

for quotation

are distributed
and in limited
They should not be quoted without

n.znbers

for cornts only.

written

permission.

infonilly

This report has not undergone the review accorded official NBER

publications; in particular, it has not yet been submitted for
approval by the Board of Directors.

*N Coiiuter Research Center and Massachusetts Institute of
Techno1oj, Lparbnt of Economics. Research supported in
part by National Science Foundation Grant GJ-115'4X3 to the
National

Bureau of Economic Research, Inc.

Abstract

This paper derives relationships between frequency-diain and
standard tine-donain distributed-lag arid autore-'essive rnvingaverage nodels. These relations are well known in the literature
but are presented here in a pedogogic fonn in order to facilitate
interpretation of spectral arid cross-spectral analyses. In addition,
the paper employs the conventions and discusses the estimation procedures used in TROLL. Some aspects of these estimation procedures
are new and have not been discussed in the literature.

Contents

1. Introduction
2.

'I'he Spectn_un . .

1
.

2

. .

ThecrossSpectrtmi.
4. SpectrumEstliration

8

.3.

5.

.

Snoothing Windows and Confidence Intervals

6. Prewhitening and Fouier Transfonns
7.

Cases of Interest

.

11.1

16

. . . .

Ppperid.i_

20

References

23

Figia'es

Figure 1. Typical Spectrum
Figure 2. Spectrum of Pure Seasonal

.

5

7

1. Introduction
Although there axe rrny good reference works describing the details
of spectral analysis, these do not focus on the fundanentaJ. relationships between spectral methods and such standard techniques as distributed lags, autoregressive processes or "naivet' ircdels. Granger
(6)*

the

is perhaps the easiest to read, thile Jenkins and Watts (10) is

nost corrçirehensive. Fishman (7) focuses on soma economic esti-

problems and Dhrymes (3, ) extends this direction with sorrewhat ncre mathematics. }{annan (8) gives a very rigorous treatmant
mation

of the nole area. Relatively short and sirrle early expositions
of the theory and practice are in Jenkins (9) and Parzen (13) with
a good application to economics in Nerlove (12). The book which is
recorrurended as a coiranion to this system is Cobley, Lewis, and
Welch (1) which is ncre application oriented and which describes, in

7, the basic concepts used in
see Cooley, Lewis, and Welch (2).

Chapters 5 and

Also

The

designing this system.

pipose of the first section of this paper is to clarify

these relationships and thereby enable a user without substantial
)iow1edge of spectral theory to carefully and accately interpret
spectral analyses in tenns of concepts nich are familiar. When
viewed in this way, spectral analysis provides a way of sirrply comparing a at many types of nodels so that the data can suggest
which is nost appropriate.
The second section of the paper will discuss the estimation
procedure as iirplennted in the TROLL system from a conceptual

*pthesjzed nirerals- refer to entries in the Reference section,
p. 23.

2

point of view. As the system uses the method of periodo'ain
averaging which has become popular since the rediscovery of the fast
Fourier transform, there are several issues which are not adequately
covered in the literature. Furthermore, a general understanding of
the estimation procedure is i1orrtant for sensible interpretation

of the results.
2. The Spectrum
Many data series can be considered successive chance observations

over time called stochastic processes. Possibly, each observation
is independent of the preceeding ones. Hever, for rrcst applications, there is some suspected dependence between the observations.
Both spectral analysis (frequency domain) and the nre familiar tine
domain analysis are ways to characterize this dependence. High
correlations between neighboring observations or seasonal conponents
might be inportant forms of this dependence. Once we have charac-

terized the stochastic process we may be able to forecast its values,
inrove the efficiency of a regression where this is the disturbance, or infer some information about the economic ndel which
produced such a variable.
Both frequency domain and tiire domain analysis begin with
stochastic processes which are covariance stationary. This means
that the covariance between an observation now and one a few periods
later depends only on the time interval, not the dates themselves.
Mathematically this can be expressed as

(1) y(a)
where

—

-'

—

y is the autocovariance function and '1i

is

the mean. The

iziportant asstion is that neither depend upon t. While this
assumption may seem strong, it is only because of this condition
that information from the past can be used to describe the present
or fixture behavior.
Many economic time series appear to violate this assi.mption,
particularly those with pronounced trends. it is generally possible,

hever, to create an approdmately stationary series by taking first

3

differences,

or extracting a trend, thus leaving the series with a

constant maan of zero. There may also be trends in variance which

can often be rerved by first taking logs of the series.
In the tima domain the most corrrrn models are the autoregressive
iroving average models (APJvIA). These may be purely autoregressive,
purely moving average, or mixed.

A pth order autoregressive and a qth order rrcving average are
shown in equations (2) and (3), respectively while () is an ARNA
(p,q).
(2)

x a1

(2')

ACE)

(3)

s

+

a2 5t—2

+

+

a 5t—p

+

e

b1ei÷ b2et...2 +

... +

+

(3') x B(L)e
a1 5t—l +

(Li)

('') A(E)x
In

+ b1 ei+ ••• + bq et_q

+

B(L)e

these equations e

where

... + a

is

a series of independent random variables

is independent of 5t-i for all i greater than zero; L is

the lag operator and ACE) and B(L) are polynomials. These classi-

fications

are not unique since one type of process can, in general,

be transformed into one of the others. Nevertheless, they provide
useful, sirrle irodels of time

series

which can be tested with data

used for analysis.
The spectrum provides another way of characterizing time series.
In this case we think of a series as being made up of a at nun—

or

ber

of sLne and cosine waves of different frequencies which have just

the right (random) airplitude to make up the original series. Thus
the list of h much of each frequency corronent was necessary is
also a full description of the tine series. The spectrum is a plot
of the squared anlitude of each camonent against the frequency of
that coironent. It is continuous and always greater than zero as
long as we have no deterministic elements (that is no exactly repeating cononents, or cononents which can be predicted exactly on the
basis of the past).

Although this sees lJ'ze an unusual way to think of a stochastic process, it is very general since any covariance stationary process can
be uniquely described in this fashion.
The spectral density function is defined as the Fourier transfonn of the ai.rtocovariance function
(5)

y(0)

f(0)

+ 2 E y(s)
8=1

vCT, e0

cos (2es)

Z y(s)e_2OB

0<0<1

sin(0), and the last equality follows
from -y (8) = y (-a). There are several inportant features of this
definition. First, although we have used complex notation, the
spectrum is real valued since all the imaginary sine terms cancel
exactly. Second, since the cosine is sylruretric f(0) f(i-e), only

when i

the

=

cos(0) + i

frequencies from 0 to 1/2 are needed to describe the spectrum.

Third, if we
the area

integrate equation (5) from 0 to 1, we will find that

under

the spectrum

is

equal to y(0), the variance. We can

show that the spectrum is a decomposition of the.
components

contribrted by

variance into the

each frequency. Fourth, since

nasured in cycles per period, it appears

that we

f is

have no component

two periods, (the Nyquist frequency).
The reason for this becorrs clear upon reflection. Wnen we observe
rronthly data, weekly fluctuations will be undistinguishable fran
from

less than one cycle every

longer oscillations which have the same value at the rrcment the
observation is taken. The weekly component will therefore be counted
with these lower frequencies.

The iortant implication of the definition, which we will not
prove, is that each spectral point can be interpreted as the variance
of the component with that frequency so that the spectrum is always
positive. It is not difficult to give an intuitive proof that the
of the spectrum at each frequency is just the squared amplitude
of a sine wave of that frequency and therefore non-negative, but the
basic theorem, called the spectral representation theorem, is quite
difficult. From this result we have the standard interpretation of
the spectrnri, as a decomposition of the variance by frequency.
value

5

To clarify the interpretation of a spectrum arid help with the
notion of frequency components, let us interpret the spectri-mi in
Figure 1 .th±ch has been estinated fran quarterly data.

log

f(O)

0

FIGURE 1. TYPICAL SPECI'RUN

We only look at the first half of the spectrum and therefore the
highest frequency oscillation we can distinguish is 0.5 cycle per
complete a
period. At this frequency, it takes two quarters to
cycle so there are two cycles per year. There is a peak at 0.25
cycles which corresponds to a four-quarter, or annual cycle. This
is most likely a seasonal component. Similarly, the peak at 0.5
also probably indicates a seasonal cronent since it has an even
ninber of cycles per year. The peak at 0.1 oorsponds to a two
and a half year oscillation. This might be a business cycle and
therefore economically interesting if it is siiificarit1y above its
neighboring points. Generally, economic tine series show behavior
much like that of Figure 1.
In

this paper we wish to

emphasize the relationship between

these

concepts of frequency domain analysis and the rrDre conventional tine

domain analysis.

The first order serial correlation coefficient is

easily calculated in the time domain and is generally large and
positive for economic tine series. We can trenslate this finding
into the frequency domain as well. If we multiply the spectrlln by

6

cos (2TrO)

integrate, we obtain from equation (5) just y (1), the
first order serial covariance. Roughly, this anoinits to miltiplying
low frequencies by a positive ner, high frequencies by a negative
and

niber, and adding. If the result is positive, there is positive
first order serial correlation. Thus data series with generally
downward sloping spectra have positive first order serial correlation
while those with upward sloping spectra have negative serial correlation. Very important is the observation that spectra .thich are roughly
synmetric about 0.25 will show no first order serial correlation.
A useful application of this analysis is found in interpretation
of regression results. The assumption of no serial correlation in
the disturban is equivalent to the assinitption that its spectrum is
constant. The Durbin-Watson statistic gives us a test against the
possibility that there is first order serial correlation.

However,

we now recogiize this as a test against a general slope of the spectrum of the disturbance, whereas we would like to

test

against all

forms of variation. In particular, notice that if the seasonality
nre severe, the spectrum might easily have no first
order serial correlation but be far from constant. Durbin (5) formulated such a test based upon the spectrum of the residuals which is
easily computed within TROLL. In general, examination of the residual spectrum gives very useful information about the validity of
in Figure 1

were

the regression assumptions.
The link between tine domain and frequency domain is completed
by a derivation of the spectrum corresponding to the ARN irDdels of

equations (2)-(). The basic result is quite simple but
established in the

EE?dA

will be

appendix.

1: If x is a stochastic process generated by the ircdel
B(L)

is a series of independent identically distributed random
variables with variance 2, and the polynomial A(L) has all roots
outside the unit circle, then the spectrum of x is given by

where

(6) f(e) =
Notice

2IB(z)I2/k(z)2, z

that z is a complex function

of 0.

7

Several exailes

should help to illustrate the usefulness of

this result. First, notice that the spectrum of the very simple
(white noise) process which has no time dependence, is just a con-

starit. It has equal contributions from all frequencies.
Now consider the first order rrving average process with para=
meter
+ -1• From equation (6) the spectrum of x is
{l

+ pe_2hi0I22

for

+ p2 + 2p

cos(2e)} 2

in the range

a siroth spectrml
which begins at (1 + p) and ends
If p is positive,
this has the typical spectral shape which is conrcn to nest economic
time series, and which implies a positive serial correlation coefficient, p/(l+p2). The first order autoregressive case is very sirniEvaluating

lar but

this

e

(0 ), gives
2
at (1 - p) .

2

gives a somewhat steeper spec-trum at low frequencies.

A very simple autoregressive rrdel which captures the behavior
of purely seasonal stochastic processes for rrnthly data is
=

pxt_l2

+

Fran equation (6) the spectrum

of

this seasonal process is given by
-

which

2p cos(24O))

is plotted in Figure 2. There are peaks at all the harrnic

frequencies:

0

1/12, 2/12,

3/12,

4/12, 5/12, 6/12, and

equally important.

1

1-p2

1
l+p2

0
FIGURE 2.

.25
SPECTRUM OF PURE SEASONAL

all

are

8

3. The Cross Spectrin
The techniques used above can also be used to describe the relations
between two jointly covariarice-stationary time series. Both the mdividual behavior and the interrelations can be decomposed into basic
sinusoidal elements.
First, we define the cross covariance function which is a
direct analogue of the autocovariance function. For two series with
mean zero this is simply defined as:
(7)

=

y(s) E(t+
Again, notice that it does not depend on t. The cross spectrum is
similarly defined as:

(8) f(S) 8?_
is no longer symmetric the cross spectrum is not a real
valued function of 0 but rather a complex valued function.
Although the cross spectrum snimerizes all the information we
need, we cannot plot it directly. Instead, we corrrrnly look at what
are called "coherence squared", "gain" (or "transfer"), and "phase".
We will define these measures here and give a rather extended interpretation below, connecting these concepts with the ideas of disBecause

tributed lag re'ession models.
The coherence squared (COH) is like a correlation coefficient
and is defined as:
(9)

COH(e)

If(o)I2/f(e)f(e)

is clearly between 0 and 1.
The gain (G) indicates how much the spectrum of x has been ampli-

which

fied to approximate that component of y. It is therefore like a

reession coefficient.
(10) G Ce)
xy

This

Ifxy (0)1/fS (0)

expression can clearly never be negative. However, if it is

small, it indicates

that

at frequency e, x has little effect on y.

9

The

phase (PH) is a nasure of the timing between the series.

It is rrasured in the fractions of a cycle that y lags x.
—Im(f (0))
(11) P11(0)

arctan

where Im and Re

are the imaginary and

Re(f(0))
real

parts of the

cross

spec-

about the phase since adding or
from an angle will not change its tangent.

tru.n!c There is a natural airiguity

subtracting 1 whole cycle

the phase is known only up to adding or subtracting an integer
therefore even the lead-lag relation is not known for sure. The

Thus

and

plot of the phase is desi&ied to errhasize this fact. It is possible to corthine

the

phase and

the

gain

in

a simple expression

(12) f (0)/fx(0) = G (0)e_2G)
xy
xy

Two

its

other potentially useful rreasures of the cross spectnnn are

anplitude, which

is nrely its absolute value, and its tizre lag.

The latter describes the phase in terms of the niniiber of periods y

lags x rather than the fraction of a cycle. A1thoui this seems like
a useful rrasure, the natural ambiguity of the phase also makes the
time lag ambiguous and difficult to interpret. This may not be the
case at low frequencies, where these difficulties are less likely
to be important.
A natural and very general way for economists to think about the

relations between two tirr series is in terms of a bivariate distributed lag rrodel, such as
-p
E

(13)
3

This is often rewritten in terms of the lag operator L
-p
(114) t . w.L3x+u

=

as

w(L)x+ut

we have, for generality, allowed for leads as well as lags and
as a lead operator. Using the sarr techniques required
interpreted
for equations (5) and (6), we can establish frequency domain interpretations of equation (114).
The appropriate quadrant for PH is chosen on the basis of the sigis
of the real and imaginary conponents of the cross spectrzn.
where

10

2: If y

EEZA

w(L)

y

where x and
15

u

0)

(16)

f(0)

is generated by a distributed lag rrDdel
x+ u

are

i.n-icorrelated

w(z

covariance stationary processes, then

and

)

w(z)I2f(0)

+

where a = e(_27nj0)
We notice from (16) that the

variance of y

is broken into two

parts; one which is the variation due to x rrdified by the lag dis-

tribution and the other due to the disturbance. From (15) we see

xyIfSis an estirrtor of w(z) which

that f

lag

is just a function

of the

coefficients. In fact, it is the Fourier transform of the lag

distribution; and therefore, once w(z) is known, all the lag coefficients can be found by rrre1y taking the inverse Fourier transform.
This is the basis of a very useful type of distributed lag estimation which is often called Hannan's

inefficient rrthod. This is

available in TROLL.
Suppose that we now consider running a ression of one com-

of y against the sane frequency component of x. The regression
coefficient would be the ratio of the covariance x and y to the

ponent

variance of x. In our notation

f
this would be just f(0)If5(0). The

R-squared of this regression is one minus the unexplained variance
over the total variance. Substituting this into equation (9) we see

the coherence squared is just the R-squared of this regression.
between
Similarly, fran equation (12) we see a very intimate relation
this regression and the gain and phase estimators. Let us explore
that

this further.

If the rrcdel is
w0 is
delay
(17)

(1) really a static rrDdel, which means

non-zero, or (2) a very sinle
model), in .friich only

w(z) =

one

w.

that only

dynamic model (often called a

is non-zero,

then

+2ii0j

*It is inefficient because it does not use the properties of the disturbance to construct an esttor with the smallest possible variance.

U
and therefore the gain should be nstant and equal to w. For nre
complicated iidels we would not expect the gain to be constant. At
low frequencies, z is close to unity and therefore the gain should
be close to the long run multiplier. At other frequencies the gain
is the effective multiplier which a sine wave of that frequency
would experience.

In the figures at the end of this paper, the gain for several
conunon simple distributed lag rrodels are computed and plotted. I\o
basic patterns appear. When the gain is a deca ining function of
frequency, the lag distribution tends to emphasize low frequencies

and eliminate, or srroth out, higher frequencies. This is the
typical pattern for moving average type of lag distributions. The
other pattern emphasizes high frequencies and it arises from lag
distributions which depend on the rate of change of the right hand
variable such as first differences or accelerator models. Of course
many more complicated models are possible, yielding a eat variety
of patterns.
The phase estinator incorporates all the infonration about
leads and lags. If the model is a static model, there should be no
phase shift. If there is a simple delay, the phase is just a
straight line with slope equal to the nnber of periods of the delay.
For more complicated models, the slope of the phase near zero frequency

can be sho-i to be equal to the average or mean lag of the lag distribution (as long as the gain is non-zero). For several examples
of this see the figures at the end of the chapter. Notice the dashed
lines which indicate the airiguity between leads and lags. This is
in exactly the same form as the computer printout.
The series of gain and phase plots (called Bode plots) presented
at the end of this paper will never be exactly the sane as any estinated
from data. Nevertheless, there ny be one close enough that it is

possible to infer a form of tine donain lag distribution. If not,
-two facilities are available. First, the definitions of gain and
phase imply that if the lag distribution is a product of two lag
distributions, the composite gain will be the product of the individual gains and the mposite phase will be the stmi of the two phases.

12

Second, you can construct any other diagram for comparison by nans
of a TROLL program.

Thus by trial and er'or it may be possible to

understand what type of lag distribution would have a spectrum simi-

lar to that estimated. Similarly, it is possible. to kn what gains
and phase are iirlied by a particular lag distribution.
L.

Spectrinn

Estiition

There are several distinct rrthods for estimating spectra and crossspectra. The advantages and disadvantages of each have been extensively discussed. In particular, see Cooley, Lewis, and Welch (1)
and Parzen (l'4). Since the rediscovery of the fast Fourier transform,
computational considerations suggest that periodogram averaging may

be the irost efficient ntbod for spectrurt estimation. In addition,
it is conceptually simplest and leads to great versatility in the
esttion procedures. Finally, the usefulness of the periodogram
in regression and various test procedures makes. it sensible to cornpute this as a first step. See also Jones (11) and Tick (15).
The periodogram is defined as the square of the absolute value
of the Fourier transform of the series at each frequency, all divided
by m, the number of observations. The formula for the periodogram

is
(18) I (8.)
where O.j/m and

m-l

ES

.
2tO.

2

j0 ,l ,2, ..., m.

This quantity is an estjrator of

the spectrun, but it is not a very good one. The expected value of
the periodograrn is
rn-i

(19)

(m-IvI)
E(IS(0.)) = E
m
v=-rn+l

I(v)e2rtOj

For large values of m this esttor is an biased estimator of the
spectrum, since y (v) is small for large v. Unfortunately, however,

it is not a consistent estintor since the variance does not decrease
as the sample approaches infinity. In fact, the spectral estizrtor
at each freqi.ncy is approximately proportional to a chi squared
random variable with two degrees of freedom, regardless of the nither

13

of observations. An intuitive explanation for this unusual circuinstance is that as the sairple becomes larger, rrcre and nore frequency
points are estsr.ted rather than obtaining better estimates of a
fixed nriber of parameters. This explanation also suggests the solution. Since neighboring points are independent (if the original
series was normal), the average of a few should give a better estimate of the spec-trin in that neighborhood (assinid.ng that it is not
changing too rapidly). Thus we must use sothing procedures to
obtain consistent spectrun estimators.
5. Sothing Windows and Confidence Intervals

Two averaging or srrcothing procedures, called "windows", are cently
available in this system. A rectangular rroving average gives the
mimirn variance for srioothing over a flat spectri.zn using only a
certain ninrüer of points. However, when there are peaks in the
spectrn, the rectangular window will lead to considerable bias and
broadening of the peaks. An alternative window is a triangular
window which gives the spectrin a much snoother appearance and is

probably better at describing the shape of peaks.
Clearly, the width of the window is an inportant parameter in
the estimation. The wider the window, the smeller is the variance
of the resulting estimate; yet, the wider the window, the rrore serious may be the bias of srroothing over non-srrooth portions of the
spectrun. Two measures of width are used to describe the windows in
the TROLL spectral package, the bandwidth and the range. The bandwidth is the half-power width of the window. It is measured in

frequency units, i.e., it is a fractional niniber of cycles per period.
If, for example, the bandwidth is specified as 0.1, there will be
five separate "bands" since the frequencies range fran 0 to 0.5.
For many purposes, spectral estimates separated by nore than one
bandwidth are considered to be independent.

The second measure is the range. This is merely the nrber of
spectral points used in each iroving average; it therefore gives the
separation between which two points are known to be con1ete1y

lL

independent. If the effective sample is 200 observations (ilying
100 points in the spectr'Lnn) arid the range is 20, there will be five
separate window widths in the estimation. A sensible value for the
range is ,', where m is the nither of observations.
Near the endpoints of the spectricn, the srroothing procedures
must be nodified. The choice followed here is to decrease the range
so that the window does not overlap the endpoints. Because the variance increases as the window becomes narrower, the variance increases
markedly at very low or very high frequencies and one must be very
cautious in interpreting low frequency peaks or troughs. The user
who wishes to construct his own window or to modify the endpoint

procedure can easily do so within the structure of the system.
The resulting spectral estimator is approximately proportional
to another chi squared random variable, this tirre with more degrees
of freedom. The equivalent degrees of freedom are just equal to;
(20) E.D.F.
where

B

Brn

is the bandwidth. This allows us to compute a confidence

interval for the spectrum. On the spectral plot a 95% confidence
interval is given for each frequency separately.
Estimates of the cross spectnn are accomplished in exactly
the same manner. The finite Fourier transform of one series is multiplied times the complex conjugate of the Fourier transform of the
other to form the cross periodogram. The real and complex parts of
this are then smoothed individually, just as for the periodogram.
The sampling distributions for the various measures derived from the
cross spectrmi also depend only on the equivalent degrees of freedom

of the estimate. With the coherence plot, the critical point for a
5% test of the hypothesis of zero coherence is given. Approximate
50% confidence intervals for the gain are plotted with the output.
These depend on the sample coherence; where the coherence is small,

the confidence interval is large.
6. Prewhitening and Fourier Thans forms

When using a wide window, peaks tend to be spread out. For many
series we }ciow a priori where these peaks will be, either because

15

the series is typical in having strong li frequencies or because it
has important seasonality. In these cases "prewhitening" is often
recaITUTnded. This ajrunts to dividing the raw periodogram by the
expected or typical shape, rothing this "prewhitened" periodogram
which no longer has the large peaks, and then "recoloringt' by multiplying by the typical spectral shape. A seasonal and non-seasonal

version of the prewhitening filter are available, but the user can
easily construct his own. Prewhitening can be done in connection
with either spectrum or cross spectrum estimation.
A second characteristic which is likely to make the srrothing
procedure badly biased in cross spectral estiirtion is misaliguTnt
of the series. When one series lags another by several .periods,
there is a peak in the cross covariance function which is not at

zero. This leads to a regular oscillation in the amplitude of the
cross periodogram. Srroothing this will obscure this particular
bit of information as well as distorting other results. The
recoirrnended procedure is to first divide the cross periodogram by
an aligning series, siTooth the cross periodogram, and then renuiltiply

it by the aligning series. The program to construct the alimant
series first computes the inverse Fourier transfor'rn of the cross
periodogram iich is exactly the cross covariance function. This
could have been computed from the data directly, but such a method
is apparently inferior to the computation of Fourier and inverse
Fourier transforms. Searching the cross covariarice function for the

maximum yields the infortion needed to construct the aliment
series. If this procedure were applied to the estimate of the
spectrum or a cross spectrum which was already aligned, the maxinuirn

covariance would be the zeroth estimate and thus the alient series
would be unity and would have no effect.
The Fourier trnsforrn algorithm used in these computations is

the Cooley-Tukey fast Fourier trensforrn. In its basic font it expects
a series with 2 elerrents and thus each series is padded out to this
length with zeros. The nrber of spectral points estimated is therefore 2n-1 which are evenly spaced between the frequencies 0 arid

16

unit of the data. If the user wishes to
the spectnnii at particular points or wishes not to pad

1/2 cycle per basic time

construct

with zeros, he is provided an option of choosing another integer, r,
so that the series is padded to N=28r. Choosing r=3, for example,
would insure factors of 12 which u1d be required in order to have
exact seasonal points with rronthly data. If unspecified by the user,
r receives the default value of 1.'

7. Cases of Interest

1. S1e Static Model

PH

1

w(L)

—

——a——=

w(z15 w0
G(e)=w0
PH(8)=O
G

wo

6

*A11

—1

—

———a

output arid statistics are corrected so that they depend on m,

not N.

17

PH

2. Sinpie L1ay
w(O)

w,

w(z1)

=

G(O)

w.

1

L
a

a

FH()

—je

G

Wi
2

—1

3. One Period
w(L)

Lag

w0+w1L

PH

1

w0,w1>O

w(z1)
G(O)

PH(O) =

V'w+w+2w1w0cos2irO
w1sin27re

//

'

wo+wicos2lTO)

G

0
Wo+w1

Iwo—wi

0

I

—1

18

if. GeoiTtriC Lag
w(L)

--

_____ - wo (1+wiL4i,12L2+...)
l-wiL

1

PH

O<w <1

w(z1) -

W0

1

2iiie

%

1-w1e

p,

G(8) = w0+w—2w1cos2rr8
P11(O)

arctw1s2O

I1cos2TO )

G

W

8

1-w1

slope

Wa

1+w1

—l

5. First Differences
w(L) = w0-w1E

w(z1)

PH

w0,w1>O

= Wo—Wie 2TriO

1

G(O) = IW+W-2WoWiCOS27rB
PH(O)

wo—wicos27rO)

G

wo+w'

-½
Iwo—wi I

I
—l

- _.__1... —

19

6. Four Period Differences
PH

w(L) = W0(1_Lk)
w(11)
G(O)

PH(8)

1

Wo(1_e8e)
w0 /2—2cos(871e)

—sr18ITe
1—cos8TrO

)

G

0

-¼

2w0

-½

e

—1

20

APPENDIX
EElvffvlA

A.1: If x is a stochastic process generated by the rrodel
4(L)

BCE)

is a series of independent identically distributed random
variables with variance a2, and ACE) has all roots outside the unit
circle, then the spectrum of x is given by
where

f(O) a2IB(z)12/IA(z)12
where z = e (—2 in )
Proof: Consider the moving average process

xt =Eq b.e t—a
where

the e are all independent. Then

E qE b e+8

y(s) = Ex+xt

q

E bk et_k
ko

where the expectation on the right only has non-zero values where
k = s-j and 0 < k < q. Therefore for q > S > 0
y(a) =a2

8

b.b 8—3

E

j=0 a

for 0 otherwise. The spectrum of x is defined using equation
(5) and the synetry of y by

f(e)

=

z

q

y(s)z8 =

Z

(s) (26+2_a) + (0)

q
8-8)+a2 Eq b.
=a2E
Z b.b .(z+z
B—a

=:i. j=0
which can be written

f(O) =

q
a2

Z

j0

j=0

q

q

b.z3 E bkz—k —alE b
k0
j=0 j2

There is nothing in this proof which requires that q be finite. Therefore, since every stable ARMA process has a (possibly infinite diiien-

sional) irving average representation, the result is true for any
ARMA process.

21

LEZ?2fA A. 2: If y is generated by a distributed lag ndel
y
where

w(L)

x+

uncorTelated covariance stationary processes, then

and u are

f(e)

=

w(z1) f(O)

and

f(e)
where

z

+ f(O)

jw(z)12

(27rie)

Proof:

Without loss of generality take both x and y to have mean zero

t+s t
=

'xy(s)
f(8)

Ew.atxt+s + Ext+8
wi(s+i)

=

y(s)z8

=

f(o) =

(8)

w(')f(e).

And

y(s)

EYt+BYt
= E(Ew

Y(8) =

E

.

+ ut+B)(Ewkxtk

EWI.WkYX(8_j+k)

+

+

Ut)

22

f(s) = Ey

By

(a)z8

z z + Ey(8 )B
2

s—j+k—kj

EZEw.w y(s_i+k)z
Ez

f(8)

kz_kf

Ew

(8)

= Iw(z)12 f(e) +

B

+

f(O)

f(O).

23

REFERENCES

(1) Cooley, J.W., P.A.W. Lewis arid P.D. Welch. The Fast Fourier
Transform Algorithm and its Applications. IBM Research Paper
RC—1743, 1967.
(2)

__________ "The Application of the Fast Fourier Transform

to the Estimation of Spectra and
Journal of Sound Vibrations, 1970.
Algorithm

(3)

Cross

Spectra",

Dhryrrs, P.J. Econometrics: Statistical Foundations and
Applications. New York: Harper and Rag, 1970.

(4) __________Distributed Lag8; Problems of Estimation and Formula-

tion. San

(5)

Francisco: Holderi Day, 1971.

Durbin, J. "Tests for Serial Correlation in Regression Analysis
Based on the Periodograin of Least Squares Residuals", Biometrica,
56, (1969), pp. 1—14.

(6) &'ariger, C.W.J. in association with N. Hatanaka. Spectral Analysis
of Economic Time Serie8. Princeton: Princeton University Press,
1964.

(7)

Fishman, G.S. Spectral Methods in Econometrics. Cambridge:
Harvard University Press, 1969.

(8) Harinan, E.J. Multiple

Time Series. New

York: J. Wiley, 1970.

(9) Jenkins, G.M. "neral Considerations in the Analysis of Spectra",
Technometrics, 3, 2, (1961), pp. 133-166.
(10) Jenkins, G.M. and D.G. Watts. Spectral Analysis and Its Applications. San Frricisco: Holden Day, 1969.
(11) Jones, R.H., "A Reappraisal of the Periodograin in Spectral
Analysis", Technometrics, 7, (1965), pp. 531—542.
(12)

Nerlove, M., "Spectral Analysis of Seasonal

Adjustnent Procedures",
Econometrica, 32, (July 1964), pp. 241-286.

(13) Parzen, E., "Mathematical Considerations in the Estimation of
Spectra", Technometrics, 3, 2, (1961), pp. 167—190.
(14)

__________ "Multiple Tirr Series Modeling" in Multivari ate
Analysis. New York: Academic Press, 1969.

(15) Tick, L.H., Letter to
pp. 559—561.

the

Editor, Technometrics,

8,

(1966),

