NB. WOPJN PAP SERIES

IDTIFIcATION TFEORY FOR TD-VARYING MODELS

Thomas F. Coo 1ey

Kent D. Wafl

Working Paper No. 127

COMPUTER RESEARCH CENTER FOR ECONOacs AND AGT SCIENCE

National Bureau of Econcnic Research, Inc.
575 Tecbriolo' Square
Cambridge, Massachusetts 02139

March 1975

Fe1ininary:
NBER working papers are

Not

for quotation

distributed

infonrally and in limited.
not be quoted without

numbers for cormients only. They should
written permission.

This report has not undergone the review accorded official NBER
publications; in particar, it has not yet been submit-ted for'
approval by the Board of Directors.

Computer Research Center' and Tufts University. Research
supoorted in part by National Science Foundation Grant GJll5LX3
to the National Bureau of Economic Research, Inc.

*NBER

;:NBER Computer Research Center. Research supported in part by
National Science Foundation Grant SJ-l15X3 to the National
Bureau

of

Economic Research, Inc.

Abstract

The identification of te-varying coefficient regression models is
investigated using an analysis of the classical information matrix.
The variable coefficients are characterized by autoregressive stochastic
processes,

allowing

the entire model

to be case in state space form.

Thus the unimown stochastic specification parameters and priors can

be interpreted in terms of the coefficient matrices and initial state
vector. Concentration of the lixelihood function on these quantities
allows the identification of each to be considered separately. Suitable

restriction of the form of the state space model, coupled with the
concept of controllabili-j, lead to sufficient conditions for the identification of the coefficient transition parameters. Partial identification
of the variance-covariance matrix for the random disturbances on the

coefficients is established in a lixe rrnner. Introducing the additional
concept of observabili-ty then provides for necessary and sufficient
conditions for identification of the un)mown priors. The results so
obtained are
econometric

completely analogous to those already establishad in the

literature, namely, that the coefficients of the

reduced

are always identified subj ect to the absence of multicollineari-ty.
Some consistency results are also presented which derive from the above
form

approach.

1. INROJICN
Identification

is an issue which

statistical rrodels.

Simply

arises

stated,

in connection with

the issue

is

w:riether one can

from observed samples the existence of a uricue underlying

structure. Econometricians

have

all parametric
infer

theoretical

long c-onoer'ned thamsieves with establish—

ing the conditions for the identifiability of structures whose parameters
are assujnecl to he constant over time. In this paPer we address the
seemingly more complex issue of the identifialili-tyof structures

when

the regression coefficients themselves are varying stochastically over

tine. This is a relevant problem
attention

in recent years increasing

has been focused on the problem of estimating time

structures.'

varying

Although estimation methods have been suggested by several

authors, little attention has

or to

because

identification
these estimatoxs. Many of the issues

been

the asmptotic theory for

paid to the problem

of

we address in this paper have been investigated by others (Tse £ Anton
[1972] and Mebra [1974] for example) bt the context and the results,
as we shall elaborate, are quite different.
The identification problem for the traditional linear econcretric

model with

uncorrelated errors was first

Reiersol [1950] and

This

recognized

by Kooprrans and

solutions were provided by Xoopmans

et

al. [1950].

theory was later extended and elaborated upon by Fisher [l96]

in his comprehensive book
Harinan

[1969,

on the subject. o imoortant papers by

1971] generalize the earlier theory to encompass ir'dels

with moving average

error processes. ost of

this prior theory

concentrates on conditions which guarantee unique solutions to -the set

—2—

of equations which characterize the structural form parameters in terms
of the reduced form parameters as manifest by Hannan's

solution.

Rothenberg [1971] takes a different approach in characterizing the

identifiability criteria in terms of the infonration matrix of classical
mathematical statistics. Rothenberg's approach has been nicely extended

to a more general representation by Bowden [1973]. It is this latter
approach which is most appropriate to problems we are considering because

of its relative independence from concepts related to sta-tionar9

stochastic process theory.
The problem we are addressing can best be illustrated by consider-

ing the

state space representation of a model with

stochastically varying

coefficients. We characterize the problem in terms of a regression relation
(or observation equation) and a "state" equation which describes the
evolution of the coefficients over time:

+

(1.1)

(1.2)

The

ti =

variables

matrix

e

+

y arid X represent the obser'vables of the system

which governs the transitions of the K component

is a (KxK)

coefficient

and

e and

are independently and identically distributed random variables
w th mean zero and covariance matrices 2 and Q respectively. It is

clear that

the identification is quite complex in this context

because

we must establish the conditions for the existence of a inique stochastic
characterizaticn of the process governing the coefficients. Identification of the coefficients

depends on the identification of the transition

—3—

matrix ,

the covariancematrix Q arid the initial conditions of the

coefficient process

The literature on varying parameter estima-

tion has focused on the problem of

estinating the initial

conditions,

but there has been no discussion of the conditions under which the other

parameters will be identified
In the following section we formulate the general estimation problem

for

time varying

solution. The

coefficients arid

initial

present

the recursive (Kalman filtering)

condition problem is discussed and

function, concentrated with respect

the 1i2:elfl-iood

to the initial conditions, is presented

to facilitate the derivation of the identification conditions. In
Section 3 the Information Natrix is derived and analyzed to give simple
sufficient conditions for the identification of

and

Q.

It

is shown

nich can be identified.
Section
briefly states the conditions for the identifiability of
using the results of Section 3. As.totic properties of the estimators

that

are

there are restrictions on the forns of

also

some

discussed. The final

section

and Q

sujiciarizes the results arid draws

conclusions.

2. Thi ESTB4ATICN TI-CRY FOR TL. ARYL G STRUOYJFES

In

the introduction

we

represented the rcblem

of time varying structures

teis of a single equation regression relationship arid an equation
which characterizes the evolution of the coefficients as a first order
in

Narkov process. As a point of departure for this section let us consider
how we might generalize this representation. Ideally, we would like to

_14_

be

able to consider general sinailtanecus equation regression relation-

ships. In practice, however, we must restrict ourselves to the consideration of reduced form relationships because the estimation theory for timevarying structural forms of simultaneous equation systems has not yet

been

developed.

In many instances one might expect to observe variation that is
systematic

include

(2.1)

but non-stochastic, or variation that is purel

these possibilities we can

ti

+

modify our

random. To

state equation to the form

+w

which admits variation of all three types. If w is equal to zero then

the

variation is

time

purely systematic. Thus, if the parameters

follow

a

trend, a sinusoidal pattern, or are correlated with exogenous var!-

ables it can be represented in this fashion. Similan models have been

considered by Beisley [1973]. If
while
model

is a unit vector, w is nonzero

0, then the formulation is equivalent to the random coefficients

considered by Swamy [1970] and others

where

the

parameters are

regarded as random drawings from a multivariate distribution with mean

vector D in the above representation. Although this is not properly a
state space formulation it can still be handled within this framework.
Thus, the evolution of the state of the system represented by equation

(2.1) is a general one ich encompasses many possibilities.2
paper

this

In this

we concentrate on stochastic coefficient variation because it is

which presents the most difficult problems of identification.3

-.5—

wish to ectend the basic state sace model to permit the
coefficient3 to be characterized by more general stochastic processes.
We

Let

each

of the

obey an autoregressive

process of order

}cl,2).. .K.

Thus

(2.2)

klk,t-l + k2k,t-2

is

0 and

where
independent

+ k,t-l

a normally distributed zero mean sequentially

random process with

=

E{nnJ

The model can

then

be represented compactly as

(2.3) YX+e1
(2.L)

t Hz.

(2.5a)

z =

where

is the state vector of the model

z
V!i-ch

zi

+

1_ (
[(zr)

...

2

(zt)

I

describing

K—
(Zr.

z.k representing the r state viae (tne

H is a Kxn (n

.

.

rik) matrix of

2

the evolution of

the

A=H

form

.

substate \lector

for

—5—

and h is a row vector of zeros except for a one in the 1 +
column.

The iratrix

+ •+n:kl

is now assumed to be of the form

ll12B
k1

kk

where

[

The assumed form of

2k
is a natural one given the autoregressive repre-

sentation of the process governing each coefficient. In the fo1lowin
discussion we assume that the off-diagonal blocks are
(c.. = 0

1J

;

since this.

is

a

null

ratrices

restriction which must be irnoseâ to.

derive a sufficient condition for identification. In Section 3.3 we

present a counter example

showing that a model without this restriction

is underidentified.

To further simplify derivation of the identifiability conditions
we replace the stochastic term of the state equation, Ant by an eçuivalent

term ru where

E[u] =
and

is Kxl vector of stochastic elements such that

E[rlt]0

,

E[utu]

I

—7—

E[n]EQ
r is an nxlK matrix

E[(HArIt)(HArlY]

of

the same

nonzero rows contain the

[(Hru)(HFu)'].

stn.icture as A with the exception that the

corresponding rows of the unique lower triangular

factorization of Q. Henceforth, (2.Sa) will

z z1

(2.5)

be replaced

by

÷ ru1.

Models like the one described by ecuations (2.3) -

(2.5) have

been

extonsively explored in the engineering literature following the york
of YiTh'an

[19605] arid a1nsn arid Bucy [l5i]. The first recognition of

the applicability of state space

representations and Kalman filtering

to the problem of estinating eonnetric relationships
with time varying structure was by Rosererg [1968]. Other approaches to
solutions

estimating models similar
by

to

the one described above have been suggested

Cocley arid Prescott [1973, 1976] and Sarris [1973]. Here, however,

we shall briefly review only the optiral recursive

because

estimation

method

it is the most convenient for establishing the. identifiability

criteria.

The

based on

estimation proSier is to obtain estimates of the states,
the observations [yl

yJ. If we let

There

of z based on observations [y1
covariasice

matrix of

the

as

tt and define the error

I

the solution is easily obtained wnen

The form

be an estimate

estimated staes as

(2.6)
then

z,

of

the solution

is known

as the

z0, , 2 and V are known.

Kalman filter arid

is

rerresented

—8—

Ztl/tl

(2.7)

(2.8)

+ rr

t-1it-1

(2.9)
(2.10)

i-1

(2.11)

Kt Pti-1

-it_

(2.12)

(2.13)

=

where

÷

Mt'
+

(I_Kt) i-i

X H

Although

the

KaJ.man Filter

has appeared many other

literature a brief interpretation may

be

'

places in the

useful. Equation (2.7) represents

the one step ahead prediction of the states based on obseniations thrcugh

period t when t =

t-1.

The quantity

matrix of the innovations. In this light
of

the

is

ca.lled the "innovations"

prediction error for the
is called the gain of the Kalman Filter and Mt is

series, is obviously the one period

quantity

which

it is

easy to see

The

covariance

the

that

the gain

filter is simply the optiiial prediction correction factor.

It

is obvious that z, p0,

applications.

The

log

a2 and r

will

not

be 3iown in most

licelihood of the system represented by (2.7) -

however,

is (see Mebra [1972]);

(2.1k)

£(z,P,®) -1/2 1[logIMI +

(2.13),

—9—

where B (2 r, ). Thus.,

estimation proceeds by selecting initial

values of z, F, 0 and using the equations of the KaLrn Filter to
define

the likelihood function.

This process proceeds iteratively and

known in the engineering literature as 'fturiing the filter'1.. The

is

engineering literature, however, has not

problems of

in general been sensitive to

estina-ein the initial state vector z0. Most of the literature

assumes that

has a proper prior distribution which eliminates the

problem. That this is seldom the case, however, is

in

not a serious Droblem

dealing with real time systems with many observations (as in most

engineering apiicatiors)

because it is easily sho-i that

under

the

condi-cions the discrete lKaJman Filter is asymptoticajly
stable and the effects of the initial conditions are
ultimately forgotten
(see Jazwinski [1970, pp. 20-23]). In econometrics, however, the
aDpropriate

situation
systems,

are

is somewhat different in

our observation

often

intervals

that we do not deal with real tine

relatively short, arid we
primarily interested in how the structure of the system evolves
are often

over tine. For all of these reasons it is particularly iuortant to be
sensitive to the stattisig problems. The first correct solution to the
starting problem was propcsed by Rosenberg [2958] arid later generalized
by

him [1973b].

The solution involves concentration of the likelihood

function with respect to the initial state vector z0. This permits
naximum likelihood estimation of z conditional on ci2,
recursive

(2.16)

equations for z0 are

o/o

(2.16) tit_i

arid r.

—10—

t/t

t/t-l -

Ht

ti_' M1

(2.1'/)
(2.18)

)

'

(2 • 19) h

("
t_ 't
t/t_1

T
•

T
At

where

and

are

as

it-p

M -1
t

lit

h
defined in equations (2.7) -

(2.13).

The matrix

then is simply a function of the transition matrix which extrapolates

'

the initial parameter vector into the. future.
Equations (2.15)

(2.20) show that the likelihood function of

the system can be concentrated with respect to the initial state vector
arid thus,

the identifiability of z0 simply requires the invertability
Ht) ich in tuni depends on the identification of and r

T

of

arid the
at

properties of the X. Consequently we can

approach

the problem

hand by first looking at the conditions for the identification of

and

F.

is worth noting that the initial condition approach outlined

It

above

does

not provide estimates of the initial covariance matrix P0.

The consequences

of this have recently been discussed in a paper by

In econometric applications one should be most
interested in obtaining "smoothed" estimates of the states (zt/T),

Garbade [1975a].

that

is, estimates which

use all of the information in the sample.

A smoothing algoritIun which avoids all

has been derived in Cooley and

Wall

of

the initial condition roblenis

[1976].

-ii3. IDEfIIFTOATION OONJ::0':s FOP !1D F

The

identifiability of the unkiown stochastic specification parameters

can be determined through an investiga-nion. of the classical Information

matrix. This approach has wo advantages: First, it permits the
identification

problem to be studied wihin the general framework of

statistical Lrlfonration theo -

a poinn well emçnasized by Bowden

[1973].

Also, it provides a useful connection heteen cermain concepts in control
systems

theory and mather-aical statistics.

3.1 The Information Natrix
The

classical Information Matrix

(see Rothenberg [1971] or owden

of

P. A.

Fisher is defined as

[1971]):

C

where, i

is the Nxl vector of u kTlown caraneters

ith true value

0;

an n p is the natural logarithm of the density function foP the jointly
< T. Thus, the first step is
observed outputs over the interval 1
to derive the density function for the ointlv observed outputs.
Combining the state anä odtput euacicns (2.3) — (2.5) permits
the formation of an expression for y ( 1,2,... ,T) exclici-tly in

terms of the vector of unJo;

(.1)

parameters.

t 1

XW + e

-12-

where,

[ ! •••
0

(z_1Y1

2

0

wt

—

•..

I

I

0

:

0

-

I•.1

:

I

LJ..

I:

OtQ.t(zyI
I

I

J

0

0

U2 ". 0

0

0

(zt.1)j...i

:
—

]

I

A

0

—
:

u.
t-

0

I

is thus a KxN ntrix with its first n columns

exhibiting a block

diagonal

stricture, the (k,k)th block having dension lXnk arid containing the sub—
state vector associated with the kth
columns form a matrix in the

elements

last row consisting of u1.
compactly in terms of (3.1):
(3.2)

z

The

+

where,

I

0

xl
0

0

I

•••

X2 i...

regression coefficient. The last K(K+1)/2

I

0

10

--—I---H---

of

u1, with the last K columns of the

joint observation can now be written

—wJ-

w

w

WT.

[e1,e2,. .

e

The

iden-ioally dierihuted normal random
variables so the probability density fictiori for conditional on XT
and

are independently and

is;

PT;

e

=

()i/2(2)T/2

Taking natural logarithms and then partially differentiating with respect
to it gives

—

9n p(Ym;X.. it))
(,3•4)

—.

Finally,

the

I(i) to

yield

(3.5)

-m_y

ij

above eression may be substituted into the definition for

I(p) —E{(- w)( c)}

The replacement of YT.Wit) by ET follc'.:s

at =i°.

_—.j_

The

from the

evaluation

of

Infonmatioh matrix is seen to depen on the exDectation of
a product of random matrices.

-l'4-

In order to facilitate tne
we resort

(3.6)

evaluation

of the

expectation operation,

to consideration of the (1,)tn element of l(i):

{I()}..

ejwjj]L
nT

— E1

r
E {

a tl

1

T

irT

TK

ij[51 e

er

E{e}

(xw.1 )

m esmwri1)

E( xtw.)

1

1

TX

(1j

)1

(xw.)
3

E{x w.)(wx )}
—t

1T

__5_

o

Here —t
x

t=i

denotes the t w
—of >—Iand w.1 with .th colu of

. It is

now

possible to cons'uct the Inonration Mtri, element-by-elenent once the

expectation of the outer product ww is computed.
Appendix A contains the details of the element-by-element construction

of I(i),

along

(3.7)

I(p) =---

with some additional steps required to put l()
useful form for analysis. The end result is:
a

t=l t

t

into

a rrre

—15—

t is a nonsisigular elementary rasfonition of the data rtrices:

t

0

z1z2

V

0

xI
I
VR x)ck
01

L0 DKJ
The nxn ma S1 is the genera1ize varance-covariace caix fcr the
state-space process z1, i.e. S1 E{z1zJ (See Bryson Ho [1959]
pp. 320—325). Thc }((K+i)/2 x K(K+1)/2 cetrix D, has a block diagorl

stn.cture
AK

K—i

-16-

where each, O K, K-i,..., 1) is a kXk rnatrx with unity in
every location. In view of (3.7), it is clear that the identificaticn
of the ui)o-ion-is in

the

and I depends upon the rank (or, equivalently,

positive definiteness) of both

3.2

S1 and Dk.

Identification Conditions

Two points

are immediately

since

of. full rank

each

Thus all the unJown
but K linear

has only

elements

combinations

evident from

(3.7).

one linearly

in F can

never

First, DK is never

independent column.

be identified simultarec:siy,

of these elements are

identified.

Second,

the identifiability of the parameters depends on whether or not S,
is positive definite. If conditions can
then the unJmown

elements

of

be

found which establish this,

will be identified.

The question of identification of can

the

readily

be resolved with

aid of the concept of controllability ;5

Definition

1. The state-space model

(2.5) is said to be
controllable (UCC) with respect to
the disturbances, ut_i, if arid only if there exists an
integer N1 > 0 arid constants c, C2 > 0 such that6
uriiforiifty

0 <

ccmpletely

cI

for all t >
is

(3.8)

C(t,t-N1) cI <
N1, where the controllability

C(t,-t-N1)

t1 t1—T-,
ill (Ot1T

Definition 1 and the restricted structure of
prove

C(t,t-N1)

defined by

the rr5 result of this paper:

are

all that

is needed to

Theorem 1. If the time-varying coefficients of (2.3) have
their transition relationships realized by (2.5) with

(2.5) is UCO then: (1) the n-o-o-i sochastic specification parameters in are globally enthiled; and (ii) only X
linear combinations of the ur.or.s in F are identified.

arid if

Proof: The identifiability resul- ico F bas already been
established from our observations conceco-ing the D, matrix, so
we shall concentrate on the proof of (i . Yrrn

the

state equations for

z, the generalized varience-covariance nanrioes are seen to obey the equation
St
which

(3.9)

+ 11

St_i

has a unique solution given by.

S
L

t—l

) + t—l
E t- --T

F( -T)•.

t—l

S1(

TO

The second term on the righthand side ci (3. ) is nothing more then the

controllability matrix C(t,O) defined in (3.8) with N1t. rrom the UCC
of (2.5) there will always exist a t=7 such that C(t,O) > 0 for all

tt1.

Thus for all tt1 (3.9) will be posifive definite and the identification
of is established.
3.3

Remarks

The identifiability of

relies abnos exclusively on the special

underlying the state-space noiel, ith the principle condition
being the block diagonal form. This resus in an with its upper leftstructure

hand block identically equal to S1. ne

controllability condition

then imposed to giarantee that S1 > fr

is

t>t1+l. Controllability
alone is not a sufficient condition :Tcr iienification of - it mist be
all

—18-

structure in . Actelly,

accomanied by anpropriate
which yields

this

structure

in

*

has

any ( j) air

linear in p, and is

UOC will

give exactly the same conclusions as Theoreri.l.
The controllability

requirement ny apocar

imoossible

a priori since it is stated in teis of the

owns.

to verify

practice,
however, this is no real lijnitation since the block diagonaltiy off
perrilts (2.5) to be viewed as a grouping of K independent subsystems
In

(sec. Luenberger [1967]. Each "subsystem" will he UCC if arid only if
0 and at least one nonzero element apocars in the corresponding
row

of r. If each subsystem is
UOC. The

will be

is

less than or

second

requirement is met

equal to the "tnie

if

the specified order, ri1,,

autoregressive

to concieve of

order, while the

a realistic situation where such conditions

the case where all K coefficients obey

processes

each lagged

the

first order autoregressive

becomes an element of the

and our results regarding the

His

the overall state-space model

be a.b:irt.
In

ith

then

is met if there is any trace of randomness in each coefficient.

It is difficult

will

first

UOC,

state vector (i.e.,HI),

lack of complete identification of r agree

results of 'ebra [±9i] co-'.ce: ang -

_:entfablrty

r Q

other results are not generally comparable to ours cecause ne consrders

only models with stationary regression relationships, i.e. X constant
for all t.

The results in the control theory literature (see Tse and \e±nert [1975])

suggest that more general forms for

can be identified (specifically, block

triangular 'I). The following counter examrle, hcwever, demonstrates that

this specification for will not be identified in the tire-varying coefficients
problem.

—19—

Consider the special case where

Kz2,

r1ri2

1 (which more

closely

reserr1es the control thec case), ar let some interccn1irg between

coefficients be pers'itted through 21

L21 22
This lower (block) trianguier
constructing

is not inentified. as can be seen by

the associated 1 () following the steo contained

Appendix:

E

a t=l t

t t

Ixiti

-

I

lxii

=t_

ii

TiZ2t
I

L
H11 11
S11

t

1s12

I

i2

ll

l2

S12

S22

0

110

I-

110

0

L

I

in the

—20--

Clearly the upper-left 3X3 block of 2÷ is singular so that all ..
elements are not identified. Whereas the control theory srate model
has

one substate—vector associated with each element of :÷ the time-

varying coefficient model has one subsrate—vector associated with each
element. 7

4.

In

CONTROLLABILITY, OBSERVAEILITY ATD CONSISTCY8

Section 2 it was shown that

the likelihood function

can

be concentrated

with respect to

the initial vector. This allowed us o consider the

identification of

and F separately. We now t1rn to the establishment

of the identification conditions for . Conditions which establish the
identification of any ft can easily be derived with the aid of certain
qualitative concepts from control theory as in the previous section.
In addition to controllability, the concept of Uniform Complete Observability

(UCO) is helpful. It is introduced by a second definition:9

Dfinition 2. The model (2.3) - (2.5) is said to be uniforray

completely observabie (UCO) witn respec to the ou Lrt,
and only if there exists an integer N2>O and constanrs c3,c>O
such that

(4.1)

0 <

c31 . O(t,t—N2)

for

all
defined

(4.2)

where

the observahility

by

O(t,t—N,)
L

c41 <

t
Tt—N2

matrix O(t,t-N2) is

(T—t'
) T—t

—21--

Taken together, controllability arid obseiability imrly the identification
of each point on the trai, ectcry for . The nin result is given by the
following theorem

Theorem 2. If the system defined by (2.3) - (2.5) is both
UCO and UOC, then
is completely identified.

Proof: Each
the

zT can be exresse

terms

of zL via

solution of

underlying state equations, i.e.,
T—t

Z

T-l -T-l—S

+

St

Substitution of this exression into that for the observed outputs yields,

YT XZ + 2.T1 Tl_ST. +

Az,
TI: +'•
T

The jointly observed

process, iith

a an unJrncn parameter

no be represented as in regression theri: (let mx

YAz+V
where

't1

'-t—N'
A

V

[A

tN

I

L_j

..

A]

z

to be unique are that

—

1t-:r+1'

The standand conditions for

AA

-

(o1ty

both

vector, can

-22--

ad the veriarice-covariance matrix
11 12

E{Vv}

H 21

R6.. +

22

m..
X.

12T

ra..

mm {i,j}

ó..

Kronecker delta

13

3.3

m. .—-1

ri ( m.ij .--1.)

be nonsingular. The first of these is just UCO, while the
irrmediately from UCC. Finally, since
is unique whenever z÷

is

I.

Hzt and H is full rank,

L

identified.

2 can inmediately be specialized to

Theorem

second follows

the problem

of

estimating

priors. In such a situation, the observation interval ns from
the point of interest, tzO, forward to I. Thus, by setting N- e
find that is identified if and only if
unc-io-i

(.3)

0 <

TT+l

i

()TT_l

<

The above condition is equivalent to requiring that the matrix
2j

(TlyyJ

be of (full) rank K. The full rank interDpetatjOn of (4.L)
interpreted as a generalized muiticollinearity condition.

can be

Observability and controflabi]i-y are also quite useful in e<arnining
the consistency of tine-varying coefficient esttes. Both
C(t,--N) and O(,t-.N)
can be used to establish bounds on the estimation erTol'

—23—

rtrix and thus to study the behavior of the err as T - . The essence
othase steps is contained in the following theorem.
Theorem 3. Let the tine-varying coefficient model (2.3) (2.5) be both UCO and UCO. If t . N max {N1,N2} then the

best ]J-iear unbiased

estima:e

Proof: First, consider

variance-covariance

is never consistent.

the behavior

matrix P. Together UCO and UCC

existence, uniqueness, and stability of
tends toward -°° Furthermore, for any
tnat P > 0.
the

filtered

of the filter estimation error

(See JaZWLnSki [1970],

as t0,

the

guarantee

the

initial tim.e

prior P > 0, UCO guarantees

Lerrma 7.3,

estimate's error variance-covariance

.

238-239).

matrix can

Thus

never

decay

to zero no matter how much ata, up through tLrne t, has been emplc-ied.
Next consider

the behavior of the smoother estimaticn error ;ariance-

covariance matrix, F4, ,, which uses all data in the sanijle. Fraser arid
Potter

[1989] have shown that

[(f)l +

t/T

is the filtered ermor variance-covanjance of a

tu filter begri at t

1 ama rmnning :orard to

i, while
is the one-stan prediction error variance-ccvariam:e of a "back?ard"
filter begun at t T and runnim ackward uivtil
Fixing t
and letting T -*

reveals that cnly

dependent on T. Now, from
no matter how

the

fr "back" it

clear that Pt/t+j

> 0

P?/1 will change since only it

is

oositive definite roperty of

was started (i.e. how large T is), it is

and hence ? >

always be inconsistent

=

C.

The smoothed estimate will

—24—

Specializing

the theorem to the estination of n}oc.•r prior:,

it is clear that inconsistency persists. For diffuse prior:,
P

- [ + (pb
"
—

O/T

0/i

)_ll - pOil
—

which reveals the lack of consistency under stocbastic excitation for

the s's.

5. SULARY AND COi'CLUSlC S

The growing literature on the estimation of models with time Vao-.1ing

regression coefficients has largely ignored the issue of the identif iability of such models and consequently has left in doubt the generality
with which they cart be specified. This paper has used the classical

information matrix of statistics to establish sufficient conditions for
identifiability. The main result of the paper shows that the peramet-r
transition matrix

will be completely identified if it is in block

diagonal form. This special form of the transition matrix pe±mdts
generality

in the
aIrng

in the specification of the process gcverTling eaoh coefficient

regression relation but riles out the estimation of intercouplings

coefficients.

This is an important restriction in that n-any

theoretical considerations which

lead

one to expect stochastic vErieion

in coefficients also suggest that the nvements in the coefficients will

be related. The restriction, however, doe not preclude a priori specification

of )iown off diagonal transition parameters, arid it may often be the

case that theory will suggest a priori values for parameters.

The

—25-

identifiability conditions also show that only 1< linear coiriatinns
of the elements of the variance-covariance matrix of the coefficients

can be identified. Diagonal Q matrices will therefore always be identified

The results of Section 3 are equally aeplicable to the muitivariae
output mod--I where y is an Lxi vector. The observation error variance

is replaced by an LxL matrix R, which, as before, is always identified.
In addition, the unciown priors

are

same conditions as given in Section

identified subjeci to exactly the
(these conditions being oboalned

independent of the dimension of y÷). The only conolication is in the
evelopment

in

or the expression for

I ().

R

rep±aces trie scalar a/a2

the earlier stages of the algehrac naniou±atcns and

cannot be so

easily tractcred out" of the ensuing cerivaton -

With the ai 0: the

Kronecker product, however, an expression similar

to

obtained

which yields exactly the

(5.1)

I()

Since

same conclusions

(3.9) can

be

as before:

[ØR]
L

the Kronecker pn>duct of to positive definite

matrices

is itself

positive definite, the conditions for identification once again derive
from an analysis

of

defined in (3.9).

The

matrices above have

exactly the same form given in the apoandix with the exception -hat t:e

scalars x are replaced by LXl column vectors.

—26—

mioo priors ae always identified sabj act to the generalized
multicollii-iearity condition tnduced in Section . If is iccn
a priori then the identification of the i(Xl prior
and hence any point
The

on the

trajectory, can be established by exaaining the rank of the

associated Observabili-ty Natrix of (.3). Note that with knor, this
check can always be carTied out before estimation is attempted. The

consistency of the prior estimate cannot, however, be established. The

analysis of the dynadic properties of the estiirtion error variancecovarance matrlx reveals that random excitation of the coefficients
always prevents the limiting distribution for
dispersion. Given
that

the

from attaining a zero

comDiete observabili-ty (identification) the most

can be achieved is an asymptotically finite error distribution for

estimates of the randomly

excited coefficients.

AP?ENDIZ
DF.EOTATIOI EVALUATION ANP

FOFJATION OF

i n\TcRwTIo:
The

Inforniation Matrix construction resented in Seotien

to the evaluation of {w.(w.) '} where w.
(see

colurru-is, respectively, of

and

w denote

3.1

ne i

th

i,j < N,

n7n stochastic specification para-

meters for the B. process, this airnts to the evaluation of
expectations forned from various vector outer products straightforward

and

ecuation (3•3))•12 Since 1 <

where N is the total nuier of u

tions are

reduces

matrix

These evalua—

if care is taken to avoid the potential for

confusion. Tras can be achieved

by

decomtosing the evaluations to

three pants, depending on the relati.'e value of the subscripts i arid j.

To this end let denote the set ci integers containing the colurrri
nunibers of the states in W.associacei 7ith the k coefficient in
other words, Ck contains the coluirr ncbers in which the

states

are located. For exarle,
C1

1, 2, ..., n1

C2

n1-1-l, ...,

nKi+i, ..., nl+n2+..
First,
w.

J

consider the case in which i,j < n,

i.e., in which w. arid

are both taken from the first n colujru-is of U . Tr:s let

j c Cm

t

,

then

.1 c C arid

£

E

[1 1

H
[O...EJ

Zj,_1

O...iJ

I

Hi
KxX rrtrix

position
The

of zeros with the ()th

-

replaced b' {z1,_i z }

eectaticn E{z±ti z,_1}

is noth

element of the generalized variance

than the

covariance function St

E(zt z associated with the COT. lete state representatic:. for
the coefficient transitions defined by (2.5). If this elemenT is
then14

denoted by

E{w.(w.)'}
3-

i

el&ent

KxKtrjx of zeroes with the (9)th

replaced by s.

Second, consider the

with any of

1]

case

in which i

while j

is ass:ciated

the last K(K+l)/2 coluTns of U. Then it is easy to see

that

Ew.(wi'}
:L KxK null rracrix,

(A.2)

z1 and u1 are independent. The sare result holds with the
roles of I and j exchanged.
Finally, consider the case in fnich both i and 5 are taan fr:nt
since

the last 1K(K+l)/2 colurmis in W. In general the matrix expectations
become,

Ew1(w)?} Z

UDt
LU

Obviously

[O...u0_1...o]

J

if q q the end result is a KxK null matrix. If

q then

the expectation operation results in a Kx}( matrix of zeros with one ele-

mart reolaced by unity. The exact location of unity depends, of course,
on the resmactve row -csitions Of u

,t—l

terization

arid

u

.

q,c-l

A concise chax'ac-

analogous to (A.l) does not seem possible. This dffficulty,

however, is of little consequence to the final expression for I(i) as
will beco:r.e apparent below when resort is made to the use of elementary
row and colutn-i transformations.

The above results concerning the evaluation of

no be co;abined with the Oe1nit1ori of the
mit

an elemant-by-elernen- construction

1. If i>j

belong

to the first n

of

(i

the expectatic:s

can

j).th elamen-t o () to per—

I().

More specificeflu;

columns of W, then

T

1] jt.
tl x. s.;<.

—V
o2

2. If i or j belongs
the

(A.3)

it

to the first

n colutris of

while

other is associated with the last K(K+L)/2 colutne

of W, then

i.

.3.

.()

If i and

0.

j ar-s. both

columns of U, then

(A.L)
associated with the

last

KG(+1)/2

x Efu
T

1

—0 Ll
2.

uQ

XX ;

x1

(A.5)

pq

q.
The

element-by-element construction can

finally

be corrined

give

the complete InfonTiation Matrix:

I()

=

-

E

t

(A.6)

Et

where,
z1

1

V1
V
o

2

--S

o

0
V

0

kt

:kxk

•1
st...1
Tk

Although Zk an Vk contain the sane elements cn the diagonal, they have
different dimensions. Thus Z1 is an n1xn1 ma-trix whereas V1 is merely

a scalar (lxi matrix).

The K(Y+l)/2

x K(K+1)/2 matrix

is difficult

to write down in general; it con-tains only zero-es arid oneTs following

the pattern set out below.

11010010 001
11010010 001.....
00101001000

11010010001
00101001000
00000100100
110 100 10 0 01

00101001000
00000100 100
00000000010
11010010001

The InSormat ion matrix of (A. S) can be written in a more conrenierit

form for analysis of identification by resorting to elanentarr row and.

column transformations. In Darticular there will always exist nonsingular
matrices P and Q,

composed

respectively, such that

of eiemantary excherges of rows an colum-is

0

————I-----0

whre
I.

K

K

j
a kxk matrix with 1' s everyhre. :rl addition, the srcture

with

• of

reve:i1s that for evory rc.-: exchange recuired to bring T,, to

there is a corresponding co1urn-

exchange.

Thus QP', and the final

expression for the inforrration ratrix becones

t
Since

P

derend

(A.7)
0

is nonsingular the rank of I(4i), and hence its definiteness,
on

the rarJ and definiteness of

[1] Aoki, N. [1967], pt5mizatior!

Academic Press.

of S:cbasoin

Systems, New Yor::

[2] Beisley, David [1973], "On the Date
Variation in the Linear Regrassic-

Social

Measurement, Vol.

ation of Systematic Far—meter
Ycia1', Aunais of Ecorcnfo and
3, October, 1973.

[3J Bowden, R. [1973], "The Theory of rarecric :deritification'. Fconometrioa,
Vol. 1l, No. 6, pp. 1069—1o7.

[]

Bryson, A. E., and Y. C. Ho [1969]. Auclied Cc]nal Control, Naitham,

Mass.:

Girci—Blaisdell.

[5] Cooley, T. F. and . Prescott [197, Varyirr Preceter P,ecression",
A Theory and Some Appiications'. Annals ci gccnorric and Social

MeasurEiTnsnt, Vol. 3, October.

[6]

__________ and _________ L::EJ, 'istirnation in the Presence
of Stochastic Parameter Variation' Zconornet-'ica,
Vol. , Un. 1,
—
January.

K. B. Wall [l97. On the Identification of Tine
[7] __________
Varying Stroctures', NBR, \Ocrkin: Pacer Mc. 85, Mar'.

[8] ___________ and _________ [l97E]. "A Mote On Optimal Smoothing

In Varying Coefficient Reges cn'. ME'E,, March.

[9] Deyst, J. J. [1973], Correction to 'Unn Onions for Asyrrtotic StaLi1it
of the Discrete i
-Var--cs_Tatcr', IEEE Tbn. Auto.
Control, Vol. AC—IS, no. 5, OctcUnr, ct. 5"A563.

[10]

and C. P. Price [l96. 'Ccodicicns for Asyi'np'rr':ic StabiUnty
rdC.

O. L11 JLS.ELC
Cortrol, Vol. AC—13, no. 6, Decander, ZD. 7:2—705.

T'-—,

[lii Fisher, F. N. [1966], The Identidicenion Problem in Econonics.
McGraw—Hill.

rIe York:

5. H. Potter [19], The Ontimun Linear imocther as
a Corrination of o Optinm Ninear FiUners', IEEE Trans. Auto Control.

[121 Fraser, B. C. and

[13]

Garbade, K. [1975a1, "The Initiali:.eoion Probem In Variable Parameter
Regression", Working Paper, Nan; Unrk University, August.

[14]

[1975b], "To Methods f:r Pxandr:ncr the Stabi1i of

Regression Coeffacaents", Research
ranc'i No. 186, Eccnometrccs
Research Program, Princeton Unioe:-isry, October.

[15] Hanrian, H. J.

[1969],

"The Identification of Vector Mixed AucoregressOne-

Moving Average Systems", Bicretrina, 57, po. 223-225.

[16] Uaruian, E. J. [1971], "The Identificatic Problem for :'N1tiie Ectic
Systems 71th
751—765.

[17]

Noving A1erage ors",

Econometrica,

Jazwinski, A. H. [1970], Stochastic Focesses and
New YorK: Acaderc ri7eSS.

9, Seri r, p.

Filterir:

Theorz,

[18] KJjmem, R. E. [1969a], 'Cn the Ceneral Theory of Control SY5emS!?,
Proceedings First int'l Congress IFAC, Nbscow, U.S.S.R.
[19]

___________ [1960b], "A New Anproach to Linear Filcerincr and Prediction
Problems", 'fransactions of ASME, Series D, Jourr'ial of Basic gineering,
82, pp. 35—5.

[20] ___________ and R. S. Buoy [1961], Ne Resul-s in Linear Filtering and
Preiiction Thoory',. Transactions of ASi-, Series D, Journal of 3asic

giruering, 83, po. 95—108.

[21] ___________ [1963], 'New Nethods in Wiener Filtering Theory", Prc>o.
Symp. F:nc,. Appl. Ran±xn Function Theory and Prohab lity (Bc'gdanoff
arid Kozja-i, eds.) Ne York: .7iiey.

C. and C. Reiersol [1950], "The Identification
Characteristics", Annals of Ilatherratical Statistics, Vol.

[22] Kooprnans, T.

[23]

_______, H. Rubin ant R..

ystams

of £jnainic

f

STructural
165-181.

21, p.

Leipnik [1950], "Measuring te Equation
Economics", Statistical Inference in Eqmarfc Eo-xnrriic
B.

Models, Cowles Corrmission Ncnograrh, No. 10

[2] Luenberger, D.
G. [1967], 'Canornical Forms for Linear Multivariable
Systems", IEEE Trans. Auto. Contcol, vol. AC—12, no. 3, June, to. 29)293.

[25] Mebra,

R. K.

[1970], "On

the Identification of Variances ani Adaptive

KJmn Filtering', lEE Trans.scticns on Automatic Control, Aoril,
pp. 175_18L.

[26] ____________ [1971], "On Lins Identification of Linear nar±c Susteirs
with Applications to Kairan Filtering", IEEE ansactions on Automatic
Conol, AC-16, No. 1, February.
[27] ________
[1972], 'Arroaches to Adaptive Fi1terin', I Transactions
on Automatic Controi, October'. p. 693-98.
[28] ___________ [197LJ, "Identification in Control arid Econometrics: Similarities and Differences", Annals of Economic arid Social Measurement, Vol. 3,
pp. 21_L.7.

[29] Pagan, A. R. [197L], "A Note on the Ectrac-tion of Comnonents from Time
Series", Econome-trica, L3, pp. 163-168.

[30] Rosenberg, B. N. [1968], "Varying-Parameter Estimaticn, Unpublished Ph.D.
dissertation, Deparirent of Economics, }-Larvard Uni'.'ersity.

[31] ____________ [1973a1, "A Survey of 3-ochasric Paramecer Regresion",
Annals of
Econoraic and So: iaJ

[32] ____________ [1973b],

il__renenr, 7o1 3, October.

Analysis of a Cross Section of Tin.e Series
and Social easuroraen-, Vol. 3, lotoher.
"The

by Sooc-as-tccel1y Oonvergc-'- nete -e'essior" n-a1s c

[33] Rosenbrock, I-i. H.

[1970], StatSoe.ca and Nlnivaria1.e Theory, New York:

Jobn Wiley 6 Sons.

[3] Rothenberg, T. J. [1971], ?Identificaton in ?arame-raic Models",
Econome-ioa,

39., pp.

577.

Arrvoao to E:tion of Tine-VarvinC
Regrcssicn
Coefficients',
Anain
cf Econco-:lo and Social Neanorct,
r-

[35] Sais, A. [1973], "A Bayesian
JCLO

[36]

Swamy,

,

cm
p. Ju—.
—'

P. A. V. B. [1970]. "Fffiofin-c :nferenoe in a

Regression

Model", Econometrica.

E. and J. Anton [1972],
IEEE Thans. Auto. Control,

[37] Tse,

_______

and.

39, p:. 31—323.

'Cr. .ce idenoifi-obility

Random

Coefficient

of Pararetero",

Vol. -l7, No. , October.
H. Weinert [1973],
ntire :etcmin.tion anf ?arareter

Identification for Nultivaniabje Snoohastic Linaayy Systens?!, i
Thans. Auto. Control, vol. AC-2.. no. 6. 2eoember, on

FOOTflCTi'S

1. See, for

exaniple, Garbade [1975a, 1975b], Cooley [197], Pager. [197],
Rosenberg [1973a, 1973b], Cooley and Prescott [19761.

2. For an excellent survey

of

generic relaticus among

models with rot-

constant coefficients see Rosenberg [137 3a1.

3.

earlier version of this paper (Cooley and Wall [1375]) anely:oad
the differences bet :eeri t ie seque:::ial nonsoochas tic variatito pr'obinT

An

arid the stochastic variation proh1am.
i.

The ccrdrtucus are that the systr is u

cceolete:j olervable

and uniformly cort1ete1y controllable.

5. The derivation of ccrro1 lability cotta ned in the folliwin; definition
is beyond the scope of this panor. The reader nay consult any
tects such as Zadeb and besoer [1963; pp. 506-509] for
of it
an excefle::: de'lcbmcnt. It shc:dui be noted that there are. rrmmy
definitions cf controllability, each with its. own subtle twist (sac

Rosenbrock
6.

7.

8.

[1970; EThpt. 5

0 6]).

21
Let x be any arbitr p>l vector and A an pXp matrix. Than ci <
<
where
I
is
the
op
identify
matrix.
is taken to mean xxr < xAx 6xx
There is a basic difference bet:een the identification problem posed in
this paper and that considered the control engineering literature. There
ornationi available in the latter case because cash diagonal
is more
block in the crisiticn matrix (i.e. each state subgroup, z) is
a d±fferonr. coreme oto ( it )
a soc± to

wish to ac}cowledge an anorvres referee whose heluful
corn-ants have greatly facilitated the presentation of Theorem 2.
The authors

9. Obsarvability was another qualitative SVa L-err rromertv firsr defined he
Kalman [l96[)ai in a purely deteitidnistic framework. Stochastic versions
of this concept were also aitrociuceG by Ka2nan [1963], Ache [1967], arid
Jazwinski [l370]. The sole difference between the stocheemi: and determin-

istic versions is the insertion of R—1, the variarica-covariance of e-,
bet :aen X- and X. This distinction is, however, immaterial so long as
R is assumed positive definite.
10. This fundamental result was first obtained by }(abran [1903] for the r
coos_oared

:eysa
case The e_screte—tarc case as fxst
cedagogical
oresencaarid Price [1968] arid Deyst [1973], with subsequent
tion given by Jazwirski [19701. The interested readar cs referred to
any of these for a proof.
contlnuoes time

ii. iJte-ati'e1y,
the exoressio: couli have bee:. itter. usir
end

with equal validity. In a ccninuc us-time frame mr-.

lcilosyncracy disappeers, I . e. both fil-er variance-covarian:ss -e
em?loyed.

12. The. time dependence of each colupm of

is supresed in cYder to
avoid the use of dobie subscrjD-ts :hich are reserved for eements
os matrices.

13. Fm the definj-tjor of the overall state vecor, z-, giveri in Section 2,
it is cleaT -that 4
if p is such that z,t_1 appca in the
Ith colunri of W-. fikewise,

Zj,
z,-:-l z ,-t-: if q is such tt z,t_i

aprears in the jth colua-u-i of W:.

14. The supersorapt t is used hare to aoid triue subscripts while still
retaining explicit indication of the time de:endence of

