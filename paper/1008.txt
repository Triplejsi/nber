NBER WORKING PAPER SERIES

THE DIFFUSION OF INNOVATIONS:
A METHODOLOGICAL REAPPRAISAL

Manuel Trajtenberg
Shiomo Yitzhakj

Working Paper No. 1008

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge MA 02138

October 1982

The research reported here is part of the NBER's research program
in Productivity. Any opinions expressed are those of the authors
and not those of the National Bureau of Economic Research.

NBER Working Paper #1008
October 1982

THE DIFFUSION OF INNOVATIONS: A METHODOLOGICAL REAPPRAISAL

Abstract

Studies
tions ——
We

argue

of diffusion have traditionally relied on specific

prinRrily

the logistic —-

to

distribu-

characterize and estimate those processes.

here that such approach gives rise to serious problems of comparability

and interpretation, and may result

in large biases in

the estimates of the para—

meters of interest. We propose instead the Ginits expected mean difference
as a
measure of diffusion speed, discuss its advantages over the traditional
approach, and tackle with it the problems of truncated

processes, inter—group

comparisons, and related issues. We also elaborate on the use of the hazard
rate, and suggest some possible extensions. The diffusion of CT scanners is
presented as an illustration.

Manuel Trajtenberg
National Bureau of Economic
1050 Massachusetts Avenue
Cambridge, MA 02138
Tel: (617) 868—3980

Research

Shlomo Yitzhaki
Falk Institute of Economic Research
Hebrew University, Mt. Scopus
Jerusalem 91905

1. Introduction

One of the main difficulties hindering the

study of technological

change is the lack of good empirical counterparts to —— and hence of measures
of —— many
of the concepts that figure prominently in the theoretical analysis
(e.g. "knowledge", "quality", "appropriabjlity", etc.). The area of diffusion

of innovations has been relatively fortunate

in that respect, at least since the

publication of Griliches' pathbreaking work on hybrid corn [101. Indeed, much
of the appeal of that paper stemmed from its having brought diffusion into the
realm of the en-ipiricaliy measurable, i.e. from its having shown a way

to

quan-

tify the phenomenon, and capture its essentials with the aid of just a few
parameters (that could in turn be related to optimizing behavior). Yet, and notwithstanding the prolonged success of the paradigmatic approacti established by
110], some basic methodological issues (primarily those associated with the
reliance on specific distributions, most commonly

the

logistic) have not been

satisfactorily resolved, and hence a reexamination is called forth.

That is,

for the most part, the task to be undertaken here, i.e. the dominant concerns in

this paper are, once again, the definition of the concepts to be measured in
diffusion, how to measure them, and how to illuminate and expand the analysis of
the phenomenon with the aid of such measures. The focus is on "aggregate"
diffusion, i.e., the pattern followed by the cumulative percentage of adapters
over time, rather than on the underlying behavioral ——
the piocess (in Section 8,

or

"micro" ——

aspects of

though, the relationship between the two levels of

analysis is briefly discussed). Within that context we concentrate on diffusion
speed, which is the parameter that has commanded the nist attention in the
literature.

—2—

Following a critical review of current methodolo

in Section 2, we

pursue in Section 3 the prime objective of the paper, namely to put forward the
Gini's expected mean difference ("Gini" hereafter) as a convenient measure of

diffusion speed, elaborate on its meaning and implications, and outline its conceptual and methodological advantages over traditional measures.

Section

deals with an intricate problem often encountered in diffusion studies:
measurement of

diffusion

the

speed of truncateU processes. We develop a procedure

on the Gini that allows us to accurately measure the diffusion speed of
just the observed segment of the process, and to compare processes that have
based

been

truncated at different levels, andlor estimated with different methods.

Noting that it is often of interest to partition the universe of adopters into
sub—groups, we present in Section 5 a way of assessing the impact of diffusion

within each group on the diffusion speed of the aggregate process. In Section 6
we elaborate on (and advocate for) the use of the "hazard ratet' as a simple yet
incisive tool to probe further into the nature of diffusion processes.
The actual implementation of these ideas is illustrated in Section 1

via

selected results from a case study on the diffusion of CT scanners —— a

major innovation in medical technoloy ——

in

US hospitals. Finally, Section 8

sketches two possible extensions, linking diffusion with other topics in the
economic and statistical literature.
To repeat, our interest throughout the paper centers on measurement
issues, reflecting not only an obvious

but

also

concern with "measuring

things right",

the belief that good measurement can breed good theory (the converse is

usually taken for granted). In
vailing ad hoc ——

or

that vein,

it sens that the replacement of pre-

distribution—specific ——

estimates

by a well—defined

measure having general applicability, can only foster the much needed upgrading
of diffusion theory.

—3—

A Critique of Current Methodology

2.

ypicafly, empirical

studies of diffusion of innovations have assumed

these processes follow a logistic pattern, i.e., that the cumulative
distribution of adopters as a function of time is:'3
that

(i)

F(t)

= 1 / Ii +

exp -

(+ t)I

and proceeded to estimate the logit transform, using
in IF(t)/(l —

(2)

Attention

F(t)]

is focused

=

&+

weighted

or unweighted LS:

t

on the estimate

which, being the coefficient

of tine, is obviously related to some notion of speed of diffusion C aF(t)/ a > o
and hence the larger is

speed

diffusion process).
coefficient,

diffusion

by regressing the estijnated i3's on measures of profitability,

investment, etc. In

'

the

diffusion processes can thus be compared in terms of this
often an attempt is made to explain the observed differences in

Different
and

the faster will be

size of

almost all such studies, LS estimates of equation (2)

Historically, the use of the logistic in diffusion studies is a clear case of
methodological

"spill—over&' from other disciplines, primarily from Biology
(e.g., bio—assay) and Population Studies.

3.

More generally, F(t) = K/Il + exp — (z +t)1 , where 0 < K < 1 is the
effective ceiling. We assume for the time being that K = 1 ; in Section 4
we discuss the case of K < 1

4.

The intercept
has been, for the most part, dismissed as irréle'iant,
except for its role in setting an "origin", as defined in Griliches [loj.
Whereas it is true that, being a constant of integration (to be precise,
the constant of integration is exp
does not affect the shape of
),
the distribution, it does convey an important piece of information: it can
easily be shown that _ct/ is the mean adoption time.

result in very high R2t5 (usually better than .90) and, notwithstanding the
voicing of some reservations (e.g., Griliches [io, p. 5051, Mansfield [i6,
p.

i4i1 ),

that is taken as evidence upholding the logistic specification.

Now, if it could be safely assumed that most diffusion processes of
interest do correspond to the logistic distribution (or, that even if they do
not, that the resulting mispecification biases in the estimates were negli-

gible), then no major objections could be raised against the received methodo-

logy.

But, as we shall argue below, the fact is that there are neither

compelling a priori reasons to sustain this particular specification, nor does

the available empirical evidence provide stron support to it. The reliance on
(2) and on the estimate

is therefore called into question.

As to theoretical considerations regarding the shape of aggregate diffusion processes:5
cases

in Economics

devoted

to

Diffusion has been until very recently one of those rare
where,

for better and for worse, the bulk of research was

to empirical studies rather than to theory. Thus, one can hardly

find theoretical results that will provide decisive support for

expect

par-

ticular specification.

conventional wisdom underlying most empirical studies had it that,

The

due primarily to information—spreading and uncertainty—reducing mechanisms, the

probability of adoption at any tixi
individuals

t would

be related to the proportion of

that have already adopted by t (this is

often

referred to as the

"epidemic" or "contagion" effect). Or, more precisely, that the "hazard rate"

(to borr the term from Reliability Theory), defined as

5.

A full discussion of the subject is beyond the scope of this paper —— here
we shall content ourselves with sketciiirig the main arguments.

—5—

()

h(t)

f(t)

1.-F(t)

,

f(t)

would be a positive function of F(t)

=

.

(t)
In

particular, it has been assumed that

the relationship is linear, leading to the differential equation
f(t) =

)

(t)1i

-

F(t)]

which solution is the logistic function (1). Notwithstanding
some attents to
derive it more rigorously,6
it is apparent that this amounts to no more than

moving the assumption one step back. To be sure, (4) has sensible —
vague —

if too

behavioral

underpinings (i.e., the "contagion effect") whereas (2) by
itself has none, but the fact remains that it is an ad hoc
assumption rather

than a result stemming from theoretical

analysis.

Recently, though, various attexrts have been made to model formally the
behavioral phenomena underlying

diffusion (see primari].y Fakes 1181, Jensen

112,13], and Reinnum [19]). The main ingredients of these modelsI
and, for
that

matter, of any plausible theory of diffusion, are: (a) a model of
decision akin regarding the adoption of the innovation by the
individual; (b)
the identification of those attributes of individuals that, in the
context of

6.

See,

h(t)

for
exple,nsfield 1i6J
=
[F(t),

he postulates the general relationship
where x is a vector of explanatory variables
(inprofitability and size

xl,

cluding prinErily
of investment), approximates cg.)
a Taylor expansion and, by dropping terms as necessary, arrives_at
an equation similar to (4), except that it includes the effect of

with

x on

7.

Except for Reinganum [19], where diffusion is the result of strategic behavior rather than differences
among individuals. The problem there is that
there is no mechanism to determine
a unique ordering of adoption dates (as
reflected in the fact that these are
n! equally likely Nash equilibria,
n being the number of adopters),
which is precisely the question that a
behavioral model of diffusion is supposed to answer.

—6—
(a), result in their having different resonses at different tines; (c) conjectures regarding the distribution of those attributes; (d) the specification of

the "trigger mechanism", i.e., of the endogeneous or exogenous changes over time

that activate the adoption decision. Clearly, this framework contains too many
degrees of freedom for the ensuing theoretical analysis to be able to generate
universal a priori restrictions on the shape of the aggregate diffusion process.

Crucial in this respect is (c): As Fakes [181 has suggested, almost any diffusion curve can be arrived at by specifying suitable distributions of attri-

butes. What theory can be expected to do is to provide a mapping of basic assumptions regarding (a) —

(d)

to broad families of diffusion patterns (e.g. ,

S—

shaped vs. concave, symmetric vs. asymmetric, etc.), but this remains to be done.

Now to the empirical evidence. To begin with, although being the most
popular, the logistic has not been the only specification used in studies of

di'fusion. Examples

to the

contrary include: Bain [2], lognornal; Coleman

et al. [6], both logistic and exponential;8 Dixon [7'], Gonertz; etc.

More

importantly, in those cases where the logistic was used, it is unwarranted

to infer from the high R2's obtained that the logistic is in fact the
"correct" specification. The econometric arguments stating the limitations of

the H2's as a statistic to assess the functional form are well known and will
not be repeated here. And, as was forcefully argued by Feller 181 long ago,
there is an even more pervasive problem regarding the inferential value of good-

ness of fit measures of the logistic (or any other) distribution. To quote from
Feller's later restatement [9,

pp.

52—531:

...an unbelievably huge literature tried to establish a transcendental "law of logistic growth"; measured in appropriate units, practically all growth processes were supposed to be represented by a
[logistic] function....The only trouble with the theory is that not

8.

et al. did not estimate these functions but used them to represent, algebraically and graphically, different diffusion processes.

Coleman,

—1—

only the logistic distribution, but also the normal, the Cauchy, and
other distributions can be fitted to the same material with the same
or better goodness of fit. In this competition the loistic distribution plays no distinguished role whatever; most contradictory theoretical models can be supported by the same observational material.

The crucial point is that the observed distribution will always fulfill, by
necessity, the restrictions that characterize theoretical distributions,
0 <

F(t)

< 1

,

and

F(tt ) >

F(t)

t

for all t' >

.

namely

Moreover, in most actual

diffusion patterns studied, the data show strict concavity in its upper ranbe

and strict monotonicity all along, two of the properties exhibited by most
distributions, and certainly by all those comiinly used in this context.

Thus,

y functional form of that nature will offer a good fit and result, inter
in a high R2. Yet, and contrary to what one may

be

alia,

led to believe from the

forgoing discussion, the specification choice is by no means inconsequential for

the issue of concern here, i.e., for the quality of the estimate of diffusion

speed, vided of course that diffusion speed has been clearly defined in
vance, independently of any particular distribution.
In order to gain some notion of the magnitude of the problem, we ran
simulations in which the estimated equations were

systematically misspecified,

obtaining in all cases very good fits, but also large biases in the estimates of

diffusion speed as it is defined in Section 3. The following is a typical

e

example: Data were generated by an exponential distribution,
(5)

F(t) = 1 -

for various values of I and time lengths, but a logistic (the logit transform)
was estimated instead; the R25 ranged from .95 to .99, but the biases in the
estimates of diffusion speed were on the order of

9.

Not surprisingly,

It is worth presenting explicitly one of these simulations: the distribution used to generate the observations was F(t) = 1 —
e—0.3t, tell, 25] in
intervals of .5; the estimated equation was: logit = —0.62 + 0.33t,
r2 = 0.99. As shown below,
should be compared to 21 ,
0.33 to .6,

indicating a downward bias of almost 5Oo.

i.e.,

—8—

the Durbin—Watson statistics were very low (.12 —

.18),

reflecting the extent

and nature of the niisspecification.

Thus, the logistic can by no means be presumed to be the universal,
or most accurate representation of diffusion processes and, if used indis—
crixuinatingly, the estimates may be seriously biased. The alternative is to
search in each case for the most appropriate specification, but then the

question is how to compare between different diffusion processes, keeping in
mind that an important goal of these studies is in fact to be able to make con-

sistent and systematic comparisons. This poses a problem because nowhere in the
literature is there to be found a well defined concept of speed of diffusion

that could readily be computed for any distribution. As said,

—

in

(2) —

is

taken as the appropriate measure in the case of the logistic but, what are the
equivalent parameters in, say, the noriial or the log—normal distributions to

which

should be compared? On the same note, studies using the logistic have

not succeeded in providing

with a clear—cut meaning that will have conceptual

and descriptive appeal (calling it the "rate" of diffusion is of no help): they

only indicate a way of using to calculate the time that the diffusion process
takes to go from F1 to F2, these being two arbitrarily chosen points on the
distribution.]-0 It is rather unsatisfactory that this parameter, which had
occupied such a prominent role in diffusion, cannot be grasped in its own terms
and depends upon an element of.arbitrariness for interpretation.

10. This is done as follows:
F
t(F2) —

t(F1)

=

For example, if F2 =

ln

(1—F)
]-

L(1

—F2)

F1

.8 and F1 = .2

,

(F1, F2).

l()

=

2.77;

thus it can be

stated that it took 2.7T/ years for diffusion to go from 20% to 80%.

The issue of comparability arises vividly in Dixon [71.

He reexamined

Griliches' study of hybrid corn and concluded, inter alia, that the appropriate
specification for the majority of states was the Gompertz distribution, defined
as
F(t) =

abt

rather than the logistic, as assumed by Griliches. He observes that in b
"performs a similar role to the b I

in our notation] coefficient in the

logistic function, in that it determines the rate at which
notation] approaches the ceiling value" [1,

p.

1456]. That is so but, more

significantly in this context, the parameters

uivalent (that is shown in Section 3)11

[ F(t) in our

and in b are in fact not exactly

and therefore what is gained in pre-

cision (of the specification) is lost in comparability.

3. The Gjnj's Mean Difference as a Measure of Diffusion S4
As stated in the Introduction, the main

propose the Gini's expected mean difference

purpose of this paper is to

as a highly convenient summary para-

meter of diffusion processes. We contend that this statistic exhibits definite
conceptual and methodological advantages over traditional measures, allowing it
to overcome the difficulties described
above, and to further extend the study of

diffusion. The Gini is defined asl2

11. Apparently, Dixon was aware of this fact, for he ran two separate
regressions of diffusion parameters on

prof itability variables IT, Table
Gompertz, and a second for those
estimated with the logistic, whereas the
preferred procedure (both from a
concept1 and econometric viewpoint) would have been to run
single
regression for all states.
Iv],

one

for the states esti.inated with the

a

12. Given that (6)

is

a double integral but

case to the sane variable t
"double counting".

,

and x2 correspond in this
it has to x1
be divided by 2 so as to avoid

—10—

F

(6)

=

1/2

x1 —

x2

f(x1) f(x2) dx1 dx2

where x1 and x2 are two independent, identically distributed random variables (or equivalently, two random realizations of the same variable x ).

In

the context of diffusion the variable of interest is obviously tiiI, t1 and
t2 being the dates of any two adoptions.

in

Writing (6)

a slightly different

way,
F =

()

(t —

—j

2

t f(t f(t
1

)

2

)

1

)

dt 2

dt

1

1

its meaning becomes transparent: the Gini measures the expected time difference
between any two adoptions over the whole diffusion process. Or to put it differently, it is the expected 'waiting time' of a random potential adopter at a

random point in time (within the relevant time period).13 This constitutes a

well—defined notion of speed of diffusion, and has generally applicability,
i.e. ,

is

not contingent on specific distributions or any other pecularitieS of

the processes studied.

Before turning to a more general measurement procedure, it is worth
showing what the Gini is for those distributions commonly used in diffusion.
This will not only help estimate the Gini in those cases where the underlying

13. In order to understand the precise meaning of the measure, it may be helpful to think of it as follows: a store announces a new product, to be sold
on a first—come, first—serve basis, and all potential buyers (adopters)
up in a queue and wait for their turn. At regular time intervals a
line
statistician calculates the expected waiting tii for those still in the
queue, and at the end computes the overall average, which is exactly the
Gini.

14. "Speed" is commonly defined in terms of distance per unit tiixe, except when
the distance is a given, in which case the reciprocal (i.e., time per unit
distance) is most often used (e.g., in foot races, or in describing the
speed of a photographic camera). In diffusion the distance is indeed given
by the unit interval, and hence it makes more sense to define speed in

terms of F rather than 1/F .

Moreover, the denominator of F is not

absolute distance but differences between any two points, making it hard to
define speed as 1/ F

—11—

distribution is known, but it also will allow to bring the results obtained in
previous studies to a common denominator.

(i) The logistic distribution. A straightforward way to proceed in this

rather

case is to start up with ()

than (2), and to use a suitable transfor-

mation of (6),15

r=

(5)

Integrating

j

F(t) i -

F(t)]

at

p4),

(9)

j

f(t)dt

(t)

=

But the left hand of (9) equals

1,

Ii

- F(t)]dt

and

therefore

=

(io)

(ii)

The exponential distribution. Substituting (5)

= e (1 —

(11)
r

(12)

=

e')

in

(8),

dt

1/21

The Ginj for the normal and log—normal are well—known, and that for the Goirertz

is derived in the Appendix. Thble I shows them in a condensed form.
In view of these results, we can now reexamine the problem in Dixon's

work referred to above: the equivalent parameters there are not

logistic) and in b (from the Gompertz), but i and

(from the

in b/.7 (more precisely,

their reciprocals). The diffusion processes of all states can be thus compared,
regardless of which distribution was

15.

This

fitted.

Likewise, there is no longer need

is done by substituting
—

t2

=

2

2

—

mm

(t1, t2) in (6).

See Kendall and Stuart [l4] and Lomnicki 1151.

—12—
Table I
The Gini for Various Distributions

Gini

Distributiona

[1

1. Logistic:

F(t) =

2.

Exponential:

F(t) = 1

3.

Norxnal:b

4.

IQgnormal

mt

5.

Gompertz:

F(t) =

+

e1

-1

e'
t N( ,)

1/21

—

)
abt

a

e

[2 (—)—i1
O.7/ln b

aFor convenience, we avoid writin6 explicitly the cumulative distributions for
the normal and lognormal.

b Nair [iii.
cSee Aitchison and Brown [1]; 4 stands for the standard normal.

—13—

to split the states into two groups in order to assess the effect of profitability variables on interstate differences in diffusion

speed, but a single regres-

sion having the Gini as dependent variable will do.
As we argued before, though, in most cases there is no good prior
regarding the specific form of the underlying distribution, and the search for
the correct specification can be cumbersome, and often inconclusive. In this
respect as well the Gini proves to be highly

advantageous,

construct a simple, distribution—free measure of it.

for it is possible to

Integrating equation (8)

by parts,

F =

F(t) [i -

F(t)1

dt

define

t

u =

(13)

,

v = F(t)

tF(t)

F =

1 -

Ii —

F(t)]

F(t)1

,

-

v'

=

f(t)

jtf(t)

[1 —

i -

2F(t)]

(t)]

>

dt

But the first—hand term vanishes, and rearringing the second term,

r= 2 JtIF(t) - 0.5] f(t)dt

(1k)

Noting that dF =

f(t)dt

,

and changing variables accordingly,

1

F = 2 j t(F)(F — 0.5) dF = 2

(15)

0

Coy (t, F)

since F distributes unifornilly along the interval Eo,ij .
xnation on each adoption is available,
(t1 ,

t2

,

..., t)

If detailed infor—

i.e., if the data consists of the vector

where t is the adoption date of individual

(15) can be computed simply

by

i ,

then

(i6)

I' = 2 Coy (, t)
R.

where F =

,

is the rank of tj .

and.

But,

the data are often agre—

gated in discrete time periods, in which case the integral in (15) has to be
approximated linearly,

n
(17)

2

1'

t

i=1

1

= (t.1

+

1

1

— 0.5)

t.i+1 )!

£.1

, F.1 = (F.1 + F.i+1 )/2

£*'. =

'

1

F.

i+1

— F.

1

Thus, it is altogether unnecessary to resort to ad hoc assumptions or engage in

specification search: the speed of diffusion, defined as the expected time difference between adoptions, can be computed readily f roa the original data by

the covariance defined in (i6), or by (ii).

4• Estimating the Speed of Diffusion of Truncated Processes

We have assumed up to now that the diffusion process is observed in its

entirety, i.e., that the data comprises the whole distribution 0

F(t)

1.

In many actual cases, though, F(T) = p < 1 , where T is the last date for

which data are available. Now, if it cxild be safely assumed that the process

is near completion by T , i.e., that F(t) = K =

t +

fraction

p

+

, where

is a small

of K , then it is possible to estimate K (usually referred to as the

effective ceiling) along with the other diffusion parameters. That necessarily
entails the making of assumptions regarding the overall course of the process,

most likely on the basis of its observed behavior up to T , e.g., assuming a
logistic distribution and estimating it using maxiimim

likelihood

or other

—15—

nonlinear methods.16 The

quality of the estimates so obtained will obviously
depend on the validity of the behavioral assumptions (and thus be subjected to

the same reservations rised above) and on how small
It is worth pointing out

the population of potential

isJT

that, in fact, what this case implies is that

adopters was not correctly identified at the outset:

the (l—K)% that did not and

presumably will not adopt must have some distinc-

tive characteristics that set them apart in term of their behavior vis a vis

the innovation. Thus, what is ultimately important is to identify those characteristics and delimit accordingly the "right" population set: a finding that
K < 1 does not resolve the issue,
only indicates that we have insufIicient
information, 18

A more serious difficulty arises when there is no indication that the

process is near completion by T (that in turn implying that p << 1
there is no reason to believe that, if K < 1

,

regarding the shape of the whole distribution.19

16.

(K — p)

and that

is small) and no prior

Obviously, the only safe ——

if

See for example Jarvis 1111; a further issue dealt with there is that k
is not necessarily
constant, but may vary over time as a function of exogenous variables, such as prices.

iT. It is important to note that the estimate of
tive to K , and therefore the relative size of
cision of the former as much as for the latter.

in the logistic is sensiis crucial for the pre-

back to the opening assumption "that the process is near coiiiple—
if that was actually known
with a high degree of certainty —— such

18. This links
tion":

knowledge presumably stemming from having information on the relevant
characteristics of the population ——
would imply knowing the approximate
value of K as well, and therefore

it

its actual estimation can only improve
its accuracy, but not render new information. If, on the other hand, there
is not factual basis to assess the
sta€e at which the process stands at T

then the estimate of K can only be regarded as highly tentative, reinforcing the need to look closely at the attributes of the population.

19. As was already argued, the lack of good priors is the prevalent situation
in most diffusion studies, but the probl is obviously aggravated when we
observe a truncated distribution:
the shorter is the range of the observed
distribution, the less will be our ability to discriminate between alternative specifications, and hence the more arbitrary the
Obviously the less reliable the estimates will be).

choice becomes (and

—16—

trivial ——

solution

is to wait until more data become available. But, this just

evokes a basic tension that arises only too often in empirical research having a

claim for "relevance": the longer the wait and hence the more complete and
accurate the data, the more removed the study will turn out to be from current
concerns, be them policy—oriented, or simply
better

the "here and now". And

nature

regarding

part

of the quest to understand

there certainly are plenty of concerns of that

diffusion, ranging from general issues such as: the extent to

which the current productivity slowdown is related to a failure in the incentives to adopt innovations rather than to the drying up of inventive activity;
whether there are structural differences between different sectors of the economy in that respect; to more specific, policy related issues such as the impact

of government regulations on the diffusion of medical technologies. Moreover,
the dilemma is made particularly acute in view of the long time span of most
diffusion processes (10—30 years).

Clearly, any attempt to estimate the parameters of diffusion in these

circumstances will render less than satisfactory results. The main contribution
of the Gini in this respect is that it allows to accurately measure the speed of
diffusion of the observed segment of the process, independently of any assunip—

tions (implicit or explicit) regarding its future trajectory. Clearly, that is
not possible if, instead, a particular distribution is assumed and estimated on

the basis of the truncated distribution.20 Partitioning the overall time span

into two periods, the observed (—, T) , and the unobserved (T, °) , (8) can
be rewritten as:

20. One could assume that K = p

and estimate, say, the logistic; but that
would entail an internal contradiction: if the tn.ie distribution —— having
an unknown K* > p —— is really logistic, then it cannot be true that the
truncated distribution also corresponds to a logistic with K = p , and
thus the estimates will be necessarily biased.

—11—

T

r= j

(18)

+

F(t)[1-F(t)jdt

j F(t)j1-F(t)dt

I +

jil

T

Integrating

10 by parts as in (13):

t F(t) [1-F(t) I

=

(19)

T

+2

= p(1-p)T + 2p2
=

T
t[F(t) -

—

2 t)

where * indicates
f

dt

dt =

=

T

-

p(i-p)

j

t f*() dt

that the distribution has been nor1ized (i.e.

,

F

= F

T

and

=

10 =

p2r*

),

f(t)

1

p(1-p)T + 2p2 j t(P*)(F*_o.5)dF*
0

and f* =

0.5]

tf(t)dt is the average time of the observed period.

Thus ,21

(20)
where f*

+

p(1-p)(T—t)

2 Cov(F*,-t) is the Gini of the observed segment, calculated as if

it were a complete process in itself (which is the inlication
nialized

the

of having

nor—

distribution), i.e., it measures the speed of diffusion among those

that adopted up to T

,

ignoring

the fact that they are only a subset of the

population of potential adopters. What 10 does is to correct for that fact,
thus measuring the contribution of the

p x n initial adopters to the Gini of

21. Ivbre generally,
ro(K) =

given that

r*

is

K2

Ip

+ p(K-p) (T- I

independent of K ,

this

allows to easily conute 0

under different assumptions regarding the ceiling. Note also
that (20)

one of the many forms that the decomposition of the Gini can take: see,
for example, Yitzhaki [26j.

is

—18—

the

entire process. This is as much as the data can tell without imposing addi-

tional structure on it and, as shown below, there are a variety of ways in which

these partial measures can be used for comparative purposes. However, if there
exists additional information that allows to form priors regarding the unob-

served segment of the process (i.e., regarding '

), then

the Gini of the

entire process, r , can be readily obtained by simply adding the prior to
The

advantage of this procedure over the fitting of a particular distribution to

the whole process, is that it keeps observed phenomena strictly separate
conjectures

(or projections), thus allowing to ascertain

of different sets of

manner the effect on

from

in a straightforward

assumptions regarding the

remaining diffusion path, without these distorting the iasure of the observed
segment.

An assumption often made in these circumstances is that the process

will exhibit in the future the same behavior —— on average —— as it did up to T
(we call this the "uniformity assumption") or, more precisely, that

T'

(21)

It

,',
FT;

fF(t)I1—F(t)ldt

=

r

for all T' >
—T

is easy to show that this property holds for the logistic, but for our pur-

poses we need not assume that F(t) corresponds to that distribution over its
entire range, only that (21) holds on average over the period following T
under this assumption is simply:

The estimate of

(22)

=

= p1

+

(l-p)(T-)

Note that (21) and (22) have important implications for comparing the partial
measure

to the existing

body of

results from past diffusion studies, which

—19—

constitutes the only readily available and natural reference group. Given that
in most cases the original data used in those studies are not available, but
only the published estimates of the diffusion parameters (and therefore '0
cannot be computed for them), and that in all of them the estimates refer to
whole prosesses (either because the data were indeed complete or because the

truncation problem was assumed away), it is imperative to bring these estimates

and j0 to common grounds. This involves using the published estimates to eva—
T'

luate the integral

j

F(t)[l—F(t)Jdt

,

T'T(p)

.

As suggested above, if the

estimated distribution was a logistic, then this integral is simply
2

(it is

in the case of an exponential distribution), but other distributions require

that the integral be evaluated numerically. Thus, I can be compared to, say,
without this requiring any assumptions regarding

1'

•

This

simple result

facilitates the required comparisons, nre so in view of the fact that
most previous studies did in fact use the logistic.
greatly

Noting that comparing 1 to

—
10

1'

i , it
—

to

p
uniformity

is formally equivalent to comparing

could be argued that there is in fact no way of escaping the

assumption. But this is not so: the comparison of 1° to

places the uniformity assumption (i.e., "the burden of the proof") on the other
process (the one which
restriction:

in

corresponds

to), and that represents no extra

the assumption, justified or not, was there to begin with, implied

the fitting of a logistic distribution.
A different case arises when original data (i.e., the vectors F(t),t)

for all the processes to be compared are actually available. This is the likely
situation when the diffusion of a particular innovation is being studied, but
the total population of adopters is divided into subsets, each generating its
own

process,

and the objective is to compare between them (e.g., Griliches'

study of hybrid corn, by geographical areas). Suppose that there are m such

—20—

processes, and that they have reached levels p1 , p2

..., p

,

As before, if reasonable conjectures can be made on the 's ,

T .

processes can be compared in terms of their estimated 1•'s

(

then

the

+ 1 ) , where

are calculated using all the data available for each process.

the

Otherwise, the processes have to be truncated at the sane cut—off level:
p0 =

Mm

(p1, p2, ..,

p

),

arid the '?'s

(in which terms the comparisons are to

be made)22 are calculated using only the p0 x n initial observations of each
process. This entails loosing information at the upper end of those processes
with relative high p. 's , which is the cost to be paid for not resorting to
1

assumptions regarding the unobserved segnnt of the process. There is no way to
avoid this trade—off, and no dominant strater: the course of action to be
taken will depend upon the particulars of each study.

It is important to stress again the partial and hence tentative nature

of all these comparisons: as more data become available the measures ought to
be revised and the comparisons redone.

Finally, it should be clear that the procedures described here apply to
any case in which sorr part of the distribution is missing, and not just its up-

per end. In Russell [201 for example, the data on the initial stages of two of
the innovations studies are severely lacking (one starts at 19% and the other at
148%), which is not an uncommon situation: data on diffusion are often gathered
only after the innovation has become important enough and hence widely spread.

22Note that truncating the process at a common level p0 usually implies
T T. and t. t. , and that these are in fact parameters of interest
1

J

1

3

in themselves. Now, if (T. —
1

p2 1' + c ,where c =
compute P? , but

suffices

t.)
1

(T —
j

0(i — p0)(T —

t),
j

i,j =

, and

1,

..., in

,

then

hence there is no need to

—— which enjoys some advantage in interpretation ——

for comparative purposes.

—21—

5. Decomposition by Groups

As mentioned in Section 4, it is often of interest to divide the population of adopters into sub—groups, and do a comparative study of their diffu-

sion processes. A related issue is to investigate the impact of each group on
the aggregate process, i.e., the extent to which diffusion within each
group
accelerates or slows down overall diffusion.

Formally, this involves decom-

posing the "overall" Gini into group—specific
tive size of each group, and the

components that capture the rela-

similarity of its process to (or its correla-

tion with) the aggregate process.

Let F.(t) be the diffusion process and n1 the size of group i

1,
(23)

..., m.

The aggregate process will then be

m

F (t) = —

Nii n.
1 F1(t)

o

,

N

=

m

n.
i=l1

and the overall Gin±,

(24)

= f1—F(t)]F(t)dt

Substituting (23) for F
(25)

ro =

m

in (24),

r

i=l 0.1

where
(26)

F. =
The .'5 are

_

[1—F(t)}F.(t)dt

i=

,

•.., m

the magnitudes of interest: the larger the correla-

tion between the diffusion process in group

and the aggregate process (i.e.,

the larger is the integral in (26)), the larger F
0.1

group

1,

is, and hence the more

will slow down aggregate diffusion (the same holds, mutatis mutandis,

—22--

for the relative size of group i ,

n./N).

For comparative purposes, though, it

is more convenient to use the shares:

m

w.

r0.1•/r0 ,

=

(21)

1

which meaning is immediate: w.

is simply

= 1

the

fraction of the overall Gini

accounted for by group i or, in other words, it is the percentage contribution

of the diffusion process in group i to the averae waiting time between adoptions in the total population.

The actual computation of (21) is done as follows: let to be the vector of adoption times of the aggregate process, and t the analogous vector

for group i

Define a new vector t. for each group i , so that its th

.

element is:

(t.
if t.t.
1
03
03

••

<

13

thus,

t =

t.

i=11

,

1'

=

if t.t.
1
03
2 Coy (F , t
0
0
)

= 2

in

i1

Coy

(F ,

0

1

and
(28)

w, = Coy (F ,
0
1

Finally,
similar

to the

tj/Cov
1

(F ,

0

t0

)

it is worth noting that the decomposition here is formally

one performed in the context of the familiar CAPM: the groups in

diffusion can be thought of as different stocks, and aggregate diffusion as the

•'

—— properly
portfolio. As shown in Shalit and Yitzhaki [231, the r
normalized —— are analogous to the 's in CAPM, a fact that facilitates the

market

interpretation of these measures, and may prove

useful to further explore the

links between diffusions by groups and aggregate diffusion.

—23—

6. The

Adoption Rate

So far we have been concerned exclusively with the measurement of the
speed of diffusion, as a one—parameter representation of the diffusion process.
The next question is whether it is possible to learn more about the process
itself, still within the same restrictive framework, i.e., having data only on
adoption dates (or percentages of adopters in discrete time periods), and

without imposing additional structure on it. The answer is a qualified yes:
there are obviously numerous properties of the observed diffusion process that
could be sought, and at least as many statistical tests that could be applied to

them. &it, apart from purely descriptive purposes, it is worth investigating a
characteristic only in so far as it enhances the understanding of diffusion as a
socio—economic phenomenon, or if it gives some indication for further research.

Of course, it is theory's customary role to provide guidance in that respect
but, as stated before, the results are wanting.

Thus, any further step taken in

this direction will be necessarily tentative, and no general conclusions can be
expected.

We want to suggest the behavior over time of the hazard rate (which
could be appropriately relabeled in this context the "adoption rate") as a

likely candidate for investigation. To recall, the adoption rate is formally
defined as23

h(t) =

By
the

23.

analor

f(t)
1 — F(t)

Reliability Theory, h(t) can be interpreted here as
conditional probability of adoption at t , having been a "hold—out" until
to its meaning in

For a description of the properties of
Prochan 131. The relationship between
discussed

the hazard rate, see Barlow

and

the hazard rate and the Gini is

in Chandra and Singpurwalla 151.

214-.

then. Now, if h(t) =

I i.e.,
,

if the conditional probability is constant over

time, then the underlying distribution is necessarily exponential, suggesting
that the "contagion effect" (that is, the direct influence of previous adopters
on would—be adopters) is not the predominant force driving the diffusion pro-

cess. On the other hand, if h'(t) > 0 ,

the

corresponding distribution is

likely to be S—shaped, and the contagion effect
inferences

be at work, but no solid

can be drawn without further information (the case of h' (t) <

0

does not seem to be relevant in diffusion).
A good

example is provided in the study of Coleman et. al. [61 on

the diffusion of the use of a new drug among physicians. They use the adoption
rate (without referring to it as such) in order to distinguish between what they

call "snowball" vs. "individual" diffusion processes. The nest telling finding
is that the adoption rate of socially integrated doctors increases sharply over
time, whereas that of isolated doctors oscillates without displaying a trend.

Thus, they conclude that the contagion effect ——

associated with h'(t) > 0

at work in the former case but not in the latter, for which h'(t) = 0

——

is

•2 Note

that what allows the authors to draw these conclusions is not just the sign of
h'(t) ,

but

the fact that adopters were separated into subgroups according to

variables reflecting the extent of their social integration, which has a direct
bearing on the plausibility of the contagion effect.

The simplest procedure will thus be to regress h(t) on t (and/or on
F(t) ) and test for the significance of the slope coefficients. But, this test
will be meaningful only if the diffusion process displays a uniform behavior

over time. In some cases, though, the observed distribution results from the
concatenation of different sequential processes, each initiated in response to

24. Following the same reasoning, they characterize the diffusion process among
socially integrated doctors as logistic, and that of isolated doctors as
exponential.

—25—

discrete changes in the exogenous variables governing the adoption decision
(e.g., major technological improvements in the innovation, jumps in prices,

changes in government policies, etc.). This sort of phenomena cannot be cap-

tured in the simple correlation between h(t) and t ,

show—up in a plot of h(t) on t

but will nst likely

as will become apparent in the empirical

illustration below, the visual inspection of such plots can be highly informative, and provide the researcl-ier with much needed guidance

for

measuring and

analyzing the diffusion process.

7. An Empirical Illustration: The Diffusion of CT Scanners

The approach laid out in the preceeding sections can be best appraised

by applying it to a concrete case, for which purpose we have chosen the diffu-

sion of CT

Scanners

in U.S. hospitals. CT (Computed Tomography) is a revolu-

tionary diagnostic technolo that produces highly

detailed

and accurate pic-

of thin "slices" of any section of the human body, using a sophisticated
configuration of x—rays, detectors and computers. Developed in the late sixtures

ties, the

first operational prototype as built by the British firm EMI in 1971,

and the first commercial installation in the U.S. took place in June 1973. It
has commanded,

a great deal of public attention

ever since, partly because of its

scientific merits, but also because of growing concerns that this kind of expensive advances in medical technologies y have been fueling the rapid rise in

health care costs. Acting on this belief, the governnnt enacted a series of
regulations designed to slow—down the diffusion of CT scanners. It is still a

matter of controversy whether diffusion was indeed "too fast", and whether those

regulations have had a noticeable effect on it. Thus, the interest in the case
is not only academic, but has policy implications as well.

—26—

The data used in this study consist of the adoption dates (nnth, year)
of' all first scanners (some medical institutions have acquired more than one)

installed in community hospitals during the period 6/13 —

12/81,25 and supplemen-

tary information from the American Hospital Association (AHA) Annual Surveys of
Hospitals. Table II shows the distribution of' hospitals and adopters by bed—size

category. Given that only 1.2% of hospitals with less than 100 beds had CT
scanners, we decided to exclude them from the study. Still, the diffusion pro-

cess for community hospitals with beds > 100

from complete (p = .39

"hospitals") is far

loped in Section

4

for

)

(hereafter referred to just as
and therefore the

methods deve-

truncated distributions are called into action.

The previous statement implies having an idea of the value of K ; and
indeed, although it is hard to predict at this stage what will be the precise
ceiling for CT scanners, it can

be safely assumed

that it will not surpass the

ceiling reached by Diagnostic Hadioisotopes, a previous innovation in imaging

techno1or,26 shown in Table III. Thus, most of the calculations will be done

for K = .81k , but lower ceilings will be considered as well (K = .1 and K = .6
is highly implausible that K will be less than 60%). We

diffusion

discuss below "overall"

(i.e., diffusion among all hospitals), diffusion by bed—size groups, and by

type of control.

25.

26.

; it

These data were collected by the first author as part of a much wider
research project on CT scanners. We report here only partial results that
have a bearing on the methodological issues addressed in this paper.
This conjecture is based on information regarding the relative prices of
the two systems, the availability of competing technologies along the diffusion path, etc.

—27—

Table

II

Distribution of Comirunity Hospitalsa and Adopters

of CT Scanners by Bed—Size

(1)

Number
of Beds

( 3)

(2)

Total Number
of Hospitals

Hospitals with
CT Scanners

p:
(2) *

(1)

up to 99

2,848

34

.012

100 — 199

1,417

181

.132

200 — 299

7l

285

.396

99

384

254

.662

400 — 499

244

201

.824

500+

314

275

.876

TOTAL

5,926

1,236

.209

100+

3,078

1,202

.390

300 —

aThe definition of "community hospitals" used by the AHA is:
"Non—federal,
short—term general and other special hospitals, excluding hospital units of
institutions". This excludes approxinte1y 1,200 long—terre and/or federal
hospitals, of which only 37 had CT scanners.

Table III

Ceilings for Diagnostic Radioisotopes

Bed—size:

Ceiling:

100—199

200—299

300+

All

70%

92%

98%

84%

Source: AHA 1977 Survey.

—28—

7.1

Overall Diffusion
The objective here is to estimate the diffusion speed of CT scanners

so as to coirxpare it with other innovations. To recall, if we want to avoid

making

to be

assumptions about the

future course of the process, the comparisons

are

(see equation (20)) which, allowing for

based on the partial measure 1'o

different K's can be written as:

(29)

(f.)

=

[

1° +

(i —)(T —t) I

The availability of very detailed data allowed us to compute
(16) rather than (17) (i.e., using ranks), rendering a value of
i.e., the average time difference between

=

r*

using

12.89

arw two adoptions for the set of

hospitals that adopte3. CT scanners up to T = 12/81

was of slightly nre than a

year.27 Plugging it in (29), 1 was computed for the various K's , and the
results are presented in Table IV.

Table

IV

Estimates of

.6

27'.

in nnths

i1.o6

15.20

15.77

in years

1.17

1.27

1.31

t

is the
The time unit of the data and hence of the estirites is months (
number of months elapsed since Nov. 1972, the date when the innovation was
first announced and displayed in the U.S.). For some comparisons, though,
the estimate will be transformed into years.

—29--

We want now to compare these with estimates of the diffusion speed of
20 innovations reported in the literature (see Table v).

All of them were esti-

mated using the logistic specification and, as shown in Section 4, the tranfor—

mation of the reported 's that allows comparability with our results is
simply

10 () =

.

Figure

1 summarizes the results: The diffusion of

CT scanners was indeed quite fast, i.e., it belongs to the fastest third of the

innovations studied. Moreover, it was more than 3 tirrs faster than the diffusion of the other two reported innovations in diagnostic

technologies

(electroencephalograph and diagnostic radioisotopes). As Figure 1 makes clear,
the conclusions hold for the three alternative ceilings considered.

7.2 The Adoption Rate
We examine now the bahavior of the adoption rate which, as argued in
Section 6, nay provide some insight into the nature of the process. Regressing

,28

it on time and on Ft),
(30)

h =

0.00
(3.5)

(31)

h =

+

0.90008

t

r2 = .20

(4.9)

0.004 + 0.01 F(t)
()
(4.)

r2 =

.19

These results are informative only in a "negative" sense:

(31) makes

it highly unlikely that the process as a whole corresponds to the logistic,

because (a) the very low r2, which indicates that h(t)

was not smoothly increas-

ing with F(t), as it should have been if the underlying distribution was a
logistic, and (b) the very small coefficient of F(t) which, appropriately transformed, renders an estimate of diffusion speed 3 times larger (i.e., 3 times
slower) than that calculated with the Gini in Table IV (for K =

.84).

Likewise,

(30) rules out the possibility that the process conforms to an exponential—type

28. These calculations have been done for K = .814.

—30—

Table
and I°(K)

Innovation

for

V
a

Twenty Innovations

(1)

(2)

Reported

I°(K=.84)

(3)

(4)

i°(K=.1)

1°(K=.6)

Griliches 1101

0.54

0.86

1.03

1.20

0.55

0.84

1.01

1.18

Bituminous coal mining:
3. Shuttle Car
4. Trackless mobile loader
5. Continuous mining loader

0.32
0.32
0.49

1.45
1.45
0.95

1.74
1.74
i.i4

2.03
2.03

Iron
6.
1.
8.

0.17
0.34

2.13
1.31

3.28
i.64

3.82

0.11

2.73

3.28

3.82

0.55
2.40
0.36

o.84
0.19
1.29

1.01
0.23
1.55

1.18
0.27

0.20
0.19
0.11

2.32
2.44
4.22

2.79
2.93
5.06

3.25
3.42
5.91

0.35

1.33

1.59

i.86

0.31

1.50
1.55
3.87
3.57
1.13

1.80
1.86
4.64
4.29
1.36

2.10
2.17
5.42
5.00
1.59

Hybrid comb

1.

Jarvis

[n]

2. Improved pastures in UruguayC
Mansfield 1161

and Steel:
By—product coke oven
Continuous wide—strip mill
Continuous annealing line
for tin plate

Brewing:

Pallet

loading machine
10. Tin container
11. High-speed bottle filler
Railroads:
12. Diesel locomotive
13. Centralized traffic control
14. Car retarders
9.

1.33

1.91

1.81

Romeo [221

15. Numerically controlled
machine_toolsb

Russell
16.
17.
18.
19.
20.

Post operative recovery room
Intensive care unit
Electroencephalograph
Diagnostic radioisotopes
Respiratory therapy

0.30
0.12
0.13
0.141

—31-.

V, continued

Table

Footnotes
aThe

's are the logistic coefficients
reported in thetudies listed here
(the time unit is years).
In columns (2) to (14), the 's are transformed
into the partial measure I'°(p/K) for different K's, so as to enable comparisons with CT scanners. To recall, if F is logistic then:

10(p/K)

According to Table II,

JTtF(1F)dt
p =

p/Ku

.39, hence

10

,

T'

T(p/K)

= .39/Ks

all

these cases we have taken the average of the group coefficients:
states in
Griliches, industries in Romeo, and different classes of hospitals
in Russell (the estirrates for hospitals with beds <

excluded).
This is not equivalent to the coefficient of the aggregatewere
process, but it
100

is a good enough approxinEtion for our

CJarvis

purposes.

tried several specifications, but the coefficients did not vary much:
.59 with an average of .55, which is the figure
reported here.

the range was .51 —

—32—

Figure 1

The Frequency Distribution of F°(K) for 20 Innovations

CT Scanners

4

K .6
2

CT Scanners

K:.7

4
/

/

2

/.
-

-l

I

I

I

1

1

1.27

6

CT Scanners

K:.84

4

Other Diagnostic
Te cnn o I g I e s

2

0.5

1,0

1,5

2.0 2.5

3.0 3.5

1:17

Sources: Table 4, and Table 5, Columns (2 )-(4)

4.0 4.5

5.0 5.5 F(K)

—33—

(30) rules out the possibility that the process conforms to an exponential—type
distribjtjon, because the time

coefficient,

although very small, is nevertheless

significant. Thus, a more complex pattern is suggested instead. The plot of

h(t) on time (see Figure 2) clarifies the issue: there was

a

sharp discon-

tinuity midway along the diffusion path (in the third quarter of 1911), the pro-

cess behaving very differently before and after. In the first period h'(t) >>
0

,

suggesting an S—shaped distribution (and the "contagion effectt), whereas

afterwards

there is a drop

in the

level of h(t)

, and

h' (t)

0 , inJ.ying a

slow—down in the process and an exponential—like pattern thereafter. Following

this lead we computed separate 's for each period, and found that the first
was faster than the second by a factor of 2.
Furthermore, the logistic fits
well

the first period, rendering an estimate of diffusion speed consistent with

the partial Gini. A discussion of the causes underlying this rather dramatic
change is beyond the scope of this paper; suffice it to say here that it was due
primarily to the implementation of government

regualtions, and prior expec-

tations in this regard.
The important point is that, had we proceeded according to the
received methodoloy, we would have probably overlooked this crucial feature of

the diffusion process (as can be seen in Figure 3, the plot of F(t) —— often
shown in diffusion studies —— does not reveal it

ticular

either)

and assuming a par-

distribution would have resulted in biased estimates. To illustrate, we

estimated the logistic for the whole period (and different K's ).
the results in Table VI to those in Table

Comparing

IV, the logistic overestimates the

speed of diffusion by 50_80%.29

29. According to the logistic estimates, CT scanners would have been the second
fastest innovation, the first being tin containers in Mansfield's study
(which is a puzzling outlier).

i)

1914

aAssuminq K

9T3

o.00

0.005

0.010

0.015

0.020

0.025

0.030

0.03 5

0.040

0.045

h(

.84

1915

1916

1918

1980

1981

Years

t (quarters)

U,

CD

0

C-,

a

-1
(n

C)

0-4.

CD

0
-4.

0

-o
-4.

0
0

CD

-1

1975

Ull]Y

°Assuming K=.84

1914

UllIl!

1973

0.00

0.05

E

025

A7f
v.Jv

035

0.40

0.45

F(t)

1976

]IflI]V

1

1917

1918

1919

1980

1981

Iii iii
Years

I

0

0

U)

C

a

—1

—36—

Table VI
Logistic Estimates

1.3 Diffusion by Bed—Size Groups
As shown in Table II, the percentage of hospitals that adopted CT scan-

ners by 12/81, p. ,

varies

a great deal across bed—size groups, ranging from

.132 for hospitals with 100 < beds < 199

to .876

for

the largest hospitals.

The question is how to compare them in terms of diffusion speed, in view of

these disparities in the proportion of the process that is observed. It was
argued in Section IV that there are two alternative ways to proceed:

cate the processes at the same cut—off level (minimum p. ),
tions

regarding 1 •

In

or

(a) trim—

(b) make assump-

this case (a) has to be discarded because it will

imply doing away with most of the available data. On the other hand we do

not

have specific priors regarding the unobserved segnnt of each group's process,
and hence the only alternative left is to resort to the uniformity assumption,
i.e., to estimate equation (22)

in

for

each group. This is certainly troublesome

the case of small hospitals in view of their very low p ,

estimates for them should be regarded accordingly.

and

hence the

—37—

Table VII

presents both the estimates

and their cosonents so as to

provide a better idea of the nature of these calculations. Except for hospitals
with

200—299 beds versus those with 100—199 beds, diffusion speed increases sub-

stantially

with bed size, a result consistent with previous studies (e.g.,

Russell 1201). But, a closer look at the table indicates that the intra—group
behavior of adopters was fairly similar across groups (as evidenced by the
small variation in

),

and that the observed differences in speed were due

mostly to differences in p/K and in the mean adoption time. To illustrate the
point: suppose that the total number of hospitals with 100 < beds < 199 was
much smaller, so that p/K was equal to that of the largest hospitals; in that
case diffusion in small hospitals would have been faster than in the 500+
group, because of the high

(i.e., small (T —

t)

)

of

the former, i.e.,

because the process was "crammed" in the later period. This underscores the
fact

that diffusion speed as defined here and elsewhere is only a measure of

Table VII

Estimates of Diffusion Speed under the Uniformity

t)

Assumption

Bed—size

P/Ka

f'

100 — 199

.189

11.089

30.872

27.14

2.26

200 — 299

.30

12.346

39.839

28.01

2.33

300 — 399

.676

11.982

42.732

21.96

1.83

499

.841

11.866

146.891

17.44

1.145

.894

11.476

57.527

16.36

1.36

1400 —

500+

(T —

i:

(months)

aThe p's are taken from Table II and the K's from Table III.

r (years)

—38—

dispersion,

and by

no means

the

ony relevant aspect of diffusion: the location

in time of the process is at least as ixrortant, for which the mean adoption

time, t ,

is

in fact an appropriate measure.3°

7.14 Decomposition by Type of Control

The objective here is to illustrate the procedure developed in Sec-

tion 5 for assessing the contribution of different grips to the Gini of the
overall process. We have chosen for that purpose to partition the hospitals by
type of control, as shown in Table VIII.

In view of the fact that there are no wide differences in the i's ,

it is appropriate in this case to truncate the processes at in

=

Table VIII
Distribution of Hospitalsa b Type of Control

Number of
adopters

Type of Control

Number of
Hospitals

Investor—owned/for profit (FP)

102

3142

.30

Government, non—federal (GNF)

188

576

•33

Not—for—profit (NFP)

912

2,160

.142

1,202

3,078

.39

TOTAL

aComnity hospitals with beds > 100

30. The "origin"
the

in

arbitrary constant.

)/ , is precisely
an

defined as (—2.2 —
as estinted by the logistic (—

Griliches [101,

mean adoption tine

/)

, plus

—39—

computing the f*'5 for the .3x (number of hospitals in class i )
1

initial

observations of each group. The resulting figures are presented in Table IX and
the decomposition in Table X (see equations (25) through (28)).

Table IX
Diffusion Parameters by Type of Control,
With Common Cut—off Level (p =

(1)

Control

ri.

1

(2)

(3)

n./N
1

i

.3)
(14)

(5)

T

FP

102

.11

GNF

173

.19

11.12

98

58.35

NFP

68

.70

8.14

8

51.62

923

1.00

955a

108

514.69

All hospitals

aJTh5 figure corresponds to 1' in equation (21).
0
Table X
Decomposition of the Gini by ¶Ipe of Control

(1)

Control

FP

GNF

NFP

Total

r

o.i

( 2)
w
i

3.8143

3.322

.35

2.384

.25

9.5149

1.00

_140_

The findings can be summarized as follows: Not—for—profit hospitals

were the
owned

its

fastest to adopt, followed by government non—federal and investor—

(Table IX, column (3)).

In

spite of NFP being the largest group (10%),

diffusion process was the least correlated with the overall process, and the

opposite is true for FP hospitals (Table X, column (1)). As to the net effect
on aggregate diffusion, NFP hospitals accounted for 25% of the overall Gini, GNF
for 35% and FP for )40% (Table X, column (2)).

8. Extensions

One of the main methodological advantages of studying diffusion with
the aid of tools that are well known and widely applied (rather than issue—
specific), is that the analysis of the phenomenon can be readily extended by
drawing from the literature in which these and related tools play a key role.

The Gini is certainly a tool of that nature, and it opens up numerous possibi-

lities for

first

further research. We would like to suggest two such extensions: the

links diffusion with stochastic dominance, and the second with rank—order

tests of linear hypotheses. Both topics require careful elaboration, but that
lies beyond the scope of this paper; thus, we shall limit ourselves here to
introducing the issues.

Although the treatment of diffusion has been carried out almost exclusively in positive terms, there is certainly a normative aspect to it namely,
the assessment of the relative desirability of alternative diffusion process, in
view of the costs and benefits of delaying adoption, and society's time

preferences.31 The following high si1ified forilation of this issue
suggests a line of inquiry that may

prove

fruitful.

Assume that the net social loss due to postponing the adoption of the

innovation until time t is v(t)

v'

>

0

and v" < 0

,

of the loss, E[v(t)1

,

exhibiting

the properties: v(O) = 0

and that the objective is to minimize the
expected value
,

for

all t

(o,°°) .

This is in fact analogous to the

problem dealt with in the literature on stochastic
Yitzhalcj [27J, given two diffusion

l

dominance: As shown in

processes F1(t) and F2(t)

,

necessary conditions for second order stochastic dominance are:
—

of F•

, where

I 2 —
,

=

1,2

.

Sufficient

is the expected adoption ti and

the
and

<

the Gini

conditions can also be derived for distributions

that intersect at most once, with the aid of the extended Gini. If the factors
affecting the value of these parameters were known (e.g., the effect of tax
incentives, regulation, market structure, etc.), then it could be possible to

design optimal or second best diffusion policies.
The

second extension has to do with an issue

of prime concern in dif-

fusion studies: the identification of the variables that affect the decision to
adopt, and the timing of adoption. This has been approached in various ways in
the literature: linear probability models

(Russell [211 ), discrete choice

models (Somnrs 125]), simple regressions with the estimated 's

as the

dependent variable (Griliches 1101, Mansfield [161), etc. Consider now the
following linear model:

31.

The most serious difficulties of this kind of welfare analysis are the
identification of those costs and benefits, and the modelling of the dyna-

mic interactions between the expectations and
consequent decisions of individual adopters, and the evolution (pricewise and technological) of the
innovations over time.

_14 2—

J

(32)

where

1

=

L . X.JJ
j=l
J

+ C.
1

.=1

,

..., N

t is the time of the 1th adoption, x ,

j

=

1,

...,

J

are the vari-

ables presumed to affect the adoption decision (e.g., the characteristics of the
individual adopters or of grxips of adopters, time—dependent attributes of the

innovation and of the environint, etc.), and C. is the error term assumed to
be i.id. but not necessarily noriiially distributed. Substituting (32) for t
in (15),

J

F = 2 Cov[t,F(t)i = 2

(33)

L

. Covix.,

F(t)1 + 2 CoviC

,

F(t)1

j=1

where 2 Cov[x F(t)1 is the contribution of the th variable to the Gini,
and 2 Covie ,

F(tfl

is its unexplained portion. If instead of estimating (32)

for

we substitute F. =

t (where H. is the rank of t ), we obtain in

fact Bennett's model 141 for non—parametric tests of linear hypotheses.32
I.e., this specification allows to perforxii
Ho:

•.. =

= ... =

tests of the null hypothesis

= 0 , L < J , which meaning can be best understood

in the context of (33).

Although the relative merits of this approach vis a vis those mentioned
above are yet to be examined, it is worth noting some of the features that make

it attractive: it provides with a direct way for assessing the effect of exogenous variables on the diffusion process (rather than indirect or two—stage pro—
cedures as in Griliches and Mansfield), it does not require restrictive assumptions regarding the distribution of the error term, and it enhances the coherence and scope of the xnethodolor presented here for the stuiy of diffusion.

323ee also Shirley [241 for a description of the model.

_143_

Appendix

The Gini of the Goxnpertz Distribution

Let t be a random variable having a Gompertz distribution:
(Al)

t
F(t) = ab

Inverting it,

(A2)

t(F) =

(1/in

b) in (in F/in a)

Applying equation (15):

(A3)

r

=

=

=

(An)

1

2

b j0

in (in F/in a)(F -

0.5) dF =

1

2

in

in b

Fl

—

inJ

in aj )(F —

1

in

b

0

ml in Fl (F —0.5) dF

Evaiuating numerically the integrai in (A)-),

1
(A5)

j
0

ml in

FL (F —

Thus,

(A6)

F

0.7/in b

0.5) dF

0.35

0.5) dF

>

References

1. Aitchison, J. and J.A.C. Brown: The Lognormal Distribution. Cambridge:
Cambridge University Press, 1963.
2. Bain, A.D.: The Growth of Television Ownership in the United Kingdom since the
War: A Lognormal Model. Cambridge: Cambridge University Press, 1964.
3. Barlow, R.E. and F. Proschan: Statistical Theory of Reliability and Life
Testing. New York: Bolt, Rinehart and Winston, Inc., 1975.
4. Bennett, B.M.: "Rank—Order Tests of Linear Hypotheses," Journal of the Royal
Series B, 30 (1968), 483—489.
Statistical Soci

5. Chandra, M. and N.D. Singpurwalla: "Relationships between son Notions which
are Common to Reliability Theory and Economics," Mathematics of Operations
Research, 6 (1981).
6. Coleman, J.S., E. Katz and H. Menzel: Medical Innovation: A Diffusion Study.
Indianapolis: Bobs-Merrill, 1966.

7. Dixon, R.:

"Hybrid Corn Revisited," Econometrica, 148 (1980), 1451—114b1.

"On the Logistic Law of Growth and its Empirical Verification in
8. Feller, W.:
Biolor," Acta Biotheoretica, 5 (1940), 51—65.

9. Feller, W.: An Introduction to Probability Theory and Its Applications, Vol. 2,
2nd edition. New York: John Wiley & Sons, Inc., 1971.
10. Griliches, Z.: "Hybrid Corn: An Exploration in the Economics of Technological
Change," Econometrica, 27 (1957), 501—522.
11. Jarvis, L.S.: "Predicting the Diffusion of Improved Pastures in Uruguay,"
American Journal of Agricultural Economics, 63 (1981), 1495—502.

12. Jensen, H.: "Innovation Adoption and Diffusion when there are Competing Innovations," Working Paper No. 71, Departsnt of Economics and Mershon Center,
Ohio State University, April 1981.
13. Jensen, R.: "Adoption and Diffusion of an Innovation of Uncertain Profitability," Journal of Economic Theory, 1982 (forthcoming).
14. Kendall, M. and A. Stuart: The Advanced Theory of Statistics, Vol. 1, 4th ed.
London: Griffin, 1977.

15. Lomnicki, Z.A.: "The Standard Error of Gini's Mean Difference," Annals Math.
Statist., 23 (1952), 635—631.
16. Mansfield, B.: Industrial Research and Technological Innovation. New York
Norton, 1968.
17. Nair, U.S.: "The Standard Error of Gini's Mean Difference," Biometrika, 28
(1936), 428—1436.

—4 5—

18. Pakes, A.:
"A Simple Aggregate Diffusion Model, Estimation Techniques, and a
Case Study in a Secondary Country," Unpublished Ph.D. Dissertation,
Chapter )4, Department of Economics, Harvard University, 1978.
19. Reinganuni, J.F.: "Market Structure and the Diffusion of New Technology," The
Bell Journal of Economics, 12 (1981), 618—621..

20. Russell, L.B.: "The Diffusion of Hospital Technologies: Some Econometric
Evidence," The Journal of Human Resources, 12 (1977), 1482_502.

21. Russell, L.B.: Technology in Hospitals: Medical Advances and their Diffusion.
Washington, D.C.: The Brookings Institution, 1979.
22. Romeo, A.: "Interindustry and Interfirm Differences in the Rate of Djffusjo of
an Innovation," The Review of Economics and

Statistics, 57 (1975), 311—319.

H. and S. Yitzhaki: "Mean—Gini, Portfolio Theory and The
Pricing
Risky Assets," Discussion Paper No. 820I, The Center for
Agricultural

23. Shalit,

of

Economic Research, Rehovot, Israel, 1982.
2I.

Shirley, E.A.: "A Distrithtjon_free Method for Analysis of Covariance Based on
Ranked Data," ppl. Statist., 30 (1981), 158—162.

25. Sonmiers,

P. "The Adoption of Nuclear Power Generation," The Bell Journal of

Economics,

12 (1981), 293—291.

26. Yitzhaki, S.: "Relative Deprivation and Economic Welfare," European Economic
Review

27.

17 (1982), 99—113.

Yitzhaki, S.: "Stochastic Dominance, Mean Variance and Gini's Mean Difference,"
American Economic Review, 72 (1982), 178—185.

