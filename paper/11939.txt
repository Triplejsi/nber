NBER WORKING PAPER SERIES

EVALUATING THE DIFFERENTIAL EFFECTS OF
ALTERNATIVE WELFARE-TO-WORK
TRAINING COMPONENTS: A RE-ANALYSIS
OF THE CALIFORNIA GAIN PROGRAM
V. Joseph Hotz
Guido Imbens
Jacob A. Klerman
Working Paper 11939
http://www.nber.org/papers/w11939
NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
January 2006
We wish to thank Julie Mortimer, Wes Hartmann and especially Oscar Mitnik for their able research
assistance on this project. Jan Hanley, Laurie McDonald, and Debbie Wesley of RAND helped with
the preparation of the data. We also wish to thank Howard Bloom, Jim Riccio, Hans Bos, John
Wallace, David Ellwood, and participants in the IRP and NBER Summer Institutes, a workshop at
Berkeley and the Tenth International Conference on Panel Data for helpful comments on an earlier
draft of this paper and to two referees who provided valuable comments and suggestions on an
earlier draft of this paper. This research was funded, in part, by NSF Grant SES 9818644.
Development of the methodological approaches used in this research also was funded by a contract
from the California Department of Social Services to the RAND Corporation for the conduct of the
Statewide CalWORKS Evaluation. All opinions expressed in this paper and any remaining errors
are the sole responsibility of the authors. In particular, this paper does not necessarily represent the
position of the National Science Foundation, the State of California or its agencies, RAND, or the
RAND Statewide CalWORKS Evaluation. The views expressed herein are those of the author(s)
and do not necessarily reflect the views of the National Bureau of Economic Research.
©2006 by V. Joseph Hotz, Guido W. Imbens and Jacob A. Klerman. All rights reserved. Short
sections of text, not to exceed two paragraphs, may be quoted without explicit permission provided
that full credit, including © notice, is given to the source.

Evaluating the Differential Effects of Alternative Welfare-to-Work Training Components: A ReAnalysis of the California GAIN Program
V. Joseph Hotz, Guido W. Imbens and Jacob A. Klerman
NBER Working Paper No. 11939
January 2006
JEL No. C1, C5, I3
ABSTRACT
In this paper, we explore ways of combining experimental data and non-experimental methods to
estimate the differential effects of components of training programs. We show how data from a
multi-site experimental evaluation in which subjects are randomly assigned to any treatment versus
a control group who receives no treatment can be combined with non-experimental regressionadjustment methods to estimate the differential effects of particular types of treatments. We also
devise tests of the validity of using the latter methods. We use these methods and tests to re-analyze
data from the MDRC Evaluation of California’s Greater Avenues to Independence (GAIN) program.
While not designed to estimate the differential effects of the Labor Force Attachment (LFA) training
and Human Capital Development (HCD) training components used in this program, we show how
data from this experimental evaluation can be used in conjunction with non-experimental methods
to estimate such effects. We present estimates of both the short- and long-term differential effects
of these two training components on employment and earnings. We find that while there are shortterm positive differential effects of LFA versus HCD, the latter training component is relatively more
beneficial in the longer-term.
V. Joseph Hotz
Department of Economics
UCLA
Los Angeles, CA 90095
and NBER
hotz@econ.ucla.edu
Guido W. Imbens
Department of Economics
University of California, Berkeley
549 Evans Hall, #3880
Berkeley, CA 94720
and NBER
imbens@econ.berkeley.edu

Jacob A. Klerman
RAND
jacob_klerman@rand.org

1.

Introduction
In this paper, we explore ways of combining experimental data and non-experimental

methods to estimate the differential effects of components of training programs. In particular, we
show how data from a multi-site experimental evaluation in which subjects are randomly assigned to any treatment versus a control group who receives no treatment can be combined with
non-experimental regression-adjustment methods to estimate the differential effects of particular
types of treatments. Our methods allow the implemented programs to vary across sites and
across subjects within a site. The availability of such experimental data allow us to test, in part,
the plausibility of our regression-adjustment methods for eliminating selection biases that result
from non-random assignment of program components to individuals in the various sites. We use
our method to adjust for across-site differences in background and pre-program variables as well
as post-randomization local economic conditions and validate our methods on experimentallygenerated control groups is a spirit similar to the approaches taken in Lalonde (1986), Heckman
and Hotz (1989), Friedlander and Robins, (1995), and Heckman, Ichimura, and Todd (1997,
1998) Heckman, Ichimura, Smith and Todd (1998), and Dehejia and Wahba (1999) and Hotz,
Imbens and Mortimer (2005).
An example of why determining how to properly compare the effects of different treatments across sites in order to assess the relative effectiveness of specific treatments arises in the
case of evaluating welfare reform. Over the last three decades, as the United States has sought to
reform its welfare system, states have sought to design their mandated welfare-to-work programs
in order to reduce dependency on welfare and promote work among disadvantaged households.
Over this period, states differed in the components, or approach, they emphasized in these programs.

1

One approach, the “Human Capital Development” (HCD) approach, emphasizes education and vocational training programs, such as GED and English as Second Language (ESL)
programs and vocational training in the health care industry. The HCD approach seeks to improve the basic and job-related skills of welfare recipients. Advocates of this approach argue that
acquiring such skills are necessary for adults on welfare to “get a job, especially one that is relatively stable, pays enough to support their children and leaves them less vulnerable during an
economic downturn.” 1
The other primary approach used in designing welfare-to-work programs is the “Labor
Force Attachment” (LFA), such as job clubs, which teaches welfare recipients how to prepare
résumés and interview for jobs, and assistance in finding jobs. The LFA approach seeks to move
adults on welfare quickly into jobs, even if they are low paying jobs. Supporters of the LFA approach “see work as the most direct route to ending … the negative effects of welfare on families
and children.” 2 The advocates of the LFA approach also argue that it is a better than the formal
classroom training stressed in the HCD approach to build the skills of most low-skilled adults. A
natural question is: “Which approach is better?”
The MDRC GAIN Evaluation was one of the most influential evaluations that shed light
on the impacts of these two approaches. Welfare recipients in six California counties were randomly assigned to either a “treatment” group that was to receive services in a county based and
designed “welfare-to-work” program, or to a “control” group to which these services were denied. Under the GAIN program, California’s counties had considerable discretion designing their
welfare-to-work programs and counties emphasized the LFA versus HDC approaches to different degrees. Thus, the MDRC study conducted separate evaluations of each county’s program,
1

Gueron and Hamilton (2002).

2

Gueron and Hamilton (2002).

2

where the training components of the program, the populations served and the prevailing local
economic conditions varied across counties.
To date, the results of this experimental evaluation often have been interpreted as favoring the LFA relative to the HCD approach. Based on an analysis of data, three years after after
random assignment, MDRC found that the largest effects on participants were for Riverside
County’s GAIN program, a program that emphasized the LFA approach. 3 In contrast, the GAIN
participants in the three largest of the other counties in the MDRC Evaluation (Alameda, Los
Angeles and San Diego counties), that placed much greater emphasis on HDC, had much smaller
gains. 4 The LFA, or “work-first,” approach of Riverside received national (and international) acclaim for its success 5 and has become the model for welfare-to-work programs across the nation. 6
The fallacy of this conclusion stems from attributing all of the differences in results
across counties to differences in the treatment approaches used. For example, treatment effects
could vary across programs due to differences in the populations treated, in the strategies used to
assign various treatment components across that population and to differences in the economic
environments and local labor markets conditions. 7 While MDRC made clear in its reports that its
3

Among female heads of households on Aid to Families with Dependent Children (AFDC) in Riverside’s GAIN
program, the number of quarters in which recipients worked were 63 percent higher than those for the control group,
and trainees’ labor market earnings were 63 percent higher over the three-year evaluation period. Riverside
County’s GAIN program emphasized the LFA approach with tightly focused job search assistance, as well as providing participants with the consistent message “that employment is central and should be sought expeditiously and
that opportunities to obtain low-paying jobs should not be turned down.” See Hogan (1995) for details.

4

These counties experienced only a 21 percent increase in quarters of work and a 23 percent increase in earnings
relative to the outcomes for the control group members in these counties.

5

For example, the Riverside GAIN program was awarded the Harvard Kennedy School of Government’s “Innovations in American Government Award” in 1996.

6

For example, the State of California strongly encouraged all of the state’s counties to adopt the Riverside LFA approach in its GAIN programs.

7

See Hotz, Imbens and Mortimer (2005) for a systematic development and treatment of this issue. Also see Bloom,
Hill and Riccio (2005).

3

experimental design did not allow one to directly draw inferences about the differential impact of
alternative types of welfare-to-work components such as LFA and HCD, the results have been
consistently interpreted by policy makers in exactly that way. Thus, the second objective of this
paper is to use our methods to address directly whether LFA worked better than HCD based on
data for subjects in the MDRC GAIN Evaluation.
A third objective of our paper is to distinguish the short-run from the long-run effects of
LFA versus HCD training components. The formal MDRC GAIN Evaluation was based on experimental estimates of program impacts for a three-year post-randomization period. 8 Extrapolating from such short run estimates of social program impacts to what will happen in the longer
run can be misleading, as Couch (1992) and Friedlander and Burtless (1995) have noted. This is
especially true for assessing the effectiveness of HCD relative to LFA training approaches, since
HCD training components tend to be more time-intensive treatments and typically take longer to
complete relative to LFA programs. As such, there is a strong presumption that results from
short-term evaluations will tend to favor work-first programs over human-capital development
ones. 9 Estimates of program effects over a longer post-enrollment period are needed to fairly assess the relative long-run benefits of these alternative welfare-to-work strategies.
To address the above substantive concerns, we apply our methods to estimate both shortand long-term differential effects of the LFA versus HCD training components in a re-analysis of
the data from the MDRC evaluation of California’s GAIN program. We focus our analysis on
four of the six California counties (Alameda, Los Angeles, Riverside and San Diego counties)

8

An unpublished MDRC report presents estimates for the first five years after randomization.

9

A similar point is made by Mincer (1974) in his model of schooling decisions. Therein, Mincer notes that at early
ages the earnings of individuals who choose additional schooling will be lower than those who choose to go to work
at early ages, simply because attending school inhibits going to work, even if all alternative activities yield the same
present value of lifetime earnings. See also Ham and LaLonde (1996).

4

analyzed in original GAIN Evaluation 10 and estimate differential effects for the post-random assignment employment, labor market earnings, and welfare participation outcomes of participants
in this evaluation. We make use of data on these outcomes for a period of nine years after random assignment, data that was not previously available. We exploit the data for the control
groups in this Evaluation to implement the tests of some of the assumptions that justify the use of
non-experimental regression-adjustment methods. Finally, we consider the extent which inferences about the temporal patterns of training effect estimates are sensitive to post-randomization
variation in local labor market conditions. As we establish below, our re-analysis of the GAIN data leads to a substantively different set of conclusions about the relative effectiveness of LFA
versus HCD training components.
The remainder of the paper is organized as follows. In Section 2, we provide a brief description of California’s GAIN program and the original MDRC evaluation. In Section 3, we
characterize several alternative treatment effects, including average differential treatment effects
of two different treatment components, consider the conditions for their identification and discuss alternative strategies for estimating each. In Section 4, we present estimates of the effects of
being assigned to receive some training component for four of the six counties in the MDRC
GAIN Evaluation for a nine-year post-randomization follow-up period. We then present shortand long-term estimates of the average differential effects of LFA versus HCD training components using regression-adjustment methods on these data and the results for tests on control
group data that provide a partial assessment of the validity of these methods for estimating average differential treatment effects. Finally, we offer some conclusions about the implications of
our findings in Section 5.
10

We omit the two rural counties included in the original MDRC evaluation, (Butte and Tulare), because these rural
economies are quite different from the four urban counties.

5

2.

The GAIN Program and the MDRC GAIN Evaluation
The GAIN program began in California in 1986 and, in 1989, became the state’s official

welfare-to-work or Job Opportunities and Basic Skills Training (JOBS) Program, authorized by
the Family Support Act. 11 Except for female heads with children under the age of 6, all adults on
welfare were required to register in their county-of-residence GAIN program. 12 Each registrant
was administered a screening test to measure a registrant’s basic reading and math skills, with
the same test being used in all counties. Registrants with low test scores and who did not have a
high school diploma or GED were deemed “in need of basic education” and targeted to receive
HCD training components, such as Adult Basic Education (ABE) and/or English as a Second
Language (ESL) courses. Those judged not to be in need of basic education were to bypass these
basic education services and either move into LFA, such as job search assistance, or HCD, such
as vocational or on-the-job training. Decisions about which activities GAIN registrants received
were under the control of county GAIN administrators. In fact, the legislation that established the
GAIN program gave California’s 58 counties substantial discretion and flexibility in designing
their programs, including the types and mix of training components they offered to GAIN registrants. 13
MDRC conducted a randomized evaluation of the impacts and cost-effectiveness of the
GAIN program in six research counties (Alameda, Butte, Los Angeles, Riverside, San Diego,
11

The legislation that created the GAIN program represented a political compromise between two groups in the
State’s legislature with different visions of how to reform the welfare system. One group favored the “work-first”
approach, i.e., use of a relatively short-term program of mandatory job search, followed by unpaid work experience
for participants who did not find jobs. The other group favored the “human capital” approach, i.e., a program providing a broader range of services designed to develop the skills of welfare recipients. In crafting the GAIN legislation, these two groups compromised on a program that contained work-first as well as basic skills and education
components in what became known as the GAIN Program Model. See Riccio and Friedlander (1992) for a more
complete description of this model.
12

See Riccio, et al. (1989) for a more complete description of the criteria for mandated participation.

13

See Riccio and Friedlander (1992), chapter 1.

6

and Tulare). Beginning in 1988, MDRC randomly assigned a subset of the GAIN registrants in
these counties, either to an experimental group, which was eligible to receive GAIN services and
subject to its participation mandates or to a control group, which was ineligible for GAIN services but could seek (on their own initiative) alternative services in their communities. Control
group members were embargoed from GAIN services until June 30, 1993 and, for two years after this date they were allowed, but not required, to participate in GAIN. MDRC collected data
on experimental and control group members in the research counties, including background and
demographic characteristics and pre-random assignment employment, earnings, and welfare
utilization. Originally, MDRC gathered data on employment, earnings and welfare utilization, 14
for a three-year post-randomization period and reported on the findings for these outcomes in
their primary GAIN Evaluation reports. 15
Descriptive statistics and sample sizes for the participants in the MDRC evaluation in the
four counties analyzed here (Alameda, Los Angeles, Riverside and San Diego) are provided in
Table 1. We focus on GAIN registrants who were members of single-parent households on
AFDC—which are referred to as AFDC Family Group or AFDC-FG households—at the time of
random assignment. 16 Such households constitute over 80 percent of the AFDC caseload in California and the nation and almost all are female-headed. 17 As shown at the bottom of Table 1, in
14

Most of these data were obtained from state and county administrative data systems.

15

See Riccio and Friedlander (1992) and Riccio, et al. (1994). In an unpublished paper, Freedman, et al. (1996) present impact estimates for five years post-randomization period, based on additional outcomes data gathered from
administrative data sources.

16

The samples we utilize for three of the four counties (Alameda, Riverside and San Diego counties) are slightly
smaller than the original samples used by MDRC due to our inability to find records for some sample members in
California’s Unemployment Insurance Base Wage system (administered by the California Economic Development
Department) or because we were missing information on the educational attainment of the sample member. The
number of cases lost in these three counties is very small, never larger than 1.1 percent of the total sample, and does
not differ by experimental status.
17

Descriptions and results for the much smaller group of two-parent households on AFDC (AFDC-U cases) are
given in the working paper version of the paper (Hotz, Imbens and Klerman, 2000).

7

all but Alameda county, the counties assigned a larger (and varying) fraction of cases to the experimental group. Finally, we provide, in Table 1, T-statistics for the differences between experimental and control group means for the background variable. In most cases, there are no statistically significant differences in these variables by treatment status. The one exception is the year
and quarter in which cases were enrolled into the MDRC GAIN Evaluation. In particular, there
are rather large and statistically significant differences in the proportions of experimental and
control cases enrolled by quarter in Los Angeles and San Diego counties. 18 These were the result
of changes in the rates of randomization to the control status over the period in these counties as
MDRC attempted to meet targeted numbers of control cases in these counties.
Table 1 reveals notable differences in the demographic and pre-randomization characteristics of the cases enrolled in the GAIN registrants across counties. These differences stem from
two factors. First, the composition of the AFDC caseloads varies across counties. Second, the
strategies that counties adopted for registering participants from their existing caseloads into
GAIN activities also varied. The GAIN programs in Riverside and San Diego counties sought to
register all welfare cases in GAIN while the programs in Alameda and Los Angeles counties focused on long-term welfare recipients. For example, Alameda County, which began its GAIN
program in the third quarter of 1989, first registered its long-term cases and then registered cases
that had entered the AFDC caseload more recently. The GAIN program in Los Angeles County
initially only registered those cases that had been on welfare for 3 consecutive years. The consequences of these differences in selection criteria can be seen in Table 1. In Alameda and Los Angeles, over 95 percent of the cases had been on welfare a year prior to random assignment; in
San Diego and Riverside, fewer (for some cells much fewer) than 65 percent had been.
18

There are smaller discrepancies between fractions of experimentals and controls by year and quarter in Riverside
County.

8

These differences in selection criteria also contributed to substantial differences in the
employment histories and individual characteristics of the registrant populations across these
four counties. As shown in Table 1, the registrants in Alameda and Los Angeles counties had, on
average, much lower levels of earnings prior to random assignment relative to those in Riverside
and San Diego. Furthermore, the registrants in Alameda and Los Angeles were, on average,
older, had lower levels of educational attainment, and were more likely to be assessed as “in
need of basic education” when they entered the GAIN program than the average registrants in
Riverside and San Diego. The fact that Alameda and Los Angeles counties focused on its “hard
to treat” cases is a stark example of how the caseload composition within the GAIN experiment
varied across counties and why it is implausible that all of the differences across counties in
treatment effects are solely due to the various treatment components.
The counties in the GAIN Evaluation also differed with respect to the conditions in the
labor market immediately prior to random assignment and these differences also may account for
the across-county differences in the Evaluation subjects displayed in Table 1. Figures 1-4 display
the time series of two sets of measures of labor market conditions for each of the four counties in
the GAIN Evaluation. Figure 1 plots the county-level ratio of total employment to the adult
population and Figure 2 displays the average annual earnings per worker for those employed.19
These measures provide indicators of the across-county and over time differences in the labor
markets for the four counties in the years prior to random assignment. Figures 3 and 4 display the
corresponding employment-to-population ratios and average annual earnings per work for those
employed in the retail trade sector, a sector of the economy in which many low-skilled workers
19

These county-level measures were constructed from data from the Regional Economic Information System
(REIS) maintained by the Bureau of Economic Activity (BEA) in the U.S. Department of Commerce. We note that
Hoynes (2000) uses versions of both of these measures in her analysis of the effects of local labor market conditions
on welfare spells for the California AFDC caseload during the late 1980s and early 1990s. See her paper for a discussion of these and other county-level measures of local demand conditions.

9

are employed. 20 In the periods prior to random assignment, overall employment and employment
in retail trade were increasing in all four counties, although employment had begun to stagnate in
many of the counties. Furthermore, one notes substantial differences across the four counties in
these ratios, with Riverside county having a much lower total employment to adult population ratio than the other three counties. 21 Over this same period, average annual earnings per worker
was increasing in all but Alameda county (Figure 2), while earnings per worker in the retail trade
sector was declining (in real terms) in all four counties (Figure 4). Moreover, one sees that overall earnings, as well as earnings in the retail sector, were higher in Alameda and Los Angeles
counties relative to Riverside and San Diego counties. Towards the end of the next section, we
shall comment further on the post-randomization trends in these Figures.
Finally, as we noted above, the four analysis counties in the GAIN Evaluation differed in
the way they ran the programs and in the training components they emphasized. In Table 2, we
display the proportions of GAIN registrants in the four analysis counties that participated in various training components during the period in which subjects were enrolled in the MDRC GAIN
Evaluation. 22 One can see that Riverside county placed less of its GAIN registrants in HCD
training components than did the administrators of the GAIN programs in the other four counties
during the period of enrollment into the MDRC Evaluation. This is especially true relative to the
proportions of GAIN registrants enrolled in the MDRC Evaluation that were deemed “In Need of
Basic Skills,” presumably the group in greater need of HCD training components. (The propor-

20

Another sector of the economy which employs low-skilled workers is the service sector. Based on measures comparable to those in Figures 3 and 4, similar trends and differences across counties were found for this sector as those
for the retail trade sector.

21

This difference reflects, in part, the fact that many people residing in Riverside county commute to other counties,
especially Los Angeles, for their employment compared to residents of the other four counties.
22

The rows in boxes in this table show the quarters in which the random assignment of registrants into the MDRC
experimental evaluation was conducted for each of the four counties.

10

tions of these groups, by year/quarter of enrollment into the MDRC Evaluation, are found in the
last column of Table 2.) As a crude indicator of the relationship between HCD services relative
to those registrants in need of basic skills, one can take the ratio of the last two columns of Table
2. By this measure, the GAIN programs in San Diego, Los Angeles and Alameda counties appear
to provide HCD training services roughly in a 1-to-1 proportion with the fraction of registrants in
need of basic skills in their counties. In contrast, the corresponding proportion for Riverside
county’s GAIN program is 2-to-3.
The estimates in Table 2 provide a clear indicator of what was a major finding of the
MDRC GAIN Evaluation, namely that Riverside’s GAIN program had a decidedly “work-first”
orientation, especially relative to the other three counties in the Evaluation that we analyze
here. 23 In contrast, program staff in the other research counties placed less emphasis on getting
registrants into a job quickly. For example, Alameda’s GAIN managers and staff “believed
strongly in ‘human capital’ development and, within the overall constraints imposed by the
GAIN model’s service sequences, its staff encouraged registrants to be selective about the jobs
they accepted and to take advantages of GAIN’s education and training to prepare for higherpaying jobs.” 24

23

There were other indicators of Riverside’s emphasis on getting GAIN registrants quickly into jobs and on using
LFA relative to HCD training components. For example, Riverside staff required that their registrants that were enrolled in basic skills programs continue to participate in Job Club and other job search activities. In a survey of program staff conducted by MDRC at the time of its evaluation, 95 percent of case managers in Riverside rated getting
registrants into jobs quickly as their highest goal while fewer than 20 percent of managers in the other research
counties gave a similar response. In the same survey, 69 percent of Riverside case managers indicated that they
would advise a welfare mother offered a low-paying job to take it rather than wait for a better opportunity, while
only 23 percent of their counterparts in Alameda county indicated they would give this advice. See Riccio and Friedlander (1992) for further documentation of the differences in distribution of training components and other features
of the full set of six counties in the MDRC GAIN Evaluation. As Ricco and Friedlander (1992) concluded from their
study of the implementation of GAIN programs by the various counties in the MDRC Evaluations, “What is perhaps
most distinctive about Riverside’s program, though, is not that its registrants participated somewhat less in education
and training, but that the staff’s emphasis on jobs pervaded their interactions with registrants throughout the program.” (Riccio and Friedlander, 1992, p. 58)
24

See Riccio, et al. (1994), p. xxv.

11

3.

Alternative Treatment Effects and Estimation Strategies
In this section, we consider the identification of alternative treatment effects and strate-

gies for estimating them. We begin with a review of binary treatment effects which characterize
the effect of receiving some training component for enrollees in a welfare-to-work program.
Such effects were the focus of the experimental design of the MDRC GAIN Evaluation. We then
define and consider the estimation of average differential treatment effects (ADTE). The latter
effects are the focus of our re-analysis of the GAIN data. We examine the identification of and
strategies for estimating ADTEs when the econometrician has information on which treatment
components each subject was assigned and when such subject-level information is not known.
(The latter case is true for the MDRC GAIN Evaluation data we re-analyze and is true for many
data sources used to evaluate training programs.) Finally, while we show that experimental data
on subjects that are randomly assigned to some versus no treatment component is not sufficient
to identify (or consistently estimate) ADTEs, we show how such data can be exploited to assess
the validity of non-experimental methods for estimating the ADTEs.
3.1 Alternative Average Treatment Effects
Let Di be an indicator of the program/location of a training program in which subject i is
enrolled (registered). In the MDRC GAIN Evaluation, D denotes a county-run welfare-to-work
program, d. Let s denote the number of periods (years) since a subject enrolled in a welfare-towork program. Let Ti denote the training (treatment) component to which subject i is assigned,
with Ti ∈ {0,1,..., k ,..., K } and where Ti = 0 denotes the null (no) treatment component. Let Ti

denote the assignment of the ith subject to some treatment component, i.e., Ti = 1{Ti ≥ 1} . Finally,

Let Yis (W = w) denote subject i’s potential outcome as of s periods after enrollment that is asso-

12

ciated with the subject being assigned to treatment W, where W=T or T . Thus, Yis (T = 0) is the
potential outcome associated with the receipt of no treatment, Yis (T = 1) is the potential outcome
associated with the assignment to some treatment component and Yis (k ) ≡ Yis (T = k ) is the potential outcome associated with the assignment to treatment component k.
The focus of the MDRC GAIN Evaluation, and many other training evaluations, was on
estimating the average treatment effect on the treated (ATET) associated with assignment to
some treatment component in program/location d. This treatment effect is defined as

α sd ≡ E (Yis (1) − Yis (0) Ti = 1, Di = d )
= E ( Δ is Ti = 1, Di = d )

,

(1)

where Δis is subject i’s “gain” in outcome Y from being assigned to some training component. 25
Analogously, the average treatment effects associated with assignment to treatment component k
for those assigned to this component is given by

α sd (k ) ≡ E (Yis (k ) − Yis (0) Ti = 1, Di = d )
= E ( Δ is (k ) Tis = 1, Di = d )

(2)

As noted in Hotz, Imbens and Mortimer (2005), α sd may differ across programs/locations
(d), due to differences in: (a) the populations treated; (b) treatment heterogeneity (differences in
the distribution of treatment components); and/or (c) differences in economic conditions (“macro
effects”). In the case of treatment heterogeneity, one typically wishes to distinguish between the
impacts of alternative treatment components—such as the LFA and HCD training components—
in order to isolate this source of differences in α sd across programs and to isolate why some pro25

One also can define versions of α sd that condition on some set of exogenous variables, X,

α sd ( X ) ≡ E (Yis (1) − Yis (0) Ti = 1, D i = d , X i )
= E ( Δ is Ti = 1, D i = d , X i )

.

Conditional versions of the other treatment effects defined in this subsection can be defined similarly.

13

grams are more effective than others. As noted in the Introduction, and as will be documented in
Section 4, the impacts of the Riverside GAIN program were markedly different from, and more
effective than, those in the other counties of the MDRC GAIN Evaluation. Accordingly, consider
the average differential treatment effect (ADTE) of two treatment components, k and k′, among
those who are treated (i.e., those assigned to receive some treatment) which is defined as:

γ s (k , k ′) ≡ E (Yis (k ) − Yis (k ′) Ti = 1)
= E ( Δ is (k ) − Δ is (k ′) Ti = 1)

,

(3)

where the second equality in (3) follows from the definition of Δis(j) in (2). Note that γ s (k , k ′) is
defined for subjects assigned to receive some treatment, i.e., for subjects characterized by Ti = 1.
For reasons that will be made clear below, conditioning on this expansive set of subjects is appropriate for our re-analysis of the MDRC GAIN Evaluation data. Imbens (2000) and Lechner
(2001) consider alternative definitions of differential treatment effects, including conditioning on
those subjects who would otherwise receive either treatment components k or k′. In general, differences in such conditioning imply different treatment effects. Also note that we have not conditioned (3) on a particular program/location (d), as our interest is in estimating the differential
effects of treatment components that are available—and comparable—across county welfare-towork programs included in the MDRC GAIN Evaluation.
3.2 Identification and Estimation of α sd

As is well understood, the identification (and thus consistent estimation) of α sd in (1) requires additional conditions to be met. In general, non-random and selective assignment of potential trainees to training programs and/or the use of non-comparable comparison groups to
measure Y(0) gives rise to problems in identifying (and obtaining unbiased estimates of) such

14

treatment effects. 26 In the context of the MDRC GAIN Evaluation, the identification problem is
“solved by design” in that this evaluation randomly selected a group of the GAIN registrants to a
control group in which subjects, who would otherwise have been assigned to some welfare-towork activity, were embargoed from receipt of treatment. That is, design of this evaluation assured that the following condition holds:
Ti ⊥ (Yis (0), Yis (1) ) Di = d ,

(RANDOM ASSIGNMENT)

(C-1)

for all d, where z ⊥ y denotes that z is (statistically) independent of y. Condition (C-1) insures
the identification of α sd as it implies that
E (Yis (0) Ti = 1, Di = d ) = E (Yis (0) Ti = 0, Di = d ) ,

(C-1′)

i.e., the mean value of Y(0) in period s for those who receive some treatment component (T = 1)
in county d would be equal to the mean of observed outcomes for control group members (T = 0)
in the same period and county. As a result, (C-1) implies that the ATET associated with program/location d is identified by

α sd = E (Yis (1) Ti = 1, Di = d ) − E (Yis (0) Ti = 0, Di = d )

(4)

and can be consistently estimated by using sample analogues to the conditional expectations in
(4), i.e., Ys (t ) =

∑

i∈{i Ti = t}

Yis N t for all s, where Nt is the sample size for the Ti = t group, t = 0,1. In

Section 4, we present county-specific estimates of the ATET for a range of post-randomization
outcomes for each of the nine years after random assignment.
3.3 Identifying Average Differential Treatment Effects

We next consider the identification (and estimation) of the average differential treatment
effect, γ s (k , k ′) . For now, we assume that we know (and can condition on) the treatment compo-

26

See, for example, Heckman, LaLonde and Smith (1999) for a survey of the evaluation literature.

15

nents to which each subject was assigned. Below, we consider the case in which a subject’s
treatment component assignment is unknown. Random assignment of subjects to Ti = 1 or 0
[Condition (C-1)], the condition that holds in the MDRC GAIN Evaluation, is not sufficient to
identify ADTEs. To see why, consider the following characterization of the differences in expected potential outcomes for treatment components, k and k′:

(

) (

E Yis (k ) Ti = k , Di = d − E Yis (k ′) Ti = k ′, Di = d ′

(

)

) (
)
= { E ( Δ (k ) T = 1, T = k , D = d ) − E ( Δ (k ′) T = 1, T = k ′, D = d ′ )}
+ { E (Y (0) T = 1, T = k , D = d ) − E (Y (0) T = 1, T = k ′, D = d ′ )} ,

= E Yis (0) + Δ is (k ) Ti = k , Di = d − E Yis (0) + Δ is (k ′) Ti = k ′, Di = d ′
is

is

i

i

i

i

i

is

i

is

i

i

i

(5)

i

i

i

for all k, k′, k ≠ k′, and all d, d′. While (C-1) implies that E (Yis (0) Ti = 1, Di = d ) =

E (Yis (0) Ti = 0, Di = d ) , it does not imply that the last term in braces in (5) equals zero, even for
the same program/location (i.e., d = d′). Furthermore, (C-1) implies nothing about the first term
in braces. As such, the mean difference between the outcomes of those receiving treatment component k and those receiving k′ does not, in general, equal γ s (k , k ′) . Additional assumptions are
required. In particular, we require:

(

) (

)

E Yis (0) Ti = 1, Ti = k , Di = d − E Yis (0) Ti = 1, Ti = k ′, Di = d ′ = 0 ,

(A-1)

i.e., there is no difference in Y(0), the no-treatment outcome, for subjects that were assigned to
treatment components k and k′, in a given program/location, and

(

)

(

)

E Δ is (k ) Ti = 1, Ti = k , Di = d = E Δ is (k ) Ti = 1, Ti = k ′, Di = d ′ = E ( Δ is (k ) Ti = 1) , (A-2)
for all k, k′, k ≠ k′, and all d, d′, i.e., the expected gross treatment effects for treatment component
k is the same for those assigned to components k and k′. 27 Given (A-1) and (A-2), it follows that
27

We ignore the possibility that both (A-1) and (A-2) are violated with off-setting biases.

16

(

the difference between E Yis (k ) Ti = k , Di = d

)

(

)

and E Yis (k ′) Ti = k ′, Di = d ′ in (5) is equal to

γ s (k , k ′) . Note that potentially weaker versions of (A-1) and (A-2) in which these assumptions
hold only within a program/location (d = d′) could be assumed, although then only program-specific γ s (k , k ′) ’s would be identified. In short, the random assignment design used in evaluations,
such as the MDRC GAIN Evaluation, is not sufficient to identify ADTEs.
In order to secure identification (and a consistent estimator) of γ s (k , k ′) , we consider the
use of non-experimental methods which imply that (A-1) and (A-2) hold under some set of circumstances. In our discussion, we describe the use of statistical matching methods in conjunction
with data in which subjects are randomly assigned to receive some treatment or a control group.
Matching methods assume that by controlling (adjusting) for a set of pre-treatment characteristics, Zi, in a non-parametric way, conditional versions of (A-1) and (A-2) will hold. 28 More precisely we assume that there exists a vector, Zi, such that: 29
(UNCONFOUNDEDNESS) Y (0), Y (1),..., Y (k ),..., Y ( K ) ⊥ T Z , ∀k and ∀d .

(C-2)

That is, the potential outcomes associated with treatment components are independent of the assignment mechanism for these components conditional on Z. It follows from (C-2) that

(

) (

)

(A-1′)

) (

)

(A-2′)

E ⎡ Yis (0) Ti = 1, Ti = k , Di = d − E Yis (0) Ti = 1, Ti = k ′, Di = d ′ Z i ⎤ = 0
⎦
Z ⎣

and

(

E ⎡ Δ is (k ) Ti = 1, Ti = k , Di = d − E Δ is (k ) Ti = 1, Ti = k ′, Di = d ′ Z i ⎤ = 0 ,
⎦
Z ⎣

for all k, k′, k ≠ k′, and all d, d′. It follows that assumptions (A-1′) and (A-2′) imply that the dif-

28

See Rubin (1973a, 1973b, 1977, 1979) for the initial formalization of the use of matching methods to reduce bias
in causal inference using non-experimental data. See also Heckman, Ichimura, and Todd (1997, 1998a) for further
refinements on these methods.

29

See Imbens (2000) and Lechner (2001) for formal treatments of matching methods in the context of multiple treatments.

17

ference

between

the

(

conditional

(on

Z)

versions

of

(

E Yis (k ) Ti = k , Di = d

)

and

)

E Yis (k ′) Ti = k ′, Di = d ′ identify γ s (k , k ′) and justify the use of matching methods—and, in certain cases, parametric regression techniques—to (consistently) estimate this ADTE.
Condition (C-2)—and, thus, (A-1′) and (A-2′)—is not directly verifiable, at least not for
situations in which treatment components are not randomly assigned. As such, matching methods
are inherently more controversial than reliance on a properly designed random assignment experiment. Nonetheless, recent studies by Dehejia and Wahba (1999), Heckman, Ichimura, and
Todd (1997, 1998a), and Hotz, Imbens and Mortimer (2005) suggest that such adjustments, with
sufficiently detailed pre-treatment characteristics, can produce credible non-experimental estimates of average treatment effects.30 Here we extend the use of these methods to estimating the
differential effects of alternative treatment components.
The availability of data for a randomly assigned control group that receives no treatment,
such as is the case with the MDRC GAIN Evaluation, does provide scope for assessing the validity of assumption (A-1′) in the case where there are only two treatment components, k and k′.
In this case, it follows that (C-1) can be written as
E (Yis (0) Ti = 0, Di = d ) = E (Yis (0) Ti = 1, Di = d )

(

)

(

)

= E Yis (0) Ti = 1, Ti = k , Di = d Pdk + E Yis (0) Ti = 1, Ti = k ′, Di = d ⎡⎣1 − Pdk ⎤⎦

(

) (
)

)

= ⎡ E Yis (0) Ti = 1, Ti = k , Di = d − E Yis (0) Ti = 1, Ti = k ′, Di = d ⎤ Pdk
⎣
⎦
+ E Yis (0) Ti = 1, Ti = k ′, Di = d ,

(

(

(C-1′′)

)

for all d, where Pdk ≡ Pr Ti = k Di = d is the proportion of subjects receiving treatment compo-

30

See Smith and Todd (2005) for a critical re-analysis of Dehejia and Wabba (1999). Smith and Todd conclude that
matching methods can be used to estimate simple treatment effects, but care must be taken as to what pre-treatment
characteristics are used in the matching.

18

nent k in program/location d. It follows from (A-1′) [and (C-1)] that the term in square brackets
after the last equality in (C-1′′) is equal to 0, for all d. That is, the mean of Y for the control group
should not depend on (vary with) Pdk . Thus, to test (A-1′), one can regress the outcomes, Y, on
Pdk , exploiting the variation in the mix of treatment components across programs/locations, and
where the regression conditions on Zi, either non-parametrically using matching methods or parametrically using regression methods, and test whether the coefficient on Pdk equals zero for all d.
We implement this test in our empirical analysis to assess the validity of (A-1′) with the MDRC
GAIN Evaluation data. 31
A similar test of the validity of (A-2′) is not available. Thus, this assumption must be
maintained when using matching methods to estimate ADTEs. Nonetheless, the validity of such
methods in the estimation of ADTEs is more plausible, although not guaranteed, if (A-1′) is
shown to hold in the data.
Until now, we have assumed knowledge of the treatment component assignments ( Ti ) to
each subject who actually receives treatment. This is not the case for the MDRC GAIN Evaluation data that we use to analyze the differential effects of LFA and HCD treatment components.
Individual-level treatment component assignments are unknown in these data. Lack of treatment
component assignment information is a common situation in other data sources used to evaluate
the effects of training programs. However, one may have information on the proportions of subjects that received various treatment components ( Pdk ) for particular programs. For the GAIN
programs in California, we have information on these proportions for the four counties we ana-

31

For other examples of assessing the validity of non-experimental methods with data from experimental data, see
Lalonde (1986), Rosenbaum (1987), Heckman and Hotz (1989), Dehejia and Wahba (1999), Heckman, Ichimura,
Smith and Todd (1997, 1998a), Hotz, Imbens and Mortimer (2005) and Smith and Todd (2005).

19

lyze from the MDRC GAIN Evaluation. In fact, we have it at the quarterly level for the quarters
in which GAIN registrants were randomly assigned to treatment or control status.
As first noted by Heckman and Robb (1985), and subsequently extended by Mitnik
(2004b) to the case of differential treatment effects, estimation of causal effects in the case of
unknown treatment status at the subject level can still proceed with data on treatment component
probabilities under certain assumptions and with sufficient variation in these probabilities across
programs and/or subgroups. Assumptions (A-1′) and (A-2′)—and, thus, (C-2)—are sufficient to
allow one to estimate γ s (k , k ′) with only data on treatment assignment proportions, rather than
individual-level treatment assignment status, since conditional on Z, the identification (consistent
estimation) of γ s (k , k ′) only requires identifying (consistently estimating) the mean differential
of outcomes for trainees who receive treatment components k and k′. Furthermore, we exploit the
variation in Pdk across counties, as well as across entry cohorts, to consistently estimate these
conditional mean differences.
3.4 Estimating Average Differential Treatment Effects

In the empirical analysis presented below, we make use of parametric regression methods, rather than non-parametric matching techniques, to condition on the Z’s as implied by assumptions (A-1′) and (A-2′) 32 to estimate the average differential treatment effect of the LFA
versus HCD treatment components. 33 For sake of clarity, we need to augment the notation used
above. Let Yis,dc denote the outcome of GAIN registrant i for post-randomization period s that is

32

While not presented herein, we also used non-parametric matching techniques, controlling for the same set of X’s
listed above, to estimate the differential treatment effects between Riverside and the various comparison counties.
The estimates, especially the inferences drawn, are quite similar to the regression-based estimates reported below.
33

See Hirano, Imbens and Ridder (2003) for a discussion of efficient estimation of average treatment effects using
propensity score methods. Also see Abadie and Imbens (2006) who characterize the asymptotic properties of matching estimators for average treatment effects.

20

located in county d and entered the MDRC Evaluation in quarter c; Ti,dc = 1 if this GAIN registrant located in county d and from entry cohort c was (randomly) assigned to the experimental
group and equal to zero otherwise; Ti ,dc denote the treatment component to which a GAIN registrant is assigned, where the components in the GAIN context are A for the LFA treatment component and h for the HCD treatment component; Zi,dc denote the vector of pre-randomization
characteristics for this subject; and PdcA denote the proportion of trainees—those for which Ti,dc =
1—that were assigned the LFA treatment component ( Ti ,dc = A ) component.
One potential strategy for estimating γ s (A, h) would be to estimate the following regression model using only data on GAIN registrants in the experimental group (Ti,dc = 1):
Yis , dc = β 0 s + γ s (A, h) PdcA + β1′s Z i ,dc + ε is , dc ,

(6)

where εis,dc is a stochastic disturbance assumed to have mean zero and the coefficient on PdcA is
the ADTE of interest, γ s (A, h) . (The elements in Zis,dc are listed in the Notes to Table 5.) Estimating (6) with the experimentals subsample will generate consistent estimates of γ s (A, h ) if both assumptions (A-1′) and (A-2′) hold and that the population regression function for Yis,dc is linear in
PdcA and Zi. We present estimates of γ s (A, h) based on only using data for the experimental group
of the MDRC GAIN Evaluation in Table 6 below.
To test assumption (A-1′), one can estimate the regression specification in (6) using data
for the subsample of controls in the four counties of the MDRC GAIN Evaluation and then test
the hypothesis that γ s (A, h) = 0. We present results for this test in Table 4 below. A potentially
more rigorous version of this test allows for the possibility that γ s (A, h) varies across counties,
i.e., estimating the following regression specification in place of (6),

21

Yis ,dc = β 0 s +

∑

j∈{ A, L , R , S }

γ sj (A, h) PjcA I i j + β1′s Z i ,dc + ε is ,dc ,

(6′)

where I i j denotes the indicator function for Di = j and the four values for j are A for Alameda
county, L for Los Angeles county, R for Riverside county and S for San Diego county. In this
case, we test the null hypothesis that γ sA(A, h) = γ sL (A, h) = γ sR (A, h) = γ sS (A, h) = 0, where now
the alternative hypothesis is that γ sd (A, h) can be non-zero in any county. We also present results
from this second test of (A-1′) in Table 4 below.
In one sense, finding that we cannot reject the null hypotheses in the above tests justifies
the maintenance of assumption (A-1′), and, thus, the reliance on the estimator of γ s (A, h) derived
from estimating (6) with data for registrants that were randomly assigned to the experimental
group in the MDRC GAIN Evaluation. But, as is always true, the results from such tests are subject to estimation error. That is, the power of any test may not be sufficient to avoid Type II errors, i.e., failing to reject null hypotheses when they are false. To guard against this possibility,
we also present results from a “difference-in-differences” (DID) estimator of γ s (A, h) that relies
on using data for experimental and control groups in estimation. In particular, this DID estimator
of γ s (A, h) is formed by estimating the following regression function: 34
Yis ,cd = β 0 s + β1s PdcA + β 2 sTi ,dc + γ s (A, h) PdcA Ti ,dc + β 3′s Z i ,dc + β 4′s Z i ,dcTi ,dc + ν is ,dc ,

(7)

Using (7) to estimate γ s (A, h) with data for the experimental and control groups in the MDRC
GAIN Evaluation still relies on assumptions (A-1′) and (A-2′) to hold but allows the data on
“controls” to empirically adjust for across-program differences in populations and treatment
component assignment mechanisms to help isolate a consistent estimate of γ s (A, h) . Furthermore,
the DID estimator allows for any estimation error that may affect the tests of (A-1′) described
34

Non-parametric versions of (7), based on matching methods, also are possible.

22

above to explicitly affect the precision of the estimate of γ s (A, h) , which is not the case for the
estimator of γ s (A, h) based solely on data for experimentals. Accordingly, we view the DID estimator as a more “conservative” method for estimating γ s (A, h) . Estimates based on this DID estimator are presented in Table 5 below.
3.5 Post-Randomization Variation in Labor Market Conditions

To this point, we have implicitly assumed that temporal variation in treatment effects reflects the profile of “returns” to training. For example, the relative effects of receiving vocational
training course received at s = 0 may decline over time as skills acquired in such a course depreciate. How rapidly the effects of alternative treatments decline with s, if they decline at all, can
provide important insights into the long-term effectiveness of alternative training strategies. But,
treatment effects also may vary over time due to post-training changes in environmental factors,
such as local labor market conditions. Recall that Yis,dc(k), the outcome of the ith subject residing
in county d and in GAIN entry cohort c that occurred s periods after receiving treatment k, can be
written as
Yis ,dc (k ) = Yis ,dc (0) + Δ is ,dc (k ) ,

(8)

where Yis,dc(0) is the potential outcome associated with the null treatment and Δis,dc(k) is the gain
in Y from receiving treatment k relative to the null treatment. Let Mds denote the labor market
conditions that prevail in county d in the calendar period corresponding to s. Suppose that labor
market conditions affect post-training outcomes. For example, a trainee’s probability of being
employed in period s (s > 0) depends with the extent of the local demand for labor in that period.
We represent this dependence by rewriting (8) as follows
Yis , dc (k , M ds ) = Yis ,dc (0, M ds ) + Δ is ,dc (k , M ds ) .

(9)

The right-hand side of (9) allows both the potential outcome for the null treatment and the gain

23

associated with treatment k to vary with Mds.
The dependence of treatment effects on labor market conditions hinges on whether
Δis,dc(k) varies with Mds. Allowing Yis,dc(0) to depend on Mds need not compromise the ability to
identify or estimate labor market invariant treatment effects so long as Δis,dc(k) is independent of
Mds. If the latter condition holds, evaluation data in which all treatments, including a null treatment, are randomly assigned can be used to generate unbiased estimates of Yis,dc(0,Mds) and
Δis,dc(k), for all k, and, thus, unbiased estimates of labor market invariant treatment effects. In the
absence of data with randomly assigned treatments, additional conditions, such as (C-2) and/or
(A-1′) and (A-2′), would be required to obtain consistent estimates of labor market invariant
treatment effects.
However, if Δis,dc(k) does vary with Mds, data for which treatments are randomly assigned
or for which an unconfoundedness condition holds will not be sufficient to isolate (identify) labor market invariant treatment effects. In this case, all one can identify non-parametrically is
Δis,dc(k,Mds) which implies that average treatment effects will, in general, depend on the distribution of post-training labor market conditions, both across localities and over time.
To explore the potential importance of heterogeneity in γ s (A, h) with respect to posttreatment labor market conditions, we estimate the following modified version of the DID estimating equation in (7):
Yis ,cd = δ 0 s + δ1s PdcA + δ 2 sTi ,dc + γ s 0 (A, h) PdcA Ti ,dc + δ 3′s Zi ,dc + δ 4′s Zi ,dcTi ,dc
+ θ1′M ds + θ 2′M dsTi ,dc + θ3′M ds PdcA Ti ,dc + υis ,dc

,

(10)

which include interactions of a vector of county-specific, post-training labor market conditions,
Mds, with Ti,dc and PdcA Ti ,dc . The specification of the interactions of local labor market conditions
with the differential effects of LFA versus HCD training in (10) is somewhat arbitrary. However,

24

it does allow us to examine the possible dependence of treatment effects on Mds by testing the
significance of the interactions of Mds with Ti,dc and PdcA Ti ,dc . Moreover, the estimates of γ s 0 (A, h)
based on (10) provide a measure of the differential effects of LFA versus HCD training components net of across time and across county differences in labor market conditions. We present the
latter estimates in Tables 5 and 6 below.
Adjusting for post-random assignment labor market conditions may be important in the
context we analyze. The four counties in the MDRC GAIN Evaluation that we analyze experienced notable changes in labor market conditions over the nine-year post-randomization period.
Moreover, there are notable differences in these conditions across counties over this period. Such
differences are evident in Figures 1-4, which display, in addition to pre-random assignment values, county-specific trends in four different measures of labor market conditions over the 9-year
post-random assignment period. As shown in Figure 1, the employment rates for all sectors of
the economy declined markedly in the first three to five years after random assignment in each of
the four counties we analyze and did not recover until years 6 through 9 after random assignment. This temporal pattern in employment reflects the recession that California experienced in
1990 and 1991 and the State’s economic recovery in the latter half of the 1990s. A similar pattern characterized the employment in the State’s retail trade sector over the post-randomization
period (Figure 3) with one notable exception, Riverside county, where retail trade employment
grew steadily throughout the post-randomization period at an average annual rate of one percent.
Over the same period, there was little change in the average real earnings per worker of
all workers in the four counties, although Alameda county experienced an average annual improvement per year in earnings per worker of almost one percent and Riverside county experienced a slight decline throughout the post-randomization period (Figure 2). The earnings per

25

worker in the retail trade sector (Figure 4)—a sector which employs a sizeable fraction of lowskilled workers—steadily declined over the first 5-6 years after random assignment and showed
some recovery after year 6, especially in Alameda county. We explore whether these across
county and temporal differences in the labor market conditions affected the temporal patterns in
the unadjusted estimates of the differential treatment effects of LFA versus HCD training on the
labor market outcomes of enrollees in the MDRC Gain Evaluation.
4.

Re-Analyzing the Effects of the California GAIN Welfare-to-Work Program, the
MDRC Evaluation and GAIN Evaluation Counties

4.1 Estimates of Nine-Year, County-Specific GAIN Impacts

In this section, we present estimates of the short- and longer-run impacts of being assigned to some GAIN training component ( α sd ) for AFDC-FG derived from the county-specific
experiments of the MDRC GAIN Evaluation. 35 We present impact estimates for three different
outcomes: (1) ever employed during year; (2) number of quarters worked per year; and (3) annual labor market earnings. 36 Mean differences between the experimental and control groups for

35

In a previous version of this paper, we examined the average (and differential) treatment effects for an additional
set of outcomes and for other subgroups of the caseloads for the four counties. In particular, we also examined the
treatment effects on two measures of post-randomization welfare participation, namely, whether the registrant received AFDC benefits—or benefits from AFDC’s successor program, the Temporary Assistance to Needy Families
(TANF) program, that began in California in 1998—during the year; and the number of quarters in the calendar year
that she received AFDC/TANF benefits For these outcomes and those for employment and earnings, we also generated treatment effect estimates separately for AFDC-FG cases determined to be in need and not in need of basic
education.
The
results
for
these
additional
analyses
can
be
found
at
www.econ.ucla.edu/hotz/GAIN_extra_results.pdf.
36

The employment and earnings outcomes were constructed with data from the State’s UI Base Wage files provided
by the California Employment Development Department (EDD). These data contain quarterly reports from employers on whether individuals were employed in a UI-covered job and their wage earnings for that job. These quarterly
data were organized into four-quarter “years” from the quarter of enrollment in the MDRC GAIN evaluation. The
“Ever Employed in Year” outcome was defined to be = 1 if the individual had positive earnings in at least one quarter during that year and = 0 otherwise. The “Annual Earnings” outcome was the sum of the four-quarter UI-covered
earnings recorded for an individual in the Base Wage file. All income variables were converted to 1999 dollars using
cost-of-living deflators.
The AFDC/TANF variables were constructed using data from the California statewide Medi-Cal Eligibility Data
System (MEDS) files, which contain monthly information on whether an individual received AFDC (before 1998)
or TANF (starting in 1998) benefits in California during a month. These monthly data were organized into 3-month

26

3-year averages of these outcomes are found in Table 3. As noted above, MDRC has published
such estimates for these outcomes for the first 3 years of post random assignment data and released corresponding estimates based on 5 years of post-random assignment data in a working
paper. 37 While the actual estimates presented in Table 3 are similar to the MDRC 5-year results,
they differ slightly due to slight differences in the samples used and, more importantly, the use of
a different “dating” convention when calculating the measured outcomes. 38 Given that these
shorter-term estimates have been thoroughly discussed in MDRC publications, we focus most of
our discussion on the longer-term impacts for 5 through 9 years after random assignment.
Consider first the estimated GAIN impacts on employment outcomes. Regardless of
whether one uses annual employment rates or the number of quarters employed in a year, the estimated impacts of Riverside’s program are consistently larger, and more likely to be statistically
significant, compared to the effects for the other three counties over the first three years after
random assignment. Over this period, the GAIN registrants in Riverside had annual employment
rates that were, on average, 13.6 percentage points (39 percent) higher than members of the control group and worked 0.43 more quarters per year (48 percent) higher than did control group
members. The employment impacts of the GAIN programs in the GAIN programs of the other
three counties are considerably smaller in magnitude and often are not statistically significant.
This apparent relative success of the Riverside GAIN training components in improving the em-

“quarters” from the quarter of enrollment in the MDRC GAIN evaluation and then organized into “years” since enrollment, as was done with the employment and earnings data. The “Ever Received AFDC/TANF Benefits in Year”
variable was defined to be = 1 if the individual received AFDC or TANF benefits in at least one month during that
year and = 0 otherwise.
37

See Riccio, et al. (1994) for 3-year impact estimates and Freedman, et al. (1996) for estimates based on five years
of follow-up data.
38

In their analysis, MDRC defined the first year of post-random assignment to be quarters 2 through 5, year two as
quarters 6 through 9, etc. In our analysis, we define year one as quarters 1 through 4, year two as quarters 5 through
8, etc. This difference in definitions results in relatively minor differences between our years 1 through 5 estimates
relative to those produced by MDRC.

27

ployment outcomes of its registrants contributed to why this program, and its work-first orientation, has been heralded nationally as a model welfare-to-work program.
In the longer run, however, the impacts on employment for the Riverside GAIN program
diminished in magnitude and in statistical significance. In years 4 through 6 after random assignment, Riverside’s GAIN registrants experience a 6.9 percentage point annual average gain in
annual rates of employment (down from 13.6 percentage points) and 0.25 quarters worked (down
from 0.43 quarters) over their control group counterparts. For years 7 through 9, the Riverside
GAIN registrants have an average annual gain of only 1.5 percentage points in annual rates of
employment and 0.08 quarters worked per year relative to the control group and these latter impacts estimates are no longer significantly different from zero. 39 The employment effects of the
GAIN programs in Alameda and San Diego also decline in magnitude and statistical significance
and the impacts attributable to GAIN in these counties remain substantially smaller than those
for Riverside. In contrast, the estimated GAIN impacts for the Los Angeles program increased in
magnitude in years 4 through 9 relative to those in the first three years for both measures of employment. On average, the GAIN program in Los Angeles was estimated to increase annual employment rates 3.3 (3.8) percentage points per year and the number of quarters worked by 0.10
(1.3) per year in years 4 through 6 (years 7 through 9) after random assignment. These later-year
estimate impacts for Los Angeles are all statistically significant and are larger than the effects
found for the first three years after random assignment. Recall that the Los Angeles county
GAIN program concentrated its services on long-term welfare recipients at the time our sample
members were randomly assigned. Further recall that this program assigned the highest proportion of its registrants to HCD training components of the four counties we analyzed from the
39

We also note that the average employment rates and quarters worked per year for experimentals in Riverside consistently decline in magnitude over the nine-year. This is in contrast to the other 3 counties, where comparable outcomes for experimentals in each of the other three counties increased over the nine-year follow-up period.

28

MDRC GAIN Evaluation.
The impacts of GAIN programs on annual earnings also are displayed in Table 3. As with
the impacts on employment, the effects of receiving some training component on annual earnings
for the Riverside and San Diego GAIN programs were sizeable—$1,416 per year in Riverside
and $411in San Diego—and statistically significant in the first 3 years after random assignment.
But, as we found for the estimated impacts on employment, the effects in these two counties both
declined in magnitude and statistical significance over time. In contrast, the effects of the GAIN
programs in Alameda and Los Angeles counties were not large in magnitude in any of the periods after random assignment and were never statistically significant.
A closer inspection of Table 3 indicates that the mean employment and earnings outcomes for the control groups are improving more rapidly over the nine-year period than they are
for the experimental group in all counties but Los Angeles. In fact, in Riverside County both of
the employment outcomes decline over time for the experimental group. 40 In particular, in all but
Los Angeles County, the declines and/or stagnation in the experimental experimental impacts on
economic outcomes after Years 1 through 3 result from more rapid improvements of the control
group outcomes relative to those for the experimental group. Moreover, the economic outcomes
for the experimental group in Riverside County actually declined after Year 3. In contrast, the
means economic outcomes for the experimental group in Los Angeles county improved relative
to this county’s control group after Year 3.
The fact that the economic outcomes of the control groups in Alameda, Riverside and
San Diego Counties were improving more rapidly than the experimental group raises the possibility that our longer-run impacts are “contaminated” because the control groups benefited from

40

This also is true for the annual employment outcome in San Diego.

29

GAIN services after the embargo on these services was lifted for this group. (Recall that the prohibition of eligibility for any GAIN services to control group members was lifted on June 30,
1993 and cases in this group could elect, but were not required, to participate in GAIN until July
1, 1995.) Depending on when they were enrolled into the MDRC evaluation, control group members were eligible to participate in GAIN activities anywhere from 3 to 4.5 years after their enrollment in this evaluation and actually were subject to a GAIN mandate from 5 to 6.5 years after
enrollment if they were on AFDC. Thus, the decline in the Riverside experimental impacts in
Years 4 through 9, for example, could be the result of some of the Riverside controls receiving
GAIN training components after their embargo from services was lifted. This same source of
“contamination” could afflict our long-term estimates of GAIN impacts for the other three counties. 41 If this occurred at sufficiently high rates among the control groups in these counties, it
could compromise the interpretation of the estimated impacts for Years 4-6 and 7-9 presented in
Table 3 as long-term impacts of GAIN.
In the Appendix we examine whether the improvements in control group economic outcomes is likely to be explained by control group members being “contaminated” in Years 4
through 9 by the fact that they received GAIN services after their embargo expired. While we
cannot rule out this explanation, the calculations presented in the Appendix (see Table A-1) cast
doubt upon its affect on the longer term experimental training effect estimates. We also note that,
unlike the economic outcomes, the mean estimates for experimentals and controls decline over
time in all four counties which is not consistent with the control group contamination explanation.
41

The possibility of this “control group contamination” is quite salient, given that the early findings for Riverside
County from MDRC’s evaluation led other counties in California to re-orient their GAIN programs towards the Riverside work-first approach. For example, in 1995 Los Angeles County re-oriented its GAIN program to a “workfirst” program, attempting to model its program after Riverside’s.

30

In summary, our examination of the long-term experimental estimates of the impacts of
the GAIN programs in these four counties indicate some noticeable differences between the estimated experimental effects in the years immediately following random assignment (years 1
through 3) compared to those at longer intervals after randomization (years 7 through 9). Furthermore, the longer run impacts of Riverside’s GAIN program are somewhat less supportive of
the view that the Riverside’s program, which placed greater emphasis on LFA versus HCD training components, dominated the training strategies in the other three counties, especially in the
longer run. However, drawing the latter conclusion, while tempting, is subject to the flaw noted
in the Introduction and Section 3, namely that the MDRC GAIN Evaluation experimental design
does permit direct inferences about the differential effects of LFA versus HCD training components. In the next section, we present evidence that attempts to shed light on such differential effects.
4.2 Estimates of Differential Effects of LFA versus HCD Training Components

In this section we present estimates of the average differential effects of LFA versus
HCD training components ( γ s (A, h) ) for the same set of outcomes considered in the previous section with the data from the MDRC GAIN Evaluation. We present year-by-year estimates of

γ s (A, h) for the 9-year post-randomization period to facilitate the examination of how they vary
with time since enrollment in GAIN training programs.
We begin by examining the results for the various tests of assumption (A-1′) using data
for the control groups in the four MDRC GAIN Evaluation counties. The results of these tests
are presented in Table 4. For each outcome, we present estimates of γ s (A, h) , and their standard
errors, based on data pooled for all four counties (columns labeled “Four County Ave. γ s (A, h) ”)
as well as P-values for the year-specific tests of whether all of the county-specific estimates of

31

γ s (A, h) equal zero (columns labeled “P-Value, γ sd (A, h) =0 for all d”). The first two columns for
each outcome contain results from regressions that do not adjust for control variables, while the
third and fourth columns contain results that control for Z using regression specifications in (6)
and (6′), respectively.
Several consistent patterns for the various outcomes emerge from these tests. First, with
no controls for background characteristics or pre-random assignment outcome variables, the test
for whether the differential effects of LFA versus HCD are zero is always rejected for the All
County estimates of γ s (A, h) and typically rejected when we allow for county specific effects of

γ s (A, h) . Recall that these tests are being conducted on data for members of the controls groups,
who did not receive any GAIN training component for at least the first three years after random
assignment. As such, there should be no differential effects of one training component over another for these groups. The results of these tests provide clear evidence that there were selective
differences in the populations and/or strategies for assigning LFA versus HCD training components across counties which implies that assumption (A-1) does not hold across counties.
Second, after controlling for background characteristics and pre-random assignment outcome variables, we cannot reject the hypothesis that the All County γ s (A, h) ’s equal zero for any
of the employment or earnings outcomes. The same conclusion holds for the county-specific estimates of γ s (A, h) for most years. That is, after controlling for Z, the test results in Table 4 provide substantial support for the validity of assumption (A-1′) for the employment and earnings
outcomes. The latter findings help to justify the application of the regression-adjustment methods
we use to estimate the differential effects of LFA versus HCD training on these outcomes. 42

42

While not reported here, we conducted the same tests of assumption (A-1′) for outcomes that measured postrandomization welfare participation. These results are found at www.econ.ucla.edu/hotz/GAIN_extra_results.pdf.

32

Given the test results in Table 4, we next consider estimates of the average training effects of LFA versus HCD training components derived from regression-adjustment methods. In
Table 5, we present the Difference-in-Differences (DID) estimates of γ s (A, h) based on the regression specification in (7), where we use data for the experimental and the control groups of
the MDRC GAIN Evaluation. Corresponding estimates derived from estimating the regression
specification in (6) with only experimental group data are presented in Table 6. As we noted
above, the DID estimates in Table 5 represent, in our view, more conservative estimates of the
average differential effects of LFA versus HCD training. Accordingly, we pay more attention to
them in our discussion. Where appropriate, however, we do discuss some of the differences in
the estimates across these two tables. We present three sets of estimates for each outcome in Table 6. The first set, in the first column, does not adjust for Z; the second set, in the second column, adjusts for Z; the third set, in third column, adjusts for Z and post-random assignment values of the county-specific labor market conditions.
Consider the estimates of γ s (A, h) for annual employment and earnings outcomes in Table 5. Without controlling for Z, the estimates of γ s (A, h) for all three outcomes are positive and
statistically significant in the first four to five years after random assignment, with the positive
(and significant) estimates of γ s (A, h) persisting through year 6 for the annual earnings outcome.
In the later years (after random assignment), the estimates turn negative and statistically insignificant for the annual employment and annual number of quarters worked outcomes and become
statistically insignificant for the annual earnings outcome, although the latter effects remain posiUsing the same testing strategy, we found that while the tests of the All County and county-specific values of the
γ s (A, h) = 0 hypothesis were typically not rejected, there are many more rejections of these tests for welfare particiaption, especially in years 8 and 9 after random assignment, than for the employment and earnings outcomes.
Thus, it is less clear that using the regression-adjustment methods to estimate the differential effects of LFA versus
HCD training is appropriate for estimating the differential treatment effects for post-randomziation welfare participation outcomes.

33

tive. Note that these unadjusted DID estimates of γ s (A, h ) implicitly assume that assumptions (A1) and (A-2) hold without any adjustments for population and/or training assignment differences
across counties, and that labor market conditions are comparable over time and across counties.
Based on these estimates, one would conclude that being assigned to LFA training components
initially had stronger effects on these outcomes than did being assigned to HCD training components, but that the advantage of LFA relative to HCD training largely vanishes in the longer run.
These results are entirely consistent with the experimental estimates produced by the
original MDRC evaluation of GAIN Evaluation. As noted at the end of Section 4.1, such findings have been inappropriately interpreted as implying that welfare-to-work programs that stress
LFA training—as emphasized in Riverside county—are more effective in improving the economic outcomes of those in welfare-to-work program relative to those that stress HCD training.
Furthermore, the relative advantage of LFA training components appears to persist for a fairly
long period (four to six years), which is notable from a training policy perspective. Finally, we
note that the unadjusted estimates of differential effects of LFA versus HCD training for employment and earnings outcomes in Table 6, which are estimated using only experimental group
data, are much larger in magnitude, especially in the initial years after random assignment, and
statistically significant in each of the nine years after random assignment, although the estimated
differential impacts appear to be unreasonably large in magnitude.
We next turn to the estimates of γ s (A, h ) which adjust for the background and pre-random
assignment variables in Z. Recall that our tests of assumption (A-1′) using control group data
provided evidence in support of adjusting for these variables to remove cross-county differences
in population and treatment assignment heterogeneity. Relative to the unadjusted estimates just
discussed, adjusting for Z leads to substantively different estimates of the relative impacts of

34

LFA versus HCD training on the post-random assignment employment and earnings outcomes,
especially in the longer run. Consider the estimates in the second columns for each outcome in
Table 5. While the differential effects of LFA versus HCD training has positive and statistically
significant effects on all three of these outcomes in the first three years after random assignment,
the effects become insignificant after Years 3 or 4, turn negative for the last three or four years
after random assignment and are statistically significant in the case of annual employment. That
is, a different conclusion emerges from this second set of estimates of the relative advantages of
LFA versus HCD training on the employment and earnings of welfare-to-work participants, especially in the longer run. While the relative benefits of HCD training appear to take a while to
emerge, based on this set of estimates, it does emerge at least for employment rates. Moreover,
the relative advantages of HCD training appear to grow with time. A similar set of conclusions
about the longer term advantages of HCD over LFA training of differential effects are also found
for employment outcome after adjusting for background and pre-random assignment outcomes
based on using only experimental group data (Table 6). We also find statistically significant estimates in favor of HCD relative to LFA training for annual earnings starting six years after random assignment.
Finally, we consider the effects that county-specific, post-randomization labor market
conditions have on one’s inferences about the differential effects of LFA versus HCD training on
employment and earnings outcomes. We present, in Table 5, estimates of γ s 0 (A, h) , based on the
regression specification in (10) and estimated with data for the experimental and control groups,
as well as a corresponding set of estimates, in Table 6, based on a version of (10) that excludes
the terms involving the experimental-control status indicator, T, and using only experimental
group data only. Such estimates are found in the third columns of for each outcome in these ta-

35

bles. These estimates adjust for both Z and for measures of post-random assignment measures of
county-specific total labor-to-population ratios and average real earnings per worker for the retail
trade sector. 43 All of the post-randomization labor market conditions variables included in the
regressions were measured as deviations from mean values for all four counties over the entire
nine-year post-randomization period. Thus, the estimates of γ s 0 (A, h) correspond to what would
prevail at these average all-county, time-invariant labor market conditions. At the bottom of each
of these tables we also present P-values for the tests of the null hypothesis that the interactions of
Mds with Ti,dc and PdcA Ti ,dc (Table 5) and of Mds with PdcA (Table 6) are all equal to zero.
Consider the findings in Table 5 based on data for both experimental and control group
members. The P-values for the tests of no interactions of labor market conditions with Ti,dc and
PdcA Ti ,dc are rejected for both the annual employment and annual quarters of work outcomes at

conventional levels of significance, although this hypothesis cannot be rejected for annual earnings. Comparing the estimates of γ s (A, h) and γ s 0 (A, h) in columns 2 and 3, respectively, for the
employment and earnings outcomes, there are two notable differences. First, one finds that the
initial post-randomization estimates of γ s (A, h) that control for post-randomization labor market
conditions are reduced in absolute value and are no longer statistically significant. Second, for all
three outcomes, the longer term (seven to nine years after random assignment) estimated negative effects of LFA versus HCD training are almost twice the size (in absolute value) of the estimates that just control for Z and, are statistically significant for both employment outcome measures.
43

While not shown here, we also estimated specifications of (10) in which Mds included county-specific measures of
the employment-to-population ratios for the retail trade sector and the average real earnings per work in all sectors
along with the total employment-to-population ratios and average real earnings per worker for retail trade. Controlling for this more comprehensive set of post-randomization county labor market conditions did not change the inferences drawn from the more limited set of conditions used in Tables 5 and 6.

36

The findings concerning the importance and consequences of interactions between postrandomization labor market conditions and the estimated profiles for γ s (A, h) using only data
from the experimental group presented in Table 6 are entirely similar to those found using experimental and control group data. We reject the null hypothesis of no interactions between postrandomization labor market conditions and PdcA and, adjusting for these conditions, we again find
evidence of the longer run advantages of HCD over LFA training for the employment prospects
of participants in the GAIN welfare-to-work programs.
5.

Conclusions

In this paper we propose and implement non-experimental regression-adjustment methods in an attempt to isolate one of the potentially important reasons for across-program differences in training effects, namely that programs differ in the mix in and assignment of different
types of training to the participants in its programs. The latter source of treatment heterogeneity
and its potential consequences for across-program differences in training effects has been noted
by Hotz, Imbens and Mortimer (2005) and others who have evaluated the effectiveness of training programs. We have demonstrated how one might isolate average differential treatment effects of different treatment components with one set of methods. Moreover, we have shown how
one can exploit the presence of data on control groups—derived from an evaluation in which
subjects are randomly assigned to control status or the receipt of some training component—in
order to assess the validity of these regression-adjustment methods. Finally, using data for which
we have nine years of post-treatment outcomes for participants in a random assignment experiment, which allows us to estimate the longest term post-training effects of training programs of
which we are aware, we have been able to investigate the longer, as well as shorter, run impacts
of welfare-to-work training programs.

37

As for the substantive implications of our re-analysis of the MDRC GAIN Evaluation
data, our estimates lead to a rather different set of conclusions about the relative advantages of
LFA versus HCD training programs on the post-training outcomes, especially in the longer run,
than exists in the training evaluation literature. Recall from the Introduction that administrators
of welfare-to-work programs across the country and welfare policy makers concluded from the
success of the LFA-oriented Riverside GAIN program documented in the MDRC GAIN Evaluation that the LFA approach was more successful (and cheaper) than the HCD approach for participants in welfare-to-work training programs.
Based on our re-analysis of the MDRC GAIN Evaluation data using the regressionadjustment methods developed above, we find that the LFA approach, at best, has only short-run
advantages over the HCD approach with respect to the employment and earnings outcomes for
low-skilled participants in California’s welfare-to-work program in the 1990s. Much of what has
been interpreted as the relative advantage of the LFA to the HCD approach appears to stem from
the relatively better local labor market conditions in Riverside county, especially over the first
three to five years after random assignment. Moreover, at least for employment, we present evidence that in the longer run (here some five to six years after training) HCD training components
yield higher employment rates for its participants than does LFA training components. Finally,
our estimates of the differential effects of LFA versus HCD training components indicate that the
longer-term advantages of HCD versus LFA training components for economic outcomes can be
sizeable. It follows that the extent to which welfare-to-work training programs care about more
than quick fixes in their attempts to improve the self-sufficiency of its participants, our findings
suggest that the use of training components that stress the development of work-related skills,
rather than simply getting people jobs, needs to be reconsidered.

38

References

Abadie, Alberto, and Guido Imbens. 2006. Large sample properties of matching estimators for
average treatment effects. Econometrica 74, no. 1:235-267.
Bloom, Howard, Carolyn J. Hill and James Riccio. 2005. Modeling cross-site experimental differences to find out why program effectiveness varies. In Learning more from social experiments: evolving analytic approaches, ed. Howard Bloom. New York: Russell Sage
Press.
Couch, Kenneth A. 1992. New evidence on the long-term effects of employment training programs. Journal of Labor Economics 10, no. 4:380-388.
Dehejia, Rajeev. 2003. Was there a Riverside miracle? A hierarchical framework for evaluating
programs with grouped data. Journal of Business and Economic Statistics 21, no. 1: 1-11.
Dehejia, Rajeev, and Sadek Wahba. 1999. Causal effects in non-experimental studies: re-evaluating the evaluation of training programs. Journal of the American Statistical Association
94, no. 448:1053-1062.
Freedman, Stephen, Daniel Friedlander, Winston Lin, and Alan Schweder. 1996. The GAIN
evaluation: five-year impacts on employment, earnings, and AFDC receipt. Working Paper 96.1, Manpower Demonstration Research Corporation, New York.
Friedlander, Daniel and Gary Burtless. 1995. Five Years After: The Long-Term Effects of Welfare-To-Work Programs. New York: Russell Sage.
Friedlander, Daniel, and Philip K. Robins. 1995. Evaluating program evaluations: New evidence
on commonly used nonexperimental methods. American Economic Review 85, no. 4:923937.
Gueron, Judith and Gayle Hamilton. 2002. The role of education and training in welfare reform.
Welfare Reform & Beyond Policy Brief No. 22, The Brookings Institution, Washington,
DC.
Ham, John C., and Robert J. LaLonde. 1996. The effect of sample, selection and initial conditions in duration models: evidence from experimental data on training. Econometrica 64,
no. 1:175-206.
Heckman, James, and V. Joseph Hotz. 1989. Choosing among alternative nonexperimental methods for estimating the impact of social programs: the case of manpower training. Journal
of the American Statistical Association 84, no. 408:862-880.
Heckman, James, Hidehiko Ichimura, and Petra Todd. 1997. Matching as an econometric evaluation estimator: evidence from evaluating a job training program. Review of Economic
Studies 64, no. 4:605-654.
Heckman, James, Hidehiko Ichimura, and Petra Todd. 1998a. Matching as an econometric

39

evaluation estimator. Review of Economic Studies 65, no. 2:261-294.
Heckman, James, Hidehiko Ichimura, Jeffrey Smith, and Petra Todd. 1998b. Characterizing selection bias using experimental data. Econometrica 66, no. 5:1017-1098.
Heckman, James, Robert LaLonde and Jeffrey Smith. 1999. The economics and econometrics of
active labor market programs. In Handbook of labor economics, Vol. 3A, ed. Orley Ashenfelter and David Card. New York: Elsevier Science.
Heckman, James, and Richard Robb. 1985. Alternative methods for evaluating the impact of interventions. In Longitudinal analysis of labor market data, ed. James Heckman and Burton Singer. New York: Cambridge University Press.
Hogan, Lyn A. 1995. Jobs, not JOBS: What it takes to put welfare recipients to work,” Policy
Briefing, Democratic Leadership Council, Washington, DC.
Hirano, Keisuke, Guido Imbens and Geert Ridder. 2003. Efficient estimation of average treatment effects using the estimated propensity score. Econometrica 71, no. 4:1161-1189.
Hotz, V. Joseph, Guido Imbens and Jacob Klerman. 2000. The long-term gains from GAIN: A
re-analysis of the impacts of the California GAIN program,” Working Paper No. 8007,
National Bureau of Economic Research, Cambridge, MA.
Hotz, V. Joseph, Guido Imbens, and Julie Mortimer. 2005. Predicting the efficacy of future training programs using past experiences. Journal of Econometrics 124:241-270.
Hoynes, Hilary. 2000. Local Labor markets and welfare spells: Do demand conditions matter?”
Review of Economics and Statistics, 73, no. 3:351-368.
Imbens, Guido. 2000. The role of the propensity score in estimation dose-response functions.
Biometrika, 87, no. 3:706-710.
Imbens, Guido. 2004. Nonparametric estimation of average treatment effects under exogeneity:
A review. Review of Economics and Statistics 86, no. 1: 4-29.
LaLonde, Robert. 1986. Evaluating the econometric evaluations of training programs with experimental data. American Economic Review 76, no. 4:604-620.
Lechner, Michael. 2001. Identification and estimation of causal effects of multiple treatments under the conditional independence assumption,” In Econometric evaluation of labour market policies, ed. Michael Lechner and Friedhelm Pfeiffer. Heidelberg, Germany:
Physica/Springer.
Mincer, Jacob. 1974. Education, Experience, and Earnings, New York: Columbia University
Press.
Mitnik, Oscar. 2004a. How do training programs assign participants to training? Characterizing
the optimal assignment rules of government agencies for welfare-to-work programs in

40

California. Unpublished manuscript, University of Miami.
Mitnik, Oscar. 2004b. Differential effects of welfare to work programs: identification with unknown treatment status. Unpublished manuscript, University of Miami, May.
Riccio, James, Barbara Goldman, Gayle Hamilton, Karin Martinson, and Alan Orenstein. 1989.
GAIN: Early implementation experiences and lessons. Manpower Demonstration Research Corporation, New York.
Riccio, James and Daniel Friedlander. 1992. GAIN: Program strategies, participation patterns,
and first-year impacts in six counties. Manpower Demonstration Research Corporation,
New York.
Riccio, James, Daniel Friedlander, and Stephen Freedman. 1994. GAIN: Benefits, costs, and
three-year impacts of a welfare-to-work program. Manpower Demonstration Research
Corporation, New York.
Rosenbaum, Paul. 1987. The role of a second control group in an observational study. Statistical
Science 2, no. 3:292-316.
Rubin, Donald. 1973a. Matching to remove bias in observational studies. Biometrics 29:159-183.
Rubin, Donald. 1973b. The use of matched sampling and regression adjustments to remove bias
in observational studies. Biometrics 29:185-203.
Rubin, Donald. 1977. Assignment to treatment group on the basis of a covariate. Journal of Educational Statistics 2, no. 1:1-26.
Rubin, Donald. 1979. Using multivariate matched sampling and regression adjustment to control
bias in observational studies. Journal of the American Statistical Association 74:318-328.
Smith, Jeffrey, and Petra Todd. 2005. Does matching overcome LaLonde’s critique of nonexperimental estimators? Journal of Econometrics 125:305-353.

41

Table 1
Background Characteristics and Pre-Randomization Histories of GAIN Evaluation Participants from AFDC Caseload
Alameda
Variable

Age
White
Hispanic
Black
Other Ethnic Groups
Female-Head
Only One Child
More than One Child
Child 0 to 5 Years
Highest Grade Completed
In Need of Basic Education
Earnings 1 Qtr. before Rand. Assign.
Earnings 4 Qtrs. before Rand. Assign.
Earnings 8 Qtrs. before Rand. Assign.
Employed 1 Qtr. before Rand. Assign.
Employed 4 Qtrs. before Rand. Assign.
Employed 8 Qtrs. before Rand. Assign.
AFDC Benefits 1 Qtr. before Rand. Assign.
AFDC Benefits 4 Qtrs. before Rand. Assign.
On AFDC 1 Qtr. before Rand. Assign.
On AFDC 4 Qtrs. before Rand. Assign.
Prop. Entered GAIN in 1988:Q3
Prop. Entered GAIN in 1988:Q4
Prop. Entered GAIN in 1989:Q1
Prop. Entered GAIN in 1989:Q2
Prop. Entered GAIN in 1989:Q3
Prop. Entered GAIN in 1989:Q4
Prop. Entered GAIN in 1990:Q1
Prop. Entered GAIN in 1990:Q2
Number of Experimental Cases
Number of Control Cases
Total Number of Cases
Fraction of Cases in Experimental Group

Mean*
34.69
0.18
0.08
0.70
0.04
0.95
0.42
0.57
0.31
11.18
0.65
$213
$264
$220
0.14
0.14
0.13
$1,907
$1,822
0.98
0.96

0.26
0.21
0.32
0.21
597
601
1,198
0.498

Los Angeles

Std. Dev. P-Value†
8.61
0.034
0.38
0.806
0.26
0.045
0.46
0.562
0.20
0.400
0.22
0.978
0.49
0.458
0.50
0.391
0.46
0.340
2.52
0.921
0.48
0.885
$851
0.797
$1,018
0.012
$1,005
0.460
0.34
0.531
0.34
0.000
0.33
0.896
$526
0.331
$551
0.317
0.14
0.692
0.19
0.982

0.44
0.41
0.47
0.41

0.944
0.767
0.769
0.578

Mean*
38.52
0.12
0.32
0.45
0.11
0.94
0.33
0.67
0.10
9.54
0.81
$221
$216
$181
0.12
0.13
0.11
$1,874
$1,867
0.99
0.98

Riverside

Std. Dev. P-Value†
8.43
0.668
0.32
0.621
0.47
0.233
0.50
0.600
0.31
0.663
0.24
0.043
0.47
0.743
0.47
0.976
0.31
0.353
3.55
0.548
0.40
0.982
$874
0.454
$866
0.405
$796
0.473
0.33
0.469
0.33
0.634
0.32
0.565
$663
0.792
$662
0.440
0.10
0.341
0.14
0.765

0.56
0.26
0.18

0.50
0.44
0.39

2,995
1,400
4,395
0.681

0.000
0.000
0.244

Mean*
33.63
0.52
0.27
0.16
0.05
0.88
0.39
0.58
0.16
10.68
0.60
$452
$614
$728
0.22
0.25
0.27
$1,190
$995
0.77
0.63
0.11
0.18
0.17
0.17
0.13
0.13
0.11

4,405
1,040
5,445
0.809

NOTE—Earnings and AFDC Benefits are deflated by Consumer Price Index; in 1999 dollars.
* Mean (and standard deviation) for full sample (i.e., experimental and control groups).
† P-Value for test of difference between experimental and control group means.

42

Std. Dev. P-Value†
8.20
0.431
0.50
0.533
0.45
0.937
0.37
0.323
0.22
0.700
0.33
0.633
0.49
0.079
0.49
0.093
0.37
0.922
2.53
0.938
0.49
0.615
$1,404
0.452
$1,603
0.073
$1,840
0.003
0.42
0.664
0.43
0.976
0.44
0.044
$1,043
0.499
$1,027
0.663
0.42
0.837
0.48
0.973
0.31
0.085
0.38
0.073
0.38
0.631
0.37
0.299
0.34
0.699
0.34
0.746
0.31
0.165

San Diego
Mean*
33.80
0.43
0.25
0.23
0.09
0.84
0.43
0.53
0.13
10.66
0.56
$588
$808
$827
0.27
0.29
0.28
$1,159
$1,008
0.73
0.60
0.15
0.24
0.24
0.21
0.16

6,978
1,154
8,132
0.858

Std. Dev. P-Value†
8.59
0.911
0.49
0.263
0.44
0.089
0.42
0.345
0.29
0.473
0.37
0.349
0.50
0.530
0.50
0.621
0.34
0.778
3.04
0.373
0.50
0.362
$1,485
0.270
$1,879
0.747
$1,958
0.301
0.44
0.118
0.45
0.926
0.45
0.149
$903
0.046
$928
0.098
0.44
0.086
0.49
0.102
0.36
0.000
0.43
0.000
0.42
0.000
0.41
0.205
0.37
0.000

Table 2
Distribution of Proportion of Participation in Various GAIN Training Components1
Labor Force Attachment (LFA)
Activities

Yr:Qtr
Alameda
1988:Q3
1988:Q4
1989:Q1
1989:Q2
1989:Q3
1989:Q4
1990:Q1
1990:Q2
Los Angeles
1988:Q3
1988:Q4
1989:Q1
1989:Q2
1989:Q3
1989:Q4
1990:Q1
1990:Q2
Riverside
1988:Q3
1988:Q4
1989:Q1
1989:Q2
1989:Q3
1989:Q4
1990:Q1
1990:Q2
San Diego
1988:Q3
1988:Q4
1989:Q1
1989:Q2
1989:Q3
1989:Q4
1990:Q1
1990:Q2

Job Club & All Other
Job Search Job Search
Activities
Activities

All LFA
Activities

Human Capital Development (HCD) Activities

Basic
Education
Program

Vocational
Training

On the Job
Training
(OJT)

All HCD
Activities

Prop. of
GAIN
Registrants
deemed
“In Need
of Basic
Skills”

0.00
0.00
0.21
0.34
0.35
0.33
0.29
0.45

0.00
0.00
0.00
0.02
0.02
0.09
0.05
0.03

0.00
0.00
0.21
0.36
0.37
0.42
0.34
0.48

0.00
0.00
0.53
0.37
0.36
0.44
0.44
0.38

1.00
1.00
0.26
0.27
0.27
0.12
0.22
0.13

0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.01

1.00
1.00
0.79
0.64
0.63
0.56
0.66
0.52

N/A
0.00
0.14
0.23
0.22
0.23
0.19
0.16

N/A
0.00
0.00
0.01
0.02
0.04
0.07
0.05

N/A
0.00
0.14
0.24
0.24
0.27
0.26
0.21

N/A
0.08
0.72
0.61
0.68
0.65
0.63
0.64

N/A
0.92
0.14
0.15
0.08
0.08
0.12
0.15

N/A
0.00
0.00
0.00
0.00
0.00
0.00
0.00

N/A
1.00
0.86
0.76
0.76
0.73
0.75
0.79

0.51
0.62
0.56
0.63
0.64
0.45
0.52
0.52

0.09
0.07
0.03
0.05
0.03
0.02
0.03
0.01

0.60
0.69
0.59
0.68
0.67
0.47
0.55
0.53

0.21
0.20
0.26
0.20
0.19
0.32
0.23
0.24

0.20
0.10
0.14
0.12
0.14
0.21
0.22
0.23

0.00
0.00
0.00
0.00
0.01
0.00
0.00
0.00

0.41
0.30
0.40
0.32
0.34
0.53
0.45
0.47

0.658
0.597
0.591
0.599
0.581
0.574
0.627

0.41
0.45
0.41
0.42
0.28
0.30
0.34
0.31

0.01
0.01
0.01
0.02
0.05
0.06
0.08
0.06

0.42
0.46
0.42
0.44
0.33
0.36
0.42
0.37

0.28
0.30
0.30
0.31
0.42
0.27
0.33
0.41

0.28
0.22
0.24
0.21
0.23
0.28
0.21
0.15

0.01
0.01
0.02
0.02
0.01
0.04
0.02
0.02

0.57
0.53
0.56
0.54
0.66
0.59
0.56
0.58

0.567
0.545
0.585
0.578
0.528

0.700
0.683
0.624
0.610

0.797
0.816
0.818

NOTE—Areas in boxes depict the quarters in which random assignment was conducted in the various counties. PREP stands for “PreEmployment Preparation. This was California’s form of Workfare, i.e., it was unpaid work experience.

43

Table 3
Experimental Estimates of Annual Impacts of GAIN
Alameda
Years
after RA
Exper.
Control
Annual Employment (%)

1-3

30.8

28.1

4-6

37.0

34.7

7-9

45.3

45.3

Los Angeles
Diff.

2.7
(2.2)
2.3
(2.4)
0.0
(2.6)

Exper.

Control

26.1

24.5

29.2

25.8

36.9

33.1

Riverside
Diff.

1.7
(1.2)
3.3***
(1.3)
3.8***
(1.4)

Exper.

Control

49.0

35.3

40.4

33.5

39.3

37.8

San Diego
Diff.

13.6***
(1.3)
6.9***
(1.4)
1.5
(1.4)

Exper.

Control

45.1

40.8

40.8

38.2

41.0

40.9

Diff.

4.3***
(1.3)
2.6*
(1.4)
0.1
(1.4)

Annual Number of Quarters Worked

1-3

0.80

0.75

4-6

1.12

1.02

7-9

1.47

1.42

0.05
(0.07)
0.10
(0.08)
0.05
(0.09)

0.71

0.67

0.87

0.77

1.16

1.03

484
(302)
727
(464)
665
(563)

1,843

1,849

2,615

2,493

3,689

3,386

0.04
(0.04)
0.10**
(0.04)
0.13***
(0.05)

1.33

0.90

1.23

0.98

1.23

1.15

3,668

2,253

4,363

3,201

4,585

4,174

0.43***
(0.04)
0.25***
(0.05)
0.08
(0.05)

1.25

1.09

1.26

1.17

1.32

1.28

1,416***
(208)
1,162***
(283)
411
(308)

3,781

3,165

4,849

4,315

5,394

4,948

0.15***
(0.04)
0.09*
(0.05)
0.04
(0.05)

Annual Earnings (1999$)

1-3

2,333

1,849

4-6

4,069

3,342

7-9

5,871

5,206

-6
(149)
122
(196)
302
(236)

NOTE—Sample: AFDC-FG Cases in MDRC GAIN Evaluation. Standard errors in parentheses.
* denotes statistically significant at 10% level.
** denotes statistically significant at 5% level.
*** denotes statistically significant at 1% level.

44

616***
(208)
534*
(283)
446
(308)

Table 4
Tests of Assumption (A-1′)
Annual Employment (%)

Year after Random Assignment

Year 1
Year 2
Year 3
Year 4
Year 5
Year 6
Year 7
Year 8
Year 9
Control for:
Personal/Family Characteristics
Pre-RA Earnings, AFDC & Employ.

Annual Quarters Worked

Annual Earnings (1999$)

Four
County
Ave.
γ s ( A, h )

P-Value,
γ sd (A, h)
=0 for all
d

Four
County
Ave.
γ s ( A, h )

P-Value,
γ sd (A, h)
=0 for all
d

Four
County
Ave.
γ s ( A, h )

P-Value,
γ sd (A, h)
=0 for all
d

Four
County
Ave.
γ s ( A, h )

P-Value,
γ sd (A, h)
=0 for all
d

Four
County
Ave.
γ s ( A, h )

P-Value,
γ sd (A, h)
=0 for all
d

Four
County
Ave.
γ s ( A, h )

P-Value,
γ sd (A, h)
=0 for all
d

37.5***
(5.5)
42.6***
(5.6)
44.1***
(5.4)
41.1***
(5.5)
29.0***
(5.5)
23.1***
(5.6)
25.8***
(5.7)
19.2***
(5.8)
21.7***
(5.9)

0.3322

-21.8
(21.6)
-5.0
(23.9)
-3.8
(24.7)
-13.1
(24.6)
-20.5
(24.3)
-13.1
(25.6)
-16.9
(26.0)
-30.2
(26.2)
3.2
(26.5)

0.4288

0.72***
(0.15)
0.96***
(0.17)
1.14***
(0.17)
1.14***
(0.18)
0.89***
(0.18)
0.77***
(0.19)
0.79***
(0.19)
0.57***
(0.20)
0.55***
(0.20)

0.1688

-0.83
(0.57)
0.24
(0.71)
-0.40
(0.76)
-0.21
(0.80)
-0.03
(0.82)
-0.31
(0.86)
0.07
(0.90)
-0.55
(0.92)
-0.53
(0.93)

0.3122

727
(522)
2,755***
(718)
3,376***
(760)
4,241***
(826)
3,401***
(879)
3,796***
(923)
3,583***
(938)
3,794***
(961)
3,814***
(1,075)

0.2937

-2,263
(1,828)
2,448
(2,883)
193
(3,155)
248
(3,385)
1,790
(3,760)
3,225
(3,847)
2,569
(4,267)
446
(4,753)
-2,625
(4,947)

0.7950

No
No

0.6933
0.9856
0.7877
0.0337
0.0131
0.0326
0.0755
0.3908

Yes
Yes

0.4577
0.9826
0.1693
0.0848
0.5829
0.0735
0.6259
0.9573

No
No

0.5195
0.6009
0.8604
0.1321
0.0119
0.0111
0.0027
0.0310

Yes
Yes

0.2980
0.5694
0.3774
0.2912
0.5393
0.1632
0.5708
0.9511

No
No

0.7372
0.5741
0.3899
0.1106
0.0471
0.0110
0.0020
0.0143

0.2857
0.2428
0.6496
0.5832
0.2597
0.1020
0.4018
0.5829

Yes
Yes

NOTE—Sample: AFDC-FG Control Group Cases from MDRC GAIN Evaluation. Standard errors in parentheses. All regressions are weighted by the size of the caseload in County of Residence
in Year/Quarter enrolled in GAIN evaluation. Regressions also include the following covariates:
Personal/Family Characteristics: Age, Age2; dummy variables for Hispanic, Black, Other Ethnic Group; Only 1 Child; Single, Some High School, High School Graduate, Some College, College
Graduate, College Plus, Registered and Enrolled in GAIN in 1988:Q3, Registered and Enrolled in GAIN in 1988:Q4, Registered and Enrolled in GAIN in 1989:Q1, Registered and Enrolled in GAIN
in 1989:Q2, Registered and Enrolled in GAIN in 1989:Q3, Registered and Enrolled in GAIN in 1989:Q4, Registered and Enrolled in GAIN in 1990:Q1, Resided in Los Angeles County, Resided in
Riverside County, Resided in San Diego County; and Whether Classified as “In Need of Basic Education” by GAIN program; and Growth Rate in Real Earnings per Worker in County of Residence
as of Quarter of Random Assignment and Growth Rate in Employment-to-Population in County of Residence. All variables are measured as of the quarter of random assignment.
Pre-RA (Random Assignment) Earnings, AFDC, Employment: dummy variables for Not Employed in Any of 8 Quarters prior to RA, Not Employed in Any of 10 Quarters prior to RA, Employed
in Quarter X before RA, X = 1,…,10, and On AFDC in Quarter X prior to RA, X = 1,…,6; and Earnings in Quarter X prior to RA, X = 1,…,10 and Amount of AFDC Payment in Quarter X prior to
RA, X = 1,…,4.
County Labor Market Conditions: Ratio of Total Employment to Adult Population for County of Residence in Year t and Annual Retail Trade Earnings per Worker (in 1000s of 1999$) for
County of Residence in Year t.
* significant at 10%;
** significant at 5%;
*** significant at 1%

45

Table 5
Difference-in-Differences Estimates of Differential Effects of Labor Force Attachment (LFA)
vs. Human Capital Development (HCD) Programs – Experimental and Control Groups
Year after Random Assignment

Annual Employment (%)

γ (A, h) in Year 1

35.6*** 32.3*** 25.6**
(6.5)
(6.6)
(12.0)

1.04*** 0.92*** 0.67*
(0.18)
(0.20)
(0.40)

3,168*** 1,518*
(613)
(815)

γ (A, h) in Year 2

34.1*** 30.8*** 19.8*
(6.5)
(6.8)
(10.9)

1.24*** 1.12*** 0.74**
(0.20)
(0.22)
(0.37)

4,842*** 3,192***
842
(837)
(973)
(1,892)

γ (A, h) in Year 3

19.3*** 16.0**
(6.3)
(6.7)

3.6
(9.6)

0.80*** 0.68*** 0.27
(0.20)
(0.22)
(0.33)

4,305*** 2,656*** 1,028
(899)
(1,020)
(1,684)

γ (A, h) in Year 4

13.0**
(6.4)

9.7
(6.8)

-2.3
(9.8)

0.54*** 0.42*
(0.21)
(0.23)

0.02
(0.34)

3,431*** 1,781*
(963)
(1,074)

707
(1,758)

γ (A, h) in Year 5

11.2*
(6.5)

8.0
(6.8)

-6.3
(10.0)

0.40*
(0.21)

0.28
(0.23)

-0.18
(0.35)

3,257*** 1,607
(1,025)
(1,127)

390
(1,812)

γ (A, h) in Year 6

-1.9
(6.6)

-5.1
(6.9)

-19.5*
(10.1)

0.06
(0.22)

-0.07
(0.24)

-0.52
(0.35)

2,164**
(1,077)

514
(1,182)

-461
(1,833)

γ (A, h) in Year 7

-11.8*
(6.7)

-15.1** -31.8*** -0.30
(7.1)
(10.2)
(0.22)

-0.42*
(0.24)

-0.93***
(0.36)

1,492
(1,098)

-158
(1,210)

-1,184
(1,860)

γ (A, h) in Year 8

-9.3
(6.8)

-12.6*
(7.1)

-30.6*** -0.20
(10.1)
(0.23)

-0.32
(0.25)

-0.86**
(0.36)

441
(1,128)

-1,208
(1,241)

-2,275
(1,856)

-14.5** -17.8** -32.4*** -0.29
(6.9)
(7.3)
(9.6)
(0.24)

-0.42
(0.26)

-0.85**
(0.34)

23
(1,250)

-1,627
(1,346)

-2,518
(1,823)

γ (A, h) in Year 9
P-Value for joint test that coefficients
on M dsTi , dc and PdcA M dsTi , dc = 0
Control for:
Personal/Family Characteristics
Pre-RA Earnings, AFDC & Employ.
Post-RA County Lab. Mkt. Cond.

Annual Quarters Worked

0.0173
No
No
No

Yes
Yes
No

Yes
Yes
Yes

Annual Earnings (1999$)

0.0605
No
No
No

Yes
Yes
No

Yes
Yes
Yes

-673
(2,033)

0.1601
No
No
No

Yes
Yes
No

Yes
Yes
Yes

NOTE—Sample: AFDC Experimental and Control Group Cases from MDRC GAIN Evaluation. Standard errors in parentheses. All regressions are
weighted by the size of the caseload in County of Residence in Year: Quarter enrolled in GAIN evaluation. Regressions also include the following covariates:
Personal/Family Characteristics: Age, Age2; dummy variables for Hispanic, Black, Other Ethnic Group; Only 1 Child; Single, Some High School,
High School Graduate, Some College, College Graduate, College Plus, Registered and Enrolled in GAIN in 1988:Q3, Registered and Enrolled in GAIN
in 1988:Q4, Registered and Enrolled in GAIN in 1989:Q1, Registered and Enrolled in GAIN in 1989:Q2, Registered and Enrolled in GAIN in 1989:Q3,
Registered and Enrolled in GAIN in 1989:Q4, Registered and Enrolled in GAIN in 1990:Q1, Resided in Los Angeles County, Resided in Riverside
County, Resided in San Diego County; and Whether Classified as “In Need of Basic Education” by GAIN program; and Growth Rate in Real Earnings
per Worker in County of Residence as of Quarter of Random Assignment and Growth Rate in Employment-to-Population in County of Residence. All of
these variables are interacted with experimental status. All variables measured as of quarter of random assignment.
Pre-RA (Random Assignment) Earnings, AFDC, Employment: dummy variables for Not Employed in Any of 8 Quarters prior to RA, Not Employed in
Any of 10 Quarters prior to RA, Employed in Quarter X before RA, X = 1,…,10, and On AFDC in Quarter X prior to RA, X = 1,…,6; and Earnings in
Quarter X prior to RA, X = 1,…,10 and Amount of AFDC Payment in Quarter X prior to RA, X = 1,…,4. All of these variables are interacted with experimental status.
Post-RA County Labor Market Conditions: Ratio of Total Employment to Adult Population and the Annual Retail Trade Earnings per Worker (in
1000s of 1999$) for County of Residence in Year t. All of these variables are interacted with experimental status and experimental status × Proportion in
LFA Activities based on Case’s County of Residence and Year: Quarter of Entry into GAIN.
*significant at 10%.
** significant at 5%.
*** significant at 1%.

46

Table 6
Difference-in-Differences Estimates of Differential Effects of Labor Force Attachment (LFA) vs.
Human Capital Development (HCD) Programs – Experimental Group Only
Year after Random Assignment

Annual Employment

γ (A, h) in Year 1

73.1*** 20.5** 29.2**
(3.3)
(9.2)
(13.5)

1.76*** 0.06
(0.09)
(0.33)

0.16
(0.48)

3,894*** -5,305*** -7,375***
(321)
(1,669)
(2,600)

γ (A, h) in Year 2

76.7*** 24.0*** 25.8*
(3.3)
(9.2)
(13.8)

2.20*** 0.51
(0.11)
(0.33)

0.36
(0.50)

7,597*** -1,603
(428)
(1,667)

-4,302
(2,693)

γ (A, h) in Year 3

63.4*** 10.8
(3.3)
(9.1)

-0.3
(15.2)

1.94*** 0.25
(0.11)
(0.33)

-0.33
(0.55)

7,681*** -1,518
(479)
(1,669)

-5,020*
(2,988)

γ (A, h) in Year 4

54.1*** 1.4
(3.3)
(9.1)

-17.4
(16.7)

1.68*** -0.01
(0.11)
(0.33)

-0.86
(0.60)

7,672*** -1,528
(495)
(1,674)

-5,619*
(3,298)

γ (A, h) in Year 5

40.3*** -12.4
(3.4)
(9.1)

-34.6*
(18.1)

1.29*** -0.40
(0.11)
(0.33)

-1.39**
(0.65)

6,658*** -2,542
(526)
(1,679)

-7,117**
(3,528)

γ (A, h) in Year 6

21.2*** -31.4*** -56.1*** 0.83*** -0.86*** -1.92***
(3.5)
(9.1)
(18.2)
(0.12)
(0.33)
(0.65)

5,960*** -3,240*
(555)
(1,686)

-7,790**
(3,540)

γ (A, h) in Year 7

14.1*** -38.6*** -64.2*** 0.49*** -1.20*** -2.25***
(3.5)
(9.1)
(17.9)
(0.12)
(0.33)
(0.64)

5,074*** -4,126**
(570)
(1,689)

-8,335**
(3,470)

γ (A, h) in Year 8

9.9*** -42.8*** -69.2*** 0.37*** -1.32*** -2.39***
(3.5)
(9.2)
(17.7)
(0.12)
(0.33)
(0.63)

4,235*** -4,965*** -9,122***
(592)
(1,693)
(3,413)

γ (A, h) in Year 9

7.1** -45.5*** -69.7*** 0.26**
(3.6)
(9.2)
(16.6)
(0.13)

3,837*** -5,363*** -9,525***
(637)
(1,715)
(3,216)

P-Value for joint test that coefficients
on PdcA M ds = 0
Control for:
Personal/Family Characteristics
Pre-RA Earnings, AFDC & Employ.
Post-RA County Lab. Mkt. Cond.

Annual Quarters Worked

-1.43*** -2.45***
(0.33)
(0.59)

0.0420
No
No
No

Yes
Yes
No

Yes
Yes
Yes

Annual Earnings

0.0828
No
No
No

Yes
Yes
No

Yes
Yes
Yes

0.3462
No
No
No

Yes
Yes
No

Yes
Yes
Yes

NOTE—Sample: AFDC Experimental Group Cases Only from MDRC GAIN Evaluation. Standard errors in parentheses. All regressions are weighted
by the size of the caseload in County of Residence in Year: Quarter enrolled in GAIN evaluation. Regressions also include the following covariates:
Personal/Family Characteristics: Age, Age2; dummy variables for Hispanic, Black, Other Ethnic Group; Only 1 Child; Single, Some High School,
High School Graduate, Some College, College Graduate, College Plus, Registered and Enrolled in GAIN in 1988:Q3, Registered and Enrolled in GAIN
in 1988:Q4, Registered and Enrolled in GAIN in 1989:Q1, Registered and Enrolled in GAIN in 1989:Q2, Registered and Enrolled in GAIN in 1989:Q3,
Registered and Enrolled in GAIN in 1989:Q4, Registered and Enrolled in GAIN in 1990:Q1, Resided in Los Angeles County, Resided in Riverside
County, Resided in San Diego County; and Whether Classified as “In Need of Basic Education” by GAIN program; and Growth Rate in Real Earnings
per Worker in County of Residence as of Quarter of Random Assignment and Growth Rate in Employment-to-Population in County of Residence. All
variables are measured as of quarter of random assignment.
Pre-RA (Random Assignment) Earnings, AFDC, Employment: dummy variables for Not Employed in Any of 8 Quarters prior to RA, Not Employed in
Any of 10 Quarters prior to RA, Employed in Quarter X before RA, X = 1,…,10, and On AFDC in Quarter X prior to RA, X = 1,…,6; and Earnings in
Quarter X prior to RA, X = 1,…,10 and Amount of AFDC Payment in Quarter X prior to RA, X = 1,…,4.
Post-RA County Labor Market Conditions: Ratio of Total Employment to Adult Population and the Annual Retail Trade Earnings per Worker (in
1000s of 1999$) for County of Residence in Year t.
* significant at 10%.
** significant at 5%.
*** significant at 1%.

47

Alameda

Los Angeles

Riverside

San Diego

All 4 Counties

1.00

Ratio

0.90

0.80

0.70

0.60
-3

-2

-1

1

2

3

4

5

6

7

8

9

Years Before & After Random Assignment

FIG. 1—Annual Ratio of Total Employment to Adult Population, All Sectors

Alameda

Los Angeles

Riverside

San Diego

All 4 Counties

$50.0

1000s of 1999$

$45.0

$40.0

$35.0
-3

-2

-1

1

2

3

4

5

6

7

Years Before & After Random Assignment

FIG. 2—Annual Earnings per Worker, All Sectors

48

8

9

Alameda

Los Angeles

Riverside

San Diego

All 4 Counties

Ratio

0.150

0.125

0.100
-3

-2

-1

1

2

3

4

5

6

7

8

9

Years Before & After Random Assignment

FIG. 3—Ratio of Annual Employment in Retail Trade Sector to Adult Population

Alameda

Los Angeles

Riverside

San Diego

All 4 Counties

1000s of 1999$

$27.0

$22.0

$17.0
-3

-2

-1

1

2

3

4

5

6

7

Years Before & After Random Assignment

FIG. 4—Annual Earnings per Worker, Retail Trade Sector

49

8

9

Appendix
Potential Contamination of Long-Term Experimental GAIN Estimates due to Expiration of
Embargo from GAIN Services for Control Group Members

To investigate the potential importance of the possibility that the improvement in the control group outcomes over Years 4 through 9 after random assignment can account for the decline
in the longer-term estimated impacts of GAIN on economic outcomes, we examine the extent to
which the improvements in control group economic outcomes might be explained by control
group members receiving and benefiting from GAIN services in Years 4 through 9. In Table A1, we compare the trends in actual control group economic outcomes for each of the four counties with estimates of these outcomes based on the assumption that all control group members
that were on AFDC experienced the mean outcomes for their county’s experimental group, with
a three year lag due to the initial embargo. The notes in Table A-1 explain exactly how we calculated these latter estimates. In that Table, we reproduce the actual mean outcomes for the control groups of each county from Table 3 and compare them with what we estimate their outcomes
would have been if the fraction of these groups that were on AFDC in Years 4 through 6 experienced the mean outcome for the experimental group with a three year lag. As seen from Table A1, we find that for most of the economic outcomes—especially for the earnings outcomes—and
in most of the counties these estimated outcomes are, on average, less than the actual outcomes
experienced by control group members. That is, it appears that only part of the improvement in
the economic outcomes for control group members could be explained by the control group receiving and benefiting from GAIN services after their embargo from receipt of these services
was lifted. The one exception to this conclusion is for the annual employment outcome in Riverside County, where the estimates based on this explanation either over-predict or slightly underpredict the actual rise for the control group in this county. We note that this exception is of some

50

importance, given that Riverside’s GAIN program was demonstrated to be effective at increasing
employment rates in the MDRC 3-Year study.
While we cannot rule out the “contaminated control group” explanation for the decline in
the longer-term impacts of GAIN in Riverside County shown in Table 3, the calculations presented in Table A-1 certainly raise questions about its validity. As a final consideration, we note
that we do not find any differences by experimental-control group status in the trends for the
AFDC participation outcomes in Table 3. In particular, for both the Ever-Received AFDC/TANF
and Number of Quarters on AFDC/TANF outcome measures, we find that the mean estimates
for experimentals and controls decline over time at approximately the same rate in Riverside
County as in the other three counties.

51

Table A-1
Comparison of Control Group Outcomes with Estimates under Assumption that Controls on AFDC had the Same Mean Outcomes as Experimental Group
Alameda

Riverside

San Diego

Years af% Diff.
% Diff. Observed
% Diff. Observed
% Diff. Observed
Est.
Est.
Est.
Est.
ter Ran- Observed
(Est.–
(Mean) (Mean)
(Est.–
dom As- (Mean) (Mean)
(Mean) (Mean)
(Est.–
(Mean) (Mean)
(Est.–
signment Outcome Outcome Observed) Outcome Outcome Observed) Outcome Outcome Observed) Outcome Outcome Observed)
Ever Employed in Year (%)
1-3
28.1
28.1
0.0%
4-6
34.7
29.8
-14.3%
7-9
45.3
31.6
-30.1%
Number of Quarters Worked in Year
1-3
0.75
0.75
0.0%
4-6
1.02
0.78
-23.3%
7-9
1.42
0.90
-36.9%
Annual Earnings (1999$)
1-3
$1,849
$1,849
0.0%
4-6
$3,342
$2,155 -35.5%
7-9
$5,206
$2,733 -47.5%

24.5
25.8
33.1

24.5
25.4
26.1

0.0%
1.7%
-21.1%

35.3
33.5
37.8

35.3
41.4
36.8

0.0%
23.7%
-2.8%

40.8
38.2
40.9

40.8
42.7
40.8

0.0%
11.7%
-0.3%

0.67
0.77
1.03

0.67
0.69
0.74

0.0%
-10.4%
-28.1%

0.90
0.98
1.15

0.90
1.09
0.99

0.0%
10.9%
-13.9%

1.09
1.17
1.28

1.09
1.16
1.14

0.0%
-1.0%
-10.8%

$1,849
$2,493
$3,386

$1,849
$1,846
$2,122

0.0%
-25.9%
-37.3%

$2,253
$3,201
$4,174

$2,253
$2,885
$2,853

0.0%
-9.9%
-31.6%

$3,165
$4,315
$4,948

$3,165
$3,439
$3,651

0.0%
-20.3%
-26.2%

NOTE—The values for the “Est. (Mean) Outcome” are calculated as follows. In Years 1-3 (t=1_3), Yˆt =1_ 3 (0) = Yt =1_ 3 (0) and for Years 4-6 and 7-9 (t=4_6 and

7_9), Yˆt (0) ≡ Pt −AFDC
× Yt −1 (kd ) + (1 − Pt −AFDC
is the proportion of
) × Yt =1_ 3 (0) ,where Yt =1_ 3 (0) is the mean outcome for the control group in period Years 1-3; Pt −AFDC
1
1
1
control group on AFDC in period t-1; and Yt −1 (kd ) is the mean outcome for experimental group in period t-1 (t-1 = 1_3 and 4_6, respectively).

52

