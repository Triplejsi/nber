NBER WORKING PAPER SERIES

THE ROLE OF SIMPLIFICATION AND INFORMATION IN COLLEGE DECISIONS:
RESULTS FROM THE H&R BLOCK FAFSA EXPERIMENT
Eric P. Bettinger
Bridget Terry Long
Philip Oreopoulos
Lisa Sanbonmatsu
Working Paper 15361
http://www.nber.org/papers/w15361

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
September 2009

This research was made possible with generous funding from The Bill and Melinda Gates Foundation;
National Science Foundation (Award No. SES-0721158); Institute of Education Sciences, U.S. Department
of Education (through the National Center for Postsecondary Research); Kauffman Foundation; Spencer
Foundation; and the MacArthur Foundation. This research was conducted in collaboration with the
LMI Policy Research Institute and H&R Block. The views expressed in this article are those of the
authors and do not necessarily reflect the views of the LMI Policy Research Institute, H&R Block,
or the National Bureau of Economic Research. All opinions and mistakes are our own.
© 2009 by Eric P. Bettinger, Bridget Terry Long, Philip Oreopoulos, and Lisa Sanbonmatsu. All rights
reserved. Short sections of text, not to exceed two paragraphs, may be quoted without explicit permission
provided that full credit, including © notice, is given to the source.

The Role of Simplification and Information in College Decisions: Results from the H&R Block
FAFSA Experiment
Eric P. Bettinger, Bridget Terry Long, Philip Oreopoulos, and Lisa Sanbonmatsu
NBER Working Paper No. 15361
September 2009
JEL No. H2,I2,J24
ABSTRACT
Growing concerns about low awareness and take-up rates for government support programs like college
financial aid have spurred calls to simplify the application process and enhance visibility. This project
examines the effects of two experimental treatments designed to test of the importance of simplification
and information using a random assignment research design. H&R Block tax professionals helped
low- to moderate-income families complete the FAFSA, the federal application for financial aid. Families
were then given an estimate of their eligibility for government aid as well as information about local
postsecondary options. A second randomly-chosen group of individuals received only personalized
aid eligibility information but did not receive help completing the FAFSA. Comparing the outcomes
of participants in the treatment groups to a control group using multiple sources of administrative data,
the analysis suggests that individuals who received assistance with the FAFSA and information about
aid were substantially more likely to submit the aid application, enroll in college the following fall,
and receive more financial aid. These results suggest that simplification and providing information
could be effective ways to improve college access. However, only providing aid eligibility information
without also giving assistance with the form had no significant effect on FAFSA submission rates.

Eric P. Bettinger
Stanford School of Education
CERAS 522, 520 Galvez Mall
Stanford, CA 94305
and NBER
ebettinger@stanford.edu
Bridget Terry Long
Harvard University
Graduate School of Education
Gutman Library 465
6 Appian Way
Cambridge, MA 02138
and NBER
longbr@gse.harvard.edu

Philip Oreopoulos
Department of Economics
University of Toronto
150 St. George Street
Toronto, Ontario M5S 3G7
CANADA
and NBER
philip.oreopoulos@utoronto.ca
Lisa Sanbonmatsu
NBER
1050 Massachusetts Avenue, 3rd Floor
Cambridge, MA 02138
lsanbonm@nber.org

I.

INTRODUCTION
Higher education can help individuals attain social and economic success; however, decades

of federal and state financial aid policies have not closed the gap between high- and low-income
students’ college attendance rates. Two likely contributing factors are the lack of accurate
information about higher education costs and low awareness of the availability of financial aid. High
school students, particularly from low-income backgrounds, have very little understanding of actual
college tuition levels, financial aid opportunities, and how to navigate the admissions and financial
aid application processes (Ikenberry and Hartle 1998; Horn, Chen, and Chapman, 2003; Kane and
Avery 2004). Additionally, the complexity of the financial aid application confuses and deters
students (ACSFA 2001, 2005). To determine eligibility, students and their families must fill out an
eight-page, detailed application called the Free Application for Federal Student Aid (FAFSA), which
has over 100 questions.1 King (2004) estimates that 850,000 college students who were eligible for
federal grant aid in 2000 did not complete the forms necessary to receive their benefits, and based on
this and other research, in 2006, the Federal Commission on the Future of Higher Education
concluded that many students “don’t enter college because of inadequate information and rising
costs, combined with a confusing financial aid system” (p. vii).
As studies of other benefit programs have demonstrated (e.g., Currie 2004), a program’s
mere existence does not ensure take-up for everyone eligible and interested. Seemingly small
differences in sign-up procedures and marketing can lead to large differences in participation. For
example, corporate savings plans that make participation the default while requiring employees to
take action to opt-out have dramatically higher participation rates than plans that require employees
to deliberately opt-in if they want to participate (Beshears et. al. 2006a). Reducing the number of
necessary decisions for sign-up also increases participation (Beshears et. al. 2006b) as does
simplifying the amount of information given to individuals to help them make sign-up decisions
(Hastings and Weinstein 2008). In the case of college financial aid, award programs that are easier to

1

The FAFSA also serves as the basis to award most state and institutional need-based aid, and so it is a critical
gatekeeper to most financial aid.

1

understand, simpler to apply for, and well-publicized also show larger effects on college enrollment
and completion (Dynarski 2000, 2002; Cornwell, Mustard, and Sridhar 2006).
Concerns about the low visibility of aid programs and the complexity of the aid process have
spurred calls to provide more assistance in filling out the form and to enhance the visibility of
programs by educating students about the availability of financial aid.2 However, there is little
rigorous research on how to implement simplification efforts in a practical manner and whether such
efforts would truly improve college outcomes and aid receipt.
Our paper attempts to quantify the effects of simplification and information provision by
examining a randomized field experiment conducted in partnership with H&R Block, an accounting
firm that provides tax preparation assistance.3 The experiment focused on low- and moderate-income
families where at least one member was between the ages of 17 and 30 and did not have an
undergraduate degree. After families completed their tax returns and consented to participate, we
randomly assigned them to one of three groups. The first group received help completing the
FAFSA using a streamlined process that entailed using the family’s tax return to pre-populate the
FAFSA and then completing the rest of the form using a brief interview protocol. As Dynarski and
Scott-Clayton (2006) note, "the [basic tax return] already collects most of the key pieces of data that
determine aid eligibility" (p. 4). In this first group, we also offered to submit the FAFSA for the
family and provided immediate personalized aid estimates along with net tuition cost information for
four nearby public colleges. The second randomly-selected group received only personalized aid
eligibility estimates based on data from their tax return as well as information on the tuition costs of
nearby colleges, but they did not receive help completing the FAFSA. The final set of individuals
2

Previous efforts to simplify and improve aid information include the creation of the FAFSA-EZ and the FAFSA4caster. However, in order to determine whether one can use the FAFSA-EZ, families must first answer a series of
complex questions of the sort that make the regular FAFSA challenging. Moreover, the FAFSA-4caster requires a
great deal of information before giving an estimate. In June 2009, the Department of Education (DOE) announced a
plan to use skip logic in the online version of the FAFSA to eliminate questions that do not apply to some students
as well as give students instant estimates of the Pell Grant and student loan eligibility. The DOE is also exploring
ways to transfer information directly from the IRS to the online FAFSA (U.S. DOE 2009). These efforts still
require families to be aware of the FAFSA and able to complete it online, preferably with high-speed internet.
3
Federal regulations prohibit any company from charging for assistance in filling out the FAFSA. In fact, H&R
Block’s involvement was the result of an outreach program managed by their Low to Moderate Income (LMI)
Group with the goals of public service in local communities and increasing client loyalty. There are no barriers to
the entry of other organizations and firms in helping students in similar ways.

2

are those who were randomly assigned into a control group, which only received a brochure on the
importance of higher education and general information on college costs and financial aid.
Our experiment serves as a test of the importance of simplifying the process of getting
financial aid and providing clear information about eligibility. The interventions also address several
major barriers in the current financial aid system, including lack of awareness about aid programs,
misinformation about college costs, and missed aid application deadlines. The interventions target
families who are unlikely to be aware of financial aid resources or how to access them. Additionally,
individuals, particularly low-income students, often greatly overestimate the cost of higher education,
and the interventions gave students accurate information about local tuition costs and individual
eligibility for financial aid. Many students miss deadlines for state and institutional aid programs,
which also rely on the FAFSA to award aid. King (2004), for example, found that more than half of
students who filed FAFSA’s in 1999-2000 missed the April 1st deadline to be eligible for additional
state and institutional aid programs. Most of our sample received their treatment in February or
March, long before this deadline. Finally, students may procrastinate. Minimizing the time and
effort necessary to complete the FAFSA may therefore make individuals more likely to spare the
time.
To study the effects of these interventions, we track the submission of aid applications,
college enrollment, and financial aid awards of participants using data made available through
collaborative partnerships with the U.S. Department of Education (DOE) and the National Student
Clearinghouse (NSC). The analysis suggests that individuals who received assistance with the
FAFSA and information about aid were substantially more likely to submit the aid application. High
school seniors and recent high school graduates among this group were also 25-30 percent more
likely to enroll in college. Similarly, the program increased college enrollment among low-income
adults with no prior college experience. The program also increased grant receipt for all participants
in our treatment groups, including those who had previously enrolled in college. These results
suggest that direct help with the application process and providing better information could be

3

effective ways to improve college access.

However, only providing aid information without

assistance with the form had no significant effect on aid application rates or college enrollment.

II.

LITERATURE REVIEW AND BACKGROUND ON THE EXPERIMENT

Prior Literature
There is a long literature examining the effects of financial aid and price on attendance (e.g.,
Kane 2003, Seftor and Turner 2002, Dynarski 2000 and 2003, Manski and Wise 1983), college
choice (e.g., Long 2004; Avery and Hoxby 2004, Van der Klauuw 2002), and persistence (e.g.,
Bettinger 2004). While price and financial aid have been found to influence decisions about college,
many remain puzzled as to why some aid programs have not been more effective in spurring
increased enrollment among targeted groups.4 Some theorize this is due to low visibility and the
complexity of the aid process, and in recent years there has been increasing interest in understanding
the role of the application process on socioeconomic outcomes. For example, at the direction of
Congress, the Advisory Committee on Student Financial Assistance (ACSFA) examined the federal
aid system and concluded:
“Millions of students and adult learners who aspire to college are overwhelmed by the
complexity of student aid. Uncertainty and confusion rob them of its significant benefits.
Rather than promote access, student aid often creates a series of barriers – a gauntlet that the
poorest students must run to get to college” (ACSFA, 2005, p. i).
The FAFSA application is perhaps the focus of most discussion regarding ways to reduce
complexity. The 2008 FAFSA was eight pages long and contained over 100 questions. To answer
three of these questions, applicants had to complete three additional worksheets with nearly 40
additional questions. As shown by Dynarski and Scott-Clayton (2006), the FAFSA is four times
longer than the simplest tax return (i.e., IRS Form 1040EZ) and longer than IRS Form 1040. Even
the lowest-income individuals, who have already established their eligibility for other federal meanstested programs, must complete this long application to receive aid for which they are almost
4

For example, researchers have not found large enrollment responses after the introduction of some financial aid
programs, such as the Pell Grant in 1972 (Manski and Wise 1983, Hansen 1983, Kane 1996). See also GAO (2005).

4

certainly eligible. Furthermore, students who are already in college must redo the application each
year to renew their aid, which may cause some students to lose their aid. In addition, the timing of
the application process is troublesome. Individuals cannot submit the FAFSA until the January of
the year of college entry. Therefore, they often must apply to college before even knowing with
certainty whether they can afford it. Even after completing a FAFSA, applicants cannot project the
exact amount of their potential aid package.
The complexity of the current federal financial aid system is even more apparent when
comparing the existing application process to the processes of other financial aid programs shown to
be effective. For example, the Social Security Student Benefit (SSSB) Program used a very simple
application process in providing college financial aid to the children of dead, disabled, or retired
Social Security beneficiaries.5 Dynarski (2003) finds that the elimination of the program led to large
reductions in college enrollment and eventual educational attainment. Similarly, the Georgia Hope
Scholarship, which provides aid to students with at least a B-average, was heavily advertised and the
application process was simplified.

Researchers have found that Georgia's program had a

surprisingly large impact on college attendances rates (Dynarski, 2000; Cornwell, Mustard, and
Sridhar, 2006).
Complexity is not the only problem with the process. Lack of information appears to be
another significant barrier, as potential students must first know about the existence of aid in order to
access it. Youth and their parents are generally unaware of aid opportunities. For instance, a 2002
Harris Poll found that nearly two-thirds of all parents and young adults planning to go to college did
not name grants as a possible source of funds when asked about types of financial aid. Low-income
families often have less information than other families about how to pay for college (Sallie Mae
Fund, 2003). Given these patterns, it is not surprising that many students eligible for aid do not apply
for it. King (2004) estimates that over 10 percent of all college students in 2000 did not complete
financial aid forms even though they would have been eligible for a Pell Grant had they done so.

5

The program did not require students to seek out the aid themselves nor was the application process complicated.
The government notified eligible students that they could receive the aid, and students only needed to return a short
form to get the benefit.

5

The same patterns can be found with state aid programs that also use the FAFSA. In California, as
many as 19,000 students who would have qualified for a Cal Grant, a need-based aid program, failed
to apply (Sturrock, 2002).
Lack of information about the true costs of college may pose an additional barrier to
enrollment. ACSFA (2005) notes that students and families, as well as adult learners, are often
intimidated by news reports about record increases in the college costs of the most selective
universities and other impressions that college is unaffordable. These stories may contribute to the
fact that individuals, particularly low-income individuals, often greatly overestimate the cost of
higher education (Horn, Chen, and Chapman 2003). Among individuals participating in our study,
we asked a subsample to report on the average costs of college and found that participants
overestimated the costs by over 300 percent.6 Oreopoulos and Dunn (2009) find high school students
are more likely to aspire going to college three weeks after being provided accurate information
about costs and benefits.
Policymakers and researchers are increasingly aware that the design of a program can affect
its take-up and effectiveness. As mentioned above, researchers have shown for other programs that
making sign-up automatic, simplifying the information distributed, or reducing the number of
choices individuals need to make to sign-up can have large effects on participation. The extent to
which these types of changes would affect college aid applications and enrollment, however, is
unknown. Our project is designed to address this hole in the literature.

The FAFSA Experiment
We developed this experiment in collaboration with H&R Block. On January 2, 2008, the
program was implemented in most of Ohio and the Charlotte, North Carolina area (a total of 156 tax
preparation offices).7 After a person completed their taxes in an H&R Block office, they were

6

The average annual tuition at a two-year, public college in Ohio was $3,099. In contrast, the median estimate
among our participants was $9,999. Dependents guessed $8,500 at the median, and independents guessed $10,000.
7
H&R Block invited proposals of interventions that would benefit low- and moderate-income families, have
national scalability, and inform important and timely policy debates. After being selected through a competitive,
peer-reviewed process, the team worked from spring 2006 to winter 2007 to develop the necessary procedures and

6

instantly screened for eligibility. Software we developed for the project identified families with
incomes less than $45,000, as measured by the adjusted gross income reported on the tax return, who
also had a family member between the ages of 15 and 30 who did not already have a bachelor's
degree. These criteria map onto two samples of interest. The first is high school seniors and recent
graduates who are typically dependent upon their parents financially.8

The second group is

independent adults (often referred to as non-traditional students).9 After identifying an eligible
participant, the H&R Block tax professional introduced the project explaining that we hoped “to
learn how people make decisions about college and how to pay for it, as well as find out how H&R
Block can best help its families navigate college finances.” The family was also offered $20 for their
time. If interested, the tax professional then asked the individual (and their legal parent or guardian,
if necessary) to complete a statement of informed consent. Once individuals consented, we asked
study participants general questions about their backgrounds and higher education perceptions.
Then, we randomly assigned individuals to one of three groups:
1. FAFSA Simplification and Assistance with Aid Eligibility Information (i.e., the FAFSA
Treatment)
For this group, we helped individuals complete the FAFSA. Our software first retained
information from the tax return to pre-populate FAFSA. Then, it led the H&R Block tax
professional through an interview protocol to gather answers to the remaining questions,
which took less than 10 minutes. These questions mostly concerned relatively straightforward
information such as parental education, educational goals, and the number of children in the
household currently attending college. After the interview protocol, the software computed

software. Based on feedback from focus groups and analysis of the operational data from the pilot conducted
January to April 2007, we finalized the procedures for the 2008 implementation.
8
In practice, most of our sample of younger students was age 17 at the time of the tax interview. This is because the
FAFSA typically considers students under the age of 24 as dependent on their parents unless they are married, have
a child, or are veterans. In these cases (in which the student is defined as a "dependent"), parental income is
required for the FAFSA, and so we focused on cases where a parent was completing taxes and the student was
declared a dependent on the tax forms. Individuals age 24 or older are automatically considered "independent" by
FAFSA standards, and parental information is not needed for the FAFSA.
9
A third sample consists of individuals who were high school sophomores or juniors (age 15-17). We gave these
families personalized aid eligibility estimates based on their tax data and in the future will examine how this early
information influenced high school academic preparation and future aid applications and college enrollment.

7

the amount of financial aid the client was eligible to receive from the federal and state
governments and provided a written explanation of these numbers (a sample award letter
appears in the appendix).10 The aid amounts reported to participants focused on need-based
aid (e.g., the Pell Grant and the Ohio College Opportunity Grant) as well as federal loans. In
reporting potential aid packages, we also presented the tuition prices of four nearby public
four- and two-year colleges.11 If all of the information necessary to complete the FAFSA
was obtained by the tax professional during this initial visit, we then offered to have H&R
Block submit the FAFSA electronically to the DOE free of charge; otherwise, families were
sent the completed paper FAFSA by mail to submit themselves.12 If we still needed to collect
additional information, an external call center contacted the family to ask the remaining
questions and offered to submit the form.13 Of the 10,634 individuals who received the
FAFSA treatment, we completed the FAFSA for nearly seven out of ten in either the office or
using the call center staff.14
2. Aid Eligibility Information only (i.e., the Information-Only Treatment)
For this group, we calculated individualized aid eligibility estimates using information from
the tax return that the participant had just completed at the H&R Block office. We also gave
individuals a written description of their aid eligibility and a list of the tuitions of four nearby
colleges. To receive the aid amounts, the tax professional then encouraged individuals in this

10

If we could not collect all the information needed for the office during the initial office visit, we still tried to
compute the amount of aid students were eligible to receive. Typically we were only missing data that is irrelevant
to the aid calculation (e.g. driver’s license number). In other cases, we were missing information on specific income
sources not listed on the tax return but needed for the FAFSA (e.g. SSI benefits).
11
For each region, we chose four plausible colleges based on enrollment patterns for that region. The schools were
a mix of open admissions and large, slightly selective institutions.
12
Approximately 42 percent of the sample preferred having H&R Block submit the FAFSA for them. Discussions
with tax professionals suggest that some participants preferred to see the form before having it submitted or felt that
by submitting the form they were committing to go to college and wanted more time to think about it.
13
Most often FAFSAs were not completed in the office because the family needed to supply additional information
such as other sources of income like veteran’s benefits or the child’s driver’s license number.
14
Completion rates differed slightly by type of participant. Among independent students with no prior college
experience, 54 percent completed their FAFSAs in the office and another 24 percent were completed with the help
of the Call Center (for a total completion rate of 78 percent). Among dependent students, 11 percent completed the
FAFSA by the end of the Call Center outreach process and another 66 percent nearly completed the form (having at
least 91 of the 103 FAFSA items). FAFSAs with missing fields may still have been deemed complete enough to
submit.

8

group to complete the FAFSA on their own (no help was given on the form as the emphasis
for this group was only on providing information).
3. Control Group (no intervention)
For this group, we only provided a brochure with basic information about the importance of
going to college and general information on costs and financial aid. We constructed the
brochure using information readily accessible online and elsewhere with the goal that this
information would not likely affect a participant’s behavior. As such, this group is our key
comparison group for determining the effects of the other interventions. The brochure was
also given to the treatment groups.
To summarize, the interventions were designed to test a program aimed at increasing college
information and to simplify the financial aid application process. The key outcome upon which we
focus is college enrollment and aid receipt. For students already attending college, the intervention
aimed to help them get additional financial aid support, which could impact the likelihood of college
persistence.
Table 1 outlines our recruitment process including the consent rates for our respective
treatment and control groups.15 During the tax season, H&R Block met with 236,483 clients in the
targeted offices. Of this group, 69,031 clients met the study’s initial criteria (having an AGI less than
$45,000 and a family member age 17 to 30), 35,793 expressed interest in learning more about college
(52 percent of clients meeting the study's criteria), and 26,401 qualified for the study after answering
in the affirmative that the target participant did not already have a bachelor’s degree (74 percent of
those expressing interest).16 Nearly all of the individuals expressing interest verbally consented to
participate in the project (26,168 individuals). Participants did not formally sign the consent form
until the end of the interview, and a small number left before doing so. For the sample of dependent
15

The dependent sample figures include both high school seniors and recent graduates, who are examined in this
paper, as well as participants who were high school sophomores and juniors, who will be examined in future,
separate work.
16
The primary reasons why some individuals did not qualify for the study was that they already had college degrees,
or were not considered independent by federal aid standards and so would need information from other family
members not present in the office in order to complete the FAFSA. Among those who qualified, tax professionals
during focus groups suggested that about half of those that expressed interest were initially attracted to the $20
discount, and the other half were interested because they wanted more information about college.

9

students, we find no statistically significant difference in the written consent rates across our
treatment groups. For independent adults, the differences in consent rates are marginally significant
at the 10 percent level. This is more likely due to the large sample (55,083) than because of real
differences. The maximal difference across groups is only 1 percentage point. The last column
reports the percentage of each group for whom we received a paper copy of the consent form.
Unfortunately, some tax professionals mistakenly sent the signed copies of the consent forms home
with the study participants, and we are prohibited from matching outcomes without proof of a signed
consent form. As a result, we had to exclude some individuals who initially consented to participate.
Importantly, however, the reasons tax professionals and district managers gave for not submitting
paper consent forms were unrelated to treatment status.17
During the experiment, we had several ways of assuring faithful implementation. First, the
software had a number of internal checks. It not only tracked completion of each question, but it also
prompted and reminded the tax professional what questions they should ask at each point of the
interview and tracked the time taken for each question. H&R Block also monitored treatment fidelity
through field visits. H&R Block received no reports of any serious deviation from the script from the
field offices. If a problem arose, we immediately integrated new procedures and training modules to
accommodate special circumstances.
We randomly assigned participants who consented to the respective groups as follows:
10,634 to the FAFSA assistance and aid interpretation group; 1,654 to the Information-only group;
and 11,916 to the Control group. The information-only is noticeably smaller as its only purpose was
to detect differences in FAFSA submission rates compared to the Control and FAFSA assistance
groups, not to detect small differences in college enrollment.18 For the FAFSA Treatment group, we
collected a sample size large enough to study the impact of the intervention on both FAFSA
17

In focus groups with tax professionals, they identified two main reasons why H&R Block central processing unit
did not receive a written copy of the consent form. First, many tax professionals accidentally sent all of the written
copies of the consent form home with the client. Second, many tax professionals filed the consent form with the tax
documentation rather than submitting the form to H&R Block’s central processing center. In both cases, we had
little recourse in retrieving the consent forms; however, we were able to identify which tax professionals made these
mistakes and train them so that they did not repeat the mistakes.
18
With a control mean of 0.2, the sample size gives us about 80 percent statistical power to detect a 3 percentage
point difference in FAFSA submission rates at the 5 percent significance level.

10

submission and college attendance. Because college enrollment is a lower probability event, we
needed a much larger sample size. It is also worth noting that the sample size for dependent students
is much smaller than that for independent adults due to the fact that H&R Block served a limited
number of families with a student under the age of 18 who was a high school senior or a recent high
school graduate.19
To study the effects of these interventions, we track the submission of applications for
financial aid, college enrollment patterns, and the financial aid awards of participants using data
made available through collaborative partnerships with the DOE and NSC.
participant information made available by H&R Block to their databases.

Each linked the
Several pieces of

information are available. First, from the NSC, we observe the institution attended and full and parttime enrollment status.20 Second, from the DOE, we observe whether the individual ever submitted a
FAFSA. Third, we observe the amount of financial aid paid out by the U. S. government for each
student. Using these data, we are able to demonstrate the effects of the intervention on the likelihood
of submitting an aid application, college attendance, and financial aid receipt.

III.

EMPIRICAL FRAMEWORK

Data – Descriptive Statistics
In Table 2, we report basic descriptive statistics for three key groups: dependent students
(i.e., high school seniors), independent adults who have not previously attended college, and
independent adults with some previous college experience. For each group, we report the means for
the control group and the differences (and their standard errors) with the treatment groups. Random
assignment should assure that our treatment and control groups are balanced and comparable. Our
19

Also, the informed consent process was a limiting factor. Parents could consent that their dependent participate if
their dependent was under the age of 18 at the time of the interview. If a student was 18 or older, we needed both
the parent’s and child’s consent to enroll them in the study. Most of these students do not accompany their parents
to H&R Block, and in our 2007 pilot, we were unable to achieve a high consent rate with this group. Hence, we
focus on the 17-year old high school seniors.
20
The NSC is a non-profit organization that provides national student degree and enrollment verification for
schools, colleges, and employers. Founded in 1993, it currently serves as a central repository for the institutions of
92 percent of college students.

11

algorithm for randomizing clients depended completely on the last two digits of the taxpayer's social
security number, and the software automatically made the treatment assignment.21 While one might
expect some small discrepancies, we should largely observe that there are no significant differences
between the control and treatment groups. As shown in Table 2, this is the case.
Among the sample of dependent participants, over 56 percent of the sample is female. The
racial distributions are also similar across treatment groups with comparable proportions of white,
black, and Hispanic participants. In the control group, 55 percent of participants were white and
about 38 percent of participants were black. Among the information-only treatment group, the
proportion of white participants was higher while the proportion of black participants was lower, but
these differences are not statistically significant. The average age of the dependent sample was about
17.7 at the time of the interview across all three groups.22
Across the groups about 85-88 percent of the samples were high school seniors according to
the parents. The others had either graduated from high school or had left high school and completed
a GRE. While most parents identified their children as being high school seniors, we searched the
NSC records to see if any of these participants had a history of previously taking a college course. In
our control and FAFSA treatment groups, nearly 6 percent of participants reported that they had
previously enrolled in college. These enrollments could represent a single course at a campus or
being in a dual enrollment program. The percentage was higher for the information-only treatment
group had previous enrollment. About 40 percent of parents reported that their children would be
targeting a bachelor's degree while 22 percent of parents reported their children’s target degree would
be an associate's degree.

The remaining parents indicated their child would be targeting a

21

Tax professionals could not override the screen prompts that were dependent on treatment status, and did not
know the nature of the treatment assignment algorithm. In focus groups, the tax professionals, confirmed that they
did not know which group individuals had been assigned to until the software made the assignment, which occurred
after the informed consent process.
22
In prior versions of the paper, we also included comparisons of parental education levels. For the dependent
participant sample, about 58- 63 percent of participants in the respective treatment groups had fathers and/or
mothers with a high school level of education. For mothers, 26-30 percent had completed some college while 16-19
percent of fathers had completed some college. The rest of the parents’ education levels were either unknown or
junior high. There were no significant differences in parental education levels across treatment groups.

12

professional certificate or indicated that they did not know. Family's average incomes were about
$23,000 while their taxable incomes were near $6,000.
For the dependent participant sample, we find no statistically significant differences between
the control group and the FAFSA treatment group or between the control group and the informationonly treatment group. Because of our sample sizes, we have sufficient power to identify even small
differences in the groups.

Hence our failure to find differences is an affirmation of our

randomization.
The rest of Table 2 shows the results for the independent adults, with separate columns for
those with and without prior college experience. We partitioned the sample into those with and
without prior college experience based on college enrollment records from NSC. We distinguish
between these groups because participants who had previously attended college would have already
navigated the college application and enrollment process at least once, and we wanted to examine
whether the effects of the interventions would differ for this group (some of this group was still
currently in college). Comparing the control and treatment groups, there are very few differences.
As is evident from the control group means, larger differences exist across the independent
participants with and without college experience. Among the sample of independent adults, about 64
percent of participants with prior college experience were female while about 57 percent of
participants without prior college experience were female.

Slightly more than 71 percent of

independents without prior college experience were white, but for those with previous college
experience the proportion was about 64 percent. Participants were 26 years old on average across
groups of independent participants and across treatments.
The proportions of independent adults focusing on bachelors and associates degrees were
similar within the various treatment groups but very different across independent participants with
and without previous college experience. Participants who had previously attended college were
more likely to pursue a bachelors or associates degree. Income levels were similar across treatment
groups but different according to whether or not participants had previous college experience. Those

13

with previous college experience had incomes that were about $1500 to $2000 more than those with
no previous college experience.
For the sample of participants without prior college experience, we find no significant
differences between the FAFSA treatment and control groups, and we find only two significant
differences between the information-only treatment and control groups. Participants in the
information-only treatment group were slightly younger and had less income. These two differences
are significant at the 10 percent level. For the sample of participants with prior college experience,
we also find no differences between our FAFSA treatment group and the control group. We find,
however, a few differences with the information-only treatment group in terms of gender, marital
status, the likelihood of being a current college student, and in target degree being a bachelor's
degree.
The differences found should not cause major concern as one would have expected some
false positives. Additionally, we have a smaller sample for the information-only treatment, so there
may be some possibility that the sample is not balanced in some characteristics. In the analysis, we
control for covariates to account for any imbalance that may exist between the information-only
treatment and our control group.

Empirical Strategy
Because the proposed treatment was administered using randomization, simple comparisons
of participants in the various treatments can identify the relative effects of the interventions. Our
control group (i.e. those receiving only a brochure of basic information) is compared to our treatment
groups. We estimate both the effects of offering the service (intent-to-treat effects) and the effects of
using the service among individuals for which a FAFSA is filed (treatment–on-the-treated effects).
The "intent-to-treat" (ITT) effect can be estimated with the following regression:
(1)

y i = δ 0 + δ 1 * FAFSA i + δ 2 * INFOi + bX i + ε i

where y is an outcome for individual i, FAFSA represents whether H&R Block offered individual i
the first treatment – assistance with completing the FAFSA and a personalized aid estimate, and

14

INFO represents whether H&R Block offered individual i the second treatment – an estimate of the
amount of financial aid he or she is eligible for at area colleges but no help with the FAFSA.
Additional controls, X, include variables such as age, gender, race, and family income.

The

outcomes of interest whether a FAFSA was filed, whether the participant enrolled in college the
following school year, whether they enrolled full- or part-time, and whether they received financial
aid.

IV.

RESULTS

Program Effects on FAFSA Submission
Table 3 reports estimated treatment effects on the likelihood of submitting a FAFSA to the
DOE for the school term immediately following the intervention. Filing status is regressed on
indicators for whether the participant was exposed to simplification and information (the FAFSA
treatment) or the information-only treatment using robust standard errors with and without
background controls.23 Among dependent students, 40.2 percent of the control group went on to file
a FAFSA. In contrast, those who were offered help completing the form through our study were 15.7
percentage points more likely to file (column 1), which corresponds to a 40 percent increase (pvalue<.01). The FAFSA treatment effect is similar with and without including controls for gender,
race, age, previous college experience, and parental education and income.
The information-only treatment did not have a substantial effect on aid application
submission. Participants who received only information about their likely grant and loan eligibility
relative to college costs were no more likely to file a FAFSA than the control group, though the small
sample size of dependent children in this treatment group makes it difficult to rule out a possible
effect for this group. However, we can rule out at the 5 percent significance level that the FAFSA
assistance and information-only treatment effects are the same. There was a clear, large effect for
those who received the FAFSA treatment.
23

Our results are robust if we cluster our standard errors at the level of the tax professional or tax office.

15

Columns 3 and 4 focus on the sample of independent adult participants with no prior college
experience. The fraction who filed a FAFSA among independent adults out of school is, not
surprisingly, smaller than that among dependents about to graduate from high school or with recent
high school degrees. Only 13.8 percent of the control group of independents without prior college
experience filed the aid application. The FAFSA treatment effect on filing, however, is very large: a
near tripling of the FAFSA submission rate to the DOE, from 13.8 percent to 39.5 percent.
Meanwhile, the information-only treatment had essentially no impact on filing.
Columns 5 and 6 show results for the independent sample who had previously attended
college. These individuals were either still in college, had taken college courses in high school, or
had stopped out of college before graduating. The FAFSA filing rate for the control group was 35.3
percent. This rate rose by 20.4 percentage points for the FAFSA treatment group, to 55.7 percent.
As with the other samples, however, the information-only treatment appears to have had no effect on
filing status.

Program Effects on College Enrollment
Table 4 shows the estimated Intent-to-Treat (ITT) effects on college enrollment during the
fall immediately after participation in the program using data from the NSC. Column 1 reports a
remarkable increase in college enrollment for dependent participants in the FAFSA treatment group.
Enrollment rates increased from 26.8 percent among the control group to 34.5 percent, or a relative
increase of about 29 percent. Adding demographics and family background controls to the estimates
in Column 2 generally does not change the results. They do show, however, that females are much
more likely to enroll. A mother with a college degree and taking a previous college course are also
strong predictors for a child going to college regardless of treatment status.
Columns 3 and 4 show estimated effects for the larger independent sample with no prior
college enrollment. The absolute difference in enrollment rates between the FAFSA treatment and
control groups is small (0.6 percentage points), but because the control group mean is small as well
(2.9 percent), this translates into a relative increase of 20.6 percent (3.5 percent compared to 2.9

16

percent). The difference is almost statistically significant with a p-value of 0.14. The 2.9 percent
attendance rate for the control group and the observed treatment effect of 0.006 are likely
underestimates of the true rates in this population. As we later show in Table 5 using data from the
DOE, 9.6 percent of the control group for the participants with no prior college experience received
some type of financial aid. The difference between the 9.6 percent and the 2.9 percent rates for the
control group is made up of students who attended colleges which do not participate in the NSC. We
expect the treatment effects to be underestimates because further analysis suggests that the treatment
group was more likely to send FAFSA data to institutions that did not participate in the NSC data
than the control group. We discuss this below during our discussion of Table 5.
For independents who had previous college experience, the mean enrollment rate was much
higher than that for other independents, but we find no significant differences between treatment and
control groups: 23.7 percent of the control group is enrolled compared to 24.3 percent of the FAFSA
treatment group (p-value=.59). In the sample of independents with prior college experience, we are
less concerned that our estimates may be downward biased. We defined prior college enrollment
using the NSC data, so these students have already attended or were attending an NSC school. These
students were likely to stay in these institutions where we have excellent coverage from the NSC.
For all samples, our estimated effects for the information-only treatment group are
insignificant. The point estimates are always small, but given our small sample size, the estimated
standard error bands remain generous. While our estimates are noisy, we interpret the lack of any
statistically significant effect as being a sign that there is no effect. As noted above, the principal
goal of including this treatment group was to test the effect of information alone on FAFSA filing
behavior. Given we failed to find an effect of the information-only treatment on FAFSA submission
rates in Table 3, we interpret the lack of finding an enrollment effect in Table 4 as not surprising.

Program Effects on Financial Aid Receipt
In Table 5, we extend the analysis by examining the effects of the treatments on the receipt of
financial aid. According to data from the DOE, about 29.8 percent of dependent participants in our

17

control group received a Pell Grant, the primary need-based federal award. The FAFSA treatment
substantially increased this rate by 9.8 percentage points, or about a relative 33 percent increase. For
independent participants with no prior college experience, our estimated treatment effect is 2
percentage points, or about 20 percent. For independent participants who had previously attended
college, the FAFSA treatment effect was about 3 percentage points, or 13 percent.
As noted above, a comparison of Tables 4 and 5 shows a major difference between the
control group’s mean attendance rates (Table 4) and the rates at which participants received grant aid
(Table 5). In the dependent sample, 30 percent of participants in the control group received aid yet
our attendance measure in Table 4 shows that 27 percent attended college. Similarly, 2.9 percent of
independent participants attended college according to the NSC data while 9.6 percent received grant
aid according to the DOE data. These discrepancies arise because of the lack of coverage of the NSC
data. The NSC data allow us to track college enrollments at about 92 percent of colleges and
universities nationwide.24 If NSC captures enrollment, it does so regardless of whether or not
students applied for financial aid. The DOE data, by contrast, covers all campuses that distribute
federal financial aid but only tracks students if they applied for the aid. Seven percent of dependent
study participants and 16 percent of independent study participants attended college without filing a
FAFSA.
We use the DOE data to shed some light on the extent to which the NSC data might underreports college enrollment rates. To do so, we identify how many participants sent FAFSA data to a
college not covered by NSC.25 Among our samples, 9.8 percent of dependent participants in the
control group listed at least one school on the FAFSA that was not covered by NSC. Similarly in our
other samples’ control groups, 9.4 percent of independents without prior college experience and 12.9
percent of independents with prior college experience listed at least one school not covered by NSC.
However, the likelihood of sending FAFSA data to a school not covered by NSC was larger among
independent participants without prior college experience who were in the FAFSA treatment group;
24

Students also have the option to request that their data not be matched to NSC. Students exercise this option
through their respective campus. We cannot observe these students.
25
At the end of the FAFSA, individuals can designate up to four colleges or universities to have their FAFSA
information sent.

18

they were 2 percentage points more likely to send their FAFSA to a school not in the NSC database.
There are no statistically significant differences for our other samples.
An extreme assumption would be to assume that sending FAFSA data to a non-NSC school
implies attendance. If we amend our college attendance variable previously based on the NSC data
alone so that participants who applied to a non-NSC school by sending their FAFSA data are counted
as having attended, then our results become stronger for the dependent sample and the independent
sample without prior college experience. The control group means become 33 percent for dependent
participants and 12 percent for independent participants without prior college, and the treatment
effects on college attendance become 8.3 and 2.4 percent, respectively.

Both estimates are

significant over a 99 percent confidence interval. With the revised measure we find no treatment
effects on enrollment for independent participants with prior college experience. We view these
estimated treatment effects using this extreme assumption as upper bounds on the potential
enrollment effects.26
In Table 5, we observe that individuals with prior college experience in our treatment group
were 3 percentage points more likely to receive grant aid. However, we find no enrollment effect in
Table 4 and in our effort to account for potential biases in the NSC measure of attendance. Together
these findings confirm prior research suggesting that some eligible college enrollees do not apply for
aid. Additionally, although it is somewhat hard to interpret given that the treatment had effects on
aid receipt, we find that the size of financial aid awards was larger for students in the FAFSA
treatment. Moreover, there was a 2 percentage point increase in student loan receipt among these
students. Therefore, while the FAFSA experiment did not necessarily increase enrollment rates
among this group, it did increase access to financial aid.

Much like our results on FAFSA

submission rates, we detect no statistically significant effects of the information-only treatment on
aid receipt or financial aid award sizes.

26

The only way that this is not true is if we have more control group participants than treatment group participants
attending non-NSC colleges and not filing FAFSA’s. This is unlikely given that 84-92 percent of control group
participants attending college file FAFSA’s.

19

In the bottom half of Table 5, we explore whether the treatments had an effect on FAFSA
filing conditional on enrollment. Our results on grant aid receipt suggest that some independent
participants with prior college experience would have received financial aid had they completed the
FAFSA. If this is true, we should also find a treatment effect on the FAFSA filing behavior of
students who attended college after the intervention.

For our control group, 84.1 percent of

independents who had prior college experience and attended college after the experiment filed a
FAFSA.

Corresponding independents in the FAFSA treatment group were 4.0 percentage points

more likely to file. This reinforces that while we can rule out large impacts on enrollment for
independents who had college experience prior to the study, providing information and assistance did
increase the fraction of those filing while in college and as we showed above it increased access to
grant and loan aid as well. We find no effects on filing behavior among those in the informationonly treatment.
For many states and institutions, there are binding deadlines for applying for financial aid.27
In Table 5, we also compare the timing of FAFSA applications among filers. Given that there was a
treatment effect on FAFSA filing, it is somewhat difficult to interpret these results. The estimated
difference in the time to file is a weighted average of the effect of the program on filing timing for
participants who would have filed regardless of the experiment and the timing of participants who
were newly induced to file because of the program and would not have filed otherwise. If the timing
of new-filers is slower than the average participant, then the comparisons would be biased
downward. However, the timing results reinforce the idea that the FAFSA intervention accelerated
the aid application submission process. Among dependent students in the control group, the average
filing date was around May 11th. Participants in the FAFSA treatment filed their FAFSA's almost
one month (32.6 days) earlier. For independent participants without prior college experience, those
treated filed FAFSA's almost 4 months earlier than the control group, and the treatment effect among
independent students with prior college experience was a little over 2 months. There was no
treatment effect on the likelihood that dependent students filed before March 1st; however, for
27

The earliest deadline among states is March 1st. Arizona, Idaho, Maryland, Michigan, Montana, Rhode Island,
Tennessee, and West Virginia all share this deadline.

20

independent students, there were large treatment effects for all independent students. Among those
without prior college experience, treated students were 55 percentage points more likely to file by
March 1st and among those with prior college experience, treated participants were 29 percentage
points more likely to file by March 1st. It is also worth noting that independent adults without prior
college experience who had the information-only treatment were also more likely to file earlier.

Heterogeneous Enrollment Effects
In Table 6 and 7, we explore whether the program had heterogeneous effects among
participants. Table 6 focuses on college enrollment outcomes to examine whether the program
treatments increased particular types of attendance. The FAFSA treatment effect on enrollment
occurred mostly from increases in public college enrollment. Public college enrollment rose 5.0
percentage points (p-value=.059) for the dependent sample, compared to 1.8 percentage points at
private colleges (p-value=.233). For the dependent students, we also find a doubling in the rate of
attendance at selective colleges for those who received the FAFSA treatment. Additionally, most of
the increase in attendance rates came from full-time attendance as the estimate of the effect on partand full-time enrollment is not much different than the estimate on full-time enrollment alone.
Among independents without prior college experience, public college enrollment
immediately following treatment rose slightly by 0.6 percentage points to 2.8 percent (p-value=.060).
Basically none of these independent adults enrolled in private colleges (the fractions are 0.1 percent
for the treated and controls).28 Most participants attended non-selective, public colleges if they chose
to attend college. Among independents with no prior college experience, we detect no difference in
part-time enrollment by treatment assignment, but we do find full-time enrollment rises .7 percentage
points (p-value 0.016). For both of our independent participant samples, we find no effect of the
treatment on the selectivity of the college attended.
Overall, the enrollment effects we find among independents are small, but nevertheless
important given the low cost of the FAFSA treatment and the small numbers of adults not in school
28

We include proprietary schools in our listing of private schools. Our results do not change if we break the private
results down by whether or not the private school is a proprietary school.

21

that actually go back. To get a better idea of whether these effects are concentrated among particular
subgroups, we estimated the FAFSA treatment impact for this sample by household income. We
interacted enrollment patterns with quartic polynomials for household adjusted gross income (AGI),
separately for the control group and treated. Figure 1 shows clearly that the FAFSA treatment
affected mostly low-income households (those with an adjusted gross income less than $22,000).
Among this group, college enrollment is 4.0 percent for the FAFSA treatment compared to 2.9
percent for the control group (p-value for the difference is 0.017).

Interestingly, the DOE’s

Estimated Family Contribution (EFC), which is the amount the federal government calculates a
family should be able to give something towards college expenses, begins to rise for households with
incomes around $22,000.

In essence, the results suggest that independent participants in the

treatment group who were told that their family was not expected to contribute towards college
expenses were the one who were the most influenced to go to college by the FAFSA intervention.
Conversely, individuals told that the government would only cover part of the costs of college were
less likely to attend.
Subdividing the data by whether the EFC estimate sent to participants is estimated to be zero
or positive leads to generally larger and significant effects for the former group, and insignificant
effects for the latter. Table 7 displays treatment effect estimates for the independent sample without
prior college, split by whether EFC was estimated based on FAFSA information to be zero or
positive. The FAFSA treatment effect for the EFC=0 sample is 1.2 percentage points. The effect
when EFC>0 is -0.8 percentage points, but not statistically significant, and the Information-only
treatment effect point estimates are close to zero. Subdividing further by background characteristics
and survey responses, we find larger FAFSA treatment effects for the groups generally one would
expect. The effects among independents with no prior college and EFC predicted to be zero are
larger for those who, before treatment, expressed strong interest in college (a 1.8 percentage point
increase in enrollment from treatment for this group), and for those who say some do not go to
college because they have to work (a 3.4 percentage point increase).

The effects are also

concentrated among females and those without dependent children. With one exception (Black

22

participants with EFC>0 in information-only treatment sample), all of the information-only treatment
effect estimates, and the FAFSA treatment effects for the predicted EFC>0 sample are not
significantly different from zero.

V.

CONCLUSIONS AND IMPLICATIONS
The results of the H&R Block FAFSA experiment are unambiguously positive in terms of the

effects of simplifying the financial aid application process combined with providing individualized
aid eligibility information. The estimates suggest that the FAFSA treatment had strong effects in
terms of increasing college financial aid applications, improving the timeliness of aid application
submission, increasing the likelihood college attendance, and increasing the receipt of need-based
grant aid. This is true for students who were just graduating from high school and for most
independent adults without prior college experience. Even though we found no enrollment effect for
non-traditional students who had already spent time in college, the FAFSA treatment did improve
FAFSA submission rates, increase the likelihood that these participants received financial aid, and
increase the average amount of financial aid received.
The FAFSA Experiment’s main treatment consisted of three potential mechanisms –
simplification of the FAFSA application by pre-populating the form with tax data, assistance in
filling out the aid forms with a streamlined interview protocol, and information provision. A test of
whether only providing information could explain the results failed to produce statistically significant
effects. We can reject the hypothesis that the information-only treatment had a similar effect on
FAFSA submission rates as our FAFSA treatment. It is important to note that our experiment only
tested the impact of providing particular types of information to students at the end of high school or
afterwards. We can say nothing about whether providing different types of facts or information to
younger students would affect college decisions.29 However, given that information alone cannot

29

Several access initiatives focus on giving middle and early high school students information about college and
financial aid.

23

explain our results, we consider the possible roles of simplification and assistance as the mechanisms
responsible for the large effects found on submission, enrollment, and aid receipt.
The FAFSA Experiment was not designed to distinguish between the relative effectiveness of
simplification versus assistance as being most effective in bringing about the results. There were,
however, some places during implementation where assistance was minimized and the intervention
experienced by individuals focused mainly on simplifying the process. To see this, it is first worth
noting the different options participants had when deciding whether to file a FAFSA with the DOE.
Some options required more action by the individual than others:
i.

FAFSAs completed in the office: If an independent participant provided all the necessary
information to complete the FAFSA while at the tax preparation office, she was asked whether
she wanted H&R Block to file the form on her behalf electronically (through batch files sent
directly to the DOE). Doing so required the tax professional to verify the information with the
client before transmitting it to the DOE, and the only thing the participant had to do was sign a
FAFSA signature page while in the office. As an alternative to having H&R Block submit the
form, participants also had the option of receiving a paper copy of the completed FAFSA, which
they could elect to submit it to the DOE themselves. In contrast to electronic submission, this
option would have required the individual to take additional steps in order for the FAFSA to be
filed.

ii. FAFSAs completed with the call center: If the independent participant was not able to answer all

the necessary questions in the office but did so afterwards with the Call Center, they were also
offered two choices. If the participant wanted H&R Block to submit the completed form to the
DOE, this was done by Call Center staff via the DOE website.

After web submission,

participants were sent a paper copy of the application and a FAFSA signature page that they
needed to sign and return to the DOE using a prepaid envelope. Unlike participants who were
able to complete all of the questions in the office and sign the form in person, this group needed
to complete this minor, final step via the mail. Similar to above, participants who did not want

24

H&R Block to submit the form to the DOE were sent a paper copy of the completed FAFSA,
which they could elect to submit it to the DOE themselves.
iii. Incomplete FAFSAS: Finally, if the Call Center could not reach the family after three tries and/or

collect all the necessary FAFSA information from the participant over the telephone, the
participant was sent the partially-completed paper FAFSA in the mail.

Instructions were

included to help the participant finish the form, and a prepaid envelope was provided to enable
submission to the DOE. In this case, the participant needed to take several additional steps on
their own to submit the FAFSA.
The submission options for dependent participants were slightly different.

Because electronic

submission by H&R Block via batch files would have required that both the child and parent sign the
application in the office, dependent participants were not given this option (see footnote 8). Instead,
if the participant wanted H&R Block to submit on their behalf, it was done via the DOE website, and
the family was sent a FAFSA signature page to return. Otherwise, a paper FAFSA was sent to them.
As detailed with the above scenarios, there was variation in how much action a participant
needed to take in order to submit the FAFSA. Clearly, this variation is not random as the profiles of
participants who could complete the form entirely while in the H&R Block office are different from
those who used the Call Center or could not be contacted. Still, we find interesting patterns for the
control and treatment groups based on the different modes of submission.
Among dependent participants, nearly the entire control group who submitted a FAFSA used
the web to file, but those in our FAFSA treatment group were more likely to do so (45.0 percent
versus 37.9 percent). Dependent students in the FAFSA treatment group were also more likely to file
by paper in comparison to the control group (9.1 percent versus 1.3 percent). Interestingly, the filing
rate for participants who were sent completed paper FAFSAs that only required a signature before
mailing was about the same rate as participants sent incomplete paper FAFSAs and thus needed to
fill in additional information before submission. In other words, dependent participants who elected
to submit the FAFSA themselves rather than having H&R Block submit it for them it via the web
were far less likely to complete the process.

25

For all independent participants, the large positive effects on FAFSA submission rates
experienced by those assigned to the FAFSA treatment came from the large number of applications
submitted electronically. Of the overall estimated 23.5 percentage point increase in FAFSA filing,
90.2 percent of this increase comes from those who filed electronically.30 Interestingly, among the
cases that were completely finished while the person was in the H&R Block office, 56 percent
preferred to have the application sent to them in paper form. For this treated group, there was no
difference from the control group in terms of FAFSA filling rates (13.5 percent versus 13.8 percent,
respectively).
Thus, we find that nearly all of the estimated effects for independent participants on filing
occur within the group of individuals who indicated a preference for direct submission and had it
done electronically by H&R Block. These individuals for whom assistance and simplification with
the application were most prominent (and the FAFSA was completed in the office) appear to be the
ones most affected by the treatment. Though the participant would have still needed to take action to
actually enroll in college, minimizing the amount of work needed to complete the FAFSA application
had profound effects.

In contrast, the treatment effect was not present for those indicating a

preference for paper submission. This could be related to the amount of additional effort these
participants needed to take (i.e., receiving, signing, and sending the FAFSA signature page).
However, as noted above, those who elected to receive the paper form are not a random subsample,
and their preference to not have H&R Block submit the form could be indicative of less commitment
by this group to submit the requisite forms and to attend college.
While the patterns of application rates by submission type (electronic, web, or paper) are not
a perfect test of which aspect of the intervention was most important in driving the results, the results
do suggest that providing assistance and streamlining the submission process are crucial elements in
improving aid application submission and increasing college enrollment. However, does the fact that
the largest results were among those for whom H&R Block submitted the FAFSA mean that prepopulating the form with tax data (i.e., reducing the number of FAFSA questions) is not useful at all?
30

This was calculated by adjusting down the 23.5 percentage point increase in electronic submissions by the 1.3
percentage point decrease in web submissions among the FAFSA treatment group.

26

To the contrary, we believe simplification still played an important role in the positive effects. Our
results clearly show that FAFSA applications were done more efficiently by using information from
an IRS tax form. In the experiment, the H&R Block tax professionals were able to complete the rest
of the FAFSA with the client in less than ten minutes because of the ability to simplify the data
collection elements by using tax data that was already in the system. The remaining FAFSA
questions are relatively straightforward and easy (e.g., gender, citizenship, veteran status, state of
legal residence, parents' education, intended degree, phone number, driver's license number). In
comparison, the typical method of completing the FAFSA at home takes hours. The FAFSA is
similar to the regular 1040 tax form, which the IRS (conservatively) estimates will take 13 hours to
complete. This suggests that linking tax data and the FAFSA on a larger scale would significantly
cut the number of necessary elements on the form and in turn substantially reduce the time necessary
to complete the form and improve the accuracy of the information submitted. It is worth noting that
the DOE has recently taken efforts to pilot this sort of partnership (see footnote 2). Such a change
would also make it easier to develop programs (assistance) that could help families to fill out and
submit the form (such as our automated process that walked families through the remaining
questions).
In summary, the results suggest that simplification and assistance together are effective ways
to increase the submission of financial aid applications. The combination of pre-populating the
FAFSA with tax information (i.e., simplification), providing assistance with remaining questions
using the interview protocol we automated with computer software, and giving participants the
option to submit the FAFSA to the DOE electronically was highly effective.. On the other hand,
simply informing high school seniors and older adults about their aid eligibility did not appear to
improve the submission of financial aid applications. This suggests the complexity of the FAFSA
and/or the time required to complete the form are substantial barriers to FAFSA completion, and
making the form shorter (i.e., simplification alone) would likely increase FAFSA submissions. We
hope future research can shed additional light on which elements of the overall intervention were
most effective.

27

REFERENCES
Advisory Committee on Student Financial Assistance.

(2001). Access Denied:

Restoring the

Nation's Commitment to Equal Educational Opportunity. Washington, D.C.: Department of
Education.
Advisory Committee on Student Financial Assistance. (2005). “The Student Aid Gauntlet: Making
Access to College Simple and Certain.” Final Report of the Special Study of Simplification
of Need Analysis and Application for Title IV Aid. Washington, D.C.: Department of
Education.
Avery, Chris and Caroline Hoxby. (2004). Do and should financial aid packages affect students’
college choices? In Hoxby, C. (Ed.), College Choices: The Economics of Which College,
When College, and How to Pay For It. Chicago: University of Chicago Press.
Bettinger, Eric, “Is the Finish Line in Sight? Financial Aid’s Impact on Retention and Graduation.”
(2004) College Choices: The Economics of Where to Go, When to Go, and How to Pay For
It, ed. Caroline M. Hoxby, Chicago University Press and NBER.
Beshears, John, James J. Choi, David Laibson, and Brigitte C. Madrian (2006a). “The importance of
default options for retirement savings outcomes: Evidence from the United States.” NBER
Working Paper #12009.
Beshears, John, James J. Choi, David Laibson, and Brigitte C. Madrian (2006b). “Simplification and
savings.” NBER Working Paper #12659.
Commission on the Future of Higher Education. (2006). Commission Report 08/09/06. Accessed on
10/23/06 at http://www.ed.gov/about/bdscomm/list/hiedfuture/reports/0809-draft.pdf .
Cornwell, C., Mustard, D., & Sridhar, D. (2006). The enrollment effects of merit-based financial aid:
Evidence from Georgia's HOPE scholarship. Journal of Labor Economics 24 (2006) 761786.
Currie, Janet (2004) "The Take Up of Social Benefits." NBER Working Paper #10488.
Dickert, N., Emanuel, E. & Grady, C. (2002) "Paying research subjects: an analysis of current
policies." Annals of Internal Medicine 136: 368-373.

28

Dynarski, Susan. (2000). Hope for whom? Financial aid for the middle class and its impact on
college attendance. National Tax Journal, 53(3), 629–661.
Dynarski, Susan. (2003). Does Aid Matter? Measuring the affects of student aid on college
attendance and completion. American Economic Review 93(1), 279–288.
Dynarski, Susan and Jill Scott-Clayton (2006) "The Cost of Complexity in Federal Student Aid:
Lessons from Optimal Tax Theory and Behavioral Economics." Harvard University mimeo.
Dynarski, Susan. (2002) "The Behavioral and Distributional Implications of Subsidies for College."
American Economic Review 92(2): 279-285.
General Accountability Office. (2005). Student Aid And Postsecondary Tax Preferences: Limited
Research Exists on Effectiveness of Tools to Assist Students and Families through Title IV
Student Aid and Tax Preferences. GAO-05-684, July 29.
Hansen, W. L. (1983). “Impact of Student Financial Aid on Access,” Proceedings of the Academy of
Political Science, Vol. 35, No. 2, The Crisis in Higher Education, pp. 84-96
Hastings, Justine, and Jeffrey Weinstein (2008). “Information, school choice, and academic
achievement: Evidence from two experiments,” Quarterly Journal of Economics, Vol. 123(4),
pp. 1372-1313..
Horn, Laura J., Xianglei Chen, and Chris Chapman. (2003). Getting Ready to Pay for College: What
Students and Their Parents Know About the Cost of College Tuition and What They Are
Doing to Find Out. National Center for Education Statistics Report No. 2003030.
Washington, D.C.: National Center for Education Statistics.
Ikenberry, S. O. and T. W. Hartle. (1998). Too little knowledge is a dangerous thing: What the public
thinks about paying for college. Washington, DC, American Council on Education.
Kane, Thomas J. (1996) “College costs, borrowing constraints and the timing of college entry,”
Eastern economic Journal, Vol. 22, No. 2, pp. 182-194
Kane, T. J. (2003). A Quasi-Experimental Estimate of the Impact of Financial Aid on College-Going.
National Bureau of Economic Research Working Paper No. 9703, Cambridge, MA.

29

Kane, Thomas J. and Christopher Avery. (2004) “Student Perceptions of College Opportunities: The
Boston COACH Program” in Caroline Hoxby (ed.) College Decisions: The New Economics
of Choosing, Attending and Completing College. Chicago: University of Chicago Press.
King, Jacqueline E. (2004) “Missed Opportunities: Students who do not Apply for Financial Aid,”
American Council on Education Issue Brief.
Long, Bridget Terry (2004). How Have College Decisions Changed Overtime? An Application of the
Conditional Logistic Choice Model. Journal of Econometrics, 121(1-2), 271-296.
Manski, Charles F. and Wise, David A. (1983) College Choice in America. Harvard University Press.
Oreopoulos, Philip, and Ryan Dunn. (2003) “Providing Information and Increasing Knowledge
About Post Secondary Education: Evidence from a Randomized Field Experiment.”
unpublished mimeo.
Sallie Mae Fund (2003) Press release January 20, 2003.

Accessed January 23, 2006, from

http://www.thesalliemaefund.org/news/news_nr184.html.
Seftor, N. S. and Sarah Turner. (2002) “Back to School – Federal Student Aid Policy and Adult
College Enrollment.” Journal of Human Resources, 37(2): 336-352.

Sturrock, C. (2002). Students miss out on free aid. Contra Costa Times, December 26.
U.S. Department of Education. (2009) “Making College More Affordable By Simplifying The
Student Financial Aid Application.” Press Release, June 24. Accessed July 6, 2009, from
http://www.ed.gov/print/finaid/info/apply/simplification.htm

30

-.02

0

.02

.04

.06

Figure 1. Predicted Enrollments by Income, Independent Participants

0

10000

20000
Adjusted Gross Income

Control
95 Percent Conf Int Upper

30000

40000

Treatment
95 Percent Conf Int Lower

.1

.15

.2

.25

.3

A. Independent Students with No Prior College Experience

0

10000

20000
Adjusted Gross Income

Control
95 Percent Conf Int Upper

30000

40000

Treatment
95 Percent Conf Int Lower

B. Independent Students with Prior College Experience
Notes: Predicted enrollments are estimated separately using a 4th order polynomial in adjusted gross income.
Models are estimated separately for treatment and control.

31

Table 1. Consent, Exit, and Processing Rates by Treatment Status
Initial
Screening
Qualification
(number)

Expressed
Interest

Qualified
(Final)

Accepted
Finished
and Gave
Office
Consent
Interview
(Fraction of Total)

Paper
Consent Form
Received

A. Dependent Sample
Control Group

6438

0.532

0.413

0.403

0.400

0.301

FAFSA Treatment Group

7510

0.512

0.404

0.395

0.392

0.295

13,948

0.521

0.408

0.398

0.396

0.298

Full Sample
F-test p-value (Testing of
Equality of Means)
B. Independent Sample
Control Group

---

0.023

0.284

0.327

0.334

0.496

25,215

0.515

0.374

0.372

0.369

0.279

FAFSA Treatment Group

25,491

0.521

0.379

0.377

0.374

0.288

4377

0.511

0.367

0.365

0.361

0.277

55,083

0.518

0.376

0.374

0.371

0.283

Info Only Treatment Group
Full Sample

F-test p-value
--0.274
0.287
0.216
0.144
0.057
Notes: The dependent sample figures includes both high school seniors and recent graduates, who are examined in
this paper, as well as participants age 15-17, who will be examined in future work. To initially qualify, families had
to have an AGI less than $45,000 and a family member between the ages of 15 and 30 who did not already have a
bachelor's degree. After asking whether these potentially eligible families were interested in learning more about
college (the second column of numbers), the tax professional posed additional questions to check for eligibility and
determine final qualification (the third column). Nearly all of these participants agreed to give consent (the fourth
column) and then completed the office interview (the fifth column). The last column reports the percentage of each
group for whom we received a paper copy of the consent form, which had to be sent via snail mail to the central
project office by the tax professional.

32

Table 2. Descriptive Statistics and Differences by Treatment Status
Dependent Participants
Control
Female

0.560

White

0.553

Black

0.379

Hispanic

0.023

Age

17.72
(.46)

Previous College Enrollment

0.056

FAFSA
Treatment
.019
(.035)
.003
(.036)
.014
(.035)
-.005
(.010)
.020
(.035)
.003
(.017)

Info
Treatment
.014
(.061)
.097
(.059)
-.079
(.057)
.002
(.019)
.042
(.051)
.057
(.037)

Married
Single
Divorced or Separated
Current College Student (self report)

0

0

.002
(.007)
.002
(.009)
-.003
(.005)
-.004
(.006)

-.020
(.013)
.023
(.015)
-.002
(.010)
-.029
(.008)

.002
(.007)
.002
(.009)
-.003
(.005)
-.004
(.006)

-.006
(.010)
.012
(.010)

.005
(.018)
.007
(.018)

1
0.127
0.807
0.065
0.324

1

1

-.010
(.008)
.009
(.010)
.001
(.006)
.005
(.012)

-.023
(.015)
.033*
(.018)
-.010
(.011)
.062**
(.023)

.001
(.013)
-.007
(.013)

.046*
(.024)
-.016
(.023)

.013
(.043)
-.024
(.060)
-.010
(.050)

0.275

$23,214
(11,667)

378.12
(817.76)

-704.66
(1403.14)

$16,315
(9741)

-261.57
(210.73)

-668.41*
(374.82)

$17,944
(9834)

111.61
(251.66)

-207.08
(464.23)

396

390

80

4155

4350

732

3006

3124

507

0.848

Target Degree Would Be Bachelor's

0.412

Target Degree Would Be Associate

0.222

Observations

0

Independent Participants
with Prior College Experience
FAFSA
Info
Control
Treatment Treatment
-.007
-.043*
0.641
(.012)
(.023)
.002
-.005
0.638
(.012)
(.023)
.006
.007
0.303
(.012)
(.022)
-.003
-.001
0.021
(.004)
(.007)
26.14
.060
-.118
(2.82)
(.072)
(.132)

.022
(.025)
-.014
(.035)
.001
(.030)

Current High School Student

Adjusted Gross Income

Independent Participants
with No Prior College Experience
FAFSA
Info
Control
Treatment
Treatment
-.001
-.020
0.573
(.011)
(.020)
-.009
.007
0.713
(.010)
(.018)
.006
-.013
0.233
(.009)
(.017)
.002
-.002
0.025
(.003)
(.006)
25.96
.021
-.214*
(3.12)
(.068)
(.124)

0.297

0.424
0.411

Notes: Standard deviations appear in parentheses for non-binary variables. By FAFSA standards, dependent students are typically under the age of 24 and financially dependent
on their parents. In this case, most dependent participants in the sample are high school seniors. Independent participants were over the age of 24 or married, had a child, a
veteran, or an orphan. "Prior college experience" is defined using data from the National Student Clearinghouse

33

Table 3. OLS Regressions of the Effects on FAFSA Filing
Dependent Variable = Filed a FAFSA with the U.S. Dept. of Education
Dependent
Participants
Control Mean = .402
(1)
(2)

Independent Participants
with No Prior College
Experience
Control Mean = .138
(3)
(4)

Independent Participants
with Prior College
Experience
Control Mean = .353
(5)
(6)

FAFSA Treatment

.157**
(.035)

.146**
(.033)

.257**
(.009)

.257**
(.009)

.204**
(.012)

.206**
(.012)

Information-Only
Treatment

-.012
(.060)

-.034
(.055)

-.011
(.013)

-.013
(.013)

.019
(.023)

.023
(.022)

Female

.120**
(.032)

.079**
(.009)

.139**
(.012)

White

-.147
(.090)

-.005
(.028)

-.014
(.031)

Black

-.058
(.091)

.050*
(.028)

.092**
(.032)

Hispanic

-.019
(.155)

-.016
(.036)

.056
(.053)

Age (years)

.255**
(.021)

-.010
(.001)

-.013**
(.002)

Previous College
Enrollment

.290**
(.064)

Father's Highest
Educ = College

-.096
(.065)

-.003
(.016)

-.008
(.023)

Father's Highest
Educ = High school

-.069
(.053)

-.005
(.013)

-.010
(.021)

Mother's Highest
Educ = College

.195**
(.084)

.002
(.018)

.061**
(.032)

Mother's Highest
Educ = High school

.105
(.081)

-.016
(.015)

.042
(.032)

.0035**
(.0014)

-.0032**
(.0004)

-.0036**
(.0006)

Adjusted Gross
Income (000's)
Observations

866

866

9237

9237

6637

6637

Notes: Robust standard errors appear in parentheses.

34

Table 4. OLS Regressions of Intention to Treat Effects on College Attendance
Dependent Variable = College Attendance between April 15 and November 1, 2008
Dependent
Participants
Control Mean = .268
(1)
(2)

Independent Participants
with No Prior College
Experience
Control Mean = .029
(3)
(4)

Independent Participants
with Prior College
Experience
Control Mean = .237
(5)
(6)

FAFSA treatment

.077**
(.033)

.069**
(.032)

.006
(.004)

.006
(.004)

.006
(.011)

.007
(.011)

Information-Only
Treatment

.034
(.056)

.009
(.051)

-.0007
(.0070)

-.001
(.007)

.008
(.021)

.009
(.020)

Female

.119**
(.029)

.009**
(.004)

.040**
(.011)

White

-.146
(.091)

-.018
(.013)

-.033
(.029)

Black

-.124
(.092)

.001
(.013)

-.027
(.030)

Hispanic

.064
(.152)

-.010
(.017)

.035
(.050)

Age (years)

.130**
(.018)

-.003**
(.001)

-.010**
(.002)

Previous College
Enrollment

.338**
(.070)

Father's Highest
Educ = College

.043
(.060)

.001
(.007)

-.012
(.021)

Father's Highest
Educ = High school

.008
(.046)

-.002
(.007)

-.024
(.020)

Mother's Highest
Educ = College

.147**
(.073)

.003
(.008)

-.007
(.029)

Mother's Highest
Educ = High school

.063
(.066)

-.002
(.007)

-.027
(.029)

.0026**
(.0013)

.00002
(.00019)

-.0009*
(.0005)

Adjusted Gross
Income (000's)
Observations

866

866

9237

9237

6637

6637

Notes: Enrollment is measured using the National Student Clearinghouse data. Robust standard errors
appear in parentheses.

35

Table 5. OLS Regressions of the Effects on Aid Receipt and FAFSA Filing
Dependent Participants

Dependent Variable

Control
Mean

OLS Estimates
FAFSA
Info-Only
Treatment
Treatment

Independent Participants
with No Prior College Experience
OLS Estimates
Control
FAFSA
Info-Only
Mean
Treatment
Treatment

Independent Participants
with Prior College Experience
OLS Estimates
Control
FAFSA
Info-Only
Mean
Treatment
Treatment

.298

.098**
(.033)

-.018
(.051)

.096

.019**
(.007)

-.016
(.011)

.233

.031**
(.011)

.020
(.020)

$1363
(2229)

375**
(156)

-192
(250)

444
(1415)

79**
(31)

-76
(52)

1026
(1971)

145**
(49)

78
(88)

Received Federal Student
Loan

.232

.031
(.030)

-.065
(.045)

.069

.004
(.006)

-.018**
(.009)

.179

.020**
(.010)

.017
(.018)

Filed FAFSA
Conditional on Attendance

.925

.034
(.033)

.011
(.066)

.836

.116**
(.036)

.085
(.073)

.841

.040**
(.017)

-.008
(.035)

Date of FAFSA Filing 2008
Conditional on Filing (in
days)

May 11
(103.1)

-32.6
(10.1)

-17.5
(18.6)

Jul 7
(98.3)

-112.9
(4.6)

-25.1
(11.0)

Jun 6
(98.2)

-63.4
(3.6)

-12.9
(7.4)

.365

.039
(.052)

.006
(.096)

.064

.554
(.016)

.038
(.034)

.191

.291
(.017)

.015
(.032)

Received Any Pell Grant
(not conditional on enrollment)
Total Scheduled Amount of
Federal Grants

Filed FAFSA before March
1, 2008 Conditional on Filing

Notes: The outcomes are defined using data from the U.S. Department of Education. Specifications include controls for race, gender, age, prior college
experience, parents' education levels, and family income. Robust standard errors appear in parentheses. Total scheduled amount of grant aid includes all
payments scheduled during the 2008-2009 school year. Total paid reflects the actual amount of money transferred to schools as of March 2009. This may differ
from the scheduled amounts if students withdraw from school or transfer or if payments for a spring term have not yet been transferred to the students’ schools.
The regressions with dependent participants have 868 observations, except for those that are conditional. The samples are 264 if conditional on attendance and
407 if conditional on FAFSA filing. The regressions with independent participants without prior college experience have 9237 observations. The samples are
295 if conditional on attendance and 2392 if conditional on FAFSA filing. The regressions with independent participants with prior college experience have 6637
observations. The conditional samples have 1594 if conditional on attendance and 2992 if conditional on FAFSA filing.

36

Table 6. OLS Regressions of the Effects on Patterns of Attendance Post Experiment

Dependent Variable

Control
Mean

Dependent
Participants
(N = 868)
OLS Estimates
FAFSA
Info-only
Treatment
Treatment

Independent Participants
with No Prior College Experience
(N = 9237)
OLS Estimates
Control
FAFSA
Info-only
Mean
Treatment
Treatment

Independent Participants
with Prior College Experience
(N = 6637)
OLS Estimates
Control
FAFSA
Info-only
Mean
Treatment
Treatment

Attended Public
College

.222

.050*
(.030)

.030
(.050)

.022

.006*
(.003)

.001
(.006)

.181

.003
(.010)

-.003
(.018)

Attended Private
College

.048

.018
(.016)

-.025
(.020)

.007

-.001
(.002)

-.002
(.003)

.058

.006
(.006)

.011
(.012)

Attended Four-year
Campus

.169

.043
(.028)

-.019
(.043)

.009

.004*
(.002)

.003
(.004)

.113

.003
(.008)

.013
(.016)

Attended Two-year
Campus

.098

.027
(.023)

.027
(.041)

.019

.001
(.003)

-.003
(.005)

.122

.006
(.008)

-.002
(.016)

Attended Selective
College

.038

.040**
(.017)

.022
(.028

.001

.001
(.001)

-.0011**
(.0005)

.026

-.005
(.004)

.010
(.090)

Attended Non-selective
College

.174

.014
(.027)

-.002
(.045)

.024

.004
(.003)

.002
(.006)

.182

.005
(.010)

.001
(.018)

Attended Full-time

.189

.054*
(.029)

-.017
(.045)

.013

.007**
(.003)

-.004
(.004)

.116

-.007
(.008)

-.008
(.015)

Attended Part-time or
Full-time

.207

.056*
(.030)

.025
(.048)

.020

.006*
(.003)

-.002
(.005)

.184

.0001
(.0099)

.014
(.019)

Withdrew from College
Fall 2008 (uncondit.)

.010

-.006
(.006)

-.012*
(.006)

.001

.0002
(.0008)

.0001
(.0015)

.016

.003
(.003)

.0003
(.0060)

Notes: Enrollment is measured using the National Student Clearinghouse data. Specifications include controls for race, gender, age, prior college experience,
parents' education levels, and family income. Robust standard errors appear in parentheses. Selective colleges include those colleges classified by Barron’s
guide as “most,” “highly,” or “very competitive.”

37

Table 7. OLS Regressions of Intention-to-Treat Effects
Independent Participants with No Prior College Experience
Dependent Variable = College Attendance between April 15 and November 1, 2008
Participants with Estimated
Expected Family Contribution (EFC) = 0

Participants with Estimated
Expected Family Contribution (EFC) > 0

FAFSA
Treatment

Info-Only
Treatment

N

FAFSA
Treatment

Info-Only
Treatment

N

Full Sample

.012**
(.005)

-.002
(.009)

6266

-.008
(.006)

.003
(.011)

2971

"Very Interested in
College"

.018**
(.008)

-.005
(.014)

3405

-.013
(.013)

-.004
(.022)

1200

Not "Very
Interested"

.003
(.005)

.001
(.001)

2861

-.005
(.005)

.004
(.010)

1771

Some Do not Go
because Must Work

.034***
(.011)

.032
(.020)

1250

.004
(.012)

.035
(.021)

798

Other Reasons Why
Some Do not Go

.005
(.011)

-.012
(.010)

5016

-.012*
(.007)

-.011
(.013)

2173

Female

.015**
(.006)

-.008
(.012)

3890

-.006
(.010)

.011
(.018)

1388

Male

.006
(.008)

.005
(.013)

2376

-.009
(.007)

-.005
(.013)

1583

White

.010*
(.005)

.006
(.010)

4598

-.008
(.006)

-.010
(.011)

2467

Black

.015
(.011)

-.028
(.021)

1668

-.007
(.018)

.073**
(.035)

504

Without Dependent
Children

.032
(.021)

-.044
(.037)

387

-.012
(.012)

-.012
(.024)

168

With Dependent
Children

.010**
(.005)

-.005
(.009)

5879

-.008
(.006)

.004
(.012)

2803

Notes: Robust standard errors appear in parentheses. Specifications include controls for race, gender, age, prior
college experience, parents' education levels, and family income

38

Appendix Figure 1. Information and Aid Calculation Worksheet

39

