NBER WORKING PAPER SERIES

ESTIMATING THE CONTINUOUS TIME
CONSUMPTION BASED ASSET PRICING MODEL

Sanford J. Grossman
Angelo Melino
Robert J. Shiller

Working Paper No. 1643

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
June 1985

The research reported here is part of the NBEP's research program
in Financial Markets and Monetary Economics. Any opinions
expressed are those of the authors and not those of the National
Bureau of Economic Research.

NBER WORKING PAPER #1643
June 1985

Estimating the Continuous Time
Consumption Based Asset Pricing Model

ABS TRACT

The consumption based asset pricing model predicts that excess
yields are determined in a fairly simple way by the market's degree of
relative risk aversion and by the pattern of covariances between per

capita consumption growth and asset returns. Estimation and testing
is complicated by the fact that the model's predictions relate to the
instantaneous flow of consumption and point—in—time asset values, but
only data on the integral or unit average of the consumption flow is

available. In our paper, we show how to estimate the parameters of
interest consistently from the available data by maximum likelihood.

We estimate the market's degree of relative risk aversion and the
instantaneous covariances of asset yields and consumption using six

different data sets. We also test the model's overidentifying
restrictions.

Sanford J. Grossman
Department of Economics
Dickinson Hall
Princeton University
Princeton, N.J. 08544
(609) 452—4035

Angelo Melino
Department of Economics
University of Toronto
150 St. George Street
Toronto, Canada M5S lAl
(416) 978—6541

Robert J. Shiller
Cowles Foundation for
Research in Economics
Yale University
Box 2125 Yale Station
New Haven CT 06520
(203) 432—4134

I.

JrodLtction
In this paper, we provide an

empirical test of the continuous

time intertemporal capital asset pricing model, first proposed
by

Merton[1971].

that

an asset

The model as clarified by Breederi[1979] implies

will

be

priced so that the expected return required

will increase with its covariability

growth.

with per capita consumption

Previous tests of this theory (e.g. Grossman—ShillerEl9BOJ,

Harsen—SincUetorE19833) have examined discrete time versions
a-F

the

the

model under the assumption that the timing interval of

model matches exactly the sampling interval for available

data on per capita consumption. That is, if we have data on
quarter 1 y consumpt i on,
1—quarter

time

of a

model,

year.

then the time period is assumed to
We show that if the true model is a

be

continuous

and time averaged data (such as quarterly consumption)

is used to test

then substantial biases may be introduced
unless the estimation procedure is corrected to take account
of the effects of time averaging. We provide a procedure for
obtainiri consistent estimates with time averaged data. We
then estimate and test the model using data on per capita
consumption

it,

and the

cumulated

real returns to holding portfolios

o-f stocks, bonds, and short—term paper.

II

The Model

It
follows

is useful

to review the Merton model. Our discussion

closely the exposition of its generalization in

Grossman—Shiller[1982J.

In a discrete time model, each consumer

is assumed to maximize a time—additive utility function over
a single consumption good

T / h

(2.1)

U
.j =0

where T is his time horizon. c(t) is consumption at time t and
is the discount •factor between utility at time t arid t+h.

For the purposes of this paper, we assume that the period utility
functior, is o-f the constant relative risk aversion (or isoelastic)
-f or ir

(2.2>

Lt(C)

c'/(1—Pi)

Let v (t) denote the value o-f asset i at time t including

any accrued cash disbursements (such as dividends or coupons)

earned between t—h and t. Assume that asset i is freely tradeable.
A standard argument shows that
(2.3)

Etu' (c (t+h> )v (t+h) =

u

Cc (t) )v1 Ct)

where the expectation is conditioned on all the information
possessed by the trader at time t. Using (2.2> arid iterating
(2.3)

, we can write
(2.4>

Et(c(7)) vi(T) =
c(t)
v(t)

(l)t

= t+h.t+2h,...

for 7

I-f we take the limit to continuous time and apply Ito's Lemma,

we obtain
(2.5)

Etdv1

+ 1*A(A+1)*Var(dc)
2

c

—

lndt

A*Etdc +
c

=

A*Cov(dc,dv)
c

v

where Var and Coy denote the variance and covariance operators.

Note that (2.5) holds for an individual. Under various
assumptions about heterogeneity of information and wealth. (2.5)

can be aqregated over individuals so that

c

can be interpreted

as per capita cortsumption and A is replaced by a particular
weighted averaqe of the individual consumer's A (see
Grossmart—ShillerEl982)). Clearly (2.5) holds for all tradeable
assets.

If

is

defined as the excess rate of return of asset

i over say short—term paper, then (2.5) can be used for these
two assets to yield
(2.6)

ER A*Cov(R,dc/c)

The aggregate

parameter of relative r i sk aversi or, can be

computed by (2.6) given data or mean excess returns and the
covariances between excess returns and per capita consumption
growth. Table I provides some estimates of A based on the
descriptive statistics from Table 7. The various data sets
and variable definitions are described more fully in Section

III. At this point, we simply wish to draw attention to one
of the important empirical anomalies associated with the model
and the potential role for- time averaging as an explanation.

The table shows that the mean excess return on stocks is associated
with a relatively small covariance with consumption changes.
Therefore this can be justified only by an implausibly high

estimate of the risk aversion parameter. Similiar conclusions
are reached by examining the excess returns on bonds.

One explanation for this is based on the idea that a time
averaged variable is smoother than the same point sampled variable.
In particular, if the true model holds in continuous time then

the instantaneous rates of change in consumption can be more

4
var-i

ahi e (and also covari able with returns) than is

the

averaue

consumption chariqe across years or quarters.

Art emp1e

To understand this e-ffect, consider the following very
simple process for v, the value of asset i in excess of asset
1, and consumption:
dc =
(2.7a)

dv = J1dt + d'ri

(2..7b)

where

pdt + d€

are correlated Brownian motions with Cov(d€,d)Thdt.

Let E(t) and

(t)

be the time averaged values of c(t) and

v(t) ,i.e..,

E(t) =
We

T1j c(t+s)ds

=

T'f v(t+s)ds -

will show that

(2.8> Cov(E,) EE(E(t)—E(t—T))((t)—(t—T))] — pT.LT
—
—, i'"rO••
— _l._)I

If

we normalize T=1, then the covariance of time averaged

consurnptions changes and price changes is 2/3 of the instantaneous
value
A

o Roughly speaking,

this would

lead us to overestimate

by

To understand (2.8)

just note

that

(2.9) E(t) — E(t—T) =
= pT

pds + T'14_T d€(7)ds
+ T1f4+ST dE(7)ds
+

=

T1f45 dE(7)ds

pT + T'ft_T
+

(T—t+s)d€(s)

Tl4±T (t+T_s)d(s)

5
A similiar expression may be

derived for (t)—(t—T). Hence,

(2.10> E[(E(t)—E(t—T))((t)—(t—-T))]
=pTu1T +

T2E[4_T(T—t+s>2d€d

+

Equation (2.8) is easily derived from the last expression.
The purpose of this example is to give the reader a relatively
simple view of the effect of time averaging in generatinq a
stochastic

process which is " smoother"

than

the instantaneous

process. This suggests the possibility that assets appear to
have a low risk (i.e. low covariaruce with consumption changes)
because measured consumption changes are less van able than
instantaneous
with

consumpti on changes. Since it

instantaneous consumption changes that

measure

i s the coven ance

is the relevant

of an assets risk, this leads us to overestimate A.

In our simple example, A is overestimated by SOY.. As we shall

see below, for certain processes, the bias can be arbitrarily
large.
Multivariate Model

In our empirical work, we postulate a slightly more complicated
stochastic process for consumption and asset values. Define
Y(t) according to
(2.11)

Y(t) =

in

in

c(t)

—

v1 (t)

In v(t) —

In

v-.(t) —

kc — gt
k1 — g1t
k, — g.t
k3 —

gt

—
=

C(t)

1

V1 (t)

V9(t)

V-.(t)

We assume that Y(t) satisfies the stochastic differential
equation
(2.12)

dY = BYdt + Eh/'2dZ

6

where B and 2.. are (4x4) matrices and Z(t) is a vector o-f standard

independent Wiener processes.

is assumed

to be

symmetric

and positive definite. Without any loss of Qenerality,
can be taken to be I ower

tn anqul ar

with positive diagonal

elements. Let a denote the vector of nontrivial parameters

in

—'4

1,—s

Switching to logarithms and applying Ito's Lemma we can
rewrite (2.5) in terms of the V(t) process as

EEdVj(t) —

(2.13)

+

If

*dC(t))

—

+

*g

+

lnS)dt

1/2*P2*Var(dC) — *Cov(dC.dV) + 1/2*Var(dV) = 0.

this is to hold at all points in time in m.s.. then

EtEdV(t) —

(2.14)

*dC(t))

=

C).

The reason is that, according to our assumptions, the remaining

terms in the expression are not functions of information. Since
the model is homogeneous, the only way this sum can be constant
is if it is zero.

Therefore (2.5) imposes the following restrictions on our
nodel

(2.lSa)

J1B = 0

(2.15b)

—

e)

where

and

+ 1/2*J1L3

+

lru

= 0

i=1,2,3

is the vector with unity in component

i and zero elsewhere.

Suppose that the process Y(t) is sampled at regular intervals.
It is straightforward (see BergstromEl984)) to show that the

point sampled process has the representation
(2.16)

Y(t) = ØY(t—1) +

u(t)

7
= eB, the matrix

where

variable 4_

exponential

et5l2dZs.

of B, and u(t) is the random

Let 7(t) denote the time average

of the Y(t) process, i.e. V(t)=4_1 Y(s)ds. Upon integrating
both sides of (2.16) we obtain
7(t) = ØV(t—1) + (t)

(2.17)

eB)dZs>dl.

where (t) is the random variable 4_1x_1

Let + and q denote two 'smooth" real—valued functions and

(s) a univariate Wiener process. Using the definition of the
Ito integral, the following two results can be established:
(2.18)

f f(t)Ef

(2.19)

ECftf(s)d(s)]Efq(7)d(7)J =

g(s)d(s))dt =

where M

JE4f(t)dt](s)d(s)
Jf(s)g(s)ds

Et1,t2]fl[t-.,t4J

and where the equality is understood in the mean square sense.

Applying (2.18) element by element and other standard properties
of the Ito integral allow us to write
(2.20)

Define

[(t)
E

=

4:4' e

(t)(t—'r) and F(r,w)

and standard change of
(2.21a)

d'rdZ(s + il-.iil

variable

ed7dZs.

eB'ZeB'W. Applying (2.19)

rules, we obtain

fl() 444 F(r,w)drdwds +

(2.21b)

=

x4i F(r,w)drdwds

(2.21c)

=

0

fJJ F(r,w)drdwds

'r2.

We conclude that '7(t) is a vector ARFIA(1,1)

process.

PhillipsEl97B]

and BergstromCl984] develop similiar results although the latter

only considers the case where B is invertible. We can therefore
write
(2.22)

7t = ?(t—1)

+ €(t) + E€(t—1)

B

where the innovations
S.

and e is

(t)

0.

=

covariance matrix

(2.15) are

in v2(t) in v.(t))'.

Eq (2.22) can be rewritten

+ s(t—1) + €(t) + $€(t—1)

+

= (IS)k+Øq. '( = (I—ø)g,

restrictions
=

(In c(t) in v1(t)

t) be its unit averaQe.

(2.23)

where

have mean zero and

a matrix with spectral radius not exceedinq unity.

Define y(t)

and let

€(t)

(t+s)ds.

and t =

easily shown to imply 3i1 =

The

J(I—ø)

In particular, it also follows that the vector k cannot

be identified uniquely. Je

therefore

impose the identification

restriction k1 = A*kc in our estimation.

tedious arqument

also shows that

(2.24) (J—J) ((t)—(t—1)) =

3i3jO +

(J—J)€(t)

+

so that the time averaaed excess returns on asset i over j follows

an M(1) process with coefficient .268.
To gain further intuition about the possible consequences
of time averaqing suppose B =

be shown that :>(,j) =
=

diag()1,?2,?,X4).

h(,2)Z(i,i)

()E1

+

+ (1 + e>(1 —
and equal to the obvious limits as

—

,

Then it can

where

2*(?+7)(1_eM3>
+ (1 + e)(1 —
or X goes to 0.

simple example corresponds to the case h(0,0)

= 2/3.

e)/X)
Our

If the

process were stationary around trend, the elgenvalues of B would

have negative real parts. Sampling a few values, we see that
h(—. 1,—. 1) =

.60, h(—.5,—.5) = .45, h(—1,—1) = .28, and h goes

9

to zero as

arid

both go to minus infinity. The bias in

the estimate of A using time averaged data and (2.5) car therefore
be arbitrarily larqei

III

DATA ANALYSIS

Data

Description

The data are fully described in an appendix to this paper

which is available from the authors. Here we shall give only
a broad description of the data to indicate how they were assembled
and to show that they correspond as much as possible to the
concepts represented in the model above.

Six separate data sets were prepared, each intended to
represent a series of observations on the four—element vector

.

The data sets differ in sample period, sources and assumptions

about taxation. Table 2 summarizes the important differences.
Data sets ore and two are long historical annual

time

series

beginning in the year l89O These data sets are based on those
used in Grossman and Shiller[1981] and described also in
ShillerEl9B2J

Data sets three through six are quarterly time

series. Data sets three an.d four
of

1953.

Data sets five and six

begin in the

second quarter

begin in the second quarter

of 1947. The use of annual and quarterly time series was dictated

more relevant comparison might be the ratio of A that would
be obtained using time averaged data to that using point sampled
data. Although details differ, it is easily shown that this
ratio also can be arbitrarily large.

1 0

by the existinQ consumption data. Long time series data or
consLtmption are available only on an annual basis. Quarterly
consumption data are available only for the post—war period.

Monthly consumption data are available startinQ in l99. We

did

not use

accuracy

of

those data here because of some concern as to the
the monthly data and because of the somewhat shorter

sample period that such data would impose.
In all data sets, the first element o-f 9

is

the log of

real per capita seasonally—adjusted consumption on nondurables

and services. For years beginning with 1929 these data are
from the National Income and Product Accounts of the United

States. Earlier data are the Kuznets—Kendrick series. Since
the published consumption series are total consumption over

the period, the first element of 9

departs

somewhat from that

hypothesized in the paper: it is the log of the integral rather

than the integral of the 1og Note that we use a physical
measure of consumption directly and do not deflate nominal
consumption by a price index that is averaged over the year,

which would have introduced another departure from the assumptions
of our model.

In all data sets the second element of 9

is

a measure of

the interval averaged log cumulated real return on corporate
stocks,
log

the third element is

a measure of the interval averaged

cumulated real return on short debt and the fourth element

Some Monte Carlo simulations indicate that the biases introduced
by using the log of the average instead of the average of the
log are extremely small, at least for our data

11.

i s a measure of the interval averaged log cumul ated real return
or long—term bonds. The even—numbered data sets are based on

after—tax returns. In constructing these series, the (after—tax
in even—numbered cases) nominal returns were first computed

on a monthly basis. At that point, a choice had to be made
whether to use the consumption deflator to convert nominal returns
to real returns or to use one of the monthly price indices for
this purpose. The consumption deflator has the advantace that
it corresponds to the measure of consumption that is supposed

to enter the utility function. The monthly price indices have
the advantage that we can use them to produce a monthly real

series,

so that our interval average will correspond more closely

to the integral of the log of the real

portfolio value as

represented in our model. It was decided to use the consumption
deflator for data sets one through four and the monthly consumer

price index for data sets five and six. ThUS, for example,
the

second through fourth elements o-f the

vector in data

constructed by first producing monthly series
representing the cumulated after—tax nominal returns of the
assets. Each series represented the nominal value of the portfolio
set two were

of

an individual who reinvests all after—tax income from the

asset in the same asset.- The average for the year of the log
of

the

monthly portfolio values was used to construct an annual

series. Finally, the log of the consumption deflator was subtracted

Let (l+rjm) denote the monthly after—tax nominal return on asset
i, and let ViL denote the cumulated after—tax return in month L.

We set VIL =

(l+rj)(l+r2)"(1+rL).

12

from each series to convert to a real series. With data set
five, the first step in the construction of
fourth

elements of

the

second through

was essentially the same. We first produced

a monthly series of cumulated returns of the assets. However,
jr data set five, this monthly series was subsequently deflated

by dividing by the consumer price index, and a quarterly series
was
o-f

produced as the average for the three months of the quarter

the ion o-F this

monthly real series.

With data sets five and six another adjustment was also
made

before the average log cumulated real

portfolio value was

into the vector . In constructing the series, there

entered

concern that the data be aligned properly. The
Ibbotson—Sinquefiel d returns data for each month are measured

was great

from

the

month.

end of the preceding month to the end of the current

This provides

four point sampled observations on the

log cumulated real portfolio for each quarter. These were connected
by

straight lines and the integral under the

interpolation

straight line

was used to estimate the corresponding component

of .
For data sets one and two, the return on corporate stocks
is computed from the Standard and Poors Composite Stock Price

Index and associated dividend series. The return on short—term
debt is computed from the prime commercial paper rate and the
reEurn on long—term debt is computed using the Macaulay railroad
bond yield data for the first part of the sample and the Moody

Aaa bond yield average for the years after l93.

13

For

series

data sets three and four,

return data come from
Stock returns are aqain

all

on the CITIESE data library.

computed usinq the monthly Standard and Poor's Composite Stock

Price

Index, while the

return
debt

return on short debt is taken from the

on three—month treasury bills and the return on long

is based on
For

yields of twenty—year treasury notes.

data sets

five and six,

return

data

come from Ibbotson

Sinquefieid[1982]. The stock return series is their series
common stocks, total returns; the short debt series is their
and

series

U.S. Treasury bills, total returns the lona debt return

is their series loriq—term corporate bonds, total returns.
For after—tax series, the assumed marginal income tax rate
for 1918 to 1980 was that implicit in the spread between municipal
series

and corporate bond yields.. Before 1918, the marginal income
tax

rate was set to zero. Since

the Ibbotson and Sinquefield

data do not allow a decomposition of returns into capital gains

income components, it was assumed for data set six that
all returns were taxed each month as income. For data sets
and

two and four, however, capital gains were assumed taxed each

month at a long—term capital gains rate. For the years l94
to 1978, the effective rate on long—term capital gains was one—half
the marginal income tax rate. For earlier years, the effective
rate on long—term capital gains was computed from the marginal
income tax rate using tax rate data in Seltzer[l951J.

14

Frel iminarie

considering formal estimation and testing, it is
to review some of the broad features o-f the six data

Be-fore
useful

sets which our model must eXplain. Some descriptive statistics
are provided in Table 3.

For all six data sets, we observe that stock portfolios

gave the highest average real return, approximately 6 p.8. on
a pre—tax basis or 47. a-f ter—tax.

Short—term paper vi el

ds averaged

longest historical
sample, but. the average yield fell to about zero in the postwar period. After—tax real returns to holding short—term paper
about

have

27. p.a. on a

beers

basis over

pre—

essentially a zero real return over the last

century,

and after—tax basis. During the post—war period,

however, pre—tax returns have been

after—tax

our

slightly negative. Long—term bonds, by contrast,

have averaged

on both a

pre—tax

basis •

slightly negative. On an

bondhol ders have seen the real value of their

portfolios shrink by over 27. p.a.

According to the consumption based asset pricing model,

these persistent differences in average yields must be accounted
for by the insurance provided by the different portfolios against

events which impinge adversely on consumption. Useful evidence
about this hypothesis is obtained by looking at the covariance
structure of measured portfolio yields and changes in consumption.
Some caution is necessary since the model 's predictions pertain
to the covari ance structure of the instantaneous returns and

15

our data

are constructed from di-ffererices of unit averaged values.

However, if BQ.

the

latter can provide a reliable guide to

the sign and order of magnitude of the instantaneous covariance
matrix.

Several empirical regularities emerge. As measured by
the variance, the change in consumption is the smoothest series,

followed closely by

the yield

on short—term paper. Long—term

bond yields have been fairly stable over our longest sample,
whereas the variance of returns to holding

a portf ol i o

of stocks

orders of magnitude larger. In the post—war
period, real returns to holding long—term bonds have been much
has been several

more volatile with a variance almost as large as the return
to holding common stocks.

Of more interest are the covariarce properties. According
to our model, it is not the variance but the covariance with

consumption that is the relevant measure of a portfolio's risk.

We find, uniformly across the six data sets, that stock yields
have the largest covariance with changes in consumption, followed
by short—term paper yields and then yields on long—term bonds.

£ualitatively, this is exactly what the model requires given

the ordering of the average yields. It indicates that the basic
idea that insurance against adverse movements in consumption
can account for observed yield differentials has some empirical
promi se.

Evidence of potential

autocovariance

structure of

difficulties is
excess returns

provided by the

on bonds and stocks

16

over short—term paper. Given our assumptions about the
probabilistic structure o-f consumption arid portfolio values

preferences, we expect the point sampled difference
vi ci ds between any two portfol i os to he serially uncorrel ated.

arid the -form o-f

in

As equation (2.24) shows, the

time averaged difference in yields

shoul d have an MA ( 1) component with coefficient about .268.
This particular prediction is independent of the mean or covariance

of returns or the deree of relative risk aversion.
Table 3 shows that

it is

important to take into account

the consequences, of time averaging. The Box—Ljung statistics
clearly indicate that the excess yields

that

are constructed

from our data are not white noise. The adjusted excess returns
referred to in Table 3 are filtered to remove the time dependence
that

is induced
the

statistics,

correlated

by unit averaging. Judging from the Box—Ljung
adjusted excess returns are indeed less serially

Nonetheless, the autocorrelations of the adjusted

.

excess returns to stocks remain statistically significant from
zero in four of the six data sets.

Some Econometric Issues

It is demonstrated above that the vector of time averaged
observations

(3.1)

has a representation of the form

(t) = Y0(u) +

+ Ø(c)(t—l)

+

€(t)

+

$()€(t—l)

where the disturbances €(t) are distributed independently
and identically as MVN(O,S(o)).

In our application, we can

17

set

,a) , where

B1 denotes the

first

row of

the B matrix.

Linear Gaussian processes have been studied extensively
by econornetricians arid statisticians. Nonetheless, there are

several features of our model which put it outside of the standard

in the literature used to prove laws of large numbers
limit theorems. First, the model contains a time

assumptions

or central

trend

so that sample autocovariances of the exogenous variabLes,

T1LXtXt_ where X. = (1 t), do riot converge to well
defined limits. Secondly, the model imposes restrictions not
i.e.

only across the autoregressive and moving average matrices,
but across these and the contemporaneous covariance matrix as
well. Finally, our model imposes the restriction that B be
of rank one, so that Ø() will have three eiaenvalues on the
unit

circle. To

our knowledge, there are no laws

of large

numbers

or central limit theorems that cover all three of these features.

Application of the standard large sample procedures to estimate
and test our model must be

considered

tentative.

Although all the features of our model have

not

been treated

together in the literature, we can use available results to
form a reasonable guess about the sampling properties of the
approximate (conditional) maximum likelihood estimator described

below. For example, it appears that a law of

large

numbers

which would allow for all three of the features noted above
would

be a modest extension of the literature. Hannan et al. El980]

provide a law of large numbers for vector ARMAX models allowing

18

for

very general restrictions and, in particular, dependence

across

the covari ance

matrix

of innovati oris

and

the other parameters

the model. Their assumptions about the error process are
clearly satisfied by our model, but they rule out time trends
of

as regressors and require all roots of the autoregressive polynomial
to be outside the unit circle.

In the absence of complicated

restrictions or unit roots, the assumption that sample covariances

defined limits

convergE to well

can be

replaced by the weaker

Grenander conditions (see HannanEl97l J) which do allow for time

trends as regressors. Similarly, in the absence of time trends
and other restrictions, strong laws of large numbers can be
established even i-f the autoregressive process is explosive.
Individually, therefore, each o-f

highlighted above
o-f

large

is

the

three features of the model

not an impediment to establishing a law

numbers.

It is

well

known that unrestricted estimates o-f

not be asymptotically normal if

there

0 will

are unit roots in the

autoregressive polynomial. A case for a central limit theorem
can be made only if the estimation procedure exploits the prior
knowledge

o-f the structure of 0. Our restrictions imply that

is a co—integrated process (see Granger—Engletl9B2J>. These

processes have had a long history in
under

the

applied empirical research

name of "error—correction" models. However, only

recently has there been any serious investigation o-f the sampling

properties of the MLE or its approxirnants. Available theorems
do not allow for a time trend or moving average terms but these

19

complications

do not appear to

present any conceptual difficulties.

The main result is that the inteqrating

factor4 is estimated

consistently by ML with a sampling error that
The ML

estimators

is o(T'2).

for the remaininq parameters are consistent

and asymptotically normal with a covariance matrix that is estimated

consistently by the usual formula. In our model, the integrating
-factor is just B1. ,

appropriately

scaled. Since we are never

concerned with testing restrictions on the components of B1

the rapid convergence of the estimated integrating factor does
not appear to present a problem.

We will proceed formally as if the standard large sample
procedures for in-fererice are valid under the maintained hypothesis

B is of rank one. s the preceding di scussi on makes
clear, however, some scepticism is in order.
that

Estimation Strategy
Several strategies for the estimation of models with M
errors have been proposed.5 In the time domain, it is natural
to consider the maximum likelihood estimator, or one of its
various approximants.

Put e(l)O and -For any admissable o define e(t)
recursively

according to

4A nonstochastic vector c such that c't is stationary is called
an integrating factor. In our application, it is any normalized
basis vector for the row space o-f 1—0.
See Osborne (1977) for a survey of the unconstrained case.

20

e(t) =

(3.2)

(t)

—

— Ø(i(t—1)

iç)(LY.) —

—

E(c.)e(t—l).

Following Wilson (1973), we choose as our estimator
which maximizes the approximate

the adrnissable vector

(conditional) ion likelihood function
(T—i) lnIS(cv)j —

L(c)

1

tr S(cM

T

where M

L e(t)e(t)'.
t=2

Since 0

bets unit roots, we have little choice but to condition

on the first observation (1).. The assumption that e(l)0.
by contrast, is made solely out of convenience.
spectral radius of
o-F

will

E)

If B=0, the

is about .268, so the sampling

distribution

not be very sensitive to this assumption about

the initial innovation. Putting e(1)=0 does simplify the
In particular, analytic derivatives

computations somewhat.

can be easily and quickly computed using the method of adjoints
and a straightforward application of the chain rule..

Several

features

challenging..

As with

to
to

of

La('.) make the evaluation of

any model with MA errors,

cl.a

it is not possible

the data through sufficient statistics and we have
deal with a likelihood function that is not guaranteed to

reduce

be globally

addition

concave. Our model poses

several

difficulties in

to these standard ones. For example, it is not possible

to concentrate out the covariance matrix, since S is functionally

related to the regression parameters of (3.1). Also, some effort
is required to evaluate (Ø(.>,S(.),$(ci). Details are provided

21

in MelinoEl985J, so we will give only a brief overview here.
Define

the

matrices

00
(3.4) C 0 —B—B
L
o
o o ol

F6H

1

L

Put C =

—C

)

i

C)

K

0 F.-)GH-,

e

0 0 F—

B J

C)

and denote the blocks of eC by

C)

'

C)

G—

F

etc.

-

it can

be shown that
(3.5)

—

KjF4

—

K11

= H163 + K1F1

+

F1Kj.

=

F4K1 +

It is also useful to note that 0

F4

Although the expressions

appear to be unappetiinq, they are straightforward to implement
given an algorithm for computing the matrix exponential. We
used a routine based on a diagonal Fade approximation that has
very nice numerical properties.6
Solving for (S.E3) given

turned out to be much easier

than conjectured by Bergstromtl9B4j. WilsonEl972J provides
a general algorithm for factoring the autocovariance function

of a multivariate MA process. We adapted his suggestion to
our special case and applied Newtons method to find the matrix
E with spectral radius no greater than unity which is a root
of the polynomial
(3.7)

0 + (ft1e

=

0.

Given an initial guess, E3(0), this leads to the iterative

scheme

6We would like to thank Dr. R.C. Ward of the Union Carbide Laboratory
in Oak Ridge for kindly providing us with this code.

,, ,-

(.8)

(fl+l)[fl>_ç1*- (n)]

— E(n)fl1E3'(n+1> =

n)fl1E3'

(ri>.

This scheme exhibits quadratic convergence and turns out to

quite fast. On average, less than three iterations were
required to find E3 given (fl-).fl1). In fact, we found that this
scheme rarely required more than 5 iterations. Siven E, it
—
is straightforward to solve for S Using S
be

Evaluation
quick and easy.

of La(cY.) and its analytic derivatives is fairly

The main

difficulty in computing ca turned

out to be the extraordinary large number of iterations required
to refine its location.

Par ameter Esti mates

Table 4 presents the estimated parameters o-f the constrained

model for each o-f the the six data sets.7 The estimates obtained
using be-fore— and our constructed after—tax yields are remarkably

sirniliar, but there are considerable differences in the estimates
across the three different sample periods.

Consider first the estimates of L, the covariarce matrix

of the instantaneous innovations. Once again, correlations

displayed above the diagonal, and the lower triangular elements
are covariances. The estimates of from the quarterly data
sets are all similiar. However, there are some sharp contrasts
are

7Estimates were obtained using the GQOPT3 package provided by
Professor Ouandt o-f Princeton University. Various algorithms
were required to refine the location of
The reported standard
errors, however, are always calculated by inverting the matrix
o-f second

derivatives evaluated at the optimum. The Hessian

was computed using symmetrical numerical differences of analytic
-first derivatives.

-7

with

the estimates from the annual samples which cast doubt

our assumption that L has been constant over time. Consumption
innovations appear to have had a much smaller variance in the
on

post—war

period, as

short—term paper.

have

had the innovations to the value

of

stock market
Values have been slightly smoother, and those for long—term
By contrast, the innovations to

bonds are roughly comparable. The covariances of the innovations
to portfolio values with consumpti on have the same ranki rig in
all six data sets, but they are much smaller in thepost—war
period.

ll six data sets yield small estimates o-f B1. the first
,

row o-F the B matrix. This indicates that the change in consumption
has only a very small predictable component, aside from trend.
The trend in consumption is estimated to be about 3% p.a. using

the two long historical samples, about 2.5% using data sets
three and four, and about 1.6% pa. using data sets five and

six.

The corresponding point estimates for

respectively,

indicate,

a substantial preference for present consumption,

a substantial preference for

future

consumption, and indifference.

These apparent differences can't be taken too seriously since
the estimated standard errors indicate substantial uncertainty.

The differences in the

estimated

parameters o-f

relative

risk aversion are extremely interesting. Using our two longest
historical samples, we obtain estimates of A of just over 20.

This is too large to be plausible. Nonetheless, as anticipated,

24

accountinc -for unit averaQiriq
substantial

of consumption results in a

reduction.8

Data sets -five and six produce a very plausible estimate
of A of just over 2. Ey contrast, data sets three and four
produce an estimate of A over 150! The difference of the parameter
estimates
data

obtained using these

sets is very large,

very simiuiar post—war quarterly

and some clarification is in order.

The estimates of A presented in Table 1 are derived from
restrictions

which relate the unconditional means to the covariances

of consumption changes and portfolio returns. However, the
model provides us with further sources of information about
Equation (2.14) tells us that the predictable change in
A..
the

value o-f any portfolio is equal to a

multiple of

the predictable

change in consumption, up to a constant. Since the multiple
is just the parameter of relative risk aversion, this gives
us another estimate a-f A based on the conditional information

in the sample. The maximum

likelihood estimator is usefully

viewed as suitably pooling the disparate estimates based on
conditional and unconditional information..

It turned out that the predictable change in consumption
around

its

mean using the lagged information in data sets 1—4

was essentially zero. As a result, the maximum likelihood estimate
of A closely reflects the estimates in Table 1 adjusted for
unit averaging..

In data sets 5 and 6, however, the predictable

8For data set 1, we also estimated the model as if the data was
actually point sampled. tie obtained an estimate A = 27.24,
with a standard error of about 11.2.

.- .

chariqe in consumption about its mean, while still small, was
larqe enouqh to provide a fairly accurate estimate of .

The

maximum likelihood estimate reported for these data sets reflects
the conditional irforrratior in the sample.9

Our model imposes restrictions or the time averaged

representation of .

In turn, the time averaged representation

imposes additional structure on the parameters of the ARM(1,1)

representation. Table 5 contains the lo likelihoods, denoted
L1, L,, arid L- respectively, for the fully restricted time averaged
estimates (Model 1) ,

the

unconstrained time averaged estimates

(Model 2), and the unconstrained ARMA(1,1> estimates (Model 3).

For the reasons discussed above, Models 2 and 3 were estimated
under the maintained hypothesis that B is of rank one and 0

is the sum of the identity and a rank one matrix. For completeness,
the log likelihoods for the totally unconstrained time averaged

and ARM(1,1) models, L and L respectively, are also reported.
The tests of the overidentifying restrictions imposed by
the model are rejected with very high confidence when compared
against either Model 2 or Model 3.

Curiously,

data sets three

and four which produced the least plausible parameter estimates,
9lmposing only the restrictions implied by (2.14), we obtained
for the six data sets:
A
(s.e. )

=

663.54
949.86
439.67
* )
(370.56) (370.56) (

(

983.73
2.07
2.60
*
) (0.92) (1.21)

Because the Hessian was singular, we are unable to provide standard
errors for the estimates from data sets three and four.
Hansen—Singleton[1983] also report a very sharp difference
in the estimate of A depending upon whether or not conditioning
information is used. (See their Table 5)

26

provide the weakest

evi. derce agai nst

restrictions. Finally

the oven deriti fyi nq

and L- indicates
that there is some di-fficulty in accounting for the autocovariances
o-f
by time averaqing a first order process.
Why

a comparison of L2

is the model rejected?

There are strona a priori reasons for linking consumption
and portfolio choices. Moreover, the sample means and cova—
riances of portfolio yields and changes in consumption lend

quaiitatve support to the notion of assets being priced in
accordance with the insurance they afford against adverse movements

in consumptort. Yet the various goodness of fit tests reported
above as well as the implausibly high estimates of relative
risk

aversion from data sets one through four appear to constitute

an overwhelming rejection of the model. What should we conclude?
A response that cannot be dismissed is that the assumed
distribution of the goodness o-f

fit tests is simply misleading.

As we noted above, we cannot rely on the standard central limit

theorems to establish the asymptotic distribution. Moreover,
even if the large sample results obtain, as we conjecture, there
is no guarantee that the asymptotic distribution provides a
close approximation for samples of the size we have examined.
Unfortunately, establishing the small sample distribution either

analytically or by Monte Carlo methods is infeasible. We choose

27

to take the

evidence against the model seriously and to focus

attention on the specific sources of predictive failure.

One is naturally led to examine more closely the various

being tested joi riti y alongside
the hypothesis that agents behave as described by (2.3). The
two most obvious are the stochastic process assumed to descri be
the evolution o-f consumption and portfolio values and the specific
auxiliary assumptions that are

form o-f pr€ferences. We will concentrat.e on the

former.

The stochastic differential equation (2.12) imposes many

overidentifying restrictions. One o-f

them

is that the

time

averaged vector has an RMA(pq) representation with pq=1.

To test this, the autoc:orrelatioris of the prediction errors
from Model 3 were calculated. Box—Liung tests did not indicate
any need for considering a higher order process.
lthoucih the evidence suggests that an ARMA(1,1) representation
for '

is

a reasonable approximation, there are problems in accepting

the restrictions that time averaging a first—order process imposes

on this representation. Fhillips(1978) shows that if BO then
ØI+B and E3.26B(I+(B—XBZ1)/4). Our unconstrained F<MPi(1 , 1)
estimates of

suggest that B is indeed small. There is little

difficulty in accepting the restrictions which a small B matrix

and time averaging impose on .

However, this combination imposes

a great deal o-f structure on E3 which is at odds with the data.

Fr all six data sets, we found that both the constrained and
unconstrained time averaged models produced estimates of E3.2681.
The unconstrained ARMc(1,1) estimates of E3 differed from .2681

28
in

LE-veral respects.

The most noticeable discrepancy was that

the unrestricted estimate of the row of the moving averaqe matrix

pErtainin to the consumpton equation was essentially zero.
in all six dat.a sets. In fact, in data sets 1—2 and 5—6, the
MA coef-ficierit for the innovation in consumption was more than

two standard deviations below .268. Failure to explain the
MA component

of

the model

o-F consumption in arid of itself would lead to rejecti on
at the 5/. level for these data sets.

One possible explanation

for the apparent absence of a

moving average component in the consumption equation is measurement

error. Suppose the unit average o-f consumption is measured

with an

error that is serially uncorrelated and independent

the true consumption process. I-f the flow-of consumption
is truly a random walk, the measured consumption series will

of

be an ARMA(1.1) process but with an

If one half of the variance of the change in measured

.268.

consumption
would

MA coe-f-ficiènt less than

is due to measurement error, the MA coefficient

be predicted to fall to just
As

.127.

pointed out earlier, our model predicts that the excess

returns of stocks and bonds over the yield on short—term paper
should be unpredictable. The time averaged excess returns should
therefore have an MA(1) structure with a coefficient of about

.268. These overidentifying predictions can be tested regardless
of the quality of the consumption data by simply regressing
the adjusted excess returns on various information sets. Moreover,
there is no problem in justifying the standard procedures to

29

test these orthoqonality restrictions. The results ar-c reported
in Table 6. The likelihood ratio test statisticq X, and the

R

of the nudi vi dual rearessi ons is also reported.
The individual F are remarkably hih and the orthoqonality
restrictions are rejected with very high confidence. Since
yield data that are point sampled are readily available, we
also tested these restrictions using the monthly point sampled
-for each

i

yields corresponding to data sets 1—6. Because a monthly price
index was not available for our longest samples, we used the
log cumulated

nominal

returns, vt. in the information set.

These results are reported in the lower half of Table 6. Although
the individual R2 are much lower, as we would expect, the rejection
a-f the orthogonality restrictions is even more pronounced.
These results are very similiar to those reported in Hansen
and Sinaleton[1983J.

One explanation for this predictive failure is simply that

the

covariance matrix c-f

constant but is state

the instantaneous innovations is not

dependent. This seems

extremely

plausible

and could also account for the noted differences in the estimates
of Z -from different sample periods. However, taking account
c-f state dependent variances would make estimation and testing

o-f the model practically impossible. Because our model imposes
restrictions across the drift and diffusion parameters, making
the latter state dependent would force us to abandon the linear

constant coefficient model of the drift as well. We would be
led

to the more general stochastic process that solves

30
(3.9)

B(t,y)dt

dy =

+

1(t,y)dZ.

The restrictions across the drift and diffusion effectively
rule out

and

any 0+ the convenient functional forms -for

B() arid

the solution of the likelihood for even the point

sampled process is difficult to implement. Computing the likelihood
-function for the unit

unimaginable,

IV

averaged

process that solves (3.9) seems

with current technology.

Conclusions
The notion of insurance against events which impinge unfavourably

on consumption choices can be used to rationalize, at least
qualitatively, the systematic differences in average yields
a-fforded

by portfolios of stocks, bonds, and short—term paper.

The sample means and covariances of portfolio returns and per
capita consumption growth indicate that the quantitative dif-ferences

in averace yields can be rationalized only by implausibly high

aversion to risk. Taking account of the fact that measured
consumption is unit averaged substantially reduces the degree
of relative risk aversion required to rationalize the data.
Nonetheless, there remains considerable evidence that
casts doubt on this view o-F the world.

In particular, it is

difficult to reconcile the importance of unit averaging of the
consumption flow with the fact that the measured logarithm of
detrended real per capita consumption has essentially no moving

average component. lso, although the model allows the average

31

return on different portfolios to diverge due to different insurance
characteristics, the particular

specification that

we examined

requires that expected excess returns should be time invariant.
This orthogoriality property is forcefully rejected by the data.

Addressing these particular predictive failures while taking

account of unit

averaging constitutes a formidable challenge
for future research.

Quarterly

Quarterly

3

5

13.76
139.13
198.56

.049
.062

.012
.012

A5

.0229

Cov(R' dc/c)

.039

ER

excess return on bonds over short term paper.

excess return on stocks over short term paper.

Annual

1

Data Set

1

-.002

-.005

-.013

ER

376.41

398.17

-.060

159.10

-.O8O

-.0l3

AB

Cov(R' dc/c)

Estimates of A Using Unconditional Means and Covariances

Table

Quarterly

Quarterly

5

6

Notes:

Munic

Consumption Deflator

Quarterly

4

Munic

(5)

Income

0

Long—Term Gain

0

Long--Term Gain

0

Capital Gains
Taxed As

2

2

1

1

1

1

Averaging Method

(6)

Column (3): To convert nominal returns to real returns, we used either the consumption deflator for non—
durables and services or the consumer price index.
Column (4): A 0 indicates pretax returns. Munic indicates that the marginal personal income tax rate
implicit in the spread between municipal and corporate bond yields was used to construct after—tax returns.
Column (6): Averaging method 1 takes the log monthly cumulated returns, forms a simple average for the
period and subtracts the log price index. Averaging method 2 takes log monthly cumulated returns,
subtracts the monthly log price index and computes the integral of the linear interpolation of the end
of month values.

CPI

0

0

Consumption Deflator

Quarterly

3

CPI

Munic

Consumption Deflator

Annual

2

0

Consumption Deflator

knnual

Rate

(4)

Marginal Tax

(3)

Price Index

(2)

Sample

1

(1)
)ata Set

Important Differences Across Data Sets

Table 2

2

:1

Data Set 3
1953: 3—1 983
119
Observations

Observations

91

1890-1980

Data Set

Observations

92

Data Set 1
1890-1981

Amy3

Amy2

Amy1

Ainc

Amy3

Amy2

Amy1

Alnc

Amy3

Amy2

Alnv1

Mnc

Variable

.0238
.273

-.059
.027

.0218

.O51

-.o13

.O51

.O29

.026

.0655

.0224

.077

.020

.0233

Q233

.159

-.185

.0229

.0231

.099

-.142

.0238

.088

.015

.0248

.o2i

.026

-.053

.0221

.261

.013

.048

.0225

.0237

—.048

.0260
.032

.094

.029

-.040

.0225

.058

.289

.019

.0225

-

.

t

t
.0215 f

.247

.216

-.067

.0254 t

.780

.318

-.160

R
R

R
R

R

R
R
R

R
R
R
R

.012

.012

-.011

.035

-.011

.035

-.013

.039

-.013

.039

Mean

Statistics

.0256 t

.692

.286

-.128

Correlation/Covariance'

.032

Mean

Some Descriptive

Table 3

22.59*

12

32.27*

18

4303**

24

25.01*

25.03*

19.45

36.72*

30.90*

30.01*

47.67**

35.69

42.68*

4.42

7.93

10.16

24.84**

11.21

11.58

26.48

31.50

36.69** 50.l1**

15.50

15.66

17.15

31.10

28.70

21.78

37.91

34.28

.52** 54.91** 62.76**
25.80*

31

22.31*

23.50*

26.28** 44.22** 48.91** 54.10**

13.02*

13.48*

9.10

29.97** 48.07** 55 l1** 59.27**

11.17

6

Box-Ljung Statistic to Lag:

—

Amy3

Amy2

Amy1

Ainc

Amy3

.266

.O37

.093

.o

.287

.o5o

.073

.0293

.242

.o254

.0221

.037

.0244

.081

.O59

.263

.080

.O54

.O310

.046

.O41O

.0l6

.140

.01l

.061

.095

.224

.O45

.O19

.311

.247

.0230

-

.O23

-.O67

.O35

.073

.057

.282
.0229

.028
.080

-

R

R

R
R

R
R
R
R

12

18

24

Lag:

10.30

14.30

14.17

13.45

29.28*

19.42

22.94

3439

27.55

12.15

14.67

37.08*

15.12

24.51

42.66** 50.62**

27.62

8.83

16.58

15.24

19.47** 24.17*

42.06*

21.08
133.00

41.86** 48.80**

31.34*

27.81** 35.38** 77.86** 85.16**

10.33

8.03

l9.71** 23.29*

27.24** 34.88** 80.04** 88.38**

8.15

7.44

10.25

22.l3** 28.66** 50.82** 56.77**

6

Box—hung Statistic to
——

.0224 14.35*

.012

.012

.015

.015

.013

.013

Mean

tDenotes adjusted to remove the effects of time averaging.

Denotes significant at 5% level.
**Denotes significant at 1% level.

2

t

t

1

1

R
R

able3

Van-

.062 t

.487

.279

.033

.02i0

.344

.241

.041

.O88

.348

.142

-.042

1

(continued)

Correlation/Covariance

.015

.0243

.011

.0251

Mean

3

mCorrelations are displayed above the diagonal.

Observations

Data Set 6
1947 :2_i 980:L
135

Amy1

1947 :2-1981:'
139
Observations

Amy2

Ainc

Amy3

Amy2

Mnv1

Ainc

Data Set 5

110
Observations

1953:3-1980:'

Data Set 4

Variable

Table

(1953:3

(1953:3

(1947:2

4

5

1981

—

:4)

1980:4)

1983:1)

-

-

(1890-1980)

(1890-1981)

3

2

1

Data Set

(.01)

(.07)

(.37)

.77

(.39)

(9.51)

21.40
(9.86)

185.38
(29.85)

2.12
(.98)

.025

(.og)

.024

(.07)

(1.60)

-.23
(.71)

(3.39)

(.024)

1.01

(.20)

1.23

(.15)

1.27

.79

21.23

154.47

S

A

.14

(.022)

.03

.14

(6.99)

(.01)

(.06)

.026

.03

.12

-4.61

g

K

(.027)

—.039

(.0216) (.0293) (.0236)

.0228

Q245

.05l

.o82
-.o16

.111

.155

.052
.O9l

.0249

.079
.042

.O6O
.0687

.0215

.155

.328

.003

.392
.0 13

.014
.042
.224

.049

-.068
.220

.334

.057
.0l2

.O311

.0238

.049

.091

.042

(.O12) (.016) (.077) (.040)

-.021

.228

.0221

fl447

fl3
.042

.220

.176

-.046

Q277

.790

.0 21

.0241

.0235

66
.0

-.097

-.O14

83

.199

.0252
.0

.282

.234

-.026

.041

.042

.021

.0267

.045
-

.0227

.378
.223

—.o13

-.008

.0286

-.003
.041

.0211

.0228

.0240

(.0212) (.0214) (.0233)

.0275

.214

.050

.0235

.0226

.0240

-

.374

.202

.047

.0231

744

-.008

-.004

.225

.0240

E2

-.0i7

(.098) (.0214) (.0231)

-.02l

(.o16) (.013) (.031) (.035)

.o2s

(.0230)

(.0223)

.080

B1

Estimates for the Fully Constrained Model1

Table 4

6

(1.34)

(.092)

(.80)

(.026)

1.01

S

4

(.022)

-.032

(continued)

Correlations are displayed above the diagonal.

parentheses are the estimated standard errors.

2.69

.0236

.39

A

2.

in

1980:4)

9

Figures

-

K

1.

(1947:2

Data Set

Table

(.0221)

.0232

B1

(.0279)(.0251)

.0212

-

.o8l

.026 .080

.070

.o52

.130
.0229 .213

.194

.O79

.057

E2

.083

.393

.168

-.024

849.33

856.74

1835.54

2073.78

2102.61

838.34

845.04

1803.07

1746.34

2056.02

2078.36

822.95

832.53

1794.79

1724.42

2044.57

2064.79

1

2

3

4

5

6

NP denotes the number of free parameters.

1755.34

(NP=34)

L2

(NP=25)

L2

(NP=18)

Data Set

Li

2119.85

2098.20

1755.68

1823.07

871.85

865.79

(NP4i)

L3

Goodness of Fit Tests

Table 5

•

2141.57

205(23)
=35.17

x2.0l23
=41.64

2os(7)
=14.07

x2.ol
=18.48

=32.00

x2.0106)

26.30

x2.os6)

82.98

110.12

18.68

40.00

53.62

27.14

62.52

56.56

78.64

54.90

Model 2vs
Model 3

Test of

84.36
22.90

2123.08

3

lvs

85.68

Model
Model

Test of

107.26

43.84

16.56

25.02

30.78

Model lvs
Model 2

Test of

1776.96

1852.67

885.13

877.57

(NP50)

L3

118
109
138
134

90

91

I

1, (t-l),

2
3
4
5
6

1

(8

{

}

.13
.13

.16
.15
.05
.06

.04

.21

76.67

(-q)/v' where q

z

is

the number of restrictions under test.

ratio test statistics

for the excess return on bonds equation.

A

.04

}

419.88
439.28
121.04
121.90
62.80

t

44.66
42.75
45.15

43.00
39.33

A

.20

R

1nv,_1 ,

.16
.13
.16

.27
.18

29

R

.21

.20

R

restrictions)

1nv1

for the excess return on stocks equation.

Likelihood

R2

.17
.17
.26
.22
.18
.18

R

lnv?,t_i

number of observations.

1102
1090
355
328
418
406

I

=

A

R

I

DataSet

Information Set

£

(10 restrictions)

{

Monthly Returns (Point Sampled Data)

5
6

2
3
4

1

DataSet

Information Set =

Adjusted Excess Returns (Time Averaged Data)

Notes:

II.

I.

Predictability of Excess Returns

Table 6

11.84

9.22

20.23
20.39

76.70
80.37

z

7.86

7.75
7.32

7.38
6.56
9.99

z

-7 n

Re-frences
BerqstrornqA..R. 'Continuous

Time Stochastic Models and Issues

AqgreQation Over Time,' in Z. Briliches and M. Intriligator
(eds) Handbook of Ecor,ometrics,Amsterdam:North—Holland, (19B4)

of

Breeden,D.T. 'Ar Irterternporal Asset Pricing Model with Stochastic
Consumption and Investment Opportunities, '

Journal of Financial

Economics, 7(1979) :265—296

Granqer,C.W.J. and RE. Engle 'Dynamic Model Specification with
Equilibrium Constraints: Co—integration and Error Correction,'

Department of Economics WP.#85—18, University of
San

California,

Dieqo, revised May 1985

Grossman,S.J. and R.J. Shiller 'Preliminary Results on the
Determinants of Stock Market Variability,' unpublished
mimeo, June 1980
—'Or the Determinants of Stock Market Variability, ' American

Economic Review, 7(1981):222—227
—

'Consumption Correlatedness and Risk Measurement in Economies
with Non—traded Assets and Heterogeneous Information,'
Journal of Financial Economics,10(1982): 195—210

Hannan,E.J. Multiple Time Series, New York:Wiley,1970
Hannan,E..J., W.,T.M. Dunsmuir and M. Deistler 'Estimation of

Vector AR'MAX Models,' Journal of Multivariate Analysis,

10(198W :275—295
Hansen,L.P. and K.J.

Singleton

'Stochastic Consumption,Risk

Aversion, and the Temporal Behaviour of Asset Returns,
Journal of Political Economy, 91(1983):249—265

33
Ibbotsori,R.,G. and

R.A. Sinquefield Stocks, Bonds, Bills and

Inflation:The Past. and the FLiture,

Charlottesville: Financial Analysts Research Foundation,1982
Melino,A. 'Estimation of Unit Averaqed Diffusion Processes,'

Department of Economics—Institute for Policy Analysis
WP. #8502, University of Toronto, March 1985
Merton,R.C. 'Optimum Consumption and Portfolio Rules in a Continuous

Time Mode1' Journal of Economic Theory. 3(1971):373—413
Osborne,D.R. 'Exact arid Approximate Maximum Likelihood Estimators
for Vector Moving Average Frocesses, '

Journal of the Royal

Statistical Society, Series B, 39(1977):114—118
Phillips,P..C.,B.. 'The Treatment of Flow Data in the Estimation
of Continuous Time Systems, '

in

Bergstrom et.al (eds),

Stability and Inflation, New York:Wiley, 1978

Seltzer,LH. The Nature and Tax Treatment of Capital Gains and
Losses, New York:National Bureau of Economic Research,1951

Shiller,R.J 'Consumption, Asset Markets and Macroeconomic
Fluctuations,' Carnegie—Rochester Conference Series, 17(1982)
4ilson,S.T. 'The Factorization of Matricial Spectral Densities,'

SIAM Journal of Applied Mathematics, 23(1972):420—426
— 'The Estimation of Parameters in Multivariate Time Series

Models,' Journal of the Royal Statistical Society, Series B,
35(1973):7é1—B5

