NBER WORKING PAPER SERIES

ASSET PRICING IN THE FREQUENCY DOMAIN:
THEORY AND EMPIRICS
Ian Dew-Becker
Stefano Giglio
Working Paper 19416
http://www.nber.org/papers/w19416
NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
September 2013

We appreciate helpful comments and discussions from Francisco Barillas, Rhys Bidder, Jarda
Borovicka,John Campbell, John Cochrane, Lars Hansen, John Heaton, Urban Jermann, Bryan Kelly,
Nikola Mirkov,Marius Rodriguez, Eric Swanson, and seminar participants at the San Francisco
Fed, University ofBergen, University of Wisconsin, Chicago Booth, UC Santa Cruz, Bank of
Canada, Kellogg JuniorFinance Conference, SED, ITAM, and the Macro Finance Society. The
views expressed herein arethose of the authors and do not necessarily reflect the views of the
National Bureau of Economic Research.
NBER working papers are circulated for discussion and comment purposes. They have not been peerreviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.
© 2013 by Ian Dew-Becker and Stefano Giglio. All rights reserved. Short sections of text, not to exceed
two paragraphs, may be quoted without explicit permission provided that full credit, including © notice,
is given to the source.

Asset Pricing in the Frequency Domain: Theory and Empirics
Ian Dew-Becker and Stefano Giglio
NBER Working Paper No. 19416
September 2013
JEL No. E2,E21,G0,G1,G12
ABSTRACT
In affine asset pricing models, the innovation to the pricing kernel is a function of innovations to current
and expected future values of an economic state variable, for example consumption growth, aggregate
market returns, or short-term interest rates. The impulse response of this priced variable to fundamental
shocks has a frequency (Fourier) decomposition, which captures the fluctuations induced in the priced
variable at different frequencies. We show that the price of risk for a given shock can be represented
as a weighted integral over that spectral decomposition. The weight assigned to each frequency then
represents the frequency-specific price of risk, and is entirely determined by the preferences of investors.
For example, standard Epstein-Zin preferences imply that the weight of the pricing kernel lies almost
entirely at extremely low frequencies, most of it on cycles longer than 230 years; internal habit-formation
models imply that the weight is shifted to high frequencies. We estimate the frequency-specific risk
prices for the equity market, focusing on economically interesting frequencies. Most of the pricing
weight falls on low frequencies – corresponding to cycles longer than 8 years – broadly consistent
with Epstein-Zin preferences.
Ian Dew-Becker
Fuqua School of Business
Duke University
Durham, NC 27705
ian.dewbecker@gmail.com
Stefano Giglio
University of Chicago
Booth School of Business
5807 S. Woodlawn Avenue
Chicago, IL 60637
and NBER
stefano.giglio@chicagobooth.edu

1

Introduction

This paper studies how risk prices for shocks depend on their dynamic e¤ects on the economy.
Theoretical asset pricing models have strong implications for how short- and long-term shocks
should be priced, and we empirically estimate how the power of a shock at di¤erent frequencies
determines its risk price.
A¢ ne models, which model innovations to the pricing kernel as being linearly (or log-linearly)
related to innovations in economic state variables, comprise the backbone of both theoretical and
empirical asset pricing. This paper shows that many widely used a¢ ne frameworks can be written,
estimated, and interpreted in the frequency domain. The frequency-domain decompositions give a
clear and compact characterization of the precise manner in which the dynamics of the economy
a¤ect risk prices and provide sharp tests of competing asset pricing models. The decomposition
is also economically intuitive in the sense that it provides a direct link between priced shocks and
their dynamic e¤ects on the economy.
Economic dynamics are a key input to many asset pricing models. Under Epstein–Zin (1989)
preferences, the risk premium of an asset depends on the covariance of its return with current
and expected future consumption growth. For the intertemporal CAPM (Merton, 1973; Campbell,
1993), risk premia depend on covariances with shocks to both current market returns and also
expected future returns. And in a¢ ne term structure models, risk premia can be expressed as a
function of the covariance with innovations to current and future short-term interest rates.
In dynamic asset pricing models, then, the price of risk for a shock depends on how it a¤ects
the state of the economy in the current period and in the future. Under the standard time-domain
representation, the dynamic response of the economy to a shock is summarized by an impulse
response function (IRF). Long-run shocks to consumption growth that have large risk prices under
Epstein–Zin preferences, for example, those studied in Bansal and Yaron (2004), have IRFs that
decay slowly.
In this paper we propose and derive a new frequency-domain representation of risk prices. First,
we map the IRF of a shock into the frequency domain. A shock that has strong long-run e¤ects
has high power at low frequencies, whereas shocks that dissipate rapidly have more power at high
frequencies. We refer to the frequency-domain version of the IRF as the impulse transfer function
(ITF).
Our key result is that the price of risk for a shock depends on the integral of the impulse transfer
function over the set of all frequencies !, weighted by a function Z(!). The weighting function, Z,
determines how shocks are priced depending on how they a¤ect the economy at di¤erent frequencies.
In other words, Z(!) represents the price of exposure to shocks with frequency !: it is a frequencyspeci…c price of risk. In this paper we derive Z(!) in closed form for various theoretical models and
2

estimate it empirically in equity markets.
The advantage of studying risk prices in the frequency domain is that Z gives a compact and
intuitive measure of how di¤erent shocks a¤ect the pricing kernel. Importantly, we obtain a separation result: the total price of risk for a shock depends on the interaction of two objects: the
impulse transfer function of the shock, which depends on the dynamics of the economy but not
on the agent’s preferences, and the Z function, which only depends on the preferences. We can
therefore study the frequency-speci…c risk prices by only looking at the agents’utility functions. For
example, under power utility, the only thing that determines the price of risk for a shock is how it
a¤ects consumption today. So Z is perfectly ‡at across frequencies because cycles of all frequencies
receive identical weight in the pricing kernel. Under Epstein–Zin preferences, long-run risks matter,
and Z places much more weight at low than high frequencies; in fact, the weight is focused only
at the very lowest frequencies. Conversely, for an agent with internal habit formation most of the
weight of Z is located at high frequencies.
The spectral representation we derive is useful for two main reasons. First, it gives us new
insights about the importance of the dynamics of shocks for asset prices in di¤erent models. For
example, from the spectral decomposition we learn that Epstein–Zin preferences imply that the
majority of the pricing weight lies extraordinarily close to frequency zero: under a standard calibration of the model, more than half of the mass of the spectral weighting function lies on cycles
longer than 230 years. Conversely, for an agent with internal habit formation most of the weight of
Z is located at high frequencies. The decomposition also tells us which aspects of the consumption
process one needs to focus on most when calibrating models: for example, under Epstein–Zin preferences, we …nd that the key statistics are the unconditional standard deviation and the long-run
standard deviation of consumption growth; other aspects of consumption’s dynamic behavior are
unimportant.1
The second key reason the spectral representation is useful is that it enables more general and
powerful estimation of dynamic asset pricing models. Our theoretical analysis shows that Epstein–
Zin preferences put weight on mainly the lowest-frequency e¤ects of shocks on consumption growth.
But low frequencies are precisely where we have the least estimation power empirically. Our spectral
decomposition makes it simple to test a more general model in which agents still care about “longrun” shocks, but where the long-run is de…ned as say, 10 or more years in the future, rather
than 200 years. Economically, given the range of people’s lifespans, it makes sense to test for the
importance of ‡uctuations that last for decades but decay before reaching one or two hundred years.
Furthermore, we obtain much more precise estimates of the weighting functions when considering
this alternative de…nition of “long-run” because estimation power rises substantially as we move
1

See Dew-Becker (2013) for a more extensive analysis of the issues around calibrating the long-run standard
deviation.

3

away from the lowest frequencies. We are thus able to retain the economic intuition from tightly
theorized models that long-term consumption dynamics may be important for asset pricing, but at
the same time estimate a model in a more reduced form that is superior statistically in the sense
that risk prices are more tightly estimated, as well as economically more plausible.
After deriving the frequency decomposition in section 2 and characterizing weighting functions
theoretically for various consumption-based models in section 3, we proceed in section 4 to estimate
them using the cross-section of equity prices. Since we are interested in distinguishing among
theoretical models that have very stark implications for the pricing of di¤erent frequencies, we
parametrize Z to be able to capture separately the price of high-frequency and low-frequency shocks,
letting the data speak on which are considered the more important frequencies by investors. We
do this in two ways: by restricting the weighting function Z to be the one literally implied by
the various models, and, second, by focusing on the pricing of economically interesting groups of
frequencies –frequencies related to the business cycle, trends lasting longer than the business cycle,
and ‡uctuations at frequencies shorter than business cycles.
The estimation shows strong support for long-run risk models, but only when we de…ne the longrun based on the frequency-domain interpretation of shocks with cycles longer than the business
cycle. When we estimate the parameters of Epstein–Zin preferences structurally, most of them are
insigni…cant or barely signi…cant, which would normally be interpreted as a rejection of the model:
neither short- nor long-run consumption growth seems to price equities. But that rejection would
be a mistake. When we allow “long-run”to simply mean cycles longer than the business cycle, we
…nd that covariance with long-run shocks is a statistically and economically signi…cant determinant
of average portfolio returns.
Section 5 extends the analysis to returns-based models, in which agents price equity portfolios
based on their covariance with short- and long-run shocks to equity market returns. We …nd
(consistent with Campbell and Vuolteenaho, 2004) that it is low-frequency shocks to equity market
returns that drive the pricing kernel. In section 6 we show that the methodology easily generalizes to
pricing kernels that depend on innovations of multiple variables. For example, stochastic volatility
models (as in Campbell et al., 2013) can imply that agents care about long-run innovations in
returns and volatility.
There is very little extant analysis of preference-based asset pricing in the frequency domain.
Otrok, Ravikumar, and Whiteman (2002) and Yu (2012) are two recent examples. While these
papers also present spectral decompositions of prices and consumption ‡uctuations, the object of
the decomposition is di¤erent from ours. Instead of studying how shocks at di¤erent frequencies are
priced by an agent, they ask how the price of a consumption claim depends on the spectral density
of consumption and its relation with returns. Since the price of the asset re‡ects a combination of

4

preferences and dynamics, it is impossible to evaluate the relative importance of the two beyond very
speci…c cases (in other words, no separation holds in their analysis). Relatedly, unlike this paper,
they do not obtain analytic relationships between the spectrum and asset prices; their results are
all generated numerically.2
Our paper is closely related to a vast empirical literature studying the importance of dynamics
for asset pricing in the time domain. Empirically, a number of papers study the relationship between
asset returns and consumption growth at long horizons as methods of testing the implications of
Epstein–Zin or power utility preferences.3 These papers test the asset pricing implications of speci…c
models (power utility, Epstein–Zin) about the pricing of consumption risk at di¤erent horizons.
By working in the frequency domain, we can allow for a much more general speci…cation where
shocks to consumption at di¤erent horizons may have di¤erent risk prices, for example a modi…ed
interpretation of “long-run risks” in which the important shocks are those with cycles longer than
the business cycle.
Finally, our work is related to other important decompositions of the stochastic discount factor
(SDF), most notably Alvarez and Jermann (2005), Hansen and Scheinkman (2009) and Borovicka
et al. (2011). These decompositions study the dynamic e¤ects of shocks for the evolution of
the stochastic discount factor over time. Instead, we focus on decomposing how the one-period
innovation in the stochastic discount factor depends on the way consumption responds dynamically
to the shocks. In other words, these papers analyze the impulse response function of the SDF,
while we study the impulse response function of consumption (and how it a¤ects the one-period
innovation in the SDF). Relative to these alternative decompositions, our approach has advantages
and disadvantages. The disadvantage is that we cannot study the theoretical valuation of claims
to consumption many periods from now (the focus for example of Hansen, Heaton, and Li, 2008,
and Lettau and Wachter, 2007). The reason is that these depend on the evolution of the interest
rate, which in turn depends on how the mean of the SDF will evolve over time. Naturally, this
does not leave us unable to price assets; one-period innovations in the SDF are enough to study the
cross-section of returns. The main advantage of our approach is that by focusing on the spectral
decomposition of the one-period innovation, we are able to separately study the dynamics of the
shocks from the preferences about the dynamics, a separation result that is not possible when
studying the evolution of the whole SDF. As the next sections will show, this separation result
2

Another related paper, Ortu et al. (2013), studies a di¤erent decomposition of the consumption growth process,
based on components that operate at di¤erent time scales. That paper shows by numerical calibration that the more
persistent components of the consumption growth process (as estimated from the data) could be responsible for the
high equity premium in a standard Epstein–Zin model.
3
For example, Parker and Julliard, 2005 ; Malloy, Moskowitz, and Vissing-Jorgensen, 2009; Bansal, Dittmar, and
Lundblad, 2005; Yu, 2012; Daniel and Marshall, 1997; Binsbergen, Brandt and Koijen, 2012; Hansen, Heaton, and
Li (2008).

5

will be crucial both for understanding the implications of di¤erent models for dynamics, and for
allowing us to extend and generalize the models in an economically important direction.

2

Spectral decomposition and the weighting function

We derive our spectral decomposition of the pricing kernel under two main assumptions. First,
the log pricing kernel, mt , depends on the current and future values of a scalar state variable,
xt (perhaps consumption growth or market returns). Second, the dynamics of the economy are
described by a vector moving average process Xt which includes xt .
Assumption 1: Structure of the SDF.
Denote the log pricing kernel (or stochastic discount factor, SDF) mt+1 = log(Mt+1 ).4 We
assume that mt depends on current and future values of some state variable in the economy xt :
mt+1 = F (It )

Et+1

1
X

zk xt+1+k

(1)

k=0

where xt is the priced variable, F (It ) is some unspeci…ed function of the time-t information set
It , Et+1
Et+1 Et denotes the innovation in expectations, and Et is the expectation operator conditional on information available on date t, It . This speci…cation is su¢ ciently ‡exible to
match standard empirical applications of power utility, habit formation, Epstein–Zin preferences,
the CAPM and the ICAPM (in some cases under log-linearization). Equation (1) implies that risk
prices are constant, but we relax that assumption in section 6.
Assumption 2: Dynamics of the economy.
xt is driven by an N -dimensional vector moving average process

where Xt has dimension N

xt = B1 Xt

(2)

Xt =

(3)

(L) "t

1, L is the lag operator,
(L) =

1
X

(L) is an N
k
kL

N matrix lag polynomial,
(4)

k=0

and "t is an N 1 vector of (potentially correlated) martingale di¤erence sequences. We refer
to "t as the fundamental shocks to the economy. We make no assumptions about the conditional
4

We do not take a position on whether mt is the pricing kernel for all markets or whether there is some sort of
market segmentation. We also do not assume at this point that there is a representative investor.

6

distribution of "t except that it has a mean of zero. Throughout the paper Bj denotes a conformable
(here, 1 N ) vector equal to 1 in element j and zero elsewhere. We assume without loss of generality
that xt is the …rst element of Xt . Furthermore, we require (L) to have properties su¢ cient to
ensure that xt is covariance stationary with a …nite and continuous spectrum.
Putting together the assumptions about mt+1 with those about the dynamics of the economy,
we can write the innovations to the pricing kernel as function of the impulse-response functions
(IRFs) of xt to each of the fundamental shocks. In particular, for the jth fundamental shock, "j;t ,
the IRF of xt is the set of gj;k for all horizons k de…ned as:
gj;k

(

B1

0
k Bj

for k 0
0 otherwise

(5)

We can then rewrite the innovation to the log SDF as:
Et+1 mt+1 =

1
X X
j

zk gj;k

k=0

!

"j;t+1

(6)

P
and we refer to ( 1
k=0 zk gj;k ) as the price of risk for shock j. In this representation, the e¤ect of a
fundamental shock "j;t+1 on the pricing kernel is decomposed by horizon: for every horizon k, the
e¤ect of the shock on mt+1 depends on the response of x at that horizon (captured by gj;k ) and on
the horizon-speci…c price of risk zk .
Our main result is a spectral decomposition in which the price of risk of a shock depends on the
response of x to that shock at each frequency ! and on a frequency-speci…c price of risk, Z(!).
Result 1. Under Assumptions 1 and 2, we can write the innovations to the log SDF as,
Et+1 mt+1 =

X
j

1
2

Z

Z (!) Gj (!) d! "j;t+1

(7)

where Z (!) is a weighting function depending on the risk prices fzk g and Gj (!) measures the
dynamic e¤ects of "j;t on x in the frequency domain,
Z(!)

z0 + 2

1
X

zk cos (!k)

(8)

k=1

Gj (!)

1
X

cos (!k) gj;k

k=0

7

(9)

Equivalently, the price of risk for a shock "j can be written as
1
X

zk gj;k

k=0

Z

1
=
2

Z (!) Gj (!) d!

(10)

Derivation and discussion
For each shock "j;t , the set of coe¢ cients fgj;k g is the impulse-response function of xt at di¤erent
horizons k. Moving into the frequency domain, the …rst step is to decompose the e¤ects of each
shock "j;t on the future values of xt into cycles of di¤erent frequencies. To do this, we use the
discrete Fourier transform to de…ne
1
X

~ j (!)
G

e

i!k

gj;k

(11)

k=0

~ j (!) will lie at low frequencies,
If "j;t has very long-lasting e¤ects on x, then most of the mass of G
~ j (!) will isolate high frequencies.5
while if "j;t induces mainly transitory dynamics in x, then G
~ j as the impulse transfer function (ITF) of shock j since it is the transfer function
We refer to G
P
k
associated with the …lter 1
k=0 gj;k L .
Using the inverse Fourier transform, the price of risk for shock j is
1
X

zk gj;k =

k=0

1
X
k=0

1
zk
2

Z

~ j (!) ei!k d!
G

(12)

Now note that gj;k = 0 for all k < 0. In the Appendix we show that, as a consequence, for any
5
~ gives weights in terms of cycles of di¤erent frequencies, we
To be more rigorous about the sense in which G
refer to the spectral representation theorem. Speci…cally, denote xk;t the process induced in xt if the only shock
realizations were for "k . That is,
1
X
xk;t =
gk;j "k;t k
j=0

"k;t has a spectral representation
"k;t =

Z

eit! dZ (!)

where dZ (!) is an orthogonal increment process with constant variance (see, e.g., Priestley, 1981, for a textbook
statement and proof of the spectral representation theorem). The spectral representation of xk;t is then
xk;t =

Z

eit!

1
X

gk;j e

ij!

dZ (!) =

j=0

Z

~ k (!) dZ (!)
eit! G

~ k thus determines the magnitude of ‡uctuations in xk;t at frequency !.
G

8

k > 0 we can rewrite equation (12) as:
1
X
k=0

zk gj;k =

1
2

Z

Gj (!) z0 + 2

1
X

!

zk cos (!k) d!

k=1

(13)

~ j (!),
where Gj (!) is the real part of G
~ j (!) =
G (!) = re G

1
X

cos (!k) gj;k

(14)

k=0

In other words, the price of risk for any shock depends on the integral of its response in the
frequency domain, Gj (!), weighted by a real-valued function Z (!), where
Z (!)

z0 + 2

1
X

zk cos (!k)

(15)

Gj (!) Z(!)d!

(16)

k=1

We thus have
1
X
k=0

zk gj;k

1
=
2

Z

This equation maps an element-by-element product of the in…nite collections fgj;k g and fzk g into
a simple integral over a …nite range in the frequency domain. This result is closely related to the
convolution and Parseval’s theorems, but is not identical because we take advantage of the fact that
gj;k = 0 for k < 0 to ensure that Z (!) is real-valued.6
The price of risk for shock "j thus depends on an integral over the function Gj (!), with weights
Z(!). Recall that for each frequency !, Gj (!) tells us the e¤ect of "j on x at frequency !. Z(!)
therefore determines the price of risk for any shock to the variable x at frequency !.
Three …nal points are worth making. First, in our derivation we assume that the log SDF, mt+1 ,
is linear in the news about future values of xt . We present the result in this form because the most
widely used models (including log-linearized version of non-a¢ ne models) usually specify an a¢ ne
form for the log SDF. The same decomposition holds if, instead of assuming that mt+1 is a¢ ne, we
assume that the level of the SDF Mt+1 is linear in the news terms. For the remainder of the paper,
we focus on the decomposition of the innovations in the log SDF.
Second, the result does not hinge on any particular assumption about the conditional distribution
of the shocks "t+1 (e.g., normality). Third, we are also not making any assumptions about whether
the conditional distribution of "t+1 is identical across periods or varies over time. It could be
6

We thank Urban Jermann for pointing out an alternative derivation of our result based on Parseval’s theorem.

9

heteroskedastic, for example.

2.1

Examples of impulse transfer functions Gj (!)

Before proceeding further, it is helpful to see examples of what the impulse transfer function looks
like for some simple impulse response functions. For the sake of concreteness, suppose for the
moment that the priced variable xt is log consumption growth, ct .
Figure 1 plots the impulse response and impulse transfer functions for four di¤erent hypothetical
shocks. Note that while we are ultimately interested in the e¤ects of the shocks on consumption
growth, ct (since this is what enters the log SDF), we plot the IRF in terms of consumption levels,
ct , as they are the more natural way to think about consumption.
The …rst shock is a simple one-time increase in the level of consumption. This shock has a
‡at impulse transfer function on consumption growth, indicating it has power at all frequencies.
The second shock is a long-run-risk type shock, inducing persistently positive consumption growth,
with the level of consumption ultimately reaching the same level as that induced by the …rst shock.
In this case, there is much less power at high frequencies, but the power at frequency zero is
identical, since G (0) depends only on the long-run e¤ect of the shock on the level of consumption
P
(Gj (0) = 1
k=0 gj;k ).
The next two shocks have purely transitory e¤ects. The third shock raises consumption for just a
single period, and we see now zero power at frequency zero and positive power at high frequencies.
The fourth shock is more interesting. Consumption rises initially, turns negative in the second
period, and returns to its initial level in the third period. The transfer function is again equal to
zero at ! = 0, but it now actually has negative power at low and middle frequencies. This is a
result of the fact that the impulse response of consumption is actually negative in some periods.
The sign of G re‡ects the direction in which the shock drives consumption. If we had reversed the
signs of the impulse responses for the …rst three shocks, their transfer functions would all have been
negative.

3

Weighting functions in consumption-based models

This section applies the analysis above to a range of standard utility functions for which mt+1 can
be written as a linear function of innovations to consumption growth. We analyze power utility,
models of internal and external habit formation, and Epstein–Zin preferences.7 We then estimate
7
While these models of preferences are often applied under the assumption of the existence of a representative
agent, note that that assumption is not strictly necessary. In particular, the pricing kernel generated by an agent’s
Euler equation will hold for any market in which he participates. We thus do not concern ourselves, for now, with

10

weighting functions empirically using data on equity returns.

3.1
3.1.1

Weighting functions in theoretical models
Power utility

Under power utility, the log pricing kernel is
mt+1 = log

(17)

ct+1

where ct denotes the log of an agent’s consumption, is the coe¢ cient of relative risk aversion, and
log is the rate of pure time preference. (17) implies that z0 = and zk = 0 for all k > 0, so the
weighting function under power utility is simply
Z power (!) =

(18)

Z power is ‡at and exactly equal to the coe¢ cient of relative risk aversion. Z power is constant because
the only determinant of the innovation to the SDF is the innovation to consumption on date t + 1.
A shock to consumption growth has the same e¤ect on the pricing kernel regardless of how long the
innovation is expected to last.
3.1.2

Habits

Adding an internal habit to the preferences yields the lifetime utility function
Vt =

1
X

j (Ct+j

j=0

bCt+j 1 )1
1

where Ct = exp (ct ) is the level of consumption and 0
importance of the habit. The pricing kernel is
exp (mt+1 ) =

(Ct+1
(Ct

bCt )
bCt 1 )

If we log-linearize the pricing kernel in terms of
we obtain
Et+1 mt+1

b (1

b)

2

+1

b < 1 is a parameter determining the

Et+1 b (Ct+2
Et b (Ct+1

ct+1 and

(19)

bCt+1 )
bCt )

(20)

ct+2 around a zero-growth steady-state,

Et+1 ct+1 + b (1

b)

2

Et+1 ct+2

(21)

issues of market completeness or the existence of a representative agent. Of course, we will assume a representative
agent when testing the model using data on aggregate consumption.

11

With internal habits the pricing kernel depends on both the innovation to current consumption
growth and also the change in consumption growth between dates t + 1 and t + 2. The spectral
weighting function under habit formation is
Z internal (!) =

1 + b (1

b)

2

b (1

b)

2

2 cos (!)

(22)

The weighting function with habits is equal to a constant plus a negative multiple of cos (!). As
we would expect, Z internal (!) = Z power (!) when b = 0.
The left panel of Figure 2 plots Z internal (!) for various values of b. Here and in all cases below
we only plot Z between 0 and as is standard, since Z is even and periodic. The x-axis lists the
wavelength of the cycles, as opposed to the frequency !. Given a frequency of !, the corresponding
cycle has length 2 =! periods (the smallest cycle we can discern lasts two periods).
As b rises, there are two e¤ects. First, the integral over Z gets larger, and second, its mass
shifts to higher frequencies. The latter e¤ect is consistent with the usual intuition about internal
habit formation that households prefer to smooth consumption growth and avoid high-frequency
‡uctuations to a greater extent than they would under power utility.8
One lesson from the equation for Z internal is that as long as b is the only parameter we can vary,
there is little ‡exibility in controlling preferences over di¤erent frequencies. cos (!) always crosses
zero at =2, so the pricing kernel will always place higher weight on cycles of frequency greater
than =2 and relatively less weight on cycles with frequency less than =2. Furthermore, Z internal
is monotone, regardless of the value of b.9
Under external habit formation, the SDF is
exp (mt+1 ) =

Ct+1
Ct

b Ct
bC t

(23)

1

where C denotes some external measure of consumption (e.g. aggregate consumption or that of an
agent’s neighbors). In this case, the innovation to the SDF depends only on the innovation to Ct+1 .
So the weighting function with an external habit will be completely ‡at. Otrok, Ravikumar, and
Whiteman (2002) show that the external habit has a strong e¤ect on what weights utility places on
consumption cycles of di¤erent frequencies, but what we show here is the SDF is driven entirely by
8

Otrok, Ravikumar, and Whiteman (2002) obtain a similar result, but in a di¤erent manner. Rather than
characterize the volatility of the pricing kernel, they characterize the price of a Lucas tree, which is equivalent to
simply characterizing lifetime utility as a function of the spectral density of consumption growth. While lifetime
utility is important, it is not the same as the price of risk in the economy. Our results are therefore complements
rather than substitutes.
9
One potential way to enrich preferences to allow preferences to isolate smaller ranges of the spectrum may be to
allow for more lags of consumption to enter the utility function.

12

one-period innovations, so all cycles receive the same weight in pricing assets. The pricing kernel
in models with external habit formation, e.g. Campbell and Cochrane (1999), places equal weight
on all frequencies. On the other hand, the internal habit models of Constantinides (1990) and Abel
(1990) are heavily weighted towards high-frequency ‡uctuations.
3.1.3

Epstein–Zin preferences

An alternative way of incorporating non-separabilities over time is Epstein and Zin’s (1991) formulation of recursive preferences. In general, under recursive preferences, anything that a¤ects
an agent’s welfare a¤ects the pricing kernel. So not only shocks to current and future consumption growth, but also innovations to higher moments will be priced. We begin by focusing on the
case where consumption growth is log-normal and homoskedastic. Section 5 considers models with
stochastic volatility.
Suppose an agent has lifetime utility
n
Vt = (1

) Ct1

+

1
Et Vt+1

1

o11

(24)

Campbell (1993) and Restoy and Weil (1998) show that if consumption growth is log-normal and
homoskedastic, the stochastic discount factor for these preferences can be log-linearized as
Et+1 mt+1

Et+1 ct+1 + (

) Et+1

1
X
j=0

j

ct+1+j

!

(25)

where is the inverse elasticity of intertemporal substitution (EIS), and
is the coe¢ cient of
relative risk aversion. is a parameter (generally close to 1) that comes from the log-linearization
of the return on the agent’s wealth portfolio (Campbell and Shiller, 1988).10
is a measure of
impatience: if the agent is highly impatient, then he consumes a large fraction of his wealth in each
period and is small. In the case where = 1, equation (25) is exact.
For the case of equation (25), the weighting function is
Z

EZ

(!)

+(

)

1
X

j

2 cos (!j)

(26)

j=1

10

1

Speci…cally, = 1 + DP
, where DP is the dividend-price ratio for the wealth portfolio (i.e. the consumptionwealth ratio) around which we approximate. generalizes the rate of pure time preference somewhat because it also
depends on discounting due to uncertainty about future consumption.

13

which can be further simpli…ed using Euler’s formula as
Z

EZ

(!) =

+(

)

1

2
1
2 cos (!) +

2

(27)

Under power utility,
= and Z EZ (!) =
is ‡at, so all frequencies receive equal weight, as
discussed above. On the other hand, if 6= , then weights can vary across frequencies due to the
second term.
Z EZ is much richer than what we obtain in the case of power utility and it has a number of
interesting properties. First, as with power utility, its average value is exactly equal to the coe¢ cient
of relative risk aversion,
Z
1
Z EZ (!) d! =
(28)
0

Therefore, the total weight placed on the spectrum depends only on risk aversion. Another way to
see this is that is the price of a shock that a¤ects all frequencies equally (and therefore has impulse
transfer function Gj (!) equal to 1, like shock 1 in Figure 1). To the extent that the volatility of
the pricing kernel depends on the EIS, it is due only to how
a¤ects which frequencies receive
weight.
An obvious question is how rapidly Z EZ falls as ! rises above zero. That is, how much of the
mass of Z EZ is concentrated at very low frequencies? In the limit as ! 1, i.e. the case where
households are indi¤erent about when consumption occurs, Z EZ (!) approaches
Z EZ (!) = (

) D1 (!) +

(29)

where D1 is the limit of the Dirichlet kernel (closely related to the Dirac delta function), with the
key properties

1
2

Z

D1 (!) = 0 for ! 6= 0
D1 (!) d! = 1

(30)
(31)

for ! in the interval ( ; ). Z EZ (!) can thus be thought of as roughly a point mass weighted by
(
) plus a constant . For an agent who is e¤ectively in…nitely patient, then, two features of
the consumption process matter: the permanent innovations at ! = 0 (limj!1 Et+1 ct+j ), which
are weighted by , and all transitory innovations, which have no e¤ect on limj!1 Et+1 ct+j , and
are weighted by .
Moving away from the limiting case, the right-hand panel of …gure 2 plots Z EZ for a variety
of parameterizations. The parameterizations are meant to correspond to annual data, so we take
14

= 0:975 as our benchmark, which corresponds to a 2.5 percent annual dividend yield. For = 5
and = 0:5 (an EIS of 2), we see a large peak near frequency zero, with little weight elsewhere. In
fact, half the mass of Z EZ in this case lies on cycles with length of 230 years or more, and 75 percent
lies on cycles with length 72 years or more. In this parameterization, it is e¤ectively only the very
longest cycles in consumption (up to permanent shocks) that carry any substantial weight in the
pricing kernel. Purely temporary shocks to the level of consumption (which is what are induced
by shocks to monetary policy in standard models, for example) are essentially unpriced. One way
to interpret these numbers is the following. Take a permanent shock to consumption (like shock 1
in Figure 1). We have seen above that it will have price of risk of . Now suppose we eliminate
all ‡uctuations induced by this shock that are longer than 230 years. The price of this new shock
will be one half that of the permanent shock. Then suppose we further remove all ‡uctuations with
cycles longer than 72 years. The price of the remaining shock drops to one quarter of that of the
permanent shock. A very large part of the risk premium comes from the longest ‡uctuations (of
hundreds of years) in this model.
The line that is highly negative near ! = 0 is for = 0:5 and = 5, where households prefer
a late resolution of uncertainty. In this case, the mass of Z EZ is still e¤ectively isolated near zero,
but because households now prefer an early resolution of uncertainty, Z EZ is negative at that point.
The integral of Z EZ is still equal to , though, so it turns positive at higher frequencies.11
3.1.4

Ambiguity aversion interpretation

As usual, the analysis of Epstein–Zin preferences naturally also applies to the preferences of an
ambiguity averse agent (e.g. Hansen and Sargent, 2001; Barillas, Hansen, and Sargent, 2009).
When the agent has a preference for robustness, he can be viewed as having a reference distribution
(the true distribution) and a worst-case distribution, which is what he uses to actually price assets.
Under the reference distribution, the agent simply has power utility, so his weighting function would
be ‡at. Under the worst-case distribution, though, he places relatively more weight on certain “bad”
states of the world (based on a joint entropy condition on the two distributions). Our weighting
function shows the e¤ect of that reweighing in the frequency domain. Agents essentially place
more weight on the possibility of the occurrence of low-frequency ‡uctuations, which gives them a
relatively high weight in the function Z EZ .12
Ambiguity aversion also gives a convenient way to motivate a more general spectral weighting
function than those derived above for standard models. Speci…cally, suppose an agent is ambiguity
11

Note, though, that the case where > is not taken as a benchmark and is not widely viewed as empirically
relevant (see, e.g., Bansal and Yaron, 2004).
12
Hansen and Sargent (2007) provide a similar interpretation of their multiplier preferences in the frequency domain
for a linear-quadratic control problem.

15

averse in the sense that he maximizes
Et

"

1
X

zj log Ct+j

j=0

#

(32)

where E is an expectation taken under some subjective probability measure. The set of parameters zj determines how much weight consumption receives at various dates in the future.
The appendix shows that in a standard implementation of Hansen and Sargent’s constraint preferences, i.e. where E is taken under a distribution that di¤ers from the true distribution by
some constrained entropy distance, the agent will have a spectral weighting function equal to
P
1
Z (!) 1 + 2 1 1
is the Lagrange multiplier on the entropy constraint,
k=1 zk cos (!k), where
which essentially determines risk aversion. Ambiguity averse preferences thus give a way to understand where an arbitrary spectral weighting function might come from, and what it would imply
for an agent’s underlying utility.

4

Estimates of weighting functions

We now estimate the weighting function Z(!) for consumption growth using the cross-section of
equity prices. Estimating Z involves three main steps. First, we need to estimate the dynamics of the
economy and identify the fundamental shocks "t+1 and the dynamic response of consumption growth
to these shocks. Second, we parametrize the function Z(!). Third, we estimate the parameters of
Z using the cross-section of equity returns.

4.1

Step 1: Estimation of the dynamics

We assume the process driving the priced variable, xt , follows a …nite-order VAR,
Xt =

(L) Xt

1

(33)

+ "t

where xt = B1 Xt is the …rst element of Xt and Xt has dimension N 1.13 In our benchmark results,
xt is log consumption growth, ct . If the lag polynomial (L) has order K, then we can stack K
0
consecutive observations of Xt so that Xt
Xt0 ; Xt0 1 ; ::: follows a VAR(1)
Xt = Xt

1

and xt = B1 Xt . We estimate this VAR using OLS, yielding estimates of
13

(34)

+ "t
and "t .

Recall that Bj represents a conformable selection vector equal to 1 in element j and 0 elsewhere.

16

4.2

Step 2: Parametrization of the spectral weighting function

The weighting function that we want to estimate, Z (!), is potentially in…nite-dimensional, but
we only have a …nite number of risk prices (one for each estimated shock in "t ) with which to
estimate it. We therefore need to choose a functional form to approximate Z with a …nite number
of parameters. We consider two speci…cations, a ‡exible function motivated by the utility functions
discussed above, and a step function.
4.2.1

The utility basis

The analysis of the utility functions in the previous sections suggests modeling Z as:
Z U (!) = q1

1
X

j

cos (!j) + q2 + q3 cos (!)

(35)

j=1

where q1 , q2 , and q3 are unknown coe¢ cients. We call (35) the utility basis because it nests the
weighting functions derived from utility-based models. If q3 = 0, (35) matches the weighting
function for Epstein–Zin preferences in (26). If q1 = 0, the long-run component that is crucial in
the Epstein–Zin case is shut o¤, and we obtain the weighting function for internal habit formation in
(22). Finally, if both q1 = 0 and q3 = 0, then we have the weighting function for power utility. Note
that we have an extra parameter here. Following the most common calibration of the Epstein–Zin
model that motivated our speci…cation of the Z function, we choose = 0:9751=4 for quarterly data,
corresponding to a 2.5 percent annual consumption/wealth ratio.14
Because the utility basis is so closely related to the weighting functions we derived under various
preference speci…cations, the constituent functions are already plotted in Figure 2. In particular,
P
j
cos (!j), shifted upward by
the lines in the right-hand panel represent the …rst function, 1
j=1
a constant. This function clearly isolates very low frequencies, and the extent to which the lowest
frequencies are isolated depends on the parameter .
4.2.2

The bandpass basis

One advantage of working in the frequency domain is that it is straightforward to estimate risk
prices for ranges of frequencies of interest. In particular, we can model Z(!) directly in a way
that captures the preferences of agents for economically interesting frequencies, without mapping
literally to any of the models presented above. This generalizes the various models by focusing
on the main intuitions about the preferences over dynamics. To do this, we simply break the
14

In theory, we could estimate . However, we …nd that it is poorly identi…ed in the data, so we proceed to calibrate
it to the value most commonly used in the literature.

17

interval [0; ] into three economically motivated intervals, corresponding to business-cycle length
‡uctuations with wavelength between 6 and 32 quarters (as is standard in the macro literature,
e.g. Christiano and Fitzgerald, 2003), and frequencies above and below that window. If agents
dislike long-run risks, we would expect most of the weight of Z to lie in the range of frequencies
below the business cycle, while habit formation-type preferences imply that the mass should lie
at higher frequencies. At the same time, what is considered “long-run risk” here is not the literal
interpretation of the Epstein–Zin calibration (230 years): we generalize that model by considering
as “long-run risks”any shocks that induce cycles longer than the business cycle.
We refer to the set of three step functions as the bandpass basis, since Z (!) is composed of the
sum of three bandpass …lters. Speci…cally, we de…ne
Z

(a;b)

(

(!)

1 if a < j!j b
0 otherwise

For quarterly data, our three basis functions are then Z (0;2
We therefore estimate the function
Z BP (!) = q1 Z (0;2

4.3

=32)

(!) + q2 Z (2

=32)

=32;2 =6)

(!), Z (2

(36)
=32;2 =6)

(!) + q3 Z (2

=6; )

(!), and Z (2

(!)

=6; )

(!).

(37)

Step 3: Estimation of the spectral weighting function

Result 1 and the estimated VAR imply that the innovations to the log SDF are:
Et+1 mt+1 =

W (q)"t+1

(38)

for a 1 N vector W that depends on the parameters q [q1 q2 q3 ]0 : We then estimate the vector
q using the cross-section of asset prices.
To …nd W (q) for a given basis (either utility or bandpass), we go back to the VAR representation
and write:
1
X
Et+1 mt+1 =
zk B1 k "t+1
(39)
k=0

According to Result 1, the time-domain weights fzk g are transformations of the weighting function,
zk =

(

1

R

1
2

R

Z (!) d! for k = 0
Z (!) cos (!k) d! for k > 0

(40)

For both the utility and bandpass basis, Z (!) is linear in the coe¢ cients q, which implies that zk

18

is also linear in q. Speci…cally,
zk = q 0 Hk

(41)

where Hk contains the integrals of the basis functions for Z. Importantly, these Hk vectors are
completely known (they don’t need to be estimated) because they only depend on the choice of the
set of basis functions. For the utility basis,
2

6
H0 = 4

1
2

R

1
2

3
P1 i
cos (!i) d!
i=1
R
7
1
1d!
5
2
R
cos (!) d!

2

R

1

6
Hk>0 = 4

For the bandpass basis, we obtain:
2

6
H0 = 4

1
2
R
1
2
1
2

2
3
Z (0;2 =32) (!) d!
6
7
Z (2 =32;2 =6) (!) d! 5 Hk>0 = 4
R
Z (2 =6; ) (!) d!

R

3
Z (0;2 =32) (!) cos (!k) d!
R
7
Z (2 =32;2 =6) (!) cos (!k) d! 5
R
1
Z (2 =6; ) (!) cos (!k) d!

1
1

3
P1 i
cos (!i) cos (!k) d!
i=1
R
7
1
cos (!k) d!
5
R
1
cos (!) cos (!k) d!

R

(42)

(43)

which can be further simpli…ed as a function of sines (without integrals) and then computed numerically.
Given that zk = q 0 Hk , (39) becomes
Et+1 mt+1 =

q

1
X

0

Hj B1

j=0

j

!

"t+1

(44)

Et+1 mt+1 is thus a function of the VAR parameters , the innovations "t = Xt
Xt 1 , and the
three parameters q1 ;q2 and q3 .
Equation (44) suggests an alternative interpretation of the decomposition we propose, most
immediate for the case of the bandpass basis. By regrouping the right hand side of that equation,
we can write:
Et+1 mt+1 = q 0 ut+1
with
ut+1 =

1
X

Hj B1

j=0

j

!

"t+1

It is then clear that the linearity of Z(!) with respect to the basis functions gives us a linear factor
model: the factors will be the shocks ut+1 , obtained by rotating the fundamental shocks "t+1 into
the three frequency-determined directions: a “long-run”direction, a “business cycle”direction, and
a “high frequency” direction. The parameters q1 ; q2 and q3 can then be directly interpreted as the

19

prices of these three types of risk.
We can now proceed and estimate the model by specifying the moment conditions. Following a large empirical literature (for example Campbell and Vuolteenaho, 2004; Campbell et al.,
2013; Bansal et al., 2013) we assume joint lognormality of the shocks and the returns. As we
show below, this assumption yields a linear factor model, which is easy to estimate and interpret. However, similar results are obtained by directly using the nonlinear moment condition
f
E[exp( Et+1 mt+1 )(Rt+1 Rt+1
)] = 0, which does not require the assumption of lognormality.15
Under the assumption of log-normality of the shocks, the risk prices can be estimated from the
asset pricing condition16
E[Rit+1

f
Rt+1
] =

(45)

Cov(mt+1 ; rit+1 )
"
!
#
1
X
= E q0
Hj B1 j "t+1 rit+1

(46)

j=0

which, as mentioned above, is a linear factor model.
f
f
To derive that equation, consider that for any excess return Rt+1 Rt+1
, we have Et [exp(mt+1 )(Rt+1 Rt+1
)] = 0.
f
Premultiplying by exp( Et mt+1 ) we obtain: Et [exp(mt+1 Et mt+1 )(Rt+1 Rt+1
)] = 0. The moment condition is
then obtained by conditioning down.
16
The derivation of this equation follows Campbell and Vuolteenaho (2004). Given the assumption of lognormality
of all shocks, we can write:
1 2
f
Et rit+1 rt+1
+
= Covt (mt+1 ; rit+1 )
2 it
15

f
f
where rit+1 = log(1 + Rit+1 ), rt+1
= log(1 + Rt+1
), and

2
it

= V art (rit+1 ). We then note that
0
1
X
Hj B1
Covt (mt+1 ; rit+1 ) = Covt ( Et+1 mt+1 ; rit+1 ) = Et ( Et+1 mt+1 rit+1 ) = Et ( q 0 @
j=0

Therefore, we obtain:

Et rit+1
Since Et rit+1

f
+
rt+1

1
2

2
it

1
f
rt+1
+
2

' Et [Rit+1
E[Rit+1

2
it

0

= Et (q 0 @

1
X
j=0

Hj B1

1

jA

1

jA

"t+1 rit+1 )

Rtf ], and taking unconditional expectations, we obtain
2 0
1
3
1
X
f
Rt ] = E 4q 0 @
Hj B1 j A "t+1 rit+1 5
j=0

20

"t+1 rit+1 )

Our full set of moment conditions identifying the parameters of the model is
2

6
6
Gt+1 ( ; q) = 6
X ) Xt , Rt+1
t+1
6(X
{z t
}
4| VAR moments
|

Mapping into frequency domain

f
Rt+1

z X }|
1
q0
Hj B1
j=0

{z

j

{

Asset pricing moments

Rtf

(Xt+1

!

3

7
7
Xt ) rt+1 7
7
5
}

(47)
is the vector of log test

where Rt is the vector of test asset returns,
is the risk-free rate and rt+1
asset returns.
While we could in principle minimize the GMM objective function for all the parameters simultaneously, that method has the drawbacks that the optimization is di¢ cult to perform (due
to the large number of parameters) and that it allows errors in the asset pricing model to a¤ect
the VAR estimates. We therefore construct estimates of and q by minimizing the two moment
conditions separately. That is, is simply estimated through OLS and then q is estimated taking
as given, using GMM.17 Given estimates ^ and b
q, we construct standard errors using the full set of
moments, G ^ ; b
q . The standard errors we report for the risk prices q therefore always incorporate
uncertainty about the dynamics of the economy through .
We perform the GMM estimation of q, taking as given, using either one-step GMM (using
the identity matrix to weight the asset pricing moments) or two-step GMM (using the estimated
variance-covariance matrix of the moment residuals to construct the weighting matrix for the second
step), and report the results separately.18

4.4
4.4.1

Empirical results
Data

The most natural choice for the priced variable, xt , is consumption growth, but we also explore
using other variables: GDP, durable consumption, and investment growth. The rationale for using
variables other than consumption, even though we are motivated by consumption-based models, is
17

The same methodology is used in Campbell and Vuolteenaho (2004) and Campbell et al. (2013). Optimizing
the full GMM objective function (or even using two-stage GMM) would be more e¢ cient, so our standard errors will
in general be larger than if we used a fully e¢ cient method.
18
When computing the standard errors incorporating the full estimation uncertainty (according to eq. 47), we
take into account the weighting matrix we have used to estimate q. We construct the full weighting matrix in the
following way. We assign equal weight to all VAR moment conditions (i.e. we use the identity matrix for the block of
the weighting matrix that corresponds to the VAR moment conditions). For the block that corresponds to the asset
pricing moments, we use the same weighting matrix we used in the estimation of q. We set to zero the weight on the
cross-product between VAR and asset pricing moment conditions. Finally, we scale the VAR moment conditions by
a (common) constant such that on average the block of VAR moments and the block of asset pricing moments get
the same weight.

21

that to the extent that the pricing kernel is driven by permanent shocks to consumption, permanent
shocks to any variable that is cointegrated with consumption should also proxy for the pricing kernel,
since the permanent shocks to consumption and any variable it is cointegrated with must be perfectly
correlated. That said, households want to smooth consumption compared to income, so we cannot
view estimates of the spectral weighting function for aggregates other than consumption as yielding
direct tests comparing utility functions. Rather, we interpret them as simply illustrating how the
dynamics of the economy are priced. Furthermore, Cochrane (1996) argues that investment growth
should price the cross-section of asset returns. Our results on investment are a generalization of his
analysis that asks whether and how future dynamics of investment growth are priced.
For the vector of state variables Xt , we want variables that are both priced in the cross-section
and can forecast our priced variable xt . Since the number of parameters of the VAR increases
quadratically with the dimension of Xt , we look for a parsimonious representation with few state
variables. The …rst element of Xt is the priced variable, and the other elements are the …rst
two principal components of a set of 9 real and …nancial variables: the aggregate price/earnings
and price/dividend ratios; the 10 year/3 month term spread; the Aaa–Baa corporate yield spread
(default spread); the small-stock value spread; the unemployment rate minus its 8-year moving
average; RREL, the detrended version of the short-term interest rate that Campbell (1991) …nds
forecasts market returns; the three-month Treasury yield rate; and Lettau and Ludvigson’s (2001)
cay. The results are robust to the choice of variables from which the principal components are
extracted. Because some of the variables used are only available after 1952, in the analysis that
follows we use the quarterly data over the period 1952–2011. Finally, in the analysis that follows
we use 3 lags of quarterly data, as suggested by the Akaike information criterion, but results are
robust to the choice of the number of lags. Table 1 reports the VAR coe¢ cients of the consumption
equation (using consumption growth as a priced variable).
4.4.2

Parameter estimates

Table 2 reports the estimation results using two-step GMM to estimate the risk prices. The lefthand side uses the set of 25 size- and book/market-sorted portfolios, while the right-hand side adds
in a set of 49 industry portfolios (both sets of portfolios are obtained from Ken French’s website; we
drop six industry portfolios that have missing data in the period considered). For both portfolio sets
we estimate both the bandpass basis and the utility basis. For the bandpass basis, q1 corresponds to
the price of lower-than-business cycle risks, q2 to business cycle risks, and q3 to higher-than-business
cycle risks. For the utility basis, q1 is price of the long-run component, q2 is the constant, and q3 is
the high-frequency component (coe¢ cient on cos(!)).
The …rst set of rows in table 2 reports results obtained using consumption growth as priced
22

variable in the SDF. We …nd that long-run shocks to consumption are strongly priced both in the
25 Fama–French portfolios and in the industry portfolios, while business-cycle frequency shocks and
high frequency shocks do not seem to be priced.
The result can be seen much more clearly when using the bandpass basis. When looking at the
utility basis, we can barely reject at the 10 percent level that long-run consumption shocks are not
priced, and the coe¢ cient on the long-run (Epstein–Zin) shock is not statistically di¤erent from
0 when industry portfolios are included. In other words, when estimating structural preferencebased models, we …nd no signi…cant parameters, implying that neither short- nor long-run shocks
to consumption growth are priced in equity returns. On the other hand, with the bandpass basis
we …nd that long-run shocks are signi…cantly priced.
We obtain similar results for the other priced variables: with the bandpass basis we …nd strongly
signi…cant low-frequency risk prices in almost all of the variables (GDP growth, durable consumption
growth, and the various measures of investment growth). On the contrary, we …nd almost no
signi…cance when using the utility basis.
The appendix reports two main robustness tests: it shows that we obtain similar results when
we bootstrap the p-values instead of using the asymptotic approximation, and also when we include
a set of risk-sorted portfolios (obtained sorting stocks by their loadings on the shocks in the di¤erent
frequency ranges). The appendix also reports the factor loadings of the size and book/market sorted
portfolios and the risk-sorted portfolios.19
Table 3 repeats the analysis using one-step GMM (i.e. using the identity matrix as a weighting
matrix when estimating the risk prices). Using the utility basis, we can only distinguish the price
of long-run risk from zero in a single case (residential investment, only for the cross-section of the
25 FF portfolios). Using the bandpass basis, we …nd several cases in which the long-run risk price
is signi…cant: consumption growth, durables growth, …xed investment and residential investment.
In any case, the bandpass basis yields results on the price of long-run risks that are much stronger
than the ones indicated by the utility basis.
We interpret these results in two ways. First, it is possible that agents do care about longrun shocks, but their de…nition of “long-run” is closer to the one captured by the bandpass basis
(cycles longer than the business cycle) rather than that captured by the utility basis (where more
than half of the pricing weight falls on cycles longer than 230 years). Second, the bandpass basis
loads on frequencies that can be economically considered “long-run”but are much easier to detect
empirically than frequencies close to 0 for which we have little empirical power.
Using the frequency-domain decomposition leads us to very di¤erent conclusions about the
19

We have also looked at whether our factors can explain the average returns on short-term dividend strips
documented by van Binsbergen, Brandt, and Koijen (2012), but …nd inconclusive results because of the brevity of
the available sample, which only begins in 1996.

23

underlying theories than standard time-domain techniques would have. The results that employ
the utility basis show essentially no support for the long-run risk model. Looking at the problem
using the bandpass …lter and targeting the economically relevant set of frequencies instead yields
strong and robust support for the idea that low-frequency shocks to the economy are priced in
equity markets.
4.4.3

Impulse transfer and weighting functions

The left-hand panel of …gure 3 plots the estimated impulse transfer functions, Gj , of the three
shocks "j for consumption growth. To help show the behavior of the functions near frequency zero,
we plot them from
to , instead of beginning at zero as elsewhere. Note that the functions are
all symmetrical across the vertical axis (since they are linear combinations of cosines). The shaded
regions in each …gure are 95-percent con…dence intervals.
There are two key features of the transfer functions to note. First, there are meaningful qualitative and quantitative di¤erences across the functions in how power is distributed, which helps
identify the underlying risk prices. If the transfer functions were all highly similar, then we would
not expect to be able to distinguish risk prices across frequencies very well. Looking at the con…dence bands, though, it is clear that the transfer functions are poorly estimated near frequency
zero. ! = 0 corresponds to the the in…nite-horizon response to each shock, so it is not surprising
that it is most di¢ cult to estimate. Nevertheless, the fact that the uncertainty rises so much at very
low frequencies helps explain why we have trouble estimating the coe¢ cient on the low-frequency
component of the utility basis.
The right-hand set of plots in each …gure zooms in on frequencies corresponding to cycles longer
than 5 years. In each of those right-hand-side …gures, the vertical lines demarcate the set of
frequencies that receive half the weight under our benchmark calibration of Epstein–Zin preferences
(i.e. cycles longer than 230 years). In all the cases, it is clear that the con…dence bands are far
larger in the region where the mass of the Epstein–Zin weighting function is focused than elsewhere.
Figure 4 plots the estimated spectral weighting functions for consumption growth and 95-percent
con…dence intervals, obtained using the 25 Fama–French portfolios, for the bandpass basis (darker
shaded area) and the utility basis (lighter shaded area). The left panel plots all frequencies, while
the right panel zooms in on the cycles longer than 5 years. The …gure shows signi…cant weight
at low frequencies. The price of long-run risks is quite precisely estimated using the bandpass
basis (and signi…cantly di¤erent from zero), while the standard errors of the utility basis estimates
diverge quickly as we look at frequencies closer to zero, con…rming the huge amount of statistical
uncertainty exactly in the frequency range most important for the Epstein–Zin model.

24

5

Weighting functions in returns-based models

5.1

Theoretical models

5.1.1

The CAPM

Under the CAPM, innovations to the SDF are proportional to innovations to the market return,
mt+1

Et mt+1 =

E [rm;t+1 rf;t+1 ]
(rm;t+1
V ar (rm;t+1 rf;t+1 )

Erm;t+1 )

(48)

where rm;t+1 is the market return. The weighting function under the CAPM is thus simply
Z CAP M (!) =

E [rm;t+1 rf;t+1 ]
V ar (rm;t+1 rf;t+1 )

(49)

Z CAP M is ‡at, and its level depends on the price of risk in the market, just like we obtain with
power utility (though obviously with a di¤erent priced variable).
5.1.2

Epstein–Zin and power utility

In a model with a representative agent with Epstein–Zin preferences (with power utility as a special
case) and where consumption growth is log-normal and homoskedastic, Campbell (1993) shows that
innovations to the pricing kernel can be written purely in terms of returns on the representative
agent’s wealth portfolio,
mt+1

Et mt+1 =

Et+1 rw;t+1

(

1) Et+1

1
X

j

rw;t+1+j

(50)

j=1

where rw is the log return of the wealth portfolio of the representative agent. is the same loglinearization parameter as in the previous section. Campbell (1993) interprets (50) as a version of
Merton’s (1973) intertemporal CAPM because both current returns and changes in the investment
opportunity set are priced risk factors.
The weighting function for (50) is
Z

EZ returns

(!) =

+(

1)

1
X

j

2cos(!j)

(51)

j=1

As

! 1 we obtain the limit

Z(!) = (

1) D1 (!) + 1

25

(52)

with D1 the limit of the Dirichlet kernel, which essentially corresponds to a point mass at 0. All
agents, then, regardless of (i.e., regardless of whether they have power utility or more general
recursive preferences) place high weight on low-frequency ‡uctuations in equity returns.
5.1.3

Returns-based asset pricing when we can forecast returns but not consumption

Campbell’s (1993) analysis, and that used in Campbell and Vuolteenaho (2004), assumes that risk
premia are constant and that consumption growth is potentially forecastable. Suppose, alternatively,
that we cannot forecast consumption growth at all, and that when we forecast asset returns we are
simply forecasting risk premia. For example, return predictability might arise from stochastic
volatility (as in Bansal and Yaron, 2004 and Campbell, Giglio, Polk and Turley, 2012) or timevarying risk aversion (Campbell and Cochrane, 1999; Dew-Becker, 2012). The Campbell–Shiller
approximation when consumption is unpredictable reduces to
Et+1 rw;t+1 =

Et+1 ct+1

Et+1

1
X

j

rw;t+j+1

(53)

j=1

and the pricing kernel is
Et+1 mt+1 =

Et+1 rw;t+1

1
1

Et+1

1
X

j

rw;t+j+1

(54)

j=1

This result is notably di¤erent from that of Campbell (1993) and equation (50) above, which are
derived assuming risk premia are constant. Speci…cally, if the EIS is greater than 1 ( < 1), then
the coe¢ cient on expected future returns becomes proportional to (1
): it has the opposite
sign from the one found in Campbell (1993) and equation (50). The intuition for this result is as
follows. In Campbell (1993), news about high future returns corresponds to an improvement in
future expected consumption growth (or, in the language of ICAPM, the investment opportunity
set), which is unambiguously good. If, however, high expected returns are due to high future
risk aversion or volatility, then there is only a discounting e¤ect: high future expected returns are
associated with low lifetime utility. An increase in risk aversion or volatility is purely bad news.

5.2
5.2.1

Estimation of the weighting function
Methods

Given that the weighting function presented above can be decomposed in two of the three constituent
functions that we saw for the case of consumption (and that are plotted in Figure 2), the utility
26

basis representation in the case of returns will simply be:
U

Z (!) = q1

1
X

j

cos(!j) + q2

(55)

j=1

Since we are mostly interested in estimating the pricing of long-run discount rate news, we
parametrize the bandpass basis to only include a constant and a generalized long-run component,
Z BP (!) = q1 Z (0;2

=32)

(!) + q2

(56)

again capturing frequencies lower than the business cycle.
As in Campbell and Vuolteenaho (2004), we use a VAR(1) with state vector composed of log
excess returns, the price/earnings ratio, term spread and default spread. We use quarterly data
from 1926q3 to 2011q2. We estimate the VAR using OLS, and set = 0:95 per year as in Campbell
and Vuolteenaho (2004).
We then use GMM as above to estimate the two parameters q1 and q2 using the cross-section
of 25 Fama-French portfolios or the combination of those assets and the 49 industry portfolios.
As before, we estimate
and q
[q1 ; q2 ] separately. Again, we report results using both onestep and the two-step GMM to estimate q, and compute standard errors for q taking into account
the uncertainty related to the estimation of the VAR parameters as explained in Section 4. For
robustness, we also compute the results using the three-parameters bandpass and utility basis we
presented in Section 4.
5.2.2

Results

Table 4 shows the results using only the 25 Fama–French portfolios (left columns) or adding the 49
industry portfolios (right columns). The top panel reports the version with two parameters (where
the …rst one captures the long-run risks) discussed in the previous section. For both the bandpass
basis and the utility basis, we …nd evidence that the long-run component of return news is priced, at
least when using only two parameters and using the e¢ cient matrix to estimate q. Consistent with
equation (51), when we use the utility basis we …nd that both the constant and the discount-rate
news (long-run shock to expected returns) are priced, and that q1 is approximately equal to q2 1.
Similarly, for the bandpass basis, the price for frequencies below the business cycle is positive and
signi…cant. The bottom panel of Table 4 reports estimates of the three-parameter version described
in Section 4. Here we …nd weaker evidence that long-run innovations in returns are priced. Overall,
though, looking at returns we …nd some evidence that news about the long-term expected returns
carry a positive risk price, though the results seem to be more sensitive to the speci…cation used
27

than in the previous section. Furthermore, the results are more consistent with a model in which the
main source of news is about future expected consumption rather than future expected volatility
or risk aversion.

6

Multiple priced variables and stochastic volatility

So far the analysis has focused only on the case where there is a single priced variable. In some
models, though, the dynamics of multiple variables matter for asset pricing. For example, in many
applications with Epstein–Zin preferences, both consumption growth and variation in volatility
or disaster risk are priced (e.g. Bansal and Yaron, 2004; Campbell et al., 2013; Gourio, 2012;
Constantinides and Ghosh, 2013, study a model with time-varying cross-sectional skewness with
similar results). It turns out that the results above map easily into a multivariate setting.
Assumption 1a: Structure of the SDF
Instead of there being a single priced variable xt , suppose there is an M 1 vector of priced
variables, ~xt , with
1
X
mt+1 = F (It )
Et+1
Zk ~xt+1+k
(57)
k=0

where Zk is a 1 M vector of weights and F (It ) is a scalar valued function.
Assumption 2a: Dynamics of the economy
We assume that ~xt is driven by a vector moving average process as before,
~xt = JXt

(58)

Xt =

(59)

(L) "t

for some matrix J of dimension M N .
The appendix derives the following extension to Result 1,
Result 2. Under Assumptions 1a and 2a, we can write the innovations to the SDF as,
Et+1 Mt+1 =

X
j

~ (!) is a (1
where Z

1
2

Z

~
Z(!)G
(!) d! "j;t+1

M ) vector-valued weighting function and G (!) is an (M

28

(60)

N ) transfer

function that measures the dynamic e¤ects of "t on ~x in the frequency domain,
~ (!)
Z

Z0 + 2

1
X

(61)

Zk cos (!k)

k=1

G(!)

1
X

(62)

cos (!k) gk

k=0

and gk is the vector of impulse response functions,
gk

J

k

In this case, then, we have multiple variables whose impulse responses we track in G, and each
~
of the priced variables has its own weighting function, represented as one of the elements of Z(!).

6.1

Epstein–Zin with stochastic volatility

Using Result 2, we now extend the results on Epstein–Zin preferences to also allow for stochastic
volatility, similar to Campbell et al. (2013) and Bansal and Yaron (2004). We use the same lognormal and log-linear framework as above. The log stochastic discount factor under Epstein–Zin
preferences is,
1
ct+1 +
rw;t+1
(63)
mt+1 =
1
1
where rw;t+1 is the return on a consumption claim on date t+1. Whereas we previously assumed that
consumption growth was log-normal and homoskedastic, we now allow for time-varying volatility
driven by a variable 2t . We assume that 2t follows a linear, homoskedastic, and stationary process.
We assume that log consumption growth is driven by a VMA process as in assumption 1, but that
now the shocks "t have variances that scale linearly with 2t .
It is then straightforward to show that expected returns on a consumption claim will follow
Et rw;t+1 = k0 + Et ct+1 + k1

2
t

(64)

where k0 and k1 are constants that depend on the underlying process driving consumption growth.
Using the Campbell–Shiller approximation, we can then write the innovation to the SDF as
Et+1 mt+1 =

ct+1

(

) Et+1

1
X

j

(65)

ct+1+j

j=1

1

Et+1 k1 2t+1
29

1

Et+1

1
X
j=1

j

k1

2
t+j+1

(66)

The weighting functions for consumption growth and volatility are now
ZCEZ SV

(!) =

+(

)

1
X

j

j=1

Z EZ
2

SV

(!) =

k1

1+

1

(67)

2 cos (!j)

1
X

j

!

2 cos (!j)

j=1

(68)

So the price of risk for a shock depends on its ITFs for both consumption growth and volatility.
SV
In the case where = 0, ZCEZ SV is exactly proportional to Z EZ
. In any case, even for > 1
2
EZ SV
they are highly similar. ZC
is in fact the same we obtained in the homoskedastic case. Both
SV
weighting functions have a constant and also allow for a point mass near zero. Z EZ
always has
2
the same basic shape regardless of the value of : unless we are in the particular case = in
SV
which Z EZ
(!) = 0, agents always place high weight on the low-frequency features of volatility.
2
Alternatively, the weighting functions can be written in terms of returns and their volatility,
ZREZ SV

R

(!) =

(1

)

1
X

j

Z EZ
2

SV

R

(!) =

1
k1
1

1+

(69)

2 cos (!j)

j=1

1
X
j=1

j

!

2 cos (!j)

(70)

which yields conceptually similar results.

7

Conclusion

This paper studies risk prices in the frequency domain. The impulse response of consumption
growth to a given shock to the economy can be decomposed into components of varying frequencies. In a model where innovations to current and expected future consumption growth drive the
pricing kernel, the price of risk for a given shock then depends on a weighted integral over the
frequency-domain representation of the impulse response function. The weights assigned to each
frequency represent frequency-speci…c prices of risk. They can be characterized in closed form and
only depend on the agents’preferences. We study this weighting function both theoretically and
empirically. Theoretically, we …nd that the weighting function helps us gain a deeper understanding
of the behavior of asset pricing models. Empirically, our estimates of the weighting function are
consistent with the idea of long-run risk models. Estimating a standard version of Epstein–Zin
preferences yields statistically weak results, but using our spectral decomposition to target economically meaningful “long-run” frequencies (speci…cally, below-business-cycle frequencies) yields
30

strong support for the importance of long-run risks for asset prices.

References
Abel, Andrew B., “Asset Prices under Habit Formation and Catching up with the Joneses,”The
American Economic Review, Papers and Proceedings, 1990, 80(2), 38–42.
Alvarez, Fernando and Urban J. Jermann, “Using Asset Prices to Measure the Persistence of
the Marginal Utility of Wealth,”Econometrica, 2005, 73(6), 1977–2016.
Bansal, Ravi and Amir Yaron, “Risks for the Long Run: A Potential Resolution of Asset
Pricing Puzzles,”Journal of Finance, 2004, 59 (4), 1481–1509.
, Dana Kiku, Ivan Shaliastovich, and Amir Yaron, “Volatility, the Macroeconomy and
Asset Prices,”Journal of Finance, 2013.
, Robert F. Dittmar, and Christian T. Lundblad, “Consumption, Dividends, and the
Cross-Section of Equity Returns,”Journal of Finance, 2005, 60(4), 1639–1672.
Barillas, Francisco, Lars P. Hansen, and Thomas J. Sargent, “Doubts or Variability?,”
Journal of Economic Theory, 2009, 144(6), 2388–2418.
Borovicka, Jaroslav, Lars P. Hansen, Mark Hendricks, and Jose A. Scheinkman, “Riskprice dynamics,”Journal of Financial Econometrics, 2011, 9, 3–65.
Campbell, John Y., “A Variance Decomposition for Stock Returns,” The Economic Journal,
1991, 101(405), 157–179.
, “Intertemporal Asset Pricing Without Consumption Data,” American Economic Review,
1993, 83(3), 487–512.
and John H. Cochrane, “By Force of Habit: A Consumption-Based Explanation of Aggregate Stock Market Behavior,”Journal of Political Economy, 1999, 107 (2), 205–251.
and Robert J. Shiller, “The Dividend-Price Ratio and Expectations of Future Dividends
and Discount Factors,”Review of Financial Studies, 1988, 1(3) (3), 195–228.
and Tuomo Vuolteenaho, “Bad Beta, Good Beta,” American Economic Review, 2004, 94
(5), 1249–1275.

31

, Stefano Giglio, Christopher Polk, and Robert Turley, “An Intertemporal CAPM with
Stochastic Volatility,”2013. Working paper.
Christiano, Lawrence J. and Terry J. Fitzgerald, “The Band Pass Filter,” International
Economic Review, 2003, 44(2), 435–465.
Cochrane, John H., “A Cross-Sectional Test of an Investment-Based Asset Pricing Model,”
Journal of Political Economy, 1996, 104 (3), 572–621.
Constantinides, George M., “Habit Formation: A Resolution of the Equity Premium Puzzle,”
The Journal of Political Economy, 1990, 98(3), 519–543.
and Anisha Ghosh, “Asset Pricing with Countercyclical Household Consumption Risk,”
2013. Working paper.
Daniel, Kent D. and David A. Marshall, “The Equity Premium Puzzle and the Risk-Free
Rate Puzzle at Long Horizons,”Macroeconomic Dynamics, 1997, 1(2), 452–484.
Dew-Becker, Ian, “A Model of Time-Varying Risk Premia with Habits and Production,” 2011.
Working paper.
, “Estimates of the volatility of the permanent component of consumption and their implications for asset pricing,”2013. Working paper.
Efron, Bradley and R.J. Tibshirani, An Introduction to the Bootstrap, Chapman & Hall, 1994.
Epstein, Larry G. and Stanley E. Zin, “Substitution, Risk Aversion, and the Temporal Behavior of Consumption and Asset Returns: A Theoretical Framework,” Econometrica, 1989,
57(4), 937–969.
and
, “Substitution, Risk Aversion, and the Temporal Behavior of Consumption and
Asset Returns: An Empirical Analysis,” The Journal of Political Economy, 1991, 99(2), 263–
286.
Gourio, Francois, “Credit Risk and Disaster Risk,”2011. Working paper.
Hansen, Lars P. and Jose A. Scheinkman, “Long-term risk: an operator approach,” Econometrica, 2009, 77, 177–234.
and Thomas J. Sargent, “Robust Control and Model Uncertainty,” American Economic
Review, 2001, 91(2), 60–66.

32

and

, Robustness, Princeton University Press, 2007.

, John C. Heaton, and Nan Li, “Consumption Strikes Back? Measuring Long-Run Risk,”
Journal of Political Economy, 2008, 116(2), 260–302.
Lettau, Martin and Jessica A. Wachter, “Why Is Long-Horizon Equity Less Risky? A
Duration-Based Explanation of the Value Premium,”Journal of Finance, 2007, 62 (1), 55–92.
and Sydney Ludvigson, “Consumption, Aggregate Wealth, and Expected Stock Returns,”
Journal of Finance, 2001, 56 (3), 815–849.
Malloy, Christopher J., Tobias J. Moskowitz, and Annette Vissing-Jørgensen, “LongRun Stockholder Consumption Risk and Asset Returns,” Journal of Finance, 2009, 64(6),
2427–2479.
Merton, Robert C., “An Intertemporal Capital Asset Pricing Model,” Econometrica, 1973, 41
(5), 867–887.
Ortu, Fulvio, Andrea Tamoni, and Claudio Tebaldi, “Long Run Risk and the Persistence of
Consumption Shocks,”Review of Financial Studies, forthcoming.
Otrok, Christopher, B. Ravikumar, and Charles H. Whiteman, “Habit Formation: A
Resolution of the Equity Premium Puzzle?,” Journal of Monetary Economics, 2002, 49(6),
1261–1288.
Parker, Jonathan A. and Christian Julliard, “Consumption Risk and the Cross Section of
Expected Returns,”Journal of Political Economy, 2005, 113(1), 185–222.
Restoy, Fernando and Philippe Weil, “Approximate Equilibrium Asset Prices,” 1998. NBER
Working Paper.
van Binsbergen, Jules H., Michael W. Brandt, and Ralph Koijen, “On the Timing and
Pricing of Dividends,”American Economic Review, 2012, 102, 1596–1618.
van Binsbergen, Jules, Michael Brandt, and Ralph Koijen, “On the Timing and Pricing of
Dividends,”The American Economic Review, 2012, 102(4), 1596–1618.
Yu, Jianfeng, “Using Long-Run Consumption-Return Correlations to Test Asset Pricing Models,”
2012. Working paper.

33

A

Derivation of equation (13)

For any gj;k , we have
gj;k

1
=
2

Z

~ j (!) (cos (!k) + i sin (!k)) d!
G

(71)

Now since gj;k = 0 for k < 0, for any k > 0 we have
gj;k = gj;k + gj;
1
=
2

Z

k

1
=
2

Z

~ j (!)
G

cos (!k) + i sin (!k)
cos ( !k) + i sin ( !k)

!

d!

~ j (!) 2 cos (!k) d!
G

~ (!) multiplied by any cos (!k) for integer k integrates
Furthermore, note that the complex part of G
~ . We thus have
to zero, which is why we can just study G re G
1
X
k=0

B

zk gj;k

1
=
2

Z

Gj (!) z0 + 2

1
X

!

zk cos (!k) d!

k=1

(72)

Ambiguity aversion and generalized time discounting

Suppose the utility an agent gets from a realization of her consumption stream is
1
X

U0 = c0 +

(73)

zj cj

j=1

U0 represents the total utility that the agent gets from consumption between dates 0 and 1,
discounted from the perspective of date 0 in the absence of any uncertainty. We assume that
consumption follows an MA(1) process,
(74)

ct = b (L) "t

We do not make any assumptions about the distribution of "t other than that it is not serially
correlated. It may be non-normal and heteroskedastic. We assume that "j = 0 for j 0.
Now suppose the agent solves the minimax problem,
"

1
X

V0 = c0 + min E G ("1
zj b (L) "j+1
1 )
G("1
1 )
j=1
1
+ " E [G ("1
1 ) log G ("1 )

34

K]

#

E [G ("1
1 )

(75)
1]

(76)

1
where "1
1 denotes a particular history of "j for j = 1 to 1. G ("1 ) is the extra weight placed on
a given history under the agent’s subjective measure.
multiplies the constraint on the entropy
of the shift in the distribution (with K being the bound), and multiplies the constraint that the
subjective distribution must integrate to 1.
The …rst-order condition for G yields

0 =

1
X

(77)

zj b (L) "j + (1 + log G)

j=1

G = exp

!

P1

j=1 zj b (L) "j +

exp
h
=
E0 1 exp

P1

j=1 zj b (L) "j =

P1

j=1 zj b (L) "j =

(78)

i

(79)

The pricing kernel between dates 0 and 1 is then proportional to
1
G ("1
1 ) / exp
exp (c1 )

1+

1

1
X

!

zj b (L) "1

j=1

!

(80)

P
So the price of risk for a shock "1 is then 1 + 1 1
j=1 zj b (L) , and thus the spectral weighting
1 P1
function is Z (!) = 1 + 2
j=1 cos (!j) zj , as in the text.

C

Derivation of weighting function with multiple priced
variables

The impulse response function is denoted
gk

J

(81)

k

where gk is an M N matrix whose fm; ng element determines the e¤ect of a shock to the nth
element of "t on the mth element of Xt+k . The innovation to the SDF is then
1
X

Et+1 mt+1 =

k=0

Zk gk

!

The price of risk for the jth element of " is simply the jth element of
35

(82)

"t+1
P1

k=0

Z k gk .

As before, we take the discrete Fourier transform of fgk g, de…ning
1
X

~ (!)
G

i!k

e

(83)

gk

k=0

Following the same steps as in section 2 and de…ning G (!)
1
X
k=0

Zk gk Bj

1
=
2
1
=
2

Z
Z

~
Z(!)G
(!) Bj d!

(84)

X

(85)

~ m (!)Gm;j (!) d!
Z

m

where
~ (!)
Z

~ (!) , we arrive at
re G

Z0 + 2

1
X

Zk cos (!k)

(86)

k=1

~ m (!) denotes the mth element of Z
~ (!) and Gm;j (!) denotes the m; jth element of
and where Z
G (!). We thus have M di¤erent weighting functions, one for each of the priced variables. The
M weighting functions each multiply N di¤erent impulse transfer functions, Gm;j (!). The price of
risk for shock j depends on how it a¤ects the various priced variables at all horizons.

D

Robustness tests for the empirical analysis and factor
loadings

This section discusses three issues related to the robustness of the main results. First, we bootstrap
the t-statistics to account for the possibility that the GMM asymptotics provide a poor small-sample
approximation. Second, we augment our set of test assets with nine risk-sorted portfolios and …nd
similar results to what is in the main text. Finally, we report the factor loadings of the individual
portfolios to emphasize the fact that there large and statistically signi…cant di¤erence in the factor
loadings across portfolios.

D.1

Bootstrapped t-statistics

We compute bootstrapped t-statistics following suggestions in Efron and Tibshirani (1994). Specifically, in every bootstrap sample we calculate the t-statistic for each coe¢ cient and then use the
simulated distribution of the t-statistics to construct p-values for the test of whether the coe¢ cients
are di¤erent from zero.
36

The estimation has two separate parts: the VAR and the asset pricing equations. For the VAR,
we bootstrap the residuals, and then use the simulated innovations to construct a new time series
of the state variables (based on the estimated feedback matrix). For the test assets, we draw the
returns for the same dates for which we drew the VAR residuals. More concretely, given a sample
size of N , we take (discrete) uniformly distributed draws from the interval [1; N ] with replacement.
The jth draw in bootstrap simulation i is denoted bij (that is, each bij is a random draw from the
discrete uniform distribution on [1; N ]). The ith simulated dataset is then the set of VAR residuals
N
and test asset returns for observations bij j=1 . To construct the set of state variables, we draw an
initial value of the state variables randomly from the set of observations and then use the drawn
innovations to construct the full sample.
The estimation then proceeds on the simulated dataset exactly as it does on the true dataset.
For each simulated sample we form t-statistics for the di¤erence between the bootstrapped estimate
of the coe¢ cient and the original point estimate. Suppose the empirically observed t-statistic in the
main estimate for some coe¢ cient k is equal to t^k > 0. Then the bootstrapped p-value is twice the
fraction of the simulated t-statistics at least as high as t^k (for a full description of the procedure,
see Efron and Tibshirani, 1994)
Table A1 replicates table 2 but using bootstrapped p-values instead of the asymptotic values
reported in table 2. We now obtain far more signi…cant coe¢ cients. The reason is that according to
the bootstrap, many of the estimators are substantially biased (which should not be too surprising,
since it is well known that GMM can be poorly behaved in small samples). For example, when we
simulate the model using consumption growth as the priced risk factor, the coe¢ cient estimates
are in general substantially smaller than we observe in the empirical sample, which implies that
the estimator is biased downwards. By bootstrapping the t-statistics, we are implicitly taking this
bias into account when forming p-values (though note that to be conservative we do not adjust the
point estimate to account for the bias as this would generally increase the variance of the estimate).
The basic result in table A1 is that the results we obtain are if anything stronger when we use
bootstrapped con…dence intervals rather than those obtained from the asymptotic distribution.

D.2

Risk-sorted portfolios

The 25 Fama–French portfolios were originally constructed because their returns spanned a number
of observed anomalies in the cross-section of excess returns. We would not necessarily expect them
to have large spreads in their loadings on shocks to consumption growth at di¤erent horizons. In
this section we therefore construct portfolios that are speci…cally designed to have a large spread
in factor loadings.
In every quarter, we estimate factor loadings with respect to the low- and business-cycle fre37

quency shocks (we refrain from also sorting on the high-frequency shocks to keep the portfolios
relatively large and well diversi…ed). The loadings are estimated on quarterly data over the previous 10 years. The loadings on each factor are split into terciles and we construct 3 3 portfolios.
The low- and business-cycle frequency shocks are constructed using the bandpass basis and equation
(44). Speci…cally, we have
Et+1 Mt+1 =

1
X

q0

Hj B1

j=0

The rotated shocks are thus,
ut+1 =

1
X

Hj B1

j=0

j

!

j

!

"t+1

"t+1

(87)

(88)

And the low- and business-cycle frequency components are the …rst two elements of this vector.
Table A1 reports results using the risk-sorted portfolios in addition to the size- and book/marketsorted portfolios. The results correspond to those in table 2 in that we use the e¢ cient GMM
weighting matrix. The left-hand set of columns combines the 9 risk-sorted portfolios with the
25 Fama–French portfolios used in the main text, while the right-hand side uses only 6 size- and
book/market-sorted portfolios (two size categories and three book/market categories) to put relatively more weight on the risk-sorted portfolios.
In both sets of columns we replicate our main results that low-frequency components of consumption growth and other real variables are signi…cantly priced under the bandpass basis, and
that few if any coe¢ cients are signi…cant with the utility basis. The coe¢ cients are also of a similar
magnitude to those in table 2.

D.3

Factor loadings

Table A3 reports the factor loadings and standard errors for the 25 Fama–French portfolios and
our nine risk-sorted portfolios. For the Fama–French portfolios, the di¤erences in loadings on both
the low- and business-cycle-frequency shocks are large and statistically signi…cant for all the small
versus large comparisons. Small …rms appear to be robustly more exposed to long-run and businesscycle shocks than large …rms, and this wide spread in factor loadings is what helps us identify the
risk prices in tables 2 and 3. On the value-growth dimension we …nd a much smaller spread, most of
the time statistically insigni…cant. In fact, we …nd no signi…cant spread between value and growth
stocks if one excludes the extreme growth portfolios (especially the small growth portfolio, typically
di¢ cult to price), which display a modestly higher exposure to long-run and business-cycle shocks.
We conclude that most of the identi…cation within the 25 Fama-French portfolio comes from the
heterogeneity in loadings between small and large …rms, though we note that it is not the main
38

purpose of this paper to explain the small-large or value-growth puzzle.
We see similarly large variation in the factor loadings for the risk-sorted portfolios. Interestingly,
it seems that the Fama–French portfolios actually have a slightly wider degree of variation in their
loadings. This is due to two factors. First, there are simply more of the Fama–French portfolios,
so we are more likely to …nd large di¤erences. Second, factor loadings for individual …rms are not
particularly persistent (especially since we estimate them using quarterly data, so the loadings used
for portfolio formation may be somewhat imprecise). The resulting risk-sorted portfolios thus have
a much smaller spread in post-formation loadings than they do in their pre-formation loadings.

39

Figure 1. Impulse response functions and impulse transfer functions
4.5

4.5

Impulse response functions

4

4

3.5

3.5

3

3

2.5

2.5

2

2

1.5

1.5

Impulse transfer functions

Shock 4

Shock 3

Shock 1
1

Shock 1

1

Shock 2
0.5

0.5

Shock 2

Shock 3
0

0
0

2

4

-0.5

6

8

10

0

0.5

1

1.5

2

2.5

3

-0.5

Shock 4
-1

-1

Notes: The left panel plots responses of the level of consumption to four hypothetical shocks. The right-hand panel plots the fourier transforms of
the shocks to consumption growth , which we refer to as the impulse transfer functions

Figure 2. Theoretical spectral weighting functions
40

100

Internal habit formation

Epstein–Zin preferences
α=5; ρ=0.5; θ=0.975

80
30

b=0.75

60

α=5; ρ=0.5; θ=0.9
40
20
20

0

10

Inf

b=0.25

b=0.5

-20
0
Inf

-10

20.00 10.00 6.67

5.00

4.00

3.33

2.86

2.50

2.22

2.00

Cycle length (2π/frequency)
(years)

20.00 10.00 6.67

5.00

4.00

3.33

2.86

2.50

2.22

2.00

Cycle length (2π/frequency)
(years)

-40

-60

α=0.5; ρ=5; θ=0.99

-80

-20

-100

Notes: Plots of the spectral weighting function Z for various utility functions. The x-axis is the cycle length. In the left-hand panel, the parameter b determines the
importance of the internal habit in the agent's utility function. In the right-hand panel, α is the coefficient of relative risk aversion; ρ is the inverse elasticity of
intertemporal substitution; and θ is the discount factor.

Figure 3. Estimated impulse transfer functions for consumption VAR

Shock to cycle factor

Shock to price factor

Shock to consumption growth

All frequencies

Cycles longer
than 5 years

Cycles longer
than 5 years

Cycles longer
than 5 years

Cycles longer than 5 years

50% of E–Z mass
(benchmark params
═>cycles >230 years)

50% of E–Z mass
(benchmark params
═>cycles >230 years)

50% of E–Z mass
(benchmark params
═>cycles >230 years)

Notes: Impulse transfer functions estimated from a VAR in consumption growth and the two principal
components. Shaded regions represent 95-percent confidence intervals. The left-hand plots are for all
frequencies, while the right-hand plots zoom in on cycles longer than 5 years. The range between the lines
on the right-hand side contains 50 percent of the mass of the weighting function for Epstein–Zin
preferences with RRA=5 and EIS=2 (cycles longer than 230 years). The x-axis gives frequencies in terms of
quarters. Shocks are not orthogonalized.

Figure 4. Estimated spectral weighting functions for equities
All frequencies

Cycles longer than 5 years

Bandpass basis

Bandpass basis

Utility basis
Utility basis

Notes: Estimated weighting functions for consumption growth as the priced variable. Risk prices are estimated using the 25 Fama–French portfolios
with the efficient weighting matrix for GMM. Shaded areas denote 95-percent confidence regions. The utility basis uses a discount factor of 0.975 at
the annual horizon. The x-axis gives frequencies in quarters.

Table 1. Regression coefficients from VARs
Lag 1
Cons.
Price
Cycle
Cons.
0.322 ***
0.629 *** 0.4935 **
se
(0.08)
(0.23)
(0.14)

Cons.
0.1459 **
(0.07)

Lag 2
Price
-0.485 *
(0.29)

Cycle

Cons.

-0.516 **
(0.21)

0.1658 **
(0.07)

Lag 3
Price

Cycle

-0.207
(0.15)

0.129
(0.17)

Notes: VAR results for consumption growth and the two principal components. The table reports the regression of consumption
growth on its own lags and those of the two pricipal components. The sample is 1952:1–2011:2, quarterly. Standard errors are
reported in brackets. * indicates significance at the 10-percent level, ** the 5-percent level, and *** the 1-percent level.

Table 2. Parameter estimates for the spectral weighting function (efficient matrix for GMM)
FF25

Portfolios:
Basis:

Bandpass

t-stat

FF25+IND
Utility

t-stat

Bandpass

q1
Consumption
q2
growth
q3

269
-431
138

2.47 **
-1.17
0.33

555.47
-442.65
616.12

1.66 *
-0.44
0.32

GDP

q1
q2
q3

124
-106
127

1.85 *
-1.29
1.33

231.42
119.67
-217.42

0.69
0.87
-1.04

Durables

q1
q2
q3

49
-38
33

2.66 ***
-1.26
1.70 *

75.62
44.87
-86.66

q1
Investment q2
q3

12
-7
-7

2.03 **
-1.18
-1.12

29.25
-0.22
5.17

q1
Fixed
q2
Investment
q3

27
-25
61

2.16 **
-1.11
3.10 ***

39.33
67.18
-90.96

0.81
2.59 ***
-1.66 *

15
-20
-4

q1
Residential
q2
Investment
q3

16
-3
4

3.52 ***
-0.45
0.24

27.00
-4.74
55.19

2.44 **
-0.12
0.85

3
2
-14

t-stat

Utility

t-stat

112
-116
-134

1.95 *
-0.87
-0.70

197.52
-279.30
504.32

1.35
-0.65
0.63

91
-72
22

1.64 *
-1.13
0.40

186.58
26.70
-77.25

0.69
0.24
-0.49

1.69 *
2.29 **
-0.63

15
-2
-5

2.30 **
-0.30
-0.83

19.96
10.79
19.62

1.58
2.37 **
0.55

1.03
-0.03
0.36

14
-7
-3

2.26 **
-1.22
-0.66

31.87
4.93
2.11

1.07
0.88
0.15

1.54
-1.26
-0.45

26.42
-5.05
-20.23

0.82
-0.41
-0.63

1.96 **
1.36
-2.26 **

5.38
-11.73
33.03

1.40
-1.19
1.97 **

Notes: Risk price estimates for the period 1952:1–2011:2 using quarterly data. The priced variable is listed in the left-hand column.
The left-hand set of columns uses the Fama–French portfolios as the test assets; the right-hand columns add 49 industry portfolios
from Ken French's website. For the bandpass basis, q1 is the price of low-frequency risk, q2 business-cycle frequency, and q3 high
frequency. For the utility basis, q1 is the low-frequency component, q2 the constant, and q3 the coefficient on cos(w). The asset
pricing moments are estimated using two-step GMM. The "t-stat" column gives the t statistics for the risk prices. * indicates
significance at the 10-percent level, ** the 5-percent level, and *** the 1-percent level. t-stats take into account VAR estimation
uncertainty, using GMM. The weighting matrix is constructed using the variance-covariance matrix of the asset pricing moment
residuals.

Table 3. Parameter estimates for the spectral weighting function (identity matrix for GMM)
FF25

Portfolios:
Basis:

Bandpass

t-stat

Utility

t-stat

Bandpass t-stat

FF25+IND
Utility

t-stat

q1
Consumption
q2
growth
q3

336
-541
401

1.73 *
-1.14
0.72

703.66
-340.19
558.13

1.62
-0.24
0.21

112 1.22
-116 -0.54
-131 -0.52

198.11
-277.49
502.47

1.02
-0.58
0.60

GDP

q1
q2
q3

138
-117
139

1.55
-1.11
1.10

258.39
133.31
-237.80

0.62
0.80
-0.95

91 1.38
-71 -0.85
21 0.18

186.71
25.95
-75.69

0.62
0.22
-0.37

Durables

q1
q2
q3

54
-40
37

q1
Investment q2
q3

13
-7
-7

q1
Fixed
q2
Investment
q3

37
-36
77

1.79 *
-0.98
1.31

82.87
52.91
-91.29

1.43
1.82 *
-0.48

15 0.95
-2 -0.14
-5 -0.37

19.96
10.77
19.62

0.72
0.84
0.40

30.07
0.04
4.15

0.86
0.00
0.24

14 1.55
-7 -0.86
-3 -0.40

31.64
4.74
2.20

0.94
0.63
0.13

0.77
2.03 *
-1.35

15 0.92
-19 -0.82
-4 -0.25

26.06
-5.58
-19.59

0.68
-0.29
-0.34

q1
18
2.49 **
30.60
1.98 **
3 0.75
5.44
Residential
q2
-3
-0.36
2.03
0.03
2 0.84
-11.63
Investment
q3
11
0.37
57.95
0.59
-13 -1.14
33.05
Notes: See table 2. These estimates differ only in that they use the identity matrix for the GMM weighting matrix.

0.66
-0.70
1.25

1.44
-0.80
-0.73
1.70 *
-1.03
2.15 **

54.66
84.97
-118.72

Table 4. Parameter estimates with returns as priced variable
FF25
Weighting: S
coeff
t-stat
Utility basis

q1 Long-run
q2 Constant

8.36
9.99

Bandpass basis

q1 Long-run
q2 Constant

13.10
-2.36

Weighting: I
coeff t-stat

2.19 **
3.34 ***
2.36 **
-0.65

7.99
9.56
13.65
-2.76

1.65 *
1.81 *
1.53
-0.72

FF25
Weighting: S
coeff
t-stat
Utility basis

Bandpass basis

Weighting: I
coeff t-stat

FF25 + Industry
Weighting: I
Weighting: S
coeff
t-stat
coeff
t-stat
7.01
8.60

3.06 ***
6.25 ***

7.07
8.63

9.65
-1.31

2.62 ***
-0.41

9.65
-1.36

1.57
2.09 **
1.39
-0.48

FF25 + Industry
Weighting: S
Weighting: I
coeff
t-stat
coeff
t-stat

q1 Long-run
q2 Constant
q3 High Freq

1.98
10.40
114.20

0.29
0.95
1.05

2.61
10.57
108.64

0.26
0.90
1.01

6.36
8.69
12.58

q1 Long-run
q2 Business cycle
q3 Short-run

9.22
46.38
-45.62

0.95
0.28
-0.30

9.26
52.58
-51.75

0.44
0.20
-0.22

15.53
-76.23
70.11

1.33
4.79 ***
0.17
2.53 **
-0.82
0.81

6.59
8.75
10.07
15.60
-77.02
70.80

0.83
2.09 **
0.07
1.45
-0.43
0.42

Notes: Risk price estimates for the period 1926:3 - 2011:2, using quarterly data. The top panel uses two parameters for the weighting function (a longrun component and a constant), the bottom panel uses three parameters corresponding to the decomposition of Table 2. t-statistics take into account
VAR estimation uncertainty using GMM. The weighting matrix used is either the inverse of the variance-covariance matrix of the moment residuals
(Weighting: S) or the identity matrix (Weighting: I).

Table A1. Bootstrapped p-values for table 2
FF25

Portfolios:
Basis:

Bandpass p-value

Utility

p-value

Bandpass p-value

FF25+IND
Utility p-value

q1
Consumption
q2
growth
q3

269
-431
138

0.00 ***
0.00 ***
0.88

555.47
-442.65
616.12

0.00 ***
0.10 *
0.29

112
-116
-134

0.00 ***
0.04 **
0.62

197.52
-279.30
504.32

0.01 **
0.05 *
0.15

GDP

q1
q2
q3

124
-106
127

0.00 ***
0.04 **
0.12

231.42
119.67
-217.42

0.01 **
0.31
0.17

91
-72
22

0.00 ***
0.01 **
0.32

186.58
26.70
-77.25

0.00 ***
0.60
0.31

Durables

q1
q2
q3

49
-38
33

0.00 ***
0.01 ***
0.01 **

75.62
44.87
-86.66

0.00 ***
0.01 ***
0.10 *

15
-2
-5

0.04 **
0.38
1.05

19.96
10.79
19.62

0.05 *
0.09 *
1.12

Investment

q1
q2
q3

12
-7
-7

0.03 **
0.41
0.77

29.25
-0.22
5.17

0.02 **
1.00
0.74

14
-7
-3

0.00 ***
0.08 *
1.10

31.87
4.93
2.11

0.00 ***
0.45
1.07

Fixed
Investment

q1
q2
q3

27
-25
61

0.00 ***
0.17
0.00 ***

39.33
67.18
-90.96

0.03 **
0.00 ***
0.01 **

15
-20
-4

0.01 **
0.03 **
1.33

26.42
-5.05
-20.23

0.02 **
1.05
0.19

q1
16
0.00 ***
27.00
0.00 ***
3
0.30
5.38
0.25
q2
-3
0.25
-4.74
0.43
2
0.79
-11.73
0.26
q3
4
1.12
55.19
0.07 *
-14
0.21
33.03
0.02 **
Notes: See table 2. These results use the efficient weighting matrix for the GMM estimation, but compute the standard errors using
bootstrap (2500 draws).
Residential
Investment

Table A2. Results using risk-sorted portfolios
Portfolios:
Basis:

Bandpass

FF25+9 risk sorted
t-stat
Utility

t-stat

Bandpass

FF6+9 risk sorted
t-stat
Utility

t-stat

q1
Consumption
q2
growth
q3

275
-531
-167

1.97 **
-1.20
-0.29

382.08
-798.65
1370.61

1.29
-0.75
0.62

276
-565
-271

2.04 **
-1.14
-0.47

328.92
-813.39
1300.84

1.13
-0.86
0.66

GDP

q1
q2
q3

194
-248
191

1.64
-1.64
1.20

414.23
87.77
-369.39

0.37
0.18
-0.75

148
-203
146

1.59
-1.73 *
1.28

285.22
48.45
-187.73

0.36
0.13
-0.53

Durables

q1
q2
q3

39
-33
24

3.15 ***
-1.14
1.39

35.72
30.17
-42.52

1.95 *
2.11 **
-0.55

18
-6
12

Investment

q1
q2
q3

12
-15
-16

2.16 **
-2.48 **
-3.35 ***

13.91
-26.27
10.27

0.86
-5.33 ***
1.41

14
-11
-9

1.50
-1.18
-1.57

Fixed
Investment

q1
q2
q3

36
-52
95

2.23 **
-1.63
2.42 **

66.46
76.73
-170.89

0.91
1.21
-2.35 **

26
-36
48

1.94 *
-1.39
1.35

2.03 ***
-0.32
1.17

-1.94
25.59
34.60

-0.12
3.71 ***
0.87

10.87
-12.77
13.08

0.72
-2.06 **
1.10

49.26
30.96
-101.63

0.86
0.62
-2.14 **

q1
7
3.24 ***
17.83
2.40 **
0 0.07
14.01 1.86 *
q2
1
0.46
-4.32
-0.14
6 2.24 **
-1.12 -0.04
q3
2
0.21
40.91
0.81
4 0.49
35.89 0.71
Notes: See table 2. These results use the efficient weighting matrix for GMM. The FF6 portfolios are based on sorts into
two bins by size and three by book/market. The 9 risk-sorted portfolios are based on three bins each for loadings on the
low- and business-cycle frequency shocks. The loadings are measured using the previous 20 quarters of data.
Residential
Investment

Table A3. Factor loadings for test portfolios
Low-frequency loadings:
Growth
2
Small
72.4 (12.3)
68.0 (10.1)
2
64.6 (10.9)
55.2 (9.0)
3
62.5 (9.7)
46.9 (8.1)
4
54.0 (8.8)
45.2 (7.6)
Large
41.6 (7.1)
32.6 (6.5)
Difference
-30.8 (8.9)
-35.4 (7.0)

3
53.0
48.5
41.6
41.3
29.3
-23.7

4
(9.0)
(8.1)
(7.5)
(7.4)
(6.1)
(6.4)

49.9
48.1
41.8
41.4
31.3
-18.6

(8.6)
(8.0)
(7.5)
(7.3)
(6.5)
(5.9)

Value
53.9 (9.8)
51.7 (9.0)
43.5 (8.3)
48.7 (8.4)
38.2 (7.4)
-15.7 (6.8)

Difference
-18.5 (6.7)
-12.9 (6.7)
-18.9 (6.7)
-5.3 (6.5)
-3.4 (5.9)

(4.0)
(3.7)
(3.5)
(3.4)
(3.0)
(2.8)

Value
28.5 (4.5)
26.1 (4.1)
21.9 (3.8)
24.8 (3.9)
20.5 (3.4)
-8.0 (3.2)

Difference
-10.6 (3.1)
-7.6 (3.1)
-10.5 (3.1)
-2.4 (3.0)
-2.0 (2.7)

Business-cycle frequency loadings:
Growth
2
Small
39.1 (5.6)
35.6 (4.6)
2
33.7 (5.0)
28.0 (4.1)
3
32.3 (4.4)
23.9 (3.7)
4
27.3 (4.0)
23.1 (3.5)
Large
22.5 (3.2)
17.3 (3.0)
Difference
-16.6 (4.1)
-18.3 (3.2)

26.9
24.4
21.0
21.4
16.4
-10.6

Low-frequency loadings:
BC beta low
LF beta low
23.5 (6.0)
2
26.3 (6.0)
LF beta high 35.6 (7.8)
Difference
12.1 (4.9)

(5.7)
(6.4)
(8.8)
(5.8)

BC beta high
26.7 (6.4)
35.8 (7.3)
57.8 (11.1)
31.2 (7.6)

Difference
3.2 (3.8)
9.5 (3.7)
22.2 (5.5)

Business-cycle frequency loadings:
BC beta low
2
LF beta low
16.6 (3.6)
17.0 (3.5)
2
18.5 (3.7)
20.7 (3.9)
LF beta high 26.4 (4.7)
33.8 (5.3)
Difference
9.7 (3.0)
16.8 (3.5)

BC beta high
19.7 (3.9)
27.1 (4.4)
42.0 (6.7)
22.2 (4.6)

Difference
3.1 (2.3)
8.5 (2.3)
15.6 (3.4)

2
23.8
27.9
46.7
22.9

3

4
(4.1)
(3.7)
(3.5)
(3.4)
(2.8)
(3.0)

25.1
23.3
21.1
20.3
17.2
-7.8

Notes: Each cell of each table is a factor loading for one of the portfolio returns with respect to either the
low- or business-cycle frequency shock. The top two panels report results for the 25 Fama–French portfolios,
while the bottom two panels are for the risk-sorted portfolios used in table A2. The numbers in parentheses
are standard errors for the estimated factor loadings.

