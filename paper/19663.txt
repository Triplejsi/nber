NBER WORKING PAPER SERIES

BETTER LUCK NEXT TIME:
LEARNING THROUGH RETAKING
Verónica Frisancho
Kala Krishna
Sergey Lychagin
Cemile Yavas
Working Paper 19663
http://www.nber.org/papers/w19663
NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
November 2013

We are grateful to the Center for University Selection and Placement (O SYM) for providing the data.
We would also like to thank Dilara Bakan Kalaycoglu for answering all our questions about the data
and Quang Vuong and Susumu Imai for extremely useful conversations. We are also indebted to participants
of the Pacific Conference for Development Economics 2011, the 10th Journees Louis-André Gérard-Varet
Conference in Public Economics, the LACEA 2012 Annual Meeting, the 2012 Seminar Series at the
Copenhagen Business School, the 8th Annual Conference on Economic Growth and Development
at ISI Delhi, and the 2012 Asian Meeting of the Econometric Society for suggestions and comments.
Kala Krishna would like to thank the Human Capital Foundation (www.hcfoundation.ru), and especially
Andrey P. Vavilov, for support of the Department of Economics at Penn State University. The views
expressed herein are those of the authors and do not necessarily reflect the views of the National Bureau
of Economic Research.
At least one co-author has disclosed a financial relationship of potential relevance for this research.
Further information is available online at http://www.nber.org/papers/w19663.ack
NBER working papers are circulated for discussion and comment purposes. They have not been peerreviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.
© 2013 by Verónica Frisancho, Kala Krishna, Sergey Lychagin, and Cemile Yavas. All rights reserved.
Short sections of text, not to exceed two paragraphs, may be quoted without explicit permission provided
that full credit, including © notice, is given to the source.

Better Luck Next Time: Learning Through Retaking
Verónica Frisancho, Kala Krishna, Sergey Lychagin, and Cemile Yavas
NBER Working Paper No. 19663
November 2013
JEL No. C13,C38,I23,I24
ABSTRACT
In this paper we provide some evidence that repeat taking of competitive exams may reduce the
impact of background disadvantages on educational outcomes. Using administrative data on the
university entrance exam in Turkey we estimate cumulative learning between the first and the nth
attempt while controlling for selection into retaking in terms of observed and unobserved characteristics.
We find large learning gains measured in terms of improvements in the exam scores, especially among
less advantaged students.
Verónica Frisancho
Research Department
Inter-American Development Bank (IADB)
1300 New York Ave. NW
Washington, DC 20577
vfrisancho@iadb.org
Kala Krishna
Department of Economics
523 Kern Graduate Building
The Pennsylvania State University
University Park, PA 16802
and NBER
kmk4@psu.edu

Sergey Lychagin
Department of Economics
Central European University
Nador u. 9
Budapest 1051
Hungary
lychagins@ceu.hu
Cemile Yavas
cemileyavas@gmail.com

1

Introduction

A central question in education policy is how to reduce the dependence of educational outcomes
on background. In this paper we provide evidence that repeat taking of entrance exams might
have some promise in this regard. Using administrative data on the university entrance exam
(ÖSS) in Turkey we estimate cumulative learning in repeated attempts, while controlling for
selection into retaking in terms of observed and unobserved characteristics. Our contribution
is twofold. First, we provide a simple way to estimate learning gains among retakers despite
only having cross-sectional data. Second, we find large learning gains, measured in terms of
improvements in the entrance exam scores, especially among less advantaged students.
We use administrative data on a random sample of about 115,000 ÖSS applicants (of which
only about a third are first time takers) from three high school tracks (Science, Social Studies,
Turkish/Math). Estimating learning gains from retaking is particularly challenging for us as
we cannot follow students as would be possible with panel data. However, we overcome this
limitation using information on repeat takers along with a rich set of performance measures.
Our approach controls for selection into retaking and teases out average cumulative learning
between the first and nth attempts.
Our model’s key assumptions are i) students know their own ability though it is unobserved
by the econometrician, ii) learning is a draw from a distribution that is allowed to vary with
observables and/or unobservables, and iii) performance in high school and on the entrance exam
is partly determinate, coming from observables and unobserved ability, and partly random. We
take a factor approach where the factors are the random performance shocks and the unobserved
ability. In our model ability will drive the correlation between high school grade point average
(GPA) and raw verbal and quantitative exam scores once the effect of observables is netted out.
We find important cumulative learning gains among repeat takers once selection into retaking
is controlled for. For example, we find that learning gains in the second attempt fluctuate around
5% of the predicted initial score, irrespective of the track. In the Social Studies and TurkishMath tracks, we identify larger and increasing cumulative gains as the number of attempts

1

increases. Gains in these two tracks on higher order attempts range from 8% to 14% of the
predicted initial score.
Most important, we identify larger gains among repeat takers from less advantaged backgrounds: in all tracks, students who come from public schools and households in the lowest income category experience larger learning gains than more privileged students from elite schools
or higher income households. These results suggest that disadvantaged students can meet high
admission standards though it may take them multiple attempts to do so. Although in this
paper we do not (and cannot) measure the net welfare impact of allowing retaking, our results
draw attention to the benefits that systems like the Turkish one, similar to that in much of
continental Europe, Asia, and some Latin American countries, may generate for repeat takers.
While we focus on the Turkish experience, the issues we study are far more general. Most
countries rely on different admissions systems to place students. The extent to which they rely
exclusively on an exam or on a more diverse spectrum of student characteristics varies considerably. In the US, for example, the SAT or ACT is widely used. However, performance on these
exams is only a small part of what colleges use in admissions decisions. Extracurricular activities, alumni ties, interviews, the perceived likelihood of the student coming, and donations may
matter even more than the student’s performance. As long as these factors favor more privileged students, such an allocation system will tend to perpetuate socioeconomic inequalities. By
eliminating the direct influence of socioeconomic status on school placement, the Turkish system
offers a way to level the playing field for less advantaged students. Moreover, though students’
backgrounds will still have an effect on performance indirectly, allowing multiple attempts may
enable less prepared but able students to catch up and reduce the role of background inequalities
on college admissions outcomes.
The paper proceeds as follows. Section 2 relates our work to the literature. Section 3
describes the institutional context and the data. The model and the econometric methodology
are presented in Section 4 while Section 5 presents the results. Finally, Section 6 concludes and
lays out some avenues for future research.

2

2

Related Literature

By documenting that the learning gains of repeat taking are higher for more disadvantaged
students, our paper relates to two strands of literature on educational catch-up.
The first of these strands looks at the issue of catch-up by immigrants. Portes and Rumbaut
(2001) found that immigrant children who arrive before age 13 and second generation children
in Miami and San Diego tend to perform better than their native-born schoolmates in terms of
grades, rates of school retention, and behavioral aspects (e.g., doing homework). However, those
who arrive after age 13 tend to be outperformed by native-born students. Using the 1995-2002
Current Population Surveys (CPS), Card (2005) finds some evidence in favor of educational
catch-up among second generation migrants. While immigrants have about 1.2–1.4 fewer years
of education than natives, second generation immigrants have 0.3–0.4 more years of schooling
than people whose parents were born in the US.
The second strand, which focuses on disadvantaged groups favored by affirmative action
(AA), presents a less rosy picture. In general, rather than catching-up, the beneficiaries of
AA preferences seem to fall behind. Sander (2004) finds that the average performance gap
between blacks and whites at selective law schools is large and, more importantly, tends to get
larger as both groups progress through school. Arcidiacono et al. (2012) shows that the GPA
gap between white and black students at Duke University falls by half between the first and
the last year of college, but this comes primarily from smaller variance in grading during later
years and a higher proportion of black students switching into easier majors. If weaker students
choose easier courses and this self-selection is not taken into account, one might incorrectly
interpret a reduction in the academic gap between strong and weak students as catch-up. Loury
and Garman (1993, 1995) make a related point. In settings where course selection issues are
minimized, students given preferences seem to fall behind. Frisancho and Krishna (2012) look at
the Indian higher education setting which has transparent admission criteria and a rigid course
structure as well as significant affirmative action. They find that backward groups fall behind,
and more so in more selective majors where the initial gap is greater.

3

In our setting, the exam covers the same set of subjects and has the same level of difficulty
across cohorts. This generates two advantages: i) we do not have to deal with self-selection
into majors and courses and ii) it is easier to catch up in our setting than in the AA case. The
beneficiaries of AA admission policies start college lacking prerequisite knowledge and cannot
benefit from college-level courses to the same extent as their more prepared peers. Consequently,
even by running as fast as they can, these students can hope, at best, to stay in the same place
they started.
Although relatively scarce, there have been previous attempts to measure catch-up in an
environment similar to ours, that is, in the period between high school graduation and college
enrollment. Nathan and Camara (1998) shows that 55% (35%) of the juniors taking the SAT
in the US improved (worsened) their scores as seniors. Vigdor and Clotfelter (2003) use data
on undergraduate applicants to three selective US research universities to look at the evolution
of SAT scores over multiple attempts. They implement a two-stage Heckman sample-selection
procedure and estimate that between 70% and 90% of the observed score increase remains when
selection is accounted for.
Although the contribution of the work on SATs is important, there are two important disadvantages compared to the ÖSS. First, as the SATs are one of many things that matter for
university admissions, students take them more lightly, generating noisier measures of performance. Second, the level of difficulty of the SAT is far below that of the ÖSS, with the SAT
being more of an IQ test than a skills test. This compromises its ability to distinguish between
takers, especially at the high end. Thus, we argue that our data provides important advantages
to looking for evidence on catch-up and measuring learning among repeat takers.
Our methodology imposes a factor structure on performance outcomes in high school and on
the admission exam. Net of the effects of observables, GPA and exam scores are determined by
two factors: students’ ability and randomness. Following Carneiro et al. (2003), many papers
have relied on this structure to model educational outcomes.1
1

See for example, Cooley et al. (2011).

4

3

Turkish Context

3.1

Institutional Background

In Turkey, entrance to higher education institutions is regulated by the ÖSS (Student Selection
Exam), a national examination administered by the Student Selection and Placement Center
(ÖSYM) on an annual basis. All high school seniors and graduates are eligible to take it and
there is no limit on the number of retakes.2 Even though centralized admission systems are
common in other places in Europe as well as Asia and Latin America, the Turkish setting is
particularly interesting due to the high share of repeat takers in the pool of applicants. For
instance, in 2002 roughly one-third of the exam takers were high school seniors, the remainder
being repeat takers.3 Although the high ratio of retakers coupled with a low placement rate
seems wasteful, there may be some hidden benefits of the current setup.
The college placement exam is composed of multiple choice questions with negative marking
for incorrect answers. Students’ performance is evaluated in four subjects: Mathematics, Turkish, Science, and Social Studies. The raw scores in these four subjects are then used to calculate
raw verbal scores, defined as the sum of the scores in Turkish and Social Studies, and raw quantitative scores, defined as the sum of Science and Math. All the raw scores are standardized and
used to construct three weighted scores.4 Students who obtain more than 105 in any weighted
score are eligible to submit preferences for two year schools or distance education programs. To
be able to submit preferences for four year programs, a minimum score of 120 is required.
Students choose a track while in high school; for the most part, the choice is between Sciences,
Social Studies, and Turkish-Math. The college placement process is designed to encourage
students to apply to programs that build on their high school education.5 Depending on the
college program chosen by the student, only one of the three weighted scores will be relevant.
This setup enables us to focus on a single weighted score for each track, which we call the relevant
2

See Türk Eğitim Derneği (TED or Turkish Educational Association) for more details on this exam.
The most recent ratio of high school seniors to total candidates, although higher, is still quite low: in 2013,
there were about 800,000 high school seniors among 1.9 million applications.
4
For details, see Appendix A.
5
For example, the high school GPA of someone from the Science track is given less weight if he applies to a
program compatible with another track.
3

5

exam score in the following sections. ÖSYM also calculates placement scores for each subject,
which are a combination of the weighted scores and a standardized measure of the student’s
high school GPA.6
Once the applicant learns his scores, he submits a list of his program preferences, having
complete information on the previous year’s cut-off scores for each program (i.e., the score of
the last student admitted). Placement is merit based: a student is placed in his most preferred
program, conditional on the availability of seats after all the applicants with higher scores are
placed. Students fail to be placed if they do not pass the exam or if other students with better
scores fill up all the available seats in the programs on their preference list. These students
will have the option of retaking the exam with no penalties. Students who are placed are also
allowed to retake, but their placement score is penalized if they retake the following year.

3.2

Data

Our data covers a random sample of about 120,000 students who took the ÖSS in 2002. After
cleaning the data and dealing with some minor inconsistencies, we lose 3.9% of the observations
so that our final cross section covers 114,800 applicants from the Science (38,771), Turkish-Math
(38,571), and Social Studies tracks (37,458).
ÖSYM data comes from four sources: students’ application forms, a survey applied in 2002,
high school records, and administrative records. For each student, our database contains information on high school characteristics (track and type of school), high school GPA, standing at
the time of the exam (high school senior, repeat taker, graduated from another program, among
other options), individual and background characteristics (gender, household income, parents’
education and occupation, family size, time and money spent on private tutoring, and number
of previous attempts), and performance outcomes (raw scores, weighted scores, and placement
outcomes). Since we want to measure high school performance across schools, we construct
quality normalized GPAs to control for quality heterogeneity and grade inflation across high
6
This standardization is implemented by the ÖSYM to make GPAs comparable. A detailed description of this
process is provided in Appendix A.

6

schools (see Appendix B for details).7

3.3

Preliminary Evidence

The measurement of learning gains among repeat takers would be a straightforward exercise with
longitudinal data. However, the ÖSS data only provides us with a cross-section of applicants,
both first time takers as well as repeat takers.
Although the scores of repeat takers will contain information on learning relative to their
first attempt, it is hard to isolate these gains without a counterfactual. Notice that the exam
scores of repeat takers reflect two effects: learning and selection into retaking. Learning shifts
the distribution of scores to the right over attempts while selection, which is an endogenous
process, can shift it to the right or to the left depending on who retakes.
Figure 1: Distribution of Exam Scores by Track

80

100

120
140
160
Exam Score

180

200

.05
0

.01

.02

Density
.03 .04

.05
Density
.03 .04
.02
.01
0

0

.01

.02

Density
.03 .04

.05

.06

Turkish−Math

.06

Social Studies

.06

Science

70

1st

90

2nd

110
130
Exam Score
3rd

150

4th

170

80

100

120
140
Exam Score

160

180

5th or more

Figure 1 plots the empirical distributions of exam scores by number of attempts and track.
In general, there is some evidence of compression in the distributions as the number of attempts
increases. Yet, two distinct patterns emerge. In the Science track the distribution of scores
shifts to the left, consistent with worse students selecting into retaking and limited learning. In
7

It is worth noting that very few papers have explored the Turkish data set. Tansel and Bircan (2005) studies
the determinants of attendance at private tutoring centers and its effects on performance. Saygin (2011) looks
at the gender gap in college. Moreover, Caner and Okten (2010) looks at career choice using data on preferences
while Caner and Okten (2013) examines how the benefits of publicly subsidized higher education are distributed
among students with different socioeconomic backgrounds.

7

turn, the score distribution moves to the right in Turkish-Math and Social Studies. This could
suggest sizeable learning gains but selection could be operating in either direction.
A further look into the data identifies a pattern common to all tracks. Figure 2 presents exam
score distributions by number of attempts and high school GPA quartiles. In all tracks, first
time takers do worse than repeat takers in the lowest GPA quartiles but this pattern reverses as
GPA increases. This suggests that weaker students learn more.8 If better performing students
are disproportionately found in the Science track, Figure 1 could reflect a composition effect due
to differential learning and selection across tracks.
Table C.1 shows that this is the case. We find stronger students in the Science track, where
the average standardized high school GPA is 51.7 as compared to 49 and 47.7 in Turkish-Math
and Social Studies respectively. Science track students also seem to be better off than Social
Studies and Turkish-Math students in terms of other background characteristics: they have more
educated and wealthier parents. They also tend to come from better schools and have higher
access to prep schools and/or tutoring while in high school.
The next section develops a simple dynamic model of learning and repeat taking to help
us understand the biases that selection introduces. In light of this model, we then develop our
estimation strategy.

4

Model

In this section we lay out a simple model and our estimation strategy. We show that while
students select into retaking based on ability and performance shocks on the entrance exam,
GPA performance shocks do not affect retaking when students are very patient. Based on this,
we lay out a strategy to identify and measure learning effects relying only on cross-sectional
data.

8
This pattern is also shown in Vigdor and Clotfelter (2003) among SAT repeat takers, suggesting that initially
better performing students have the lowest learning gains.

8

Figure 2: Distribution of Exam Scores by GPA quartiles and Track

100

120

140
160
Exam Score

180

200

80

100

120

140
160
Exam Score
1st

180

200

2nd

.06
.05
0

.01

.02

Density
.03 .04

.05
0

.01

.02

Density
.03 .04

.05
0

.01

.02

Density
.03 .04

.05
Density
.03 .04
.02
.01
0
80

Quartile IV

.06

Quartile III

.06

Quartile II

.06

Quartile I

80

3rd

100

4th

120

140
160
Exam Score

180

200

80

100

120

140
160
Exam Score

180

200

5th or more

(a) Science

110
130
Exam Score

150

170

70

90

110
130
Exam Score
1st

150

170

2nd

.06
.05
0

.01

.02

Density
.03 .04

.05
0

.01

.02

Density
.03 .04

.05
0

.01

.02

Density
.03 .04

.05
Density
.03 .04
.02
.01
0

90

70

3rd

90

4th

110
130
Exam Score

150

170

70

90

110
130
Exam Score

150

170

5th or more

(b) Social Studies

100

120
140
Exam Score

160

180

80

100

120
140
Exam Score
1st

160

2nd

180

.06
.05
0

.01

.02

Density
.03 .04

.05
0

.01

.02

Density
.03 .04

.05
0

.01

.02

Density
.03 .04

.05
Density
.03 .04
.02
.01
80

Quartile IV

.06

Quartile III

.06

Quartile II

.06

Quartile I

0

9

70

Quartile IV

.06

Quartile III

.06

Quartile II

.06

Quartile I

80

3rd

100

4th

(c) Turkish-Math

120
140
Exam Score
5th or more

160

180

80

100

120
140
Exam Score

160

180

Let s∗ denote the cut-off exam score for a candidate to be placed in a program.9 Although
critical, the relevant exam score for student i in his nth attempt, denoted by sin , is not all that
determines placement (see Section 3.2). For students with exam scores above s∗ , placement
scores are obtained as a weighted average of the exam score, sin , and high school GPA, gi . We
assume the system has a continuum of college qualities. Since students with higher scores have
more options open to them, they will obtain higher utility. Normalizing the weight on exam
scores to one, the instantaneous college utility is specified as follows:

−∞
if sin < s∗
u(sin , gi ) =
sin + ηgi
if sin ≥ s∗
Students with a score below s∗ (the cutoff for being eligible) cannot be placed according to
the rules. We set their utility from being placed at −∞ to reflect the impossibility of placement
while those with a cutoff above s∗ choose between being placed, retaking, and quitting.
We assume that student i’s high school GPA is given by:
gi = Xi α0 + θi + εi0

(1)

where εi0 is a random shock. The term Xi α0 captures the effect of observables on the GPA while
θi is an individual-specific component that captures the ability of the student. Both the effect
of observables and ability are known to the student, but θi is unobserved by the researcher.10
As described in the data section, the exam score comes from the performance on the verbal
and quantitative sections of the exam, appropriately weighted. Let sinq and sinv denote the
student’s quantitative and verbal scores respectively, and ω q and ω v be fixed known weights:
sinq = Xi α1q + β q θ i + Λinq + εinq

(2)

sinv = Xi α1v + β v θi + Λinv + εinv

(3)

9

As explained in Section 3, ÖSYM imposes a cut-off score to qualify for placement in university programs.
The known ability assumption is reasonable in the Turkish context. Although the exam is taken in 12th grade,
students start preparing for this exam as early as 9th grade. By the time they take the exam for the first time,
they have already taken many practice exams and have a good idea of their expected performance.
10

10

where Λinj is the cumulative learning in topic j up to attempt n.11 We assume that students
know their future learning shocks and let Λinj depend on Xi and/or θi . εinj is a random shock
drawn from a density function common to all n and i for a given j = v, q. These transitory
shocks are meant to capture chance occurrences that could affect exam performance (e.g., getting
a question you did not expect) and are therefore assumed to be iid.
The exam score is a weighted average of the verbal and quantitative scores, and hence
sin = ω q sinq + ω v sinv
= Xi α1 + βθi + Λin + εin
= s̄in + εin .
The distribution of εin is given by F (.) for all i and n. After the student learns his score, he
decides whether to retake, quit, or be placed. If he decides to retake, he pays a cost ψ that is
incurred immediately, though the results of retaking are apparent only a year later and so are
discounted by δ. Thus, the value of retaking is given by:


Vin (s̄in , gi , Λi ) = −ψ + δEεi(n+1) (max Vi(n+1) (s̄i(n+1) , gi , Λi ), u(si(n+1) , gi ), VQ )

where VQ is the value of quitting and Λi is the vector of all the learning shocks in all retaking
attempts.

4.1

Selection Into Retaking

Students who retake are those for whom retaking is better than the maximum of quitting and
being placed. There is selection on εi0 for those choosing between retaking and being placed as
well as for those choosing between retaking and quitting. In this section, we use a simplified
version of the model discussed above to understand the nature of the selection driven by εi0 .
When choosing between retaking and quitting, students with high εi0 will be more likely to
11
In what follows, we talk about raw quantitative and verbal scores for Science and Social Studies students as
defined in Sub-Section 3.1. This is natural because the pair of subjects used to construct these raw scores get
the same weight in the relevant weighted scores for these tracks. However, in the Turkish-Math track, we label
as “quantitative” and “verbal” the sum of the Turkish and Math scores and the sum of the Science and Social
Studies scores, respectively, to reflect equal weights of these pairs of subjects in the relevant weighted score.

11

retake as a higher value of the GPA shock increases Vin without affecting VQ . In other words,
students with low εi0 will quit. This makes the expected value of εi0 among retakers positive,
generating a negative bias in our learning estimates. As δ rises, Vin increases and more students
retake, reducing, but possibly not eliminating, this negative bias.
On the other hand, when choosing between retaking and placement, students with high εi0
will be less likely to retake and more likely to cash in their good GPA shocks. However, as we
show below, as δ approaches unity, this effect fades away. At δ = 1, there is no selection on the
basis of εi0 , and hence no positive bias.
Assume that there is no additional learning beyond the first retake, Λin = λi2 ≡ λi . This
assumption makes the problem stationary after the first period as the expected score for student
i is constant for each period n ≥ 2: s̄in ≡ s̄i = Xi α1 + βθi + λi . Let ε̃i be the shock that makes
student i just retake, i.e., Vi = u(s̄i , gi , ε̃i ). Given (1) and the definition of the instantaneous
utility, ε̃i is defined by
Vi = Xi α1 + βθ i + λi + ε̃i + η (Xi α0 + θ i + εi0 )

(4)

Given the stationary nature of the problem, Vi is defined by
Vi = −ψ + δF (ε̃i )Vi + δ

Z

(Xi α1 + βθi + λi + ε + η(Xi α0 + θi + εi0 )) f (ε)dε

(5)

ε=ε̃i

Substituting for Vi from (4) and rearranging gives
(Xi α1 + βθi + λi + ε̃i + η (Xi α0 + θi + εi0 )) (1 − δF (ε̃i ))
= −ψ + δ [1 − F (ε̃i )] [Xi α1 + βθi + λi + η(Xi α0 + θi + εi0 )] + δ

Z

εf (ε)dε
ε=ε̃i

which yields
ε̃i (1 − δF (ε̃i )) = −ψ + δ

Z

εf (ε)dε − (1 − δ) (Xi α1 + βθi + λi + η (Xi α0 + θi + εi0 ))

ε=ε̃i

At δ = 1 this reduces to
ε̃i (1 − F (ε̃i )) = −ψ +
12

Z

εf (ε)dε.
ε=ε̃i

(6)

Notice that for δ = 1, ε̃i is independent of εi0 , and hence E(ε0 |n) = E(ε0 ) = 0. The intuition
is simple. When students are impatient, they want to cash in their high GPA so that students
with high εi0 are less likely to retake, i.e., E(ε0 |n) < E(ε0 ) = 0. As δ goes to one, this effect
vanishes as is clear from looking at the derivative of (6) with respect to εi0 :
(1 − δ)
∂ε̃i
=−
η ≤ 0.
∂εi0
(1 − δF (ε̃i ))
In the extreme, when students are perfectly patient, the utility associated with their GPA shock
is fixed over time and hence does not affect their decision to retake.
To summarize, there are two sources of selection on εi0 among repeat takers. First, those
with low εi0 ’s may choose to quit rather than retake which tends to make E(ε0 |n) positive.
Second, those with high εi0 ’s may choose to be placed rather than retake, which tends to make
E(ε0 |n) negative. The latter source of selection vanishes when students are patient enough while
the former need not.12

4.2

Taking the Model to the Data

Of interest for estimation are equations (1), (2), and (3). To estimate learning, we need to find
a way to obtain unbiased estimates of the α’s and β’s which will let us control for selection into
retaking. This is what we turn to now.
In the model, there are four factors, (θi , εi0 , εinq , εinv ), that affect the various performance
measures. The factor loadings, β q and β v in (2) and (3), respectively, allow θi to have a
differential effect across performance measures. The other three factors, εi0 , εinq , and εinv ,
capture randomness in performance. In order to identify the loadings on ability we rely on the
following standard assumption in the literature on Factor Models.
Assumption 4.1 The factors θi , εi0 , εinq , and εinv are orthogonal to each other and to the
observables.
12

As the astute reader would notice, the selection on the basis of θi operates through the same channels as the
selection on the basis of εi0 . However, these two sources of selection differ when students are below the cutoff so
that even if there is no selection on εi0 , there could be selection on θi .

13

Figure 3 summarizes our estimation strategy, starting with first time takers on the left hand
side of the diagram. In Turkey, practically every high school senior takes the university entrance
exam. For this reason, the sub-sample of first time takers is free of selection. In this sub-sample,
we can estimate the system of performance equations given in the box for first time takers.
Figure 3: Estimation Strategy
nth Time Takers

1st Time Takers
gi

=

Xi α0 + θi + εi0

Xi α1 + βq θi + εi1q

sinq

=

Xi α1 + βq θi + Λinq + εinq

Xi α2 + βv θi + εi1v

sinv

=

Xi α2 + βv θi + Λinv + εinv

gi

=

Xi α0 + θi + εi0

si1q

=

si1v

=

STEP 2:
STEP 1:

α̂0 , α̂1 , α̂2
βˆq , βˆv

rg

=

r sq

=

gi − Xi α̂0 = θi + εi0
sinq − Xi α̂1 = βˆq θi + Λinq + εinq

r sv

=

sinv − Xi α̂2 = βˆv θi + Λinv + εinv

STEP 3:
E(rsq − βˆq rg |Ni = n)

=

E(rsv − βˆv rg |Ni = n)

=



E Λinq − βˆq εi0 |Ni = n ≈ E (Λinqd
|Ni = n)


E Λinv − βˆv εi0 |Ni = n ≈ E (Λinvd
|Ni = n)

STEP 4:
E(Λind
|Ni = n) = ωq E (Λinqd
|Ni = n) + ωv E (Λinvd
|Ni = n)

As there is no learning among first time takers, the correlation between error terms across
the three performance equations is driven by students’ unobservables. This allows us to obtain
α̂0 , α̂1 , α̂2 using ordinary least squares to separately estimate each performance equation in the

14

sample of first time takers.13 Let rg , rsq , and rsv denote the residuals from the three performance
equations. These residuals, given in step 2 in Figure 3, contain both the effect of unobservables
and random shocks to performance.
It can easily be seen that:
E(rg2 ) = E(θ 2 + ε20 ) = σ 2θ + σ 2ε0

(7)

E(rs2q ) = E(β 2q θ2 + ε21q ) = β 2q σ 2θ + σ 2ε1q

(8)

E(rs2v ) = E(β 2v θ2 + ε21v ) = β 2v σ 2θ + σ 2ε1v

(9)

E(rg rsq ) = E[(θ + ε0 )(β q θ + ε1q )] = β q σ 2θ

(10)

E(rg rsv ) = E[(θ + ε0 )(β v θ + ε1v )] = β v σ 2θ

(11)

E(rsq rsv ) = E[(β q θ + ε1q )(β v θ + ε1v )] = β q β v σ 2θ

(12)

Solving this system of equations allows us to identify factors’ variances and loadings nonparametrically.14 Table C.3 in Appendix C reports these estimates from which we only require
β̂ q and β̂ v to measure learning.
With αˆ0 , αˆ1 , αˆ2 , β̂ q , and β̂ v we can then move forward to steps 2, 3 and 4 in Figure 3. In
step 2 we use these estimates to back out θ + εi0 for each agent. This is a noisy estimate of
ability at the individual level. However, given the pattern of selection shown in Sub-Section 4.1,
when agents are patient enough E[θ i + εi0 |Ni = n] yields an upper bound of the effect of θi on
performance for Ni = n, which implies that the estimates we provide are a lower bound of the
learning effect.
In step 3, we use this noisy estimate weighted by βˆj and subtract it from rsj ∀j = {q, v}.
In other words, the difference between the score and the predicted score based on observables
and the noisy estimate of θ will give us our estimate of learning between the first and the nth
attempt. Notice that, since we allowed the learning shocks distribution to depend on Xi , we
13

Full results are shown in Table C.2 in Appendix C.
(12) divided by (11) yields βˆq . The ratio of (10) to βˆq yields σ̂2θ while the ratio of (11) to σ̂ 2θ yields βˆv . The
2
2
difference between (7) and σ̂ 2θ gives us σ̂ 20 . Similarly, the differences between (8) and βˆ σ̂ 2θ and (9) and βˆ σ̂2θ
14

q

yield σ̂ 2ε1q and σ̂2ε1v , respectively.

15

v

can also identify heterogeneous learning effects by conditioning both on Ni and background
variables.
The approach described above will work well if E(εi0 |Ni = n) is small. We carry out
simulations to confirm that the bias coming from selection on εi0 is very close to zero (see SubSection 5.2). Before proceeding to our results, we would like to emphasize that we estimate
cumulative learning for all n but cannot estimate learning between attempts. This comes from
further selection occurring for students who keep retaking.15

5

Results

Table 1 presents the estimated average cumulative learning gains for repeat takers in terms
of their absolute improvement in points. We find that cumulative learning gains on the first
retry are quite similar across tracks and amount to about 5% of the average predicted score on
their first attempt. While in the Science track cumulative learning remains at roughly the same
level across attempts, Social Studies and Turkish-Math exhibit cumulative learning gains that
are increasing in the number of attempts. By the fifth attempt, students from Social Studies
and Turkish-Math tracks record learning gains of up to 14% and 10% of their initial predicted
score, respectively. Moreover, as Figure 4 shows, learning gains are critical for crossing the 120
point threshold in Social Studies and Turkish-Math tracks while they are not that crucial for
the average repeat taker in the Science track.

5.1

Learning, Selection, and Composition Revisited

As explained earlier, the change in the distribution of scores across attempts presented in Figure
1 is driven both by selection and learning within each track. Table 2 decomposes E(sin |Ni =
n) − E(si1 |Ni = 1) into selection due to Xi , θi and learning, to get a better idea of their relative
importance by track.
In the Science track, the first row, labelled E(sin |Ni = n) − E(si1 |Ni = 1), shows that repeat
15
Students are forward-looking and know their future learning shocks, which means that students with higher
Λin s will retake more times. This implies that the difference between cumulative learning in attempts n and
(n + 1) will contain selection into retaking based on learning itself.

16

\
Table 1: E(Λin
|Ni = n) by Track
Attempts
n=2

Science
6.724
(0.233)

Social Studies
6.032
(0.263)

Turkish-Math
5.867
(0.159)

n=3

6.624
(0.341)

10.160
(0.302)

8.980
(0.219)

n=4

7.052
(0.414)
4.893
(0.475)

12.601
(0.354)
15.211
(0.423)

10.073
(0.358)
10.822
(0.574)

n≥5

2nd

3rd
4th
Number of Attempts
E(si1|Ni)

E(si1+Λin|Ni)

(a) Science

5th
s*

150
100

110

Points
120 130

140

150
140
Points
120 130
110
100

100

110

Points
120 130

140

150

Figure 4: Improvement in Gap from s∗ by Track

2nd

3rd
4th
Number of Attempts
E(si1|Ni)

E(si1+Λin|Ni)

(b) Social Studies

5th
s*

2nd

3rd
4th
Number of Attempts
E(si1|Ni)

E(si1+Λin|Ni)

5th
s*

(c) Turkish-Math

takers seem to be doing worse than first time takers on average, i.e., the density in Figure 1
moves backwards. The table shows that this is due to negative selection in terms of Xi and
θi despite the presence of positive learning, which suggests that students from disadvantaged
backgrounds tend to retake more in this track. Moreover, selection in terms of Xi is far more
important than selection in terms of unobservables and its role increases with n.
Among Social Studies students, E(sin |Ni = n) − E(si1 |Ni = 1) > 0 and almost all of
the improvement in scores over attempts is explained by the learning gains accruing to repeat
takers. Selection in terms of θi and Xi is small. This is not surprising given the high proportion
of repeat takers in this track. In the Turkish-Math track the distribution of scores also shifts

17

to the right across attempts, though less so than in Social Studies. However, there are nonnegligible negative selection effects on Xi and θi in this track, which results in learning gains
being larger than the mean score improvement would suggest.
Table 2: Decomposition of E(sin |Ni = n) − E(si1 |Ni = 1) by the contribution of Xi , θ i , and Λin
Number of Attempts
n=2 n=3 n=4 n≥5
Science
E(sin |Ni = n) − E(si1 |Ni = 1)
∆ due to Xi
∆ due to θi
∆ due to Λin

-2.3

-10.8

-15.2

-18.7

-7.0
-1.9
6.7

-12.6
-4.8
6.6

-15.7
-6.5
7.1

-18.1
-5.5
4.9

6.5

12.1

15.4

17.5

-0.3
0.8
6.0

0.8
1.1
10.2

1.2
1.6
12.6

0.6
1.7
15.2

2.8

3.3

3.2

3.4

-2.7
-0.4
5.9

-3.5
-2.2
9.0

-4.6
-2.4
10.1

-5.8
-1.6
10.8

Social Studies
E(sin |Ni = n) − E(si1 |Ni = 1)
∆ due to Xi
∆ due to θi
∆ due to Λin
Turkish-Math
E(sin |Ni = n) − E(si1 |Ni = 1)
∆ due to Xi
∆ due to θi
∆ due to Λin

Note that Table 2 offers clear support to the argument that it is critical to allow for unobservables as we do here. Had we not done so, our results would have been biased, especially in
the Science and Turkish-Math tracks. Given E[θ \
i |Ni = n] < 0 ∀n > 1 in these tracks, correcting
for selection into retaking only on Xi would underestimate learning since leaving selection on θi
out of the picture results in a higher predicted initial score among repeat takers.
Having identified mean learning gains among repeat takers, we ask whether these differ by
background. Figure 5 reports the estimated learning gap between advantaged and disadvantaged
students in each track. The former are defined as applicants in the highest income group (above
500 TL) or those who attended Anatolian or Science high schools. These are the elite high

18

1

2

3
Attempts

4

5

Gap in learning, advantaged − disadvantaged
−6
−4
−2
0
2

Gap in learning, advantaged − disadvantaged
−8
−6
−4
−2
0

Gap in learning, advantaged − disadvantaged
−6
−4
−2
0
2

Figure 5: Learning Gap Between Advantaged and Disadvantaged Students by Track

1

95% confidence interval

(a) Science

2

3
Attempts

4

5

1

2

3
Attempts

4

95% confidence interval

95% confidence interval

(b) Social Studies

(c) Turkish-Math

5

schools in Turkey, which require an admission exam.16 The latter are those in the lowest income
group (below 250 TL) and who graduated from public high schools. Except for a negligible gap
in the sub-sample of second time takers, it is clear that less advantaged students learn much
more than advantaged ones and that this gap increases with the number of attempts, irrespective
of the track. This common pattern across tracks is worth emphasizing.17
In sum, we identify large learning effects and these are particularly prevalent among repeat
takers with less advantaged backgrounds. Thus, retaking may be a way for less prepared students
to catch up before they go to college.

5.2

Simulations

Our estimates of learning in Section 5 are unbiased if E[εi0 |Ni = n], the expected value of
the GPA shock conditional on taking the exam n times, is zero. As we argued in Section
4.1, students with high εi0 accept placement, while those with low εi0 quit so that selection
16

Thus, our definition of “advantaged” students includes those who have access to better educational inputs,
both through higher family income or higher quality education.
17
A concern that the perceptive reader might have is that our results on heterogenous learning are coming from
another form of selection. Namely that the advantaged are more likely to retake than the disadvantaged. This
could occur if they face lower costs of retaking or if their discount factors are higher. As a result, their learning
between retakes could look smaller. To check if this was the case we looked at the probability of retaking and we
found similar retaking rates across groups that were differentially advantaged.

19

truncates the distribution of εi0 among retakers both from above and below. The truncation
from above makes E[εi0 |Ni = n] negative which results in learning effects being overestimated
while truncation from below works in the opposite way. Truncation from above vanishes as
students get more patient. In this section, we use simulations to demonstrate that the bias
coming from ǫi0 tends to be small even when students are impatient.
We set up and simulate a dynamic decision model with the following structure:
1. A student is born with perfect knowledge of his GPA gi , ability θi , and all future learning
shocks Λin .
2. The student takes the entrance exam and learns his εin .
3. If the student’s score is above the placement threshold (120 points), he decides whether to
be placed. Placement is the terminal state; the utility from placement equals (si + ηgi ).
4. If the student is below the threshold or chooses not to be placed, he learns the value of
quitting, V Qin = V Q0 + ξ in , and chooses between quitting and retaking.18 Quitting is the
terminal state. Retaking is costly: (i) all retakers pay ψ n before the next attempt, and
(ii) the value of retaking is discounted at a rate δ.
5. Steps 2–4 are repeated for students who choose to retake.
6. The option to retake disappears after the 10th attempt.19
In our simulations, for simplicity, students do not differ in observables Xi . We simulate GPA
and noise-free scores by independently drawing εi0 , θ i and λin from normal distributions with
parameters given in Table 3. We then substitute these draws into:
gi = E[g\
i |Ni = 1] + θ i + εi0 ,

\
sin = E[s
i1 ] + (ω q β̂ q + ω v β̂ v )θ i +

X

λik

k≤n
18
We need randomness in V Q in order to make the simulated number of retakers smooth in the model’s
parameters. This makes it easier to calibrate the model. The shock ξ in is drawn from the standard normal
distribution.
19
We choose to shut down the option of retaking rather than extending the time periods indefinitely and
assuming stationarity since most people stop retaking after three or four attempts. We do not expect our choice
in this matter to affect our results.

20

\
where E[g\
i |Ni = 1] is the mean GPA among all first time takers. E[si1 ] is the mean exam score
Table 3: Parameter values used in the simulations
Science
E[θ i ]
E[εin ] ∀n ≥ 0
σθ
σ ε0
σ εn ∀n > 0
s∗
η
E[λi2 ]
E[λi3 ]
E[λi4 ]
E[λi5 ]
E[λin ]∀n > 5
σ λin ∀n = 2 . . . 5
σ λin ∀n > 5
V Q0
ψ2, ψ3, ψ4
ψ 5 = · · · = ψ 10

Social TurkishStudies
Math
0
0
7.75
6.32
6.56
5.53
6.74
6.75
8.51
7.91
4.23
120
0.5
6.72
6.03
5.87
-0.10
4.13
3.11
-0.43
2.44
1.09
-2.16
2.61
0.75
0
10
0
0
depend on δ
depend on δ

Source
By construction
By construction
Estimates
Estimates
Estimates
ÖSS Rules
ÖSS Rules
Assumptiona/
Assumption
Assumption
Assumption
Assumption
Assumption
Assumption
Assumption
Calibration
Calibration

a/ E(λ ) are obtained from differences between cumulative effects.
ik

These are not equivalent but we use them as a reference.

for first time takers. To be specific, gi is generated by taking the mean GPA from the data, and
drawing θi and εi0 . The noise-free component of sin , sin , is generated by taking the mean score
among first time takers, and drawing θi and λik ∀k ≤ n. The ability shock is then weighted
using known parameters ω q and ω v and our estimates of β̂ q and β̂ v in each track.
We then solve the dynamic decision problem for each student starting from the 10th attempt.
At this point the student can either be placed or quit. Students who draw high scores are placed
while the remainder quit. The distribution of εi10 gives the probabilities of being placed and
quitting for the last attempt. Working backwards, a similar procedure gives the probabilities of
retaking, being placed, and quitting for every i and n in a given iteration.
In each track, we draw a data set of as many individuals as the number of first time takers in

21

the actual data. Of course, individuals in the simulated data differ only in terms of their random
shocks and unobservables. We then calibrate ψ n and V Q0 to target the number of repeat takers
in each attempt and the total number of quitters in early rounds in the actual data.20 After
calibrating the model, we use it to simulate 1000 artificial data sets and find the median bias
in our estimate of E[Λin |Ni = n] by track and number of attempts. Recall that the bias is
−(ω q β̂ q + ωv β̂ v )E[εi0 |Ni = n]. We repeat this exercise for a range of discount factor values from
0.1 to 1. The 5th, 50th and 95th percentiles of the simulated bias are plotted in Figure 6.
The bias is affected by two forces that work against each other. On the one hand, students
with high εi0 ’s cash them in and get placed. This pushes E[ǫi0 |Ni = n] down and upward biases
our learning estimates. On the other hand, quitting is more likely for students with low ǫi0 ’s.
This raises the average ǫi0 among repeat takers, making the learning bias negative. The former
effect is larger when students are impatient and thus the bias falls as δ rises. As explained
earlier, we expect no bias due to selection on ǫi0 from above when δ is close to one. If this is
true, our learning bias must be non-positive at δ = 1. This is clearly the case in the simulations.
Our simulations suggest the bias does exist, but its magnitude is substantially smaller than
any estimate of learning that we report in Tables 1 and 2. It is also worth noting that for
reasonable levels of patience (i.e., δ > 0.9) the bias in our learning estimates tends to be negative
so that we can think of them as a lower bound.

6

Conclusions and Proposed Agenda

Most people would agree that levelling the playing field in the educational arena is desirable. In
different settings, different approaches are taken with this objective in mind: minority preferences, quotas, remedial classes, scholarships, and so on. Preferential policies may however create
their own difficulties if admitted students fall further behind. Our work suggests that giving
second chances, without lowering standards, in an exam-based system may offer a way to help
the disadvantaged as they seem to learn more over attempts.
20
We choose to match quitting patterns in attempts 1–3 as the terminal period becoming closer creates distortions in the simulated moments.

22

0

.2

.4

δ

.6

.8

1

0

.2

.4

δ

.6

.8

2
−2

−1

Points
0

1

2
−2

−1

Points
0

1

2
1
Points
0
−1
−2

−2

−1

Points
0

1

2

\
Figure 6: Simulated Bias in E(Λin
|Ni = n) by Number of Attempts and Track

1

0

.2

.4

0

.2

.4

.2

.4

δ

.6

.8

1

.6

.8

1

.6

.8

1

0

.2

.4

0

.2

.4

.2

.4

δ

.6

.8

1

.6

.8

1

.6

.8

1

.2

.4

δ

.6

.8

1

0

.2

.4

δ

.6

.8

1

2
−2

−1

Points
0

1

2
−2

−1

Points
0

1

2
1
Points
0
−1
−2

−1
−2
0

δ

δ

0

.2

.4

δ

.6

.8

1

0

.2

.4

δ

.6

.8

2
−2

−1

Points
0
1

2
−2

−1

Points
0
1

2
Points
0
1
−1
−2

−1

Points
0
1

2

(b) Social Studies

−2

23

Points
0

1

2

(a) Science

1

0

Median

90% CI

δ

0

δ

(c) Turkish-Math

(a) n = 2

(b) n = 3

(c) n = 4

(d) n ≥ 5

One of the limitations of our paper is that we do not fully estimate the model outlined
in Section 4. Consequently, we cannot say much about what happens between attempts or
measure the net welfare impact of letting students retake the ÖSS and other counterfactuals.
We are currently working on a dynamic structural model that will allow us to measure marginal
learning as well as to evaluate the effects of different policy interventions such as setting a
maximum number of attempts. A second limitation is the known ability assumption. This is
still an open question that cannot be tackled with a cross-section data set. In this case, panel
data is required to disentangle learning about own ability and learning about the content of the
exam.

24

References
Arcidiacono, Peter, Esteban Aucejo, and Spenner Ken (2012) ‘What Happens After Enrollment?
An Analysis of the Time Path of Racial Differences in GPA and Major Choice.’ IZA Journal
of Labor Economics 5(1), 1–25.
Caner, Asena, and Cagla Okten (2010) ‘Risk and Career Choice: Evidence from Turkey.’ Economics of Education Review 29(6), 1060–1075.
(2013) ‘Higher education in Turkey: Subsidizing the rich or the poor?’ Economics of Education
Review 35, 75–92.
Card, David (2005) ‘Is the New Immigration Really so Bad?’
115(506), F300–F323.

The Economic Journal

Carneiro, Pedro, Karsten Hansen, and James Heckman (2003) ‘Estimating Distributions of
Treatment Effects with an Application to the Returns to Schooling and Measurement of the
Effects of Uncertainty on College.’ NBER Working Papers 9546
Cooley, Jane, Salvador Navarro, and Takahashi Yuya (2011) ‘How the Timing of Grade Retention Affects Outcomes: Identification and Estimation of Time-Varying Treatment Effects.’
Working paper.
Frisancho, Veronica, and Kala Krishna (2012) ‘Affirmative Action in Higher Education in India:
Targeting, Catch Up, and Mismatch.’ NBER Working Paper No. 17727.
Loury, Linda Datcher, and David Garman (1993) ‘Affirmative Action in Higher Education.’
American Economic Review 83(2), 99–103.
(1995) ‘College Selectivity and Earnings.’ Journal of Labor Economics 13(2), 289–308. University of Chicago Press.
Nathan, Julie, and Wayne Camara (1998) ‘Score Change When Retaking the SAT I: Reasoning
Test.’ Research Notes, The College Board, Office of Research and Development.
Portes, Alejandro, and Ruben Rumbaut (2001) Legacies: The Story of the Immigrant Second
Generation (Berkeley: University of California Press.)
Sander, Richard (2004) ‘A Systemic Analysis of Affirmative Action in American Law Schools.’
Stanford Law Review 57(2), 367–483.
Saygin, Perihan (2011) ‘Gender Differences in College Applications: Evidence from the Centralized System in Turkey.’ Working paper.
Tansel, Aysit, and Fatma Bircan (2005) ‘Effect of Private Tutoring on University Entrance
Examination Performance in Turkey.’ IZA Discussion Paper, No. 1609.
Türk Eğitim Derneği (TED or Turkish Educational Association) (2005) ‘Study on the University Placement System in Turkey and Suggestions for Solution.’ http://eua.cu.edu.tr/files/
turkiyeninyuksekogretimstratejisi.pdf. The Council of Higher Education (YÖK).
Vigdor, Jacob L., and Charles T. Clotfelter (2003) ‘Retaking the SAT.’ The Journal of Human
Resources 38(1), 1–33.
25

A

ÖSYM and the Higher Education Placement Process

The ÖSS tests student knowledge in four subjects: Mathematics, Turkish, Science, and Social
Studies.21 Each section of the exam is composed of 45 multiple choice questions which are
worth one point for each correct answer and -0.25 for each incorrect answer. ÖSYM calculates
raw scores in each subject as well as two summary scores: raw verbal (raw Turkish and Social
Studies) and raw quantitative (raw Science and Math). These six raw scores are standardized
with mean 50 and standard deviation 10. These standard scores are then used to construct three
weighted scores:
Weighted-Verbal = (1.8)*(Standard-Verbal) + (0.4)*(Standard-Quantitative),
Weighted-Quantitative = (1.8)*(Standard-Quantitative) + (0.4)*(Standard-Verbal), and
Weighted-Average = (0.8)*(Standard-Turkish + Standard-Math) + (0.3)*(Standard-Science
+ Standard-Social Studies ).
For each weighted score exceeding 105 points, a placement score is calculated for the student:
Placement-Verbal, Placement-Quantitative, and Placement-Average. The placement scores are
constructed by adding the weighted standardized high school GPAs, denoted by “wsGPA”, to
the relevant weighted scores. The wsGPAs are constructed in a way to ensure that students
will choose a field of study compatible with their high school track. As mentioned in Section
3, the available tracks in most high schools are Science, Social Studies, and Turkish-Math. The
relevant scores for each of these tracks are Quantitative, Verbal and Average, respectively.
Calculating the wsGPAs is a complicated process. First, students’ GPAs are standardized
using the GPA distribution in their high school to obtain sGPAs.22 For each student, three
weighted standardized GPAs (wsGPAV , wsGPAQ , and wsGPAA ), one for each weighted score,
are constructed according to the performance of the students’ high school in the relevant score.
Finally, these wsGPAs are added with a weight of 0.5 when the placement score type matches
the student’s high school track and a weight of 0.2 otherwise. For instance, placement scores for
a Science track student are calculated as:
Placement-Verbal = Weighted-Verbal + (0.2)*wsGPAV
Placement-Quantitative = Weighted-Quantitative + (0.5)*wsGPAQ , and
Placement-Average = Weighted-Average + (0.2)*wsGPAA .
Each field of study will assign seats to students on the basis of the relevant placement score.
For instance, a seat in a History program is based on Placement-Verbal score while a seat in
an engineering program is rationed on the basis of Placement-Quantitative scores. Qualified
21

There is also a Foreign Language Test (YDS), administered separately from the ÖSS. However, only students
who are interested in careers that rely on the acquisition of a foreign language have to take this exam. In 2002,
only around 40,000 students took this test. For that reason, we do not take the YDS into account in our analysis.
22
Student i’s sGPA score is obtained in the following way:


GPAi − µ
sGPAi = 10
+ 50
σ
where µ and σ are the mean and standard deviation of raw GPAs in student i’s high school. sGPAs are calculated
the first time a student takes the ÖSS, relative to the students graduating from his high school in that year, and
they are not updated over repeated attempts.

26

students can list up to 18 four-year programs on their preference lists in addition to 6 two-year
programs. Before a student submits his placement preferences, he has access to all his scores,
his percentiles for each score, and the previous year’s minimum and maximum scores for each
university program.

B

Standardized HS GPA versus quality normalized HS GPA

Raw and standardized GPAs ignore potential quality heterogeneity and grade inflation across
high schools. Since we are interested in obtaining a measure that will allow us to rank students
on the same scale based on their high school academic performance, neither of these measures
are useful. Obtaining 10/10 at a very selective school is not the same as obtaining 10/10 at a
very bad school.
To deal with this issue, we constructed school quality normalized GPAs. Within each track
k and for each school j, we define the adjustment factor, Ajk :
Ajk =

GPAjk
GPAk
÷
Weighted Scorejk
Weighted Scorek

(B.1)

where GPAjk and Weighted Scorejk are the average GPA and weighted scores for each high
school and track combination. GPAk and Weighted Scorek are the average GPA and weighted
score across all comparable students from the same track.23 The numerator in (B.1) should go
up if the school is inflating grades relative to its true quality. For example, if the average GPA
in school j is about 8/10 but the average exam score for its students is only 5/10, school j is
worse than the raw GPAs of its students suggest. After all, since the ÖSS is a standardized
exam, Weighted Scorejk should be a good proxy for the true quality of the school on a unique
scale. The denominator in (B.1) is just a constant for all the students in the same database and
it takes the adjustment factor to a scale that is relative to everyone in the same track.
Define the school quality normalized GPA for student i in school j and track k as:
!
] ijk
GPA
GPAnormijk = 100
max
]k
GPA
] ijk is defined as:
where GPA
] ijk =
GPA
max



GPAijk
Ajk



] k is just the maximum GPA
] ijk in a given k. Notice that if the student is in a school
and GPA
that tends to inflate the grades relative to true performance, the raw GPA of all the students in
such a school will be penalized through a higher Ajk .
23

This adjustment factor is constructed using weighted quantitative scores for Science students while Social
Studies students’ factor relies on weighted verbal scores. For Turkish-Math students, we use the weighted average.

27

C

Additional Tables and Figures
Table C.1: Descriptive Statistics

Variable
Individual and Family Background
Gender
Raw HS GPA
Standardized HS GPA
School Type
Public
Private
Anatolian/Science
Other
Father’s education
Primary or less
Middle/High school
2-year higher education
College/Master/PhD
Missing
More than 3 children in the household
Household Monthly Income
<250TL
[250 − 500]TL
>500TL
Preparation for the Exam
Student was working when exam was taken
Prep school/tutoring expenditures
Did not attend Prep school
Scholarship
<1b TL
[1 − 2]b TL
>2b TL
Missing
Exam Performance
Took language exam
Weighted score
Number of attempts
1st attempt
2nd attempt
3rd attempt
4th attempt
5th attempt
Student was placed

Science
Mean
S.D.
0.59
68.19
51.68

15.77
10.01

Social Studies
Mean
S.D.
0.57
57.28
47.66

10.64
7.78

Turkish-Math
Mean
S.D.
0.51
63.16
48.99

0.59
0.18
0.20
0.03

0.86
0.02
0.02
0.09

0.71
0.14
0.11
0.05

0.39
0.30
0.06
0.17
0.08
0.38

0.56
0.28
0.03
0.05
0.08
0.49

0.44
0.33
0.04
0.11
0.09
0.39

0.34
0.40
0.26

0.45
0.38
0.17

0.37
0.40
0.23

0.13

0.21

0.10

0.13
0.04
0.35
0.20
0.10
0.17

0.26
0.01
0.22
0.09
0.03
0.38

0.19
0.01
0.31
0.17
0.08
0.23

0.01
124.02
0.42
0.25
0.16
0.09
0.07
0.36

28

29.99

0.01
113.53
0.25
0.25
0.25
0.16
0.10
0.23

26.61

0.01
113.48
0.46
0.30
0.16
0.06
0.02
0.26

13.41
8.89

20.82

Table C.2: Estimates of [α0 , α1 , α2 ] by Track

Constant
Male
Student was working when exam was taken
School Type (base: Public)
Private
Anatolian/Science
Other
Household Monthly Income (base: <250TL)
[250500]TL

29

>500TL
School Type x HH Monthly Income
Private x [250500]TL
Private x >500TL
Anatolian/Science x [250500]TL
Anatolian/Science x >500TL
Other x [250500]TL
Other x >500TL
Expenditures in dersanes (base: Did not attend)
Scholarship
<1b TL

GPA
49.798
(1.198)
-2.611
(0.160)
-1.798
(0.465)

Science
sq
4.406
(2.240)
6.191
(0.299)
-4.21
(0.871)

sv
14.301
(2.074)
-2.423
(0.276)
-2.309
(0.806)

Social Studies
GPA
sq
sv
52.285
-1.777
27.041
(1.597) (0.564) (2.733)
-3.208
0.067
-1.07
(0.205) (0.072) (0.351)
-1.112
-0.143
-2.875
(0.324) (0.115) (0.555)

Turkish-Math
GPA
sq
sv
53.79
20.762
9.011
(1.111) (1.558) (1.072)
-4.692
-1.631
0.075
(0.153) (0.215) (0.148)
-1.666
-2.473
-1.352
(0.376) (0.528) (0.363)

5.206
(0.401)
11.033
(0.370)
-0.473
(0.672)

13.031
(0.749)
25.206
(0.693)
-1.687
(1.256)

7.143
(0.694)
17.133
(0.641)
2.122
(1.163)

10.187
(1.291)
9.09
(0.757)
0.077
(0.404)

2.499
(0.456)
3.814
(0.268)
0.006
(0.143)

16.639
(2.209)
21.204
(1.295)
-1.133
(0.691)

5.458
(0.409)
7.692
(0.374)
-0.526
(0.493)

13.052
(0.574)
19.487
(0.525)
0.548
(0.692)

7.312
(0.395)
11.284
(0.361)
0.437
(0.476)

-0.437
(0.287)
-1.492
(0.392)

-1.172
(0.538)
-2.106
(0.733)

-0.68
(0.498)
-0.353
(0.679)

-0.676
(0.258)
-1.043
(0.378)

-0.093
(0.091)
-0.624
(0.133)

-0.453
(0.442)
-1.429
(0.646)

-0.649
(0.226)
-1.996
(0.320)

-1.104
(0.317)
-2.617
(0.449)

-0.604
(0.218)
-1.752
(0.309)

-0.214
(0.506)
1.294
(0.571)
1.348
(0.455)
2.627
(0.518)
1.437
(0.932)
2.134
(1.408)

-0.809
(0.946)
-0.977
(1.068)
1.469
(0.850)
2.57
(0.968)
3.81
(1.744)
5.876
(2.634)

1.13
(0.876)
2.771
(0.988)
3.406
(0.787)
3.203
(0.896)
4.174
(1.615)
8.237
(2.438)

1.026
(1.662)
-0.868
(1.561)
2.166
(1.061)
2.085
(1.264)
0.329
(0.604)
-0.09
(0.798)

-0.287
(0.588)
0.042
(0.552)
1.074
(0.375)
5.466
(0.447)
0.149
(0.214)
0.52
(0.282)

-1.006
(2.845)
-3.722
(2.671)
-0.344
(1.816)
-1.128
(2.164)
1.246
(1.035)
1.733
(1.365)

0.873
(0.518)
0.983
(0.559)
1.235
(0.475)
3.39
(0.530)
0.012
(0.774)
1.08
(1.162)

0.859
(0.727)
0.798
(0.785)
1.25
(0.666)
3.581
(0.744)
0.527
(1.086)
0.253
(1.631)

0.006
(0.501)
-0.074
(0.540)
0.656
(0.458)
1.978
(0.512)
-0.138
(0.747)
1.494
(1.122)

28.789
20.657
7.698
(0.822) (0.760)
(1.063)
14.04
4.607
3.335
(0.516) (0.477)
(0.286)
Continues on next page...

2.227
(0.376)
1.021
(0.101)

15.819
(1.819)
10.748
(0.490)

8.182
(0.606)
3.12
(0.217)

15.212
(0.850)
9.209
(0.305)

10.053
(0.585)
4.973
(0.210)

12.367
(0.439)
4.256
(0.276)

[1 − 2]b TL
>2b TL
Missing
Father’s occupation (base: Employer)
Works for wages/salary
Self-employed
Unemployed/not in Labor Force
Mother’s occupation (base: Employer)
Works for wages/salary
Self-employed

30

Unemployed/not in Labor Force
Father’s education (base: Primary or less)
Middle/High school
2-year higher education
College/Master/PhD
Missing
Mother’s education (base: Primary or less)
Middle/High school
2-year higher education
College/Master/PhD

... continued from previous
Science
GPA
sq
sv
2.801
11.842
2.384
(0.314) (0.587) (0.543)
2.887
12.503
3.656
(0.384) (0.719) (0.666)
-0.381
0.735
0.789
(0.334) (0.625) (0.578)

page
Social Studies
GPA
sq
sv
3.157
1.537
12.218
(0.452) (0.160) (0.773)
4.13
4.328
14.227
(0.852) (0.301) (1.459)
-0.386
0.017
-0.74
(0.235) (0.083) (0.402)

Turkish-Math
GPA
sq
sv
3.417
10.871
5.642
(0.274) (0.385) (0.265)
3.666
12.608
6.737
(0.378) (0.531) (0.365)
-0.674
-0.322
-0.318
(0.234) (0.329) (0.226)

1.552
(0.391)
1.332
(0.407)
1.123
(0.467)

3.044
(0.732)
2.823
(0.762)
2.78
(0.873)

2.184
(0.677)
1.907
(0.705)
2.016
(0.808)

1.778
(0.610)
1.711
(0.619)
1.697
(0.655)

0.659
(0.216)
0.608
(0.219)
0.584
(0.231)

2.614
(1.044)
2.585
(1.060)
1.723
(1.121)

0.91
(0.370)
0.891
(0.380)
1.114
(0.432)

1.113
(0.519)
0.851
(0.533)
1.112
(0.606)

0.7
(0.357)
0.431
(0.367)
0.7
(0.417)

2.528
(1.092)
2.649
(1.145)
2.961
(1.077)

2.441
(2.042)
3.108
(2.141)
3.038
(2.015)

2.86
(1.890)
2.286
(1.982)
3.594
(1.865)

1.167
(1.502)
1.531
(1.516)
1.008
(1.469)

1.144
(0.531)
1.483
(0.536)
1.39
(0.519)

0.356
(2.571)
0.116
(2.595)
-0.426
(2.514)

1.345
(1.030)
2.363
(1.068)
2.273
(1.012)

0.282
(1.446)
0.397
(1.499)
1.064
(1.420)

1.494
(0.995)
2.087
(1.032)
1.84
(0.977)

-0.051
(0.215)
0.982
(0.364)
1.829
(0.292)
-0.098
(0.535)

0.198
(0.402)
2.34
(0.680)
4.075
(0.547)
-0.091
(1.001)

0.22
(0.372)
1.317
(0.629)
3.515
(0.506)
-1.114
(0.927)

-0.387
(0.247)
-0.344
(0.677)
1.316
(0.544)
-0.343
(0.580)

0.091
(0.087)
-0.532
(0.239)
0.488
(0.192)
-0.3
(0.205)

0.064
(0.423)
-1.23
(1.159)
2.956
(0.931)
-0.658
(0.993)

-0.143
(0.191)
0.784
(0.399)
1.329
(0.311)
0.392
(0.464)

0.133
(0.268)
0.836
(0.560)
2.462
(0.436)
0.009
(0.652)

0.19
(0.184)
0.312
(0.386)
1.839
(0.300)
-0.586
(0.448)

-1.527
0.024
-1.249
(0.425) (0.394)
(0.336)
0.913
2.396
0.11
(0.842) (0.779)
(1.169)
1.624
3.401
-0.875
(0.777) (0.719)
(1.009)
Continues on next page...

-0.023
(0.119)
2.025
(0.413)
2.715
(0.356)

-0.867
(0.575)
1.462
(2.001)
2.446
(1.726)

-0.468
(0.229)
1.137
(0.549)
1.666
(0.491)

0.57
(0.321)
2.582
(0.771)
3.959
(0.689)

-0.181
(0.221)
1.584
(0.530)
2.136
(0.474)

-0.862
(0.227)
0.725
(0.450)
1.144
(0.415)

Missing
More than 3 children in the household
Internet access (base: No internet access)
At home
Not at home
Missing
Population in Town of HS (base: Over a million)
<10,000
[10, 000 − 50, 000]
[50, 000 − 250, 000]

31

[250, 000 − 1, 000, 000]
Missing
Funds to Pay for College (base: Family funds)
Student’s work
Loan
Other
Observations
R-squared

... continued from previous page
Science
Social Studies
GPA
sq
sv
GPA
sq
sv
0.027
-0.003
1.281
-0.65
0.193
-0.676
(0.583) (1.090) (1.009)
(0.692) (0.245) (1.185)
-0.042
-0.535
-1.543
-0.125
-0.027
-1.331
(0.194) (0.364) (0.337)
(0.213) (0.075) (0.365)

Turkish-Math
GPA
sq
sv
-0.744
-0.075
0.549
(0.526) (0.738) (0.508)
0.358
-0.619
-0.02
(0.173) (0.243) (0.167)

-0.476
(0.249)
-0.009
(0.253)
-1.267
(0.496)

-0.772
(0.466)
-0.793
(0.474)
-2.914
(0.927)

-1.424
(0.431)
-2.945
(0.438)
-4.648
(0.858)

0.437
(0.482)
1.233
(0.468)
0.468
(0.609)

-0.037
(0.170)
-0.164
(0.165)
-0.213
(0.215)

0.576
(0.825)
0.706
(0.801)
-0.831
(1.042)

-0.458
(0.288)
0.389
(0.286)
-0.743
(0.452)

-1.26
(0.404)
-1.143
(0.402)
-3.005
(0.635)

-0.049
(0.278)
-0.249
(0.277)
-0.769
(0.437)

-1.458
(0.389)
-0.66
(0.370)
-0.568
(0.386)
0.362
(0.364)
-1.83
(0.456)

0.857
(0.727)
4.59
(0.693)
4.657
(0.722)
6.82
(0.680)
1.82
(0.853)

-0.962
(0.673)
3.058
(0.641)
3.177
(0.669)
6.566
(0.630)
1.34
(0.789)

-1.135
(0.360)
-1.199
(0.353)
-1.289
(0.392)
-0.578
(0.345)
-1.929
(0.387)

-0.055
(0.127)
0.263
(0.125)
0.212
(0.139)
0.577
(0.122)
-0.081
(0.137)

1.646
(0.617)
2.827
(0.604)
2.62
(0.672)
3.742
(0.591)
0.125
(0.662)

-1.999
(0.323)
-1.93
(0.314)
-1.761
(0.336)
-0.836
(0.310)
-3.501
(0.370)

-0.704
(0.453)
1.746
(0.441)
1.716
(0.471)
3.53
(0.435)
-0.843
(0.519)

-0.516
(0.312)
0.935
(0.303)
0.682
(0.324)
2.446
(0.300)
-0.254
(0.357)

-1.007
(0.216)
0.147
(0.182)
-1.384
(0.360)
15,587
0.369

-1.698
(0.403)
0.867
(0.341)
-1.555
(0.673)
15,587
0.473

-1.246
(0.373)
-0.965
(0.315)
-1.407
(0.623)
15,587
0.366

0.089
(0.249)
0.664
(0.263)
-0.266
(0.388)
9,012
0.166

0.099
(0.088)
0.237
(0.093)
0.143
(0.137)
9,012
0.251

0.103
(0.426)
1.691
(0.450)
0.83
(0.664)
9,012
0.255

-0.132
(0.197)
0.671
(0.183)
-0.389
(0.328)
16,457
0.271

0.515
(0.276)
1.393
(0.256)
-0.087
(0.460)
16,457
0.487

0.561
(0.190)
0.738
(0.176)
-0.024
(0.316)
16,457
0.378

Table C.3: Estimates of Factor Variances and Loadings
Science
1.146
(0.020)

Social Studies
2.056
(0.112)

Turkish-Math
1.028
(0.013)

βˆv

1.938
(0.028)

0.155
(0.008)

1.815
(0.022)

σˆ2θ

60.023
(1.186)

39.883
(2.451)

43.035
(0.936)

σˆ2ǫ0

30.575
(0.970)

45.362
(2.354)

45.619
(0.826)

σˆ2ǫ1q

91.559
(3.140)

9.686
(0.547)

32.685
(1.337)

σ 2ˆǫ1v

192.851
(2.344)
0.844
(0.000)

81.176
(8.839)
0.187
(0.000)

37.157
(0.666)
0.670
(0.000)

0.195
(0.000)
15,587

0.876
(0.000)
9,012

0.293
(0.000)
16,457

βˆq

ω̂ q
ω̂ v
Observations

32

