NBER WORKING PAPER SERIES

PROMISE SCHOLARSHIP PROGRAMS AS PLACE-MAKING POLICY:
EVIDENCE FROM SCHOOL ENROLLMENT AND HOUSING PRICES
Michael LeGower
Randall Walsh
Working Paper 20056
http://www.nber.org/papers/w20056
NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
April 2014

The views expressed herein are those of the authors and do not necessarily reflect the views of the
National Bureau of Economic Research.
NBER working papers are circulated for discussion and comment purposes. They have not been peerreviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.
© 2014 by Michael LeGower and Randall Walsh. All rights reserved. Short sections of text, not to
exceed two paragraphs, may be quoted without explicit permission provided that full credit, including
© notice, is given to the source.

Promise Scholarship Programs as Place-Making Policy: Evidence from School Enrollment
and Housing Prices
Michael LeGower and Randall Walsh
NBER Working Paper No. 20056
April 2014
JEL No. I22,I24,R21,R31
ABSTRACT
Following the example of the Kalamazoo Promise initiated in 2005, place-based "Promise'' scholarship
programs have proliferated over the past 8 years. These programs guarantee money towards the costs
of attendance at selected colleges and universities provided that a student has resided and attended
school within a particular public school district continuously for at least the four years prior to graduation.
While some early programs have been studied in isolation, the impact of such programs in general
is not well understood. In addition, although there is substantial and controversial variation from the
original program's design, there is no direct evidence on how outcomes vary along with these design
choices. We use a difference-in-difference approach to compare the evolution of both school enrollments
and residential real estate prices around the announcement of these programs within the affected Promise
zone and in the surrounding area. Taken together, our estimates suggest that these scholarships have
important distributional effects that bear further examination. In particular, while estimates indicate
that public school enrollments increase in Promise zones relative to their surrounding areas following
Promise announcements, schools associated with merit-based programs experience increases in white
enrollment and decreases in non-white enrollment. Furthermore, housing price effects are larger in
neighborhoods with high quality schools and in the upper half of the housing price distribution, suggesting
higher valuation by high-income households. These patterns lead us to conclude that such scholarships
are primarily affecting the behavior of households living above the median income for whom they
present the greatest value and that merit-based versions disproportionately impact white households.
Michael LeGower
Department of Economics
University of Pittsburgh
Pittsburgh, PA 15260
mjl88@pitt.edu
Randall Walsh
Department of Economics
University of Pittsburgh
4901 WW Posvar Hall
230 S. Bouquet St.
Pittsburgh, PA 15260
and NBER
walshr@pitt.edu

1. Introduction
In late 2005, the Kalamazoo Public School District announced a novel scholarship
program. Generously funded by anonymous donors, the Kalamazoo Promise offers up to
four years of tuition and mandatory fees to all high school graduates from the Kalamazoo
Public Schools, provided that they both resided within the school district boundaries and
attended public school continuously since at least 9th grade. The Kalamazoo Promise is
intended to be a catalyst for development in a flagging region, encouraging human capital
investment and offering incentives for households to remain in or relocate to the area.
In the first eight years of the Kalamazoo Promise, research has documented a number
of encouraging results, including increased public school enrollment, increased academic
achievement, reductions in behavioral issues, and increased rates of post-secondary attendance.1
Encouraged by these early returns, many organizations have implemented similar
programs modeled after the Kalamazoo Promise in urban school districts across the U.S.
Still, most programs do not adhere exactly to the Kalamazoo archetype. Each iteration
of the place-based “Promise” model varies in its features, including the restrictiveness of
eligibility requirements, the list of eligible colleges and universities, and the generosity
of the scholarship award itself. While research has been conducted on the Kalamazoo
program and its impact on various outcomes of interest, this extant work only describes
one particular intervention. As a result, we still know very little about the impact that
such programs have on their communities. With hundreds of millions of dollars being
invested in these human capital development initiatives, understanding their true impact
is an important task for policy research.
This paper broadens the scope of our understanding of Promise programs by evaluating the impact of a broad cross-section of Promise programs on two targeted development
outcomes: K-12 public school enrollment and home prices. In addition to providing the
first estimates of the impacts over a set of multiple Promise programs, we document the
1
See Bartik et al. (2010); Bartik and Lachowska (2012); Miller-Adams and Timmeney (2013); Miron
et al. (2011); Miller (2010); Andrews et al. (2010); Miller-Adams (2009, 2006); Miron and Evergreen
(2008a,b); Miron et al. (2008); Miron and Cullen (2008); Jones et al. (2008); Miron et al. (2009); Tornquist
et al. (2010) for some evaluations of the impact of the Kalamazoo Promise.

2

significant heterogeneity of these effects across different constellations of program features. While the effect of regional policy on both public school populations and housing
markets is of interest itself, including housing markets in the analysis allows us to speak
to the valuation of this program across different groups by examining the variation in
the capitalization effects across different neighborhoods and across the housing price distribution. Such patterns have important implications for the distribution of economic
benefits from Promise programs.
First, we find that, on average, the announcement of a Promise program in a school
district increases total public school enrollment. When analyzed by grade level, announcement leads to immediate increases in enrollment in primary schools (K-4) in particular.
Since it is common in Promise programs to offer escalating benefits for students beginning their continuous enrollment at earlier grade levels, this pattern lends credence to
a causal interpretation of our results. Dividing programs along prominent differences in
design, we find that programs which offer scholarships usable at a wide range of schools
provide the largest immediate boosts in total enrollment. In addition, some features of
Promise programs have significant effects on the composition of affected schools. We
find that merit requirements have differential effects across white and non-white enrollment decisions, leading to large increases in white enrollment and decreases in non-white
enrollment, potentially exacerbating existing racial inequality in educational attainment.
In addition, within 3 years of the announcement of a Promise program residential
properties within selected Promise zones experiences a 7% to 12% increase on average in
housing prices relative to the region immediately surrounding the Promise zone, reflecting
capitalization of the scholarship into housing prices.2 This increase in real estate prices
is primarily due to increases in the upper half of the distribution. These results suggest that the value of Promise scholarship programs is greater for higher-income families
while simultaneously suggesting that the welfare effects across the distribution are ambiguous. While higher-income households seem to place a higher value on access to these
scholarships, they also appear to be paying a higher premium for housing as a result.
Finally, for two Promise programs located in major metropolitan areas— Pittsburgh
2

Housing market data were not available for all Promise program locations. A sample of 8 Promise
programs were utilized in this analysis.

3

and Denver— we observe sufficient housing market transactions over the relevant time
period to analyze the heterogeneity of housing market effects across schools within the
Promise-eligible school districts. After linking housing transactions data to school attendance boundaries, we compare capitalization effects across the distribution of school
quality within each city. Appreciation in housing prices is concentrated in Pittsburgh and
Denver neighborhoods that feed into high quality schools (as measured by state standardized test scores). Since the previous evidence suggests that the increased demand is driven
by high-income households, it is natural that it should be focused on areas with already
high-achieving schools. However, this could have the effect of contributing to further
inequality in educational outcomes if the high-income households attracted by Promise
programs are exclusively attending already high-quality schools.
These results should guide those looking to establish new Promise programs or to
tailor existing Promise programs. While place-based scholarships certainly can impact
regional development, the basic features of the scholarship matter. Allowing students to
use scholarships at a wide range of schools seems to be of first-order importance for total
enrollment, with more flexible scholarships generating larger increases in total enrollment.
The decision to impose merit requirements has important compositional effects on affected
schools, leading to larger relative increases of white students in schools with merit-based
programs. When combined with the distribution of capitalization effects, the evidence
clearly suggests that Promise scholarships are having the largest impact on households in
the middle- and upper-class. It is possible, however, that the change in peer composition
and the increased tax base that result from increased demand amongst high-income, white
households may have significant spillover effects on low-income and minority students in
Promise districts. More research is needed to pin down the relative importance of these
effects.
The following section will describe the relevant literature as well as the general structure of the Promise programs being analyzed, including the dimensions along which they
vary. Section 3 will describe the data and the empirical methodology that will be used
to estimate the impact of the program on public school enrollment and housing prices.
Section 4 will be divided in to three subsections, the first of which will present the results
of the enrollment analysis on the entire sample of Promise programs. The remainder
4

of section 4 will be devoted to housing market analysis, first using a pooled sample of
local housing markets in the second subsection and subsequently focusing on two of the
larger urban areas in the final subsection. Finally, section 5 will discuss the results and
conclude.
2. Background
In addition to their policy ramifications, our findings contribute to two different
strands of literature. First is the already substantial body of work regarding the provision of financial aid. There is a large literature addressing the impact of financial
aid on postsecondary educational attainment.3 Surveying contributions too numerous
to cite individually, Dynarski (2002) reviews the recent quasi-experimental literature on
the topic and concludes that financial aid significantly increases the likelihood that an
individual attends college. Her estimates indicate that lowering the costs of college attendance by $1,000 increases attendance by roughly 4 percentage points. She further
concludes that the distributional implications of aid are ambiguous. Estimates of the
relationship between the impact of aid and income are evenly divided, with half indicating that the impact of aid rises with income. The studies she surveys focus exclusively
on how financial aid affects the college attendance decision and choice of college. While
our contribution will not address this question directly, we nevertheless provide important results on a recent development in the financial aid landscape. In particular, the
implementation of Promise programs may either contribute to or mitigate inequality in
educational attainment across racial groups, depending on the program design. We provide preliminary and indirect evidence that merit-based Promise scholarships in particular
may favor white students in the distribution of benefits. In addition, our capitalization
results suggest that high-income households are willing to pay more for access to Promise
scholarships, although the true incidence of the subsidy remains unclear due to the effects
of housing price capitalization.
The second strand of literature to which we contribute concerns research into placebased policies. Recently reviewed by Gottlieb and Glaeser (2008), these studies focus on
3

See Leslie and Brinkman (1988) for a review of early studies.

5

outcomes such as regional employment, wages, population, and housing markets. The
authors demonstrate significant agglomeration effects on these outcomes, suggesting the
potential for policies aimed at redistributing population across space to have aggregate
welfare implications. The caveat is that if agglomeration elasticity is constant across
locations, redistribution can not have any overall effect. Any place-based policy aiming
to capitalize on agglomeration externalities must rely on nonlinearities in the externality,
otherwise the gains from population increases in one place will simply be offset by the
loss of population in another. Indeed, the research on specific place-based interventions
such as the Appalachian Regional Commission, Enterprise and Empowerment Zones, the
Model Cities program, and urban renewal spending yield primarily negative results. The
authors withhold comment on whether these projects were simply underfunded or such
policies are ineffective in general, but the picture painted is not optimistic for the efficacy
of such programs. Contributing further to this pessimism are Kline and Moretti (2011),
who examine one of the more ambitious place-based policies in U.S. history: the Tennesee
Valley Authority (TVA). The authors show that the TVA led to large, persistent gains in
manufacturing employment which led to welfare gains through long term improvements
manufacturing productivity. However, the productivity gains were exclusively the result
of huge infrastructure investments; the indirect agglomeration effects of the policy were
negligible. The central message is that, while large place-based interventions can bolster
one locality at the expense of another, any gains will evaporate with the termination of
the policy and persistent net welfare gains are rare. We find that place-based Promise
scholarship programs do in fact increase public school populations and housing prices,
which is plausibly explained by the scholarship increasing the willingness to pay for housing in these areas. The existing literature suggests that these effects would evaporate
upon the withdrawal of the scholarship program from the area, unless the Promise intervention is to human capital what a program like the TVA is to physical capital. In
that case, the direct productivity effects of Promise scholarships may have lasting effects,
although the indirect agglomeration effects on productivity are likely to be minimal.
The overlap of financial aid and place-based policy did not begin with the Kalamazoo
Promise, but until recently place-based financial aid had been the domain of state education agencies. The Georgia HOPE scholarship has been in place since 1993, awarding
6

scholarships to Georgia high school graduates who satisfy GPA requirements and enroll at
a Georgia college or university. Like the Kalamazoo Promise, many states used the HOPE
scholarship as a model when introducing statewide merit-based scholarships of their own.
Several studies have thoroughly examined the impact of the HOPE scholarship program
on outcomes such as student performance in high school (Henry and Rubenstein, 2002),
college enrollment (Dynarski, 2000; Cornwell et al., 2006), college persistence (Henry et
al., 2004), and degree completion (Dynarski, 2008). To summarize the findings, the HOPE
scholarship has led to overall improvements in K-12 education in Georgia as well as reductions in racial disparities. In addition, college enrollments increased among middle- and
high-income students, but income inequality in college enrollments widened and college
persistence was not necessarily increased. While evaluating place-based policies, it is notable that most of the research on these programs has focused on the outcomes typically
associated with the financial aid literature— i.e. impact on college attendance, degree
completion, and the impact of merit scholarships on educational inequality. Because of
the statewide nature of these programs, outcomes on a smaller spatial scale that would
interest place-based policy researchers— i.e. impact on regional development outcomes,
population, public school enrollments, and housing markets— have been largely ignored.
The unexpected introduction of place-based Promise scholarship programs in school
districts across the U.S. provides a series of natural experiments similar to those provided
by statewide scholarships. However, the smaller geographic scale allows us to study
local outcomes for the first time, using the immediate geographic vicinity of a Promise
school district as a plausible counterfactual. With an ever-expanding sample of Promise
programs implemented at different times in different regions, we can now assess the
impact of providing place-based scholarships on a number of relevant but hitherto ignored
outcomes, as well as how these impacts vary with the design of the program.
2.1. Promise Scholarship Programs
According to the W.E. Upjohn Institute for Employment Research, a Promise-type
scholarship program is a “universal or near-universal, place-based scholarship program.”
Upjohn has identified a list of 23 such programs (plus the Kalamazoo Promise itself).
These programs are listed in Table 1 along with some other details of the programs

7

themselves.4,5
[Table 1 about here]
In practice, the place-based nature of these scholarships is dictated by the requirement that a student maintain continuous enrollment in a particular school district (or
other small collection of schools) for several years prior to graduation to receive any benefit.6 Although the continuous enrollment requirement alone constitutes a restriction on
residential location for most U.S. households, many programs pair this with an explicit
requirement for continuous residence in the district itself.
Although the Kalamazoo Promise was universal within its Promise zone as can be seen
in Table 1, many Promise programs have other eligibility requirements. Minimum GPA
requirements, minimum attendance requirements, and community service requirements
are common. Previous work has called attention to the variation in eligibility requirements as an important element in program design, but to date no research has empirically
investigated the impact of universal vs. merit-based eligibility on program effectiveness
in the context of Promise programs. Miller-Adams (2011) documents the successes of the
Kalamazoo Program and attributes some results to its universal eligibility. In particular,
the Kalamazoo Pubilc Schools experienced increases in enrollment without significant
changes in the ethnic, racial, or socioeconomic composition of its schools. This pattern
is attributed to the universality of the Kalamazoo Promise. Without an accompanying
analysis of near-universal programs, however, it is unclear whether similar results could
be obtained from very different interventions. In addition, some districts’ goals may include modifying the demographic composition of area schools. For example, Schwartz
(2010) indicates that relocating disadvantaged children to low-poverty schools has large
and lasting effects on their educational achievement. The analysis to date provides dis4

The majority of the list of Promise-type scholarship programs was obtained from http://www.
upjohninst.org/Research/SpecialTopics/KalamazooPromise. Further research revealed an additional Promise program in Buffalo, NY, which has been added to the list. All other information is
based on a review of each program’s website.
5
Of the programs detailed in Table 1, a number are excluded for data availability or other reasons.
Of particular interest is the intervention located in Detroit, MI which is excluded from the analysis
because the preciptous decline of Detroit in the years surrounding the Promise is likely to overshadow
the relatively insignificant intervention, as discussed in detail in the following section.
6
While not always defined in terms of school districts, we will use the terms “Promise district”,
“Promise area”, and “Promise zone” interchangeably to refer to the geographical boundaries of a Promise
program.

8

tricts looking to capitalize on such effects with no guidance regarding what program
design choices best suit their goals.
Bangs et al. (2011) review existing research on the effects of merit and universal placebased scholarship programs on K-12 enrollment, student achievement, college attainment,
and inequality. Relative to merit aid, the universal scholarships they study are more effective at increasing school district enrollment and reducing poverty and racial disparities in
educational attainment. However, the authors include only the Kalamazoo Promise and
the Pittsburgh Promise from the class of Promise programs. In addition, direct evidence
of the impact of the Pittsburgh Promise is scant; most comparisons are made between
Kalamazoo and statewide programs such as the Georgia HOPE scholarship. Using data
from over 20 Promise-type programs announced to date, many of which include a merit
eligibility requirement, we present direct evidence on the contrast between merit-based
and universal programs, specifically in the context of place-based Promise scholarship
programs.
Eligibility requirements are scarcely the only source of heterogeneity in program design; the scholarship award itself varies across programs. By way of example, the maximum award for the Jackson Legacy scholarship is $600 per year for two years, whereas
the Pittsburgh Promise recently increased their maximum scholarship award from $5,000
to $10,000 per year for up to four years. The maximum scholarship duration varies
as well from one year (Ventura College Promise) to five years (El Dorado Promise and
Denver Scholarship Foundation). However, the exact degree of variation in benefits is
obfuscated by two common features of Promise scholarships. First, scholarships are often
stated in percentage terms of tuition, which makes the value dependent on the choice of
postsecondary institution. Second, many Promise programs award benefits on a sliding
scale based on the grade at which the student first enrolled in a Promise zone school. As
an example of both, the Kalamazoo Promise benefit ranges from 65% (enrolled grades
9-12) to 100% (enrolled grades K-12) of tuition and mandatory fees at a Michigan public
college or university. As a result, the expected benefit of a Promise scholarship varies
across locations in a way that is difficult to quantify, but is nevertheless significant.
The last major feature we will address the list of colleges and universities towards
which the scholarship applies. Most programs require enrollment at an accredited post9

secondary institution located within the same state as the Promise zone. Some limit that
further to public institutions, while many scholarships are only usable at a short list of
local colleges. This aspect of the program has a substantial impact on both the value
of the scholarship in absolute terms and the distribution of its benefits across groups.
For instance, some programs have flexible scholarships that allow use at a large list of
institutions including trade schools as well as nationally-ranked four-year universities.
Naturally, scholarships that allow use at more expensive schools are potentially more
valuable to their recipients. In addition, the variation in price points and selectivity
within the list of eligible schools makes the scholarship valuable to both low-income and
high-income households alike. Programs with inflexible scholarships typically allow use
only at local junior and community colleges. This restriction not only caps the benefit
of the scholarship to full tuition at one particular school, but also presents less value to
high-income graduates focused on four-year programs.
As the oldest program in its class, a considerable amount of research has evaluated
the impact of the Kalamazoo Promise on the outcomes of students in the Kalamazoo
Public School District.7 A series of working papers from Western Michigan University’s
Department of Education outline the mechanism for community development in principle,
with the Promise generating increased attendance in secondary school leading to better
classroom performance and graduation rates and ultimately increased college attendance
in the region. Their research to date culminated in Miron et al. (2011) which presents
quantitative and qualitative evidence documenting a significant improvement in school
climate following the announcement of the Promise.8 In addition, the W.E. Upjohn
Institute for Employment Research has taken a leading role in research surrounding the
Kalamazoo Promise. Researchers there have determined that the Kalamazoo Promise has
successfully increased enrollment (Hershbein, 2013; Bartik et al., 2010), improved academic achievement (Bartik and Lachowska, 2012), and increased college attendance in
7

We have found sources that indicate Pinal County’s “Promise for the Future” program started as
early as 2001. It is perhaps more accurate to say that the Kalamazoo Promise is the oldest widelyrecognized program in this class.
8
See Miron and Evergreen (2008a), Miron and Evergreen (2008b), Miron et al. (2008), Miron and
Cullen (2008), Jones et al. (2008), Miron et al. (2009), and Tornquist et al. (2010) for more evidence
from their evaluation of the Kalamazoo Promise program.

10

certain groups (Miller-Adams and Timmeney, 2013). Finally, Miller (2010) confirms the
documented positive effects on public school enrollment, achievement, and behavioral issues. She also adds a preliminary analysis of home values, finding that the announcement
of the Promise had no impact on home prices in Kalamazoo relative to the surrounding
area.
Apart from these studies of the Kalamazoo Promise, however, little research has
been conducted on Promise programs in order to generalize the findings. Gonzalez et al.
(2011) study the early progress of Pittsburgh’s Promise program and find that it stabilized
the previously declining public school enrollment in the Pittsburgh public schools. The
study also presents survey-based and qualitative evidence that the Pittsburgh Promise’s
merit-based eligibility requirements motivate students to achieve and that the Promise
was influential in the decisions of many parents to move their children to city public
schools. Additionally, some programs’ websites present internal research intended to
promote the program’s progress. Importantly, all studies to date have been limited in
scope to an individual Promise location. Also, with the exception of some work regarding
Kalamazoo, the research has been primarily qualitative or descriptive in nature. In the
remainder of the paper, we will present the first research which utilizes data from a
broad array of Promise-type programs. We present direct evidence on the effectiveness of
Promise scholarships in increasing public school enrollments, as well as document patterns
in enrollment across different programs which are clearly related to program details such
as eligibility requirements and award amounts. In addition, we present the first analysis
confirming the influence of Promise scholarship programs on property values, the results
of which also have interesting implications for future program design.
3. Data and Methodology
Our estimation strategy for measuring the impact of the Promise hinges on treating
the announcement of a Promise program in a region as a natural experiment, relying
on the assumption that the announcement in each area was unexpected. To justify this
assumption, we conducted substantial research into the timing of program announcements
in each area that we study. The date of the announcement that we use in our analysis
corresponds to the earliest mention we could find of the program’s existence. Typically,
11

this corresponds to the date of a press release announcing the program. In cases where
press releases were unavailable, we used the Internet Archive at http://www.archive.
org to find the earliest iteration of the program’s own home page, using the archival
date as the announcement date. We were able to determine the approximate date of
announcement for 22 of the 25 known programs in Table 1; the remaining 3 were excluded
from the analysis.9 It is likely that some of our announcement dates will be subject to
measurement error. This problem is mitigated somewhat in the public school analysis,
as enrollment data evaluated on an annual basis. In addition, any bias resulting from
measurement error should serve to attenuate our estimates of the true effect of these
programs.
In addition to those programs mentioned above, the Detroit College Promise was
also excluded from the analysis. The reasons for this exclusion are two-fold. First, the
intervention in Detroit was very small. The maximum scholarship attainable under the
Detroit Promise is $500 per year, and that only for the initial two cohorts of graduates
from a particular high school; most other students are entitled to a maximum award of
$500 total.10 This small award is due to the lack of sponsorship for the Detroit Promise;
as of June 13, 2013, there was only one donor to the Detroit Promise that contributed
over $50,000. Contrasted with the 35 such donors to the Pittsburgh Promise, it is obvious
why the Detroit Promise is not capable of offering larger scholarships to its graduates.
Second, we believe the precipitous decline of a city on the verge of bankruptcy is likely to
overshadow any small positive impact on house prices that may have been generated by
the Detroit Promise. In the year following the announcement of the Detroit Promise, two
of the so-called “Big 3” automakers based in and around Detroit filed for bankruptcy,
followed by the city itself filing for bankruptcy in 2013. From 2000 to 2010, Detroit
experienced a 25% decline in population— the largest percentage decrease in population
for a U.S. city aside from the exodus out of New Orleans after Hurricane Katrina in 2005.
Because of these non-Promise related factors, we believe Detroit to be non-representative
9

The excluded programs were the Educate and Grow Scholarship (Blountville, TN), the Muskegon
Opportunity Scholarship (Muskegon, MI), and School Counts! (Hopkins County, KY).
10
The exception to this is the graduating class of 2013, who it was recently announced will receive
$600 scholarships from the Detroit Promise.

12

of the typical Promise program and we exclude it from all results below.
There are two main outcomes that we will be interested in studying in relation to
Promise Scholarship programs: K-12 public school enrollments and housing prices. Naturally, identifying and estimating the impact of the Promise presents a unique set of
empirical challenges for each outcome of interest. We will first present a description of
the data and empirical strategy used to analyze the impact of Promise programs on K-12
enrollment, followed by a similar section devoted to the data and methodological concerns
related to our housing market analysis.
3.1. Public School Enrollment
Our data source for public school enrollments is the National Center for Education
Statistics’ Common Core of Data (CCD). The CCD surveys the universe of public schools
in the United States every year. Among the data collected in the survey are the names and
locations of all schools, the operational status code as of the survey year, the instructional
level of the school (primary, middle, high), student enrollment counts by grade and by
race/ethnicity, and staff counts. As all Promise programs were announced after the year
2000, we retrieved CCD records dating from the 1999-2000 survey year up to the most
recently available 2010-2011 survey year.11 This yielded a total of 1.2 million school-year
observations. This data was then combined with information on which schools’ students
were eligible for Promise scholarships and the year the programs were announced.
Ultimately, the goal is to estimate the change in enrollments resulting from the announcement of the 21 Promise programs observed. For causal inference, however, it is not
sufficient to compare student counts in Promise districts prior to the announcement with
student counts after the announcement. We require an appropriate counterfactual to
account for the possibility that similar (or proximate) schools unaffected by the Promise
may have also experienced increases or decreases in enrollment as a result of some unobserved common shock. The interpretation of an increase in Promise school enrollment
11

Five programs— Say Yes Buffalo (Buffalo, NY), the Sparkman Promise (Sparkman, AR), the
Arkadelphia Promise (Arkadelphia, AR), the New Haven Promise (New Haven, CT), and the Great
River Promise (Phillips and Arkansas Counties, AR)— were announced recently enough that no postannouncement data is yet available. However, the pre-announcement data for these Promise Zones and
their surrounding areas is included in our analysis to help estimate nuisance parameters more precisely.
Importantly, the exclusion of these observations does not qualitatively change our estimates.

13

counts changes substantially if similar but unaffected schools experienced increases just
as large, for example. As such, we use a difference-in-differences approach to identify the
causal impact of Promise program announcement. We estimate variations of the following
fixed-effects regression
Yit = α + βP ostit · P romisei + X0it · γ + ηit + δi + εit ,

(1)

where Yit is the natural log of enrollment in school i in year t, P ostit is an indicator for
surveys occurring after the announcement of the Promise program relevant to school i,
P romisei is an indicator for schools located in Promise zones, Xit is a vector of characteristics school i in year t, ηit is a vector of region-by-year and urbanicity-by-year fixed
effects, and δi are school fixed effects. Standard errors in all specifications are clustered
at the school level to allow for correlation in εit within schools over time.
In addition, some results will be presented that modify equation 1 as follows
Yit = α +

X

X

βJK P ostit · Ji · Ki + X0it · γ + ηit + δi + εit

(2)

J∈{M,N M } K∈{W,N W }

yielding four coefficients— βM W , βN M W , βM N W , and βN M N W — where Mi indicates a
Promise program with a merit-based eligibility requirement, N Mi indicates a universal Promise program, Wi indicates a Promise program with a broad (more than three)
list of eligible postsecondary institutions, and N Wi indicates a Promise program with a
narrow (no more than three) list of eligible postsecondary institutions. This specification
allows us to answer questions regarding how the impact of Promise programs varies along
prominent design dimensions.
The coefficients of interest in the above equation estimate the impact of Promise
announcement on school outcomes— or average treatment effect— provided that the
chosen control schools act as an appropriate counterfactual for the evolution of K-12
enrollment in the absence of treatment. Our estimation strategy will use geographically
proximate schools as our control group for schools located in Promise zones. As a result,
we limit our attention to schools that were located in the county or counties surrounding
the treated schools. The intuition for this control group is that schools in the same county
or neighboring counties will be affected by the same regional shocks to K-12 enrollment

14

as their treated counterparts, such as broad regional migration or demographic patterns.
In addition, we only include surveys conducted within 4 years of the announcement date
of the Promise program relevant to the school in question. Finally, we only include
observations from schools which reported total student counts and student counts by
race/ethnicity in every available survey within the estimation window.12 This restriction
results in our baseline estimation sample of 47,600 school-year observations across 74 U.S.
counties and 947 school districts. Table 2 presents the summary statistics for the sample
of treated and untreated schools across all years in the sample.
[Table 2 about here]
The schools initiating Promise scholarship programs are statistically different from
those in the geographically proximate control group. Schools in Promise zones have fewer
students overall and fewer white students as a fraction of the total students (although
this difference, while statistically significant, is very small). In addition, the Promise
schools are much more likely to be located in urban areas, naturally making the nearby
schools in the control group much more likely to be in suburban areas. Differences in the
distribution of schools across levels are very similar, although the more urban Promise
districts tend to have fewer schools designated as middle schools in the CCD.
Bear in mind, our empirical strategy does not explicitly rely on Promise schools being
similar to comparison schools. Provided that Promise schools and non-Promise schools
are not becoming more or less dissimilar over the period prior to the Promise announcement, our estimates should identify the causal impact of the Promise announcement.
Specifically, identification of the causal effect of the Promise announcement requires that
the outcomes of interest would follow parallel trends (conditional on observable covariates) in the absence of any intervention, such that any difference in the period following
announcement can be attributed to the treatment itself. Importantly, this assumption
can not be explicitly tested as we do not observe the true counterfactual. In the next
section, however, we will present graphical evidence in support of this assumption. Specifically, we will demonstrate that the evolution of enrollment in the periods immediately
prior to Promise announcement was similar between Promise zone schools and control
12

Relaxing this restriction only slightly changes the estimated coefficients.

15

schools. This requirement also implicitly assumes that no other major changes are occurring in one group and not the other at approximately the same time as the treatment
is occurring. While we can not rule this out, due to the time variation in the announcements of the geographically diverse set of programs it is unlikely that any shock other
than the Promise program announcement would have occurred in all Promise zones at
the time of announcements, especially a shock that would differentially impact Promise
zones relative to their immediate surroundings.
3.2. Housing Prices
Our housing price data comes primarily from DataQuick Information Systems, under a license agreement with the vendor. These data contain transactions histories and
characteristics for properties in a large number of U.S. counties. Included in the data
collected are sales of newly constructed homes, re-sales, mortgage refinances and other
equity transactions, timeshare sales, and subdivision sales. The transaction related data
includes the date of the transfer, nominal price of the sale, and whether or not the transaction was arms-length. In addition, every building in the data has characteristics as
recorded from the property’s most recent tax assessment. These variables include floor
area, year built, number of bedrooms, number of bathrooms, and lot size.13 Finally, the
latitude and longitude of each property is also included.
The location of the property is crucial to the analysis. Locating the property within
a Census tract allows us to combine property characteristics with neighborhood demographic data from the U.S. Census and also allows us to control for unobserved neighborhood characteristics through the use of fixed effects. We require a fixed geographical
definition of a neighborhood for the latter, but Census tract definitions change over time.
Fortunately, the Longitudinal Tract Database (LTDB) has developed tools to estimate
any tract-level data from the 1970 onward for 2010 Census tract definitions. So, properties
were allocated to 2010 Census tracts and historical neighborhood demographic data was
13

Note that not all variables are reliably recorded across all jurisdictions. Most jurisdictions reliably
record floor area and year built, but other details are often unreliably encoded (i.e. missing values,
unrealistic quantities, no variation in codes, etc.). As a result, any analysis that pools data from all
markets only includes floor area (in square feet) and a quartic in building age in specifications where
structural characteristics are included. These characteristics were the only variables that were reliably
recorded across all jurisdictions studied.

16

estimated based on these tools, interpolating between years when necessary. These demographic data include median income, racial composition, age distribution, educational
attainment, unemployment rates, fraction in poverty, fraction of family households, and
private school attendance. Also, geographical data allows us to match properties to
school districts, counties, or Census places using U.S. Census TIGER files. As Promise
eligibility is ultimately determined by location within these boundaries, this is crucial for
determining which properties are eligible to receive Promise scholarships.
Unfortunately, not all counties that are home to Promise programs are covered by
DataQuick. As a result, the housing market analysis necessarily focuses on a subset of
eight Promise zones due to data limitations.14
As with demand for public schools, there is reason to believe that the announcement of
a Promise program will increase demand for housing within the Promise zone. However,
unlike with K-12 enrollment data, housing market data gives us an indication of the value
of the announcement of the Promise to households. Since we observe the transaction price
associated with the residential location decision, we can draw inference on the household’s
willingness to pay for access to the program. Assuming that housing supply is fixed in the
short-run, any increase in the average household’s willingness to pay must be capitalized
into prices. As a result, by identifying the change in housing prices attributable to
the announcement of a Promise program, we will recover the capitalization of program
announcement into housing prices, providing a signal of the average household’s marginal
willingness to pay for access to the program.15
14

For only six of these does the data originate from DataQuick. For two Promise programs— Say
Yes Syracuse (Onondaga County, NY) and the Kalamazoo Promise (Kalamazoo County, MI)— real
estate transaction and assessment data was pulled from public records on the internet. For Onondaga
County, parcel information and transaction histories were obtained from the Office of Real Property
Services (ORPS) websites at http://ocfintax.ongov.net/Imate/search.aspx (for Onondaga County)
and http://ocfintax.ongov.net/ImateSyr/search.aspx (for City of Syracuse). For Kalamazoo and
neighboring Van Buren county, parcel information and transaction histories for each property were
gathered from the BS&A Software portal for Kalamazoo and Van Buren Counties at https://is.
bsasoftware.com/bsa.is/. In terms of the scope of content, the data acquired in this way is comparable
to those supplied by DataQuick.
15
Kuminoff and Pope (2009) demonstrate that capitalization is equivalent to marginal willingness to
pay only if the hedonic price function is constant over time and with respect to the shock being analyzed
or if the shock is uncorrelated with remaining housing attributes. Neither condition is likely to be
satisfied here and consequently our estimates are not directly interpretable as marginal willingness to
pay. However, we present results that identify capitalization from repeat sales data which has been
shown in Monte Carlo experiments to drastically reduce so-called “capitalization bias” over pooled OLS

17

In practice, however, identifying the causal impact of a change in a local amenity like
access to a Promise scholarship is not trivial. In this paper, we use the hedonic method to
model a property’s price.16 In general, the hedonic method expresses the transaction price
of a property as a function of the characteristics of that property. The implicit price of
a characteristic is then recovered by estimating the hedonic price function via regression.
In addition, Parmeter and Pope (2009) demonstrate how combining this technique with
quasi-experimental methods allows the researcher to exploit temporal as well as crosssectional variation in amenity levels. Recent studies have used quasi-experimental hedonic
methods to recover the value of school quality (Black, 1999; Barrow and Rouse, 2004;
Figlio and Lucas, 2004), air quality (Chay and Greenstone, 2005), airport noise (Pope,
2008a), toxic releases (Bui and Mayer, 2003; Gayer et al., 2000), flood risk reduction
(Hallstrom and Smith, 2005; Pope, 2008b), crime reduction (Linden and Rockoff, 2008;
Pope, 2008c), and mortgage foreclosures (Cui and Walsh, 2013). We adopt this technique
as well in our estimation of the causal impact of Promise programs on housing prices.
As above, our estimation strategy will employ a difference-in-differences approach to
identify the causal impact of Promise program announcement, which is fairly standard
in the quasi-experimental hedonic valuation literature. Our baseline estimating equation
is written as follows:
P riceimdt = α + βP ostmt · P romised + X0it · γ + ηmt + δd + εimdt ,

(3)

where P riceimdt is the natural log of the transaction price for property i in market m
and school district d at time t, P ostmt is an indicator for transactions occurring after
the announcement of the Promise program relevant to housing market d, P romised is
an indicator for properties located in Promise zones, Xit is a vector of building and
neighborhood characteristics of property i at time t, ηmt are market-by-year-by-quarter
fixed effects, and δd are school district fixed effects. Market-by-year-by-quarter fixed
effects account for regional shocks in housing prices in a given period, while district
fixed effects control for static differences between neighborhoods over time. We also
(Kuminoff et al., 2010).
16
For a thorough review of the hedonic method, Bartik and Smith (1987), Taylor (2003), and Palmquist
(2005).

18

estimate variations on the above equation, where school district fixed effects are replaced
by 2010 Census tract fixed effects and, finally, property fixed effects. The property fixed
effects specifications yield our preferred estimates of the treatment effect, identifying the
impact of treatment from repeat sales only and thus controlling for any time-invariant
unobservables associated with an individual property. Standard errors in property fixed
effects regressions are clustered at the property level to allow for correlation in εimdt for
the same property over time; all other specifications cluster standard errors at the 2010
census tract level. Again, β identifies the impact of Promise announcement on housing
prices provided that the prices of control properties would have evolved similarly over
time in the absence of treatment.
For several reasons, we expect that the value of most Promise programs may increase
with household income. Light and Strayer (2000) find that family income and mother’s
education level increase both the likelihood of college attendance as well as the selectivity
of the chosen school, thus making the Promise scholarship more valuable to higher-income,
higher-educated households. In addition, many Promise scholarships are “middle-dollar”
or “last-dollar” aid, ultimately applied towards unmet need at your institution of choice
after the application of federal, state, and institutional aid. Importantly, while Promise
aid is typically not need-based, these other sources of aid are typically dependent on the
expected family contribution (EFC) as calculated by the household’s Free Application for
Federal Student Aid (FAFSA) form, with lower income families expected to contribute
less than higher income families. As a result, for an identical institution, higher income
families are likely to receive less aid than lower income families from these other sources,
leaving a larger amount of unmet need. For these reasons, the value of the Promise
should be greatest for families with higher incomes. As it is reasonable to expect these
higher income families to occupy higher priced domiciles, we would like to test this
hypothesis by allowing the treatment effect to vary across the housing price distribution.
As such, we perform a two-step procedure that first defines where properties lie on the
pre-Promise distribution of housing prices— even for properties sold after the Promise—
and subsequently estimates treatment effects both above and below the median of said
distribution via OLS.
The first step is accomplished by restricting attention to the pre-Promise period in
19

each housing market and estimating a standard hedonic price function which includes
all observable property-specific characteristics, i.e. structural and neighborhood features,
and controls flexibly for time through quarterly fixed effects. The coefficient estimates
from this regression are then used to predict the sale price of each property observed
in the sample— including those sold after Promise announcement— as if it had been
sold in the first quarter of the year prior to the announcement. The resulting number
provides a measure of the component of housing value that is unaffected by the treatment
by construction. All transactions are then sorted on this statistic and grouped into
observations above and below the median. This exercise tells us where a property would
have fallen in the housing price distribution for that particular housing market if the
transaction had taken place prior to the announcement of the Promise.17
The second step simply repeats the DD analysis specified in equation 3, but separately
for properties above and below the median of the distribution generated by the first step.
Each β then estimates the treatment effect of the Promise announcement within each
half of the housing price distribution.
It is worthwhile to briefly discuss the functional form assumption implicit in equation
3. The semi-log functional form, with the natural log of price as the dependent variable, is
fairly standard in the hedonic literature and has been justified by Monte Carlo simulations
performed initially by Cropper et al. (1988) and more recently by Kuminoff et al. (2010).
However, we will also present estimates using a fully linear functional form with deflated
transactions prices as the dependent variable. As all Promise scholarships are per-student
subsidies and not a per-housing-unit subsidies, there is reason to suspect that the causal
effect of the program is better interpreted in levels and not logs. For example, consider
two identical families each with one child, one moving into a 2 bedroom house and one
moving into a 10 bedroom house in the same neighborhood in a Promise zone. Both
families will be willing to pay more for the house after the announcement of the Promise
as their child will receive the scholarship with some positive probability. Yet, the expected
17

As discussed below, in some specifications the estimation sample will be restricted either geographically or as a function of observable characteristics. A property’s rank in this distribution is based on
the widest definition of the housing market and will not depend on the estimation sample. As a result,
the above and below median sample will not necessarily contain an equal number of observations when
estimation samples are restricted in this way.

20

value of the benefit is the same even though the 10 bedroom house is undoubtedly priced
higher than the 2 bedroom house. As such, we would not expect both families to be
willing to pay the same percentage premium after the announcement of the Promise,
which is what would be captured by a DD estimate in logs.
Another important consideration in any hedonic model is the spatial definition of the
relevant housing market. The trade-off between using a large geographic housing market
and a small geographic housing market is one between internal validity of the estimates
and the precision with which they are estimated (Parmeter and Pope, 2009). As such,
we take a flexible approach by estimating our equation on a number of different samples,
each representing a different housing market definition.
After determining the geographic extent of each of the eight Promise programs, two
estimation samples were constructed: one representing a relatively large housing market
definition and one representing a small housing market definition. The large housing
market is constructed by including all transactions within Promise zones as well as all
transactions occurring within 10 miles of the geographic boundary of the Promise zone.
The small sample is constructed by only using transactions within a 1 mile bandwidth
along both sides of the Promise zone boundary. Figure 1 depicts an example, using the
housing markets constructed around the Pittsburgh Promise treatment area.
[Figure 1 about here]
The large sample affords us many observations of market transactions and thus provides precise estimates. However, the concern in a large sample is that the estimate of the
treatment effect will be biased if either the scholarship is not relevant to households in
the periphery of the sample or they are simply unaware of the program. The small housing sample mitigates this bias by constructing a sample over which we can be relatively
sure that all households will be informed of the scholarship and consider it relevant. The
variance of the estimate, however, increases due to the smaller number of observations
from which to draw inference. The goal in estimating our hedonic model on both samples
is to evaluate the sensitivity of the measured treatment effect to the choice of housing
market definition.
In addition to the two geographically defined markets, we also construct a housing
market that, while bounded geographically, is defined in statistical terms. Even in the
21

small housing markets defined above, it is possible that properties on either side of the
treatment boundary can vary significantly and discontinuously in terms of observable
characteristics, calling into question their use as a counterfactual for houses within the
treatment area. By means of example, figure 2 depicts the Promise zone in New Haven,
CT (outlined in red) along with its corresponding large housing market (outlined in
black). The area is subdivided into census tracts and color coded by racial composition
according to the 2000 U.S. Census. As can plainly be seen, neighborhoods vary considerably across the border defining the Promise zone. While this difference in observables
can be controlled for econometrically, it raises the question of variation in unobservables
and, more importantly, the validity of the parallel trends assumption required for causal
interpretation of DD estimates.
[Figure 2 about here]
In econometric terms, our concern is with limited overlap in observables between
treatment and control groups which can cause “substantial bias, large variances, as well
as considerable sensitivity to the exact specification of the treatment effect regression
functions.” (Crump et al., 2009). As such, we would like to define a sample that reduces these concerns by trimming some observations in the non-overlapping region of the
support, while simultaneously minimizing the variance inflation that accompanies the
reduction in observations.
After pooling all large housing markets defined above, we follow Crump et al. (2009) to
define what the authors refer to as the optimal subpopulation. We estimate the following
logit model to predict the probability that a transaction occurs within a Promise zone
based on pre-Promise property characteristics:
Prob(P romised |Xi ) =

1
,
0
1 + eα+Xi ·γ

(4)

where Xi is a vector of time-invariant characteristics of property i including floor area
(in sq. feet), a quadratic in building age, and available 2000 U.S. Census demographic
information at the tract level.18 Recovering the associated parameters, we go on calculate
18

As all Promise programs were announced after the year 2000, there is no endogeneity concern introduced by using Census demographics. Building age is similarly unaffected by endogeneity concerns
as it is constructed as the difference between year built and year of transaction. Unfortunately, we do

22

the predicted value of P romised , obtaining propensity scores for all properties in the large
housing market sample. We then trim the sample to observations with intermediate
propensity scores.19 Equation 3 is then estimated on this sample, producing the Optimal
Subpopulation Average Treatment Effect (OSATE).
Finally, we wanted to document any heterogeneity in capitalization effects across the
distribution of school quality. It is well-known that the residential location decisions of
households with children are heavily influenced by school quality. If the intention of these
programs is in part to encourage the migration of households into Promise districts from
nearby areas with higher quality schools, it stands to reason that increases in demand
for housing should be concentrated in Promise area neighborhoods with access to relatively high quality schools. For two major metropolitan Promise zones— Pittsburgh and
Denver— we were also able to obtain school attendance boundaries from the Minnesota
Population Center’s School Attendance Boundary Information System (SABINS). After
matching properties to schools and obtaining standardized test scores at the school level
from each state’s education agency, we were able generate standardized pre-Promise measures of primary school and high school quality for each property in the Pittsburgh and
Denver samples. First, we divide the universe of schools on the basis of the highest tested
grade level, with schools testing only 8th graders and lower being labeled primary schools
and schools testing any students higher than 8th grade being labeled high schools. Then,
we calculate the percentage of tested students scoring proficient or better on standardized
tests (math and reading) in the universe of public schools in Colorado and Pennsylvania for the year 2005. Finally, within each state by school level cell we standardize this
measure such that the resulting variable is a Z-score distributed with mean zero and unit
standard deviation.
Pooling these two markets, we directly estimate how Promise capitalization varies
with school quality by estimating variations of the following equation in each market
not observe variation in other building characteristics, so for each property we do not know whether
we observe post-Promise floor area (which could potentially be endogenous to Promise announcement)
or pre-Promise floor area (which would necessarily be exogenous to Promise announcement) of each
property. However, over our short estimation window, is seems unlikely that floor area would respond
to Promise announcement in any systematic or meaningful way.
19
The optimal bounds of the propensity score distribution were calculated according to Crump et al.
(2009). We thank Oscar Mitnik for sharing the code for the procedure on his website.

23

definition:
P riceimdt = α + βQualityi · P romised · P ostdt + X0it · γ + ηt + δd + εimdt ,

(5)

where Qualityit is one of four standardized pre-Promise measures school quality for property i— primary school math Z-score, primary school reading Z-score, high school math
Z-score, or high school reading Z-score. The resulting estimate of β tells us how the
capitalization effect of the Promise varies across neighborhoods with access to different
quality schools.
For each selected housing market definition, we restrict our attention to transactions
occurring within three calendar years of the program announcement date, yielding seven
calendar years of transactions for each housing market. We limit transactions to arms
length sales or resales of owner-occupied, single-family units. Houses with missing transaction prices, transaction dates, and spatial coordinates are dropped, as were houses with
a building age of less than -1. Then, as the coverage and reliability of data varies significantly across jurisdictions, we eliminate outlying observations on a market by market
basis. This process typically removed observations with unreasonable (i.e. floor area of 0
square feet) or extreme covariate values (i.e. floor area more than 5,000 square feet, more
than 11 bedrooms, more than 10 bathrooms, etc.), taking care that the observations removed constituted a small percentage of observations (1% or less). Finally, we eliminate
transactions occurring at prices less than $1,000 or greater than $5,000,000
Table 3 presents the summary statistics for the sample of treated and untreated properties for each housing market definition.
[Table 3 about here]
As with public school data, our housing market data reveals that the neighborhoods
receiving Promise programs are different from those outside of Promise zones along several dimensions. Using a large housing market definition, the housing stock in Promise
zones covered by our housing data smaller in size and typically older than that in the
outlying areas. The Promise zones represented in the housing sample— Denver, CO;
Kalamazoo, MI; New Haven, CT; Pittsburgh, PA; Peoria, IL; Syracuse, NY; Hammond,
IN; and Pinal County, AZ— are mostly urban areas. The exceptions are Hammond and
Pinal County, both of which lie very close to urban areas (Chicago and Phoenix, respec24

tively). As such, this could be an artifact of the availability of data through DataQuick,
with rural areas being lower priority. This urban differential also reveals itself in the demographic characteristics; Promise neighborhoods typically contain more black residents,
fewer children, and fewer college educated individuals. In addition, unemployment and
poverty are more prevalent, leading to lower median incomes. Finally, Promise residents
are more likely to enroll K-12 children in private schools. Many of these gaps are reduced
or even reversed when considering our smaller geographic housing market or our propensity score screened optimal subpopulation, although differences remain significant. It is
important to note that neither of the more selective samples dominates the other in terms
of matching observables across groups. For example, the floor area of Promise properties
matches more closely to the control properties in the small geographic market than in
the optimal subpopulation, while the reverse is true for the percentage of black residents
in the neighborhood. Due to the way the optimal subpopulation is constructed, the two
groups in that sample should be matched closely on the covariates that are important
for residential location decisions. In addition, the small geographic market definition
yields fewer observations and estimates will be less precise as a result. We present results
from both samples in what follows, but we believe the optimal subpopulation represents
the best trade off between reducing bias from unbalanced observables and increasing the
variance of the resulting estimates.
4. Results
We first address the results from the K-12 enrollment data, which apply to a broad
sample of Promise scholarship programs. We follow that with evidence of the impact
of selected Promise scholarship programs on local housing markets. Finally, we present
a more detailed housing market analysis for two large metropolitan Promise zones—
Pittsburgh and Denver.
4.1. Public School Enrollment Estimates
Figure 3 provides graphical evidence, both towards the validity of the parallel trends
assumption and of the effect of the Promise on K-12 enrollment. We divide the baseline sample into geographic areas, each composed of one or two Promise zones and the
surrounding counties. Within a geographic area, years were normalized such that the
25

year that the relevant Promise was announced was set equal to zero.20 We then regress
log-transformed student counts on a full set of area-by-year fixed effects and plotted the
yearly average residuals for treated schools and untreated schools along with a linear fit.
[Figure 3 about here]
The graph depicts the variation in total student enrollment that is orthogonal to
region-wide shocks in the years leading up to and immediately following the announcement of a Promise program. While there are substantial differences in levels between the
groups, the trends in enrollment were not substantially different between groups prior to
treatment. After the announcement of a Promise program, however, the control group
continues on its pre-existing trend, while the Promise schools display a jump in enrollment
as well as a sharp upturn in their enrollment trend. We attribute this convergence to
increased demand for public schools following the announcement of a Promise program.
Table 4 displays the results of our fixed-effects estimates of school-level outcomes from
equation 1 in Panel A and equation 2 in Panel B.
[Table 4 about here]
As predicted, when enrollment in a particular set of schools gains a student access
to a potentially meaningful scholarship award, more students will enroll in those schools.
The announcement of a Promise program leads to an increase in overall enrollment of
roughly 4%. On average, increases in total enrollment are similar across racial groups,
although the effects are not significant when decomposed in this way.
It is typical for Promise programs to scale up scholarship awards with the length of
continuous enrollment at graduation. This feature makes the scholarship more valuable
to students who begin their enrollment at early grade levels. Also, students who begin
their enrollment spell past grade 9 or 10 are excluded from most Promise scholarships.
As a result, we would expect much of the enrollment increases over the initial years of
a Promise program to occur in the earlier grade levels especially in those programs that
feature this sliding scale. Figure 4 depicts the treatment effect as estimated for each
grade level separately.
[Figure 4 about here]
20

If two Promise programs were announced in the same year and were located close enough that there
was significant overlap in the adjacent counties, they were pooled into one area.

26

The estimated increases in enrollment in Promise districts match this pattern almost
precisely, with significant increases in enrollment at the lower grade levels (1-4), followed
by no detectable changes through most of the higher grades (5-11), and finally decreases
in enrollment in grade 12. Furthermore, this pattern is much more pronounced amongst
those programs featuring a sliding scale relative to those which lack this feature. This
match between the enrollment incentives provided by Promise scholarships and the estimated treatment effects gives us confidence that the identified overall effect is causal.
Turning our attention to the heterogeneity across program features, in panel B of
Table 4 the effects of Promise programs are decomposed into those generated by programs of different classes. This exercise reveals that estimated overall effect is masking
heterogeneity across programs. In addition, the variation is consistent with the expected
effect of program features on the scholarship’s prospective value. We would expect universal programs that allow use at a wide range of schools should present the most value
to the widest range of households. Either imposing a merit requirement or restricting
the list of schools should decrease the attractiveness of the program, although which restriction matters more is ambiguous. Finally, offering a merit-based scholarship usable
only at a small list of schools should present the least value for the fewest households.
Our estimates follow that profile exactly, with universal, wide-list programs generating
the largest enrollment increases (8%) followed by merit-based, wide-list programs and
universal, narrow-list progams (4%). Programs offering merit-based scholarships usable
at a small list of schools seem to have no effect on overall enrollment.
There are also racial disparities in the response to these programs that vary by program feature as indicated by columns 2 and 3 in Panel B. In particular, programs featuring
merit requirements prompt increases in white enrollment while leading to significant decreases in non-white enrollment. The racial pattern is likely explained by the existing
racial achievement gap in U.S. public schools (Murnane, 2013). As award receipt in these
programs is conditioned explicitly on success in high school, the value for the average
non-white student is diminished. Universal programs with large lists of eligible schools
seem to have no effect on relative enrollment across racial groups, consistent with the
analysis of the Kalamazoo Promise which belongs to this class. Finally, the small decrease in total enrollment in schools offering merit-based scholarships usable at a small
27

list of schools is driven by a significant decrease in the enrollment of non-white students.
Again, this conforms to our expectations regarding the incentives implied by different
scholarship features and how they interact with racial groups.
Overall, offering a Promise scholarship tied to enrollment in a particular public school
district is effective in drawing students into that school district, especially if graduates
are able to use the scholarship at a wide range of institutions or there are no merit requirements for eligibility. However, Promise programs also have an important impact
on the demographic composition of schools. Program administrators should note that
scholarships with merit requirements will primarily attract white students and may lead
to decreases in non-white enrollment, potentially contributing to racial inequality in educational attainment.
4.2. Pooled Housing Market Estimates
Our enrollment estimates suggest that demand for public schools increases in areas
where it is a pre-requisite for Promise scholarship receipt. As public school enrollment is
tied to residential location, this would imply an increase in housing demand as well. If
we assume that housing supply is fixed in the short run, any increase in housing demand
must be capitalized into housing prices. In figure 5, we repeat the graphical exercise
conducted on the K-12 enrollment data, but using instead the housing market data and
plotting separately for each market definition. Log housing prices for our eight Promiserelated housing markets were regressed on a full set of market-by-year-by-quarter fixed
effects and the monthly average residuals for treated properties and untreated properties
are plotted along with a local linear fit on either side of the announcement date.
[Figure 5 about here]
Clearly in the context of the large housing market definition, any impact of program
announcement on housing prices in Promise areas is hard to detect. While the difference
between groups narrows after the program announcement, the series diverge again to
pre-Promise levels within about 2 years. As mentioned previously, however, this estimate
is subject to significant bias due to the composition of the sample. The large market
definition includes properties in the periphery who may not be affected by the Promise
as well as properties in the center of the Promise zone that may not be considered by the

28

marginal household when making their residential location decision. Inclusion of both
groups biases the estimate of the effect towards zero.
When restricting attention to the smaller geographic housing market definition, the
impact of the Promise is more noticeable, but qualitatively similar. There is a convergence between the series immediately after the program announcement, followed by slight
divergence after about two years. It is hard to discern from the graph if there was or was
not a lasting impact of the Promise announcement on housing prices in the sample. Using
the optimal subpopulation yields a different story, however. After the announcement of
the Promise, there is a noticeable and discrete increase in prices occurring in Promise
zones which persists through the 2.5 years following the announcement.
Table 5 presents the results from our estimation of equation 3. Each panel corresponds
to a different definition of a housing market. The specification in Column 1 includes only
school district and market-specific time fixed effects. Of the difference in difference estimators, this specification is the most similar to the graphical analysis and is also subject
to the most omitted variables bias, as it identifies the effect through temporal variation
of prices at the school district level. Column 2 adds controls for various building and
neighborhood characteristics of the property and exchanges school district fixed effects
for the more spatially explicit Census tract fixed effects. Finally, column 3 includes property fixed effects, identifying the impact of the program from repeat sales of identical
properties in Promise zones vs. outside. These same estimates are repeated in Table 6
using price in constant 1990 dollars as the dependent variable
[Tables 5 and 6 about here]
The simplest DD specification yields inconsistent and imprecise capitalization estimates. This may indicate why previous studies using such a specification, but lacking
access to rich real estate data across several programs have been unable to uncover a
significant treatment effect. After controlling for property covariates and neighborhood
fixed effects, the magnitude of estimates increases and the variance decreases across all
samples, suggesting capitalization effects on the order of 4% to 6% of home values, or
between $5,500 and $8,000. Our preferred specifications use either the small geographic
housing market or propensity score screened optimal subpopulation and include property
level fixed effects, identifying the effect from repeat sales. These specifications provide
29

very precise treatment effects of between 6% and 12% of home values or $14,000 and
$20,500.
Our analysis of public school enrollment suggested that Promise programs have different impacts on different populations, particularly on different racial groups. As such,
we would like to document any such heterogeneity in the housing market as well. Our
housing market data provides no information on the characteristics of the individuals
participating in the transactions. However, we do observe the transaction price of the
house, which should be correlated with income and, as a result, race.
To investigate the heterogeneity of the capitalization of Promise scholarships with
respect to income, we divide each housing market in half according to the distribution
of housing values implied by the pre-announcement hedonic price function. As described
in the previous section, we estimate the hedonic price function over the pre-Promise
period in each housing market, recover the coefficient estimates, and then use them to
predict the sale price of all transactions observed in the sample as if each had occurred
in the first quarter of the year prior to the relevant Promise announcement. We then
repeat the DD analysis above, but separately for the samples of properties above the
median and below the median of the distribution generated by the first step. We report
the estimates from the tract-level fixed effects specification (equivalent to column 2 in
Table 5) only. The results are depicted in Figure 6. Across estimation samples, the
capitalization of Promise programs into housing prices increases across the housing price
distribution. Capitalization effects in the 1st quintile range from 2.8% to 5.5% compared
to capitalization in the top quintile of between 6.8% and 8.9%.
[Figure 6 about here]
There are several reasons why higher income households may be willing to pay more
to gain access to Promise scholarship programs. As mentioned in the previous section,
students from higher income households are more likely to attend college and the value
of access to Promise scholarships is ultimately conditional on college attendance. Even
conditional on college attendance and the quality of the institution, most Promise scholarships only apply to unmet need, which should be greater for high income households
due to a larger expected family contribution. As it is reasonable to expect these higher
income families to occupy higher priced domiciles, the results from our regressions pro30

vide more evidence in support of the claim that higher income households are willing to
pay more for access to Promise scholarship programs.
4.3. Large Urban Promise Zone Estimates
The pattern of capitalization across the housing distribution suggests that higherincome households place more value on access to Promise scholarships. As a result, one
might also expect there to be a similar pattern of capitalization across the distribution
of school quality. In order to verify such a pattern, we must link properties to schoollevel data on performance, such as state standardized test scores. Unfortunately, neither
school attendance boundaries nor standardized test performance data is readily available
for all of the Promise zones included in our housing market analysis.
For the two Promise programs in our housing market data based in large metropolitan
areas— the Pittsburgh Promise and the Denver Scholarship Foundation— we obtained
school attendance boundary maps through SABINS. In addition, we acquired school-level
data on standardized test scores from the Pennsylvania and Colorado state education
agencies. This data allows us to link properties in our housing market data to objective
measures of pre-Promise school quality. Before presenting those results, however, we
verify that the results from the pooled housing market sample also hold in both Pittsburgh and Denver. Table 7 reports estimates of the treatment effect within each market,
identifying from repeat-sales as in column 3 of Table 5.
[Table 7 about here]
Both programs display large treatment effects across all samples, ranging from 15%
to 22% in the Pittsburgh market and 5% to 11% in the Denver market. Estimates from
specifications using price in constant dollars as the dependent variable are provided for
comparison purposes; the implied capitalization amounts are roughly in line with the
magnitude of award amounts.
Our final set of results attempts to correlate the capitalization effects of these Promise
programs with the quality of schools. Our hypothesis is that capitalization will be concentrated in neighborhoods with higher quality schools. This is because the higher income
households on the margin will likely be choosing between higher quality suburban neighborhoods (and no access to Promise aid) and lower quality urban schools (with access

31

to Promise aid). As such, the households that relocate will aim first to minimize the
associated loss in school quality.
In order to quantify school quality, we first calculated the percentage of students in
each Pennsylvania or Colorado public school that scored “proficient” or better in math
and reading standardized tests in 2005, prior to the announcement of either program.
Then, we standardize this measure of quality such that within each state by school level
cell the distribution has a zero mean and unit standard deviation. Table 8 contains the
results from estimating equation 5.
[Table 8 about here]
With the exception of the measure of high school quality in the large housing market
definition, all of our school quality metrics are associated with larger capitalization effects of Promise program announcement. Across Pittsburgh and Denver, a one standard
deviation increase in the quality of the neighborhood high school leads to an increase in
the capitalization effect of the Promise of between 1% and 5% (or $2,500 and $6,000).
Estimates using primary school quality are uniformly larger; a one standard deviation
increase in the quality of the neighborhood primary school leads to an increase in the
capitalization effect of the Promise of between 5% and 10% (or $8,800 and $16,000). We
expect that the magnitude of the primary school quality effect relative to the high school
quality effect is due to a combination of factors. First, the incentives provided by many
Promise programs (including the Pittsburgh Promise) are strongest for primary school
students as the scholarship amount scales with years of continuous enrollment. As a result, primary school quality should be focal for the households most likely to be influenced
by the program. Also, due to the presence of school choice programs in Pittsburgh and
Denver, residential location is not always the sole determinant of school quality and the
strength of this link varies across grade levels. In Pittsburgh in 2010, 62% of the public
elementary school students attended their neighborhood school compared to only 52%
of public high school students. The situation in Denver is similar; in 2013, 57% of K-5
public school students attended their neighborhood school compared to 39% of public
high school students (9-12). As a result, the quality of the neighborhood high school may
be less relevant to the residential location decision than the quality of the neighborhood
primary school for which fewer feasible alternatives exist.
32

Furthermore, in results not presented here we estimated the capitalization effects by
individual high school neighborhoods and found that after the announcement of Promise
programs in Pittsburgh and Denver, housing prices increased in the neighborhoods associated with top performing high schools in the district (top 3 in Pittsburgh, top 4 in
Denver). In addition to these high-performing schools, large capitalization effects are also
estimated for the neighborhood associated with the school that ranked at the bottom of
each city’s high schools— Peabody High School in Pittsburgh and North High School in
Denver. Neighborhood level data, however, shows that school attendance rates of resident public school students are among the lowest in each district for these lower-quality
schools. On this measure, Peabody ranked 45 out of 48 traditional schools in Pittsburgh in 2010 and North ranked 97 out of 103 traditional schools in Denver in 2013. As a
result, some high-income households seem to have located in these Promise-eligible neighborhoods associated with poor quality schools, while utilizing the school choice systems
in Pittsburgh and Denver to send children to high quality public secondary schools.21
5. Conclusion
Place-based “Promise” scholarship programs have proliferated in recent years. Typically implemented at the school district level and financed privately, they guarantee
financial aid to eligible high school graduates from a particular school district, provided
they have continuously resided in the district for a number of years. In this study, we
measure the impact of a cross-section of Promise scholarships on a range of policy-relevant
outcomes, including public school enrollment and housing prices. In addition, we provide
the first direct evidence of how enrollment effects vary with features, such as eligibility
requirements and scholarship flexibility.
Using a difference-in-differences approach, we conclude that the initiation of a Promise
program leads to an increase in public school enrollment in affected schools and an increase in housing prices of between 6% and 12%, with capitalization effects most dramatic
amongst Promise zone properties in the upper half of the house price distribution. Even
so, there is substantial variation in these effects according to the features of the programs.
21

All data on neighborhood school attendance rates was provided by Pittsburgh Public Schools and
Denver Public Schools.

33

Scholarships that are usable at a wide range of institutions are effective at increasing
total public school enrollment, although this is mitigated by the imposition of merit requirements. However, the effects on school composition vary, with merit requirements
providing strong incentives for white enrollment at the expense of non-white enrollment.
Furthermore, focusing on Pittsburgh and Denver specifically, the capitalization effect
of scholarship programs into housing prices increases with the quality of the neighborhood public school. Taken together, this evidence suggests that these scholarships have
important distributional effects that bear further examination.
These results provide strong guidance to future program designers. First and foremost, place-based scholarship programs are capable of having an impact on important
regional development outcomes, such as population, school enrollment, and property values. Making the scholarship usable at a wide range of schools is essential in attracting
households to the scholarship area. Unfortunately, since minority students are less likely
to satisfy them, adding merit requirements could increase educational inequality. Further contributing to inequality, we find that the increase in housing demand resulting
from the announcement of the Promise is most pronounced in high-priced neighborhoods
with high-quality schools. As a result, the potential for peer effects to play a role in the
mitigation of inequality is greatly reduced as the high-quality students attracted by the
Promise seem to be settling into already high quality schools.
Still, these same capitalization effects are evidence that high-income households are
paying a premium for housing in the wake of a Promise scholarship program, while lowincome households do not face the same increase in housing costs to the extent that
they own instead of rent. As such, while low-income students will likely utilize these
scholarships less often than high-income students, they may benefit more net of this
house price effect, although a complementary analysis of rental rates would be necessary
to confirm this intuition. In addition, the increase in the tax base that may result from
the increase in home values leaves open the potential for more disadvantaged students to
benefit. If high-income households are contributing more to Promise school districts in
the form of property taxes, low-income students stand to benefit through that channel
as well. As a result, the impact of Promise scholarships on educational equity remains
somewhat ambiguous and is an area for future research.
34

There are many other avenues for future research into Promise scholarship programs.
Broader real estate transactions data would allow for an extension of the housing market
analysis conducted here to the remaining Promise programs. Such research would be
important in generalizing the house price effects of Promise programs beyond our sample
of eight programs, which offer little variation in program features. We also hope to
increase the scope of our evaluation to a wider range of outcomes. Any impact of Promise
scholarships on school quality and test scores is important in answering questions related
to the effect on educational inequality. Retaining high-income families has the potential
to substantially change the composition and performance of urban schools, leading to
spillover effects for low-income students.
Extending the analysis to the postsecondary education market would also be fruitful.
Some individual Promise programs have studied their effects on college choice and attendance with success. However, typically such studies are conducted through arrangements
with school districts, which often have student level records of college applications and
enrollments. As a result, data availability is a concern. The same is true for the impact of
Promise scholarships on cost of attendance. Recent studies have shown that if students
are likely to receive aid from other sources and their chosen college or university can easily
quantify the amount of aid, the institution will increase its effective price by reducing
the amount of institutional aid provided (Turner, 2011, 2012). Knowing that a student
comes from a Promise district is a fairly strong signal to a post-secondary institution that
the student may be receiving Promise aid. As a result, some of the value of the scholarship may well be captured in the market for post-secondary education. In addition, if
the signal is stronger for high-income students than low-income students, perhaps due to
uncertainty surrounding additional merit requirements, or demand is more elastic among
low-income students, documenting such an effect would have distributional implications
as well.
Acknowledgements
The authors thank Allison Shertzer, Werner Troesken, and Lise Vesterlund for their
helpful comments throughout the completion of this paper. In addition, the authors are
grateful to participants at the 2013 Midwest Economics Association Meeting and the
35

University of Pittsburgh Applied Micro Brown Bag seminar series. Any remaining errors
are their own.
Andrews, R.J., S. DesJardins, and V. Ranchhod, “The effects of the Kalamazoo Promise
on college choice,” Economics of Education Review, 2010, 29 (5), 722–737.
Bangs, Ralph, Larry E. Davis, Erik Ness, William Elliott III, and Candice Henry, “Placebased College Scholarships: An Analysis of Merit and Universal Programs,” 2011.
Barrow, L. and C.E. Rouse, “Using market valuation to assess public school spending,”
Journal of Public Economics, 2004, 88 (9), 1747–1769.
Bartik, T.J. and M. Lachowska, “The Short-Term Effects of the Kalamazoo Promise
Scholarship on Student Outcomes,” 2012.
Bartik, TJ and VK Smith, “Urban amenities and public policy,” in E.S. Mills, ed.,
Handbook of Regional and Urban Economics, vol. II, North Holland, Amsterdam, 1987.
Bartik, T.J., R.W. Eberts, and W.J. Huang, “The Kalamazoo Promise, and Enrollment
and Achievement Trends in Kalamazoo Public Schools,” 2010.
Bertrand, M., E. Duflo, and S. Mullainathan, “How much should we trust differences-indifferences estimates?,” Quarterly Journal of Economics, 2004, 119 (1), 249–275.
Black, S.E., “Do better schools matter? Parental valuation of elementary education,”
The Quarterly Journal of Economics, 1999, 114 (2), 577–599.
Bui, Linda TM and Christopher J Mayer, “Regulation and capitalization of environmental
amenities: Evidence from the toxic release inventory in Massachusetts,” Review of
Economics and statistics, 2003, 85 (3), 693–708.
Chay, Kenneth Y and Michael Greenstone, “Does air quality matter? Evidence from the
housing market,” Journal of Political Economy, 2005, 113, 376–424.
Cornwell, Christopher, David B Mustard, and Deepa J Sridhar, “The Enrollment Effects
of Merit-Based Financial Aid: Evidence from Georgia?s HOPE Program,” Journal of
Labor Economics, 2006, 24 (4), 761–786.
36

Cropper, Maureen L, Leland B Deck, and Kenenth E McConnell, “On the choice of
funtional form for hedonic price functions,” The Review of Economics and Statistics,
1988, pp. 668–675.
Crump, R.K., V.J. Hotz, G.W. Imbens, and O.A. Mitnik, “Dealing with limited overlap
in estimation of average treatment effects,” Biometrika, 2009, 96 (1), 187–199.
Cui, Lin and Randall Walsh, “Foreclosure, vacancy and crime,” 2013.
Dynarski, S., “Hope for whom? Financial aid for the middle class and its impact on
college attendance.,” National Tax Journal, 2000, 53 (3), 629–662.
, “The behavioral and distributional implications of aid for college.,” American Economic Review, 2002, 92 (2), 279–285.
Dynarski, Susan, “Building the stock of college-educated labor,” Journal of human resources, 2008, 43 (3), 576–610.
Figlio, David N and Maurice E Lucas, “What’s in a grade? School report cards and the
housing market,” American Economic Review, 2004, pp. 591–604.
Gayer, Ted, James T Hamilton, and W Kip Viscusi, “Private values of risk tradeoffs at
superfund sites: housing market evidence on learning about risk,” Review of Economics
and Statistics, 2000, 82 (3), 439–451.
Gonzalez, G.C., R. Bozick, , S. Tharp-Taylor, and A. Phillips, “Fulfilling the Pittsburgh
Promise: Early Progress of Pittsburgh’s Postsecondary Scholarship Program,” 2011.
Gottlieb, Joshua D and Edward L Glaeser, “The economics of place-making policies,”
Brookings Papers on Economic Activity, 2008, 2008 (1), 155–239.
Hallstrom, Daniel G and V Kerry Smith, “Market responses to hurricanes,” Journal of
Environmental Economics and Management, 2005, 50 (3), 541–561.
Henry, Gary T and Ross Rubenstein, “Paying for grades: Impact of merit-based financial
aid on educational quality,” Journal of Policy Analysis and Management, 2002, 21 (1),
93–109.
37

,

, and Daniel T Bugler, “Is HOPE enough? Impacts of receiving and losing merit-

based financial aid,” Educational Policy, 2004, 18 (5), 686–709.
Hershbein, Brad J, “A Second Look at Enrollment Changes after the Kalamazoo
Promise,” 2013.
Jones, J.N., G. Miron, and A.J.K. Young, “The Impact of the Kalamazoo Promise on
Teachers’ Expectations for Students,” 2008.
Kline, Patrick and Enrico Moretti, “Local economic development, agglomeration
economies and the big push: 100 years of evidence from the tennessee valley authority,”
Mimeograph UC Berkeley, 2011.
Kuminoff, Nicolai V and Jaren C Pope, “Capitalization and welfare measurement in the
hedonic model,” 2009.
, Christopher F Parmeter, and Jaren C Pope, “Which hedonic models can we trust
to recover the marginal willingness to pay for environmental amenities?,” Journal of
Environmental Economics and Management, 2010, 60 (3), 145–160.
Leslie, L.L. and P.T. Brinkman, The Economic Value of Higher Education, New York:
MacMillan, 1988.
Light, Audrey and Wayne Strayer, “Determinants of college completion: School quality
or student ability?,” Journal of Human Resources, 2000, pp. 299–332.
Linden, L. and J.E. Rockoff, “Estimates of the impact of crime risk on property values
from Megan’s Laws,” The American Economic Review, 2008, 98 (3), 1103–1127.
Logan, John R, Zengwang Xu, and Brian Stults, “Interpolating US decennial census
tract data from as early as 1970 to 2010: A longitudinal tract database,” Professional
Geographer, forthcoming, 2012.
Miller, A., “College Scholarships As A Tool for Community Development? Evidence
From The Kalamazoo Promise,” 2010.

38

Miller-Adams, M., “A simple gift? The impact of the Kalamazoo Promise on economic
revitalization,” Employment Research Newsletter, 2006, 13 (3), 1.
, The power of a promise: Education and economic renewal in Kalamazoo, WE Upjohn
Institute, 2009.
Miller-Adams, Michelle, “The Value of Universal Eligibility in Promise Scholarship Programs,” Employment Research Newsletter, 2011, 18 (4), 1.
and Bridget Timmeney, “The Impact of the Kalamazoo Promise on College Choice:
An Analysis of Kalamazoo Area Math and Science Center Graduates,” 2013.
Miron, G. and A. Cullen, “Trends and Patterns in Student Enrollment for Kalamazoo
Public Schools,” 2008.
and S. Evergreen, “The Kalamazoo Promise as a Catalyst for Change in an Urban
School District,” 2008.
and

, “Response from Community Groups,” 2008.

, J.N. Jones, and A.J.K. Young, “The Impact of the Kalamazoo Promise on Student
Attitudes, Goals, and Aspirations,” 2009.
, S. Evergreen, and J. Spybrook, “Key Findings from the 2007 Survey of High School
Students,” 2008.
Miron, Gary, Jeffrey N Jones, and Allison J Kelaher-Young, “The Kalamazoo Promise
and Perceived Changes in School Climate.,” Education Policy Analysis Archives, 2011,
19 (17), n17.
Murnane, Richard J., “U.S. High School Graduation Rates: Patterns and Explanations,”
Journal of Economic Literature, September 2013, 51 (2), 370–422.
Palmquist, Raymond B, “Property value models,” Handbook of environmental economics,
2005, 2, 763–819.

39

Parmeter, Christopher and Jaren Pope, “Quasi-experiments and hedonic property value
methods,” in J. A. List and M. K. Price, eds., Handbook on Experimental Economics
and the Environment, Edward Elgar, 2009.
Pope, Jaren C, “Buyer information and the hedonic model: the impact of a seller disclosure on the implicit price for airport noise,” Journal of Urban Economics, 2008, 63
(2), 498–516.
, “Do seller disclosures affect property values? Buyer information and the hedonic
model.,” Land Economics, 2008, 84 (4), 551–572.
, “Fear of crime and housing prices: Household reactions to sex offender registries,”
Journal of Urban Economics, 2008, 64 (3), 601–614.
Schwartz, H., “Housing policy is school policy: Economically integrative housing promotes academic success in Montgomery County, Maryland,” in “A Century Foundation
Report,” The Century Foundation, 2010.
Taylor, Laura O, “The hedonic method,” in “A primer on nonmarket valuation,” Springer,
2003, pp. 331–393.
Tornquist, E., K. Gallegos, and G. Miron, “Latinos and the Kalamazoo Promise: An Exploratory Study of Factors Related to Utilization of Kalamazoo’s Universal Scholarship
Program,” 2010.
Turner, L., “The Incidence of Student Financial Aid: Evidence from the Pell Grant
Program,” 2012.
Turner, N., “Who Benefits from Student Aid: The Economic Incidence of Tax-Based
Student Aid.,” 2011.

40

Figure 1: Large (10 mile) and Small (1 mile) Housing Markets in Pittsburgh, PA

41

Figure 2: Percent Non-Hispanic Black (2000) by Census Tract

42

Figure 3: Total Enrollment Residual by Year

43

Figure 4: Treatment Effect by Grade Level

44

Figure 5: Sale Price Residuals by Date

45

Figure 6: Treatment Effect by Above/Below Median

46

Table 1: List of Promise Type Programs

47

Name of
Program

Location

Announced Requirements

Arkadelphia
Promise

Arkadelphia,
AR

2010

Baldwin
Promise

Baldwin, MI

2010

• Graduate from
Arkadelphia HS
• Continuous enrollment
since 9th grade
• 2.5 GPA or 19 ACT
• Receive AR Lottery
scholarship
• Apply for 2 other
scholarships

• Reside within Baldwin
Community SD
• Graduate from any HS
within zone
• Continuous residency since
9th grade.

Award

Eligible Schools

Sliding scale; 65% to
100% of unmet need
per year; Max:
highest tuition at
Arkansas public PSI.

Any accredited PSI in
the U.S.

Sliding scale; $500 to
$5,000 per year

Any accredited PSI in
the Michigan

Table 1: List of Promise Type Programs

48

Name of
Program

Location

Bay
Commitment

Bay, MI

College
Bound
Scholarship
Program

Hammond,
IN

Announced Requirements
2006

Award

Eligible Schools

$2,000 per year

Delta College or
Saginaw Valley State
University

Sliding scale; 60% to
100% of unmet need
per year; Max:
tuition at Indiana
Univ. Bloomington.

Any accredited PSI in
Indiana

• Graduate from Bay County
HS
• Continuous enrollment
since 9th grade
• Continuous residency for 6
years
• First-generation college
student
2006
• Continuous residency
within Hammond City for
3 years
• Graduate from any HS in
Hammond City
• 3.0 GPA OR
• 2.5 GPA with 1000 SAT
(math and verbal) OR
• 2.5 GPA with 1400 SAT

Table 1: List of Promise Type Programs

49

Name of
Program

Location

Denver
Scholarship
Foundation

Denver, CO

Detroit
College
Promise

Detroit, MI

Educate and
Grow
Scholarship

Blountville,
TN

Announced Requirements
2006
• Graduate from Denver
Public HS
• Continuous enrollment
since 9th grade
• 2.0 GPA
• Demonstrate financial need
(EFC < 2x Pell limit)
2008
• Graduate from traditional
Detroit Public HS
• Continuous enrollment
since 9th grade
• Continuous residency since
9th grade
Unknown
• Continuous residency
within selected counties for
12 mos. prior to
graduation
• Graduate from any HS

Award

Eligible Schools

$250 to $3,400 per
year depending on
PSI and EFC

39 PSIs in Colorado

$150 to $600 for one
semester

43 public PSIs in
Michigan

Full tuition (4
semesters)

Northeast State
Community College

Table 1: List of Promise Type Programs
Name of
Program

Location

Announced Requirements

El Dorado
Promise

El Dorado,
AR

2007

Great River
Promise

Phillips
County, AR

2010

Hopkinsville
Rotary
Scholars

Hopkinsville,
KY

2005

• Graduate from El Dorado
Public Schools
• Continuous enrollment
since 9th grade
• Continuous residency since
9th grade.

50

• Graduate from Arkansas or
Phillips County HS
• Continuous enrollment
since 9th grade
• Achieve high school
attendance requirements.

• Graduate from selected
high schools
• 2.5 GPA
• 95% attendance

Award

Eligible Schools

Sliding scale; 65% to
100% of unmet need
per year; Max:
highest tuition at
Arkansas public PSI.

Any accredited PSI in
the U.S.

Full tuition (4
semesters)

Phillips Community
College of the
University of
Arkansas

Full tuition (4
semesters)

Hopkinsville
Community College

Table 1: List of Promise Type Programs
Name of
Program

Location

Announced Requirements

Jackson
Legacy

Jackson
County, MI

2006

Kalamazoo
Promise

Kalamazoo,
MI

2005

Legacy
Scholars

Battle Creek,
MI

2005

• Graduate from Jackson
County HS
• Continuous enrollment
since 10th grade
• Community service

51

• Graduate from Kalamazoo
Public Schools
• Continuous enrollment
since 9th grade
• Continuous residency since
9th grade.

• Graduate from Battle
Creek or Lakeview SD
• Continuous enrollment
since 10th grade

Award

Eligible Schools

Sliding scale; $150 to
$600 per year for two
years

Jackson Community
College, Spring Arbor
University, Baker
College of Jackson

Sliding scale; 65% to
100% of tuition per
year

Any public PSI in
Michigan

Sliding scale; 31 to 62
credit hours

Kellogg Community
College

Table 1: List of Promise Type Programs

52

Name of
Program

Location

Announced Requirements

Leopard
Challenge

Norphlet, AR

Muskegon
Opportunity

Muskegon,
MI

2009a

New Haven
Promise

New Haven,
CT

2010

2007
• Graduate from Norphlet
HS
• Continuous enrollment
since 9th grade
• Continuous residency since
9th grade
• 2.25 GPA
TBD

• Graduate from New Haven
Public Schools
• Reside in New Haven
• 3.0 GPA
• 90% attendance
• Community service

Award

Eligible Schools

Sliding scale; $2,600
to $4,000 per year

Any accredited PSI in
the U.S.

TBD

TBD

Sliding scale; 65% to
100% of unmet need
per year at public; Up
to $2,500 at private

Any accredited PSI in
Connecticut

Table 1: List of Promise Type Programs
Name of
Program

Location

Announced Requirements

Northport
Promise

Northport,
MI

2007

Peoria
Promise

Peoria, IL

2008

Pittsburgh
Promise

Pittsburgh,
PA

• Graduate from Northport
HS
• Continuous enrollment
since 9th grade
• Participate in fundraising
activities

53

• Graduate from public
school in Peoria
• Continuous enrollment
since 10th grade
• Continuous residency since
10th grade.
2006
• Graduate from Pittsburgh
Public Schools
• Continuous enrollment
since 9th grade
• Continuous residency since
9th grade
• 2.5 GPA
• 90% attendance

Award

Eligible Schools

Sliding scale; Amount
determined each year

Any public PSI in
Michigan

Sliding scale; 50% to
Illinois Central
100% of tuition for up College
to 64 credit hours

Sliding scale; $1,000
to $10,000 per year

Any accredited PSI in
Pennsylvania

Table 1: List of Promise Type Programs
Name of
Program

Location

Announced Requirements

Promise for
the Future

Pinal County,
AZ

2001b

Say Yes
Buffalo

Buffalo, NY

2012

Say Yes
Syracuse

Syracuse, NY

• Graduate from Pinal
County HS
• Continuous enrollment
since 8th grade
• 2.75 GPA

54

• Graduate from Buffalo
Public Schools
• Continuous enrollment
since 9th grade
• Continuous residency since
9th grade
2009
• Graduate from Syracuse
Public Schools
• Continuous enrollment
since 10th grade
• Continuous residency since
10th grade.

Award

Eligible Schools

Full tuition (4
semesters)

Central Arizona
College

Sliding scale; 65% to
100% unmet need

Any State University
of New York or City
University of New
York campus.c

100% unmet need

Any State University
of New York or City
University of New
York campus.c

Table 1: List of Promise Type Programs
Name of
Program

Location

Announced Requirements

School
Counts
Program

Hopkins
County, KY

Unknown

Sparkman
Promise

Sparkman,
AR

2011

55

• Graduate from Hopkins
County HS in 8
consecutive semesters
• Continuous enrollment
since 9th grade
• Continuous residency since
9th grade
• 2.5 GPA yearly
• 95% attendance
• Exceed graduation credit
requirements.

• Graduate from Sparkman
Public Schools
• Continuous enrollment
since 9th grade
• 2.5 GPA or 19 ACT
• Receive AR Lottery
scholarship
• Apply for 2 other
scholarships

Award

Eligible Schools

$1,000 per semester
for 4 semesters

Madisonville
Community College

Sliding scale; 65% to
100% of unmet need
per year; Max:
highest tuition at
Arkansas public PSI.

Any accredited PSI in
the U.S.

Table 1: List of Promise Type Programs
Name of
Program

Location

Ventura
College
Promise

Ventura
County, CA

Announced Requirements
2006
• Graduate from Ventura
County HS
• Continuous enrollment
since 9th grade
• 2.5 GPA or 19 ACT
• Receive AR Lottery
scholarship
• Apply for 2 other
scholarships

Award

Eligible Schools

Enrollment costs for 1
year

Ventura College

56
Source: http://www.upjohn.org/Research/SpecialTopics/KalamazooPromise/PromiseTypeScholarshipPrograms, Gonzalez et al. (2011), and authors’ research. Program details have changed over time; for brevity, all details reported represent current
program configurations.
a
Announced in 2009, but no details of eligibility or amount have been provided to date. Due to the high degree of uncertainty,
was not included in analysis.
b
While the Kalamazoo Promise is often referred to as the first in this class, we have found a source dating the start of the
Promise for the Future back to 2001 (“Deadline to enroll in Promise for the Future Scholarship approaching” The Superior Sun.
April 15, 2009.). Historical program details were not found during our research.
c
There are other “Say Yes” partner schools, but additional restrictions apply.

Table 2: K-12 Public School Summary Statistics
Promise
Schools

Control
Schools

t-stat

Total Enrollment

mean
(s.d.)
Obs.

599.70
(431.00)
5,287

745.36
(615.82)
42,313

24.71

% White

mean
(s.d.)
Obs.

0.44
(0.31)
5,287

0.44
(0.35)
42,313

1.84

Primary

mean
(s.d.)
Obs.

0.67
(0.47)
5,287

0.68
(0.47)
42,313

0.92

Middle

mean
(s.d.)
Obs.

0.17
(0.38)
5,287

0.16
(0.37)
42,313

1.81

High

mean
(s.d.)
Obs.

0.14
(0.35)
5,287

0.14
(0.35)
42,313

1.57

City

mean
(s.d.)
Obs.

0.57
(0.50)
5,287

0.39
(0.49)
42,313

-28.92

Suburb

mean
(s.d.)
Obs.

0.25
(0.43)
5,287

0.45
(0.50)
42,313

38.82

Town

mean
(s.d.)
Obs.

0.05
(0.21)
5,287

0.04
(0.20)
42,313

0.80

Rural

mean
(s.d.)
Obs.

0.14
(0.35)
5,287

0.12
(0.32)
42,313

-4.06

Notes: T-statistic from a two-sided t-test with unequal variance.

57

Table 3: Housing Market Summary Statistics
Large (10 mile)
Promise

Small (1 mile)

Optimal Subpop.

Control

t-stat

Promise

Control

t-stat

Promise

Control

t-stat

58

Transaction
price

mean 220,026
(s.d.) (190,684)
Obs.
95,954

219,754
(143,416)
418,440

-0.42

214,049
(190,952)
55,279

189,897
(161,839)
43,933

-21.55

216,271
(191,359)
77,059

189,513
(136,338)
174,262

-35.08

Price (1990
dollars)

mean 131,961
(s.d.) (112,909)
Obs.
95,954

134,164
(85,987)
418,440

5.68

126,971
(113,360)
55,279

114,554
(96,472)
43,933

-18.63

130,026
(113,213)
77,059

114,016
(80,906)
174,262

-35.46

Building age

mean
(s.d.)
Obs.

48.38
(36.85)
94,955

26.12
(26.81)
401,715

-175.48

45.00
(32.80)
54,867

38.72
(30.11)
43,088

-31.16

51.65
(35.27)
77,059

37.95
(29.24)
174,262

-94.43

Floor area (sq.
feet)

mean
(s.d.)
Obs.

1,595.62
(710.96)
95,954

1,820.44
(750.93)
418,440

87.41

1,573.41
(723.14)
55,279

1,598.54
(693.64)
43,933

5.56

1,540.07
(689.00)
77,059

1,578.04
(642.62)
174,262

13.00

% Black

mean
(s.d.)
Obs.

0.14
(0.17)
94,751

0.11
(0.22)
413,571

-49.37

0.16
(0.17)
54,088

0.09
(0.14)
42,424

-65.87

0.12
(0.17)
77,059

0.15
(0.25)
174,262

33.34

% under 15

mean
(s.d.)
Obs.

0.20
(0.07)
94,751

0.24
(0.06)
413,571

128.24

0.21
(0.07)
54,088

0.20
(0.07)
42,424

-24.57

0.20
(0.06)
77,059

0.21
(0.05)
174,262

46.59

% over 60

mean
(s.d.)
Obs.

0.17
(0.11)
94,751

0.16
(0.11)
413,571

-29.86

0.16
(0.09)
54,088

0.21
(0.15)
42,424

65.77

0.19
(0.10)
77,059

0.19
(0.10)
174,262

3.50

Table 3: Housing Market Summary Statistics
Large (10 mile)

Small (1 mile)

Optimal Subpop.

Promise

Control

t-stat

Promise

Control

t-stat

Promise

Control

t-stat

59

% Households
with children

mean
(s.d.)
Obs.

0.32
(0.13)
94,751

0.40
(0.11)
413,571

172.03

0.34
(0.13)
54,088

0.32
(0.12)
42,424

-22.03

0.31
(0.11)
77,059

0.34
(0.10)
174,262

75.77

% HS diploma

mean
(s.d.)
Obs.

0.40
(0.19)
95,056

0.34
(0.16)
414,961

-86.73

0.42
(0.18)
54,386

0.41
(0.16)
42,424

-3.33

0.40
(0.20)
77,053

0.43
(0.16)
174,262

29.88

% College

mean
(s.d.)
Obs.

0.34
(0.21)
95,056

0.34
(0.17)
414,961

4.47

0.32
(0.20)
54,386

0.29
(0.16)
42,424

-25.87

0.34
(0.21)
77,053

0.28
(0.16)
174,262

-71.54

% unemployed

mean
(s.d.)
Obs.

0.08
(0.04)
94,154

0.06
(0.05)
414,961

-87.68

0.08
(0.04)
53,484

0.07
(0.04)
42,424

-23.53

0.08
(0.05)
77,053

0.08
(0.05)
174,262

6.73

% in poverty

mean
(s.d.)
Obs.

0.16
(0.11)
94,154

0.08
(0.08)
414,961

-215.38

0.15
(0.10)
53,484

0.11
(0.09)
42,424

-65.11

0.16
(0.10)
77,053

0.12
(0.09)
174,262

-89.99

% K-12 private

mean
(s.d.)
Obs.

0.18
(0.17)
94,513

0.13
(0.09)
413,695

-99.90

0.18
(0.16)
54,381

0.14
(0.11)
41,751

-51.44

0.18
(0.16)
76,515

0.14
(0.12)
173,715

-59.60

Median income

mean
(s.d.)
Obs.

51,491
(21,829)
94,152

68,328
(25,221)
414,961

207.35

52,493
(22,956)
53,482

54,967
(24,406)
42,424

16.01

50,615
(20,398)
77,052

53,512
(17,851)
174,262

34.07

Notes: Prices were deflated to January 1990 dollars using the “All Urban Consumers-Owner’s Equivalent Rent of Primary Residence CPI” from the Bureau of Labor Statistics. T-statistic from a two-sided t-test with unequal variance.

Table 4: K-12 Public School Enrollment Effects of Promise Programs
Dependent Variable:

log(Total)

log(White)

log(Non-white)

0.037***
(0.007)

0.023
(0.016)

0.021
(0.012)

Panel B: Effects by type
No Merit & Wide
(117 schools)

0.080***
(0.023)

-0.010
(0.042)

0.001
(0.038)

Merit & Wide
(203 schools)

0.040**
(0.017)

0.110***
(0.038)

-0.039**
(0.020)

No Merit & No Wide
(327 schools)

0.039***
(0.009)

-0.020
(0.019)

0.076***
(0.017)

Merit & No Wide
(66 schools)

-0.031
(0.026)

0.054
(0.033)

-0.129***
(0.033)

Observations
Clusters (Schools)
R-squared

47,600
6,337
0.97

47,600
6,337
0.98

47,600
6,337
0.98

Panel A: Overall effects
PromiseXPost

Notes: Standard errors clustered at the school level in parentheses. Sample includes
open, regular schools located in Promise zones and neighboring counties that reported
student counts by race in all available surveys conducted within 4 years of the regionrelevant Promise announcement. Fixed effects at the region-by-year, locale-by-year,
and school level are included in all specifications. Controls include school level (primary, middle, high, other) and locale (city, suburb, town, rural).
*
Significant at the 10% level
**
Significant at the 5% level
***
Significant at the 1% level

60

Table 5: Capitalization Effects of Promise Programs
Dependent Variable: log(Price)
Panel A: Large (10 mile)
PromiseXPost
Observations
Clusters
R-squared
Panel B: Small (1 mile)
PromiseXPost
Observations
Clusters
R-squared
Panel C: Optimal subpopulation
PromiseXPost
Observations
Clusters
R-squared
Building Controls
Census Controls
Market-Year-Qtr FE
School District FE
Neighborhood (Tract) FE
Property FE

(1)

(2)

(3)

-0.003
(0.017)

0.039***
(0.012)

0.083***
(0.007)

514,394
2,055
0.38

487,930
2,008
0.69

505,604
393,570
0.92

-0.006
(0.022)

0.045***
(0.017)

0.066***
(0.013)

99,212
607
0.41

93,711
595
0.72

94,925
72,656
0.93

0.032*
(0.018)

0.061***
(0.013)

0.123***
(0.009)

251,321
1,465
0.38
NO
NO
YES
YES
NO
NO

250,229
1,461
0.67
YES
YES
YES
NO
YES
NO

250,229
196,877
0.92
NO
YES
YES
NO
NO
YES

Notes: Standard errors clustered at the school level (in columns 1 and 2) or the property
level (column 3) in parentheses. Sample includes arms-length transactions of owner-occupied
single family homes. All controls are interacted with housing market indicators. Building
controls in column 2 include square footage and a quadratic in building age. Census controls
include the following tract-level statistics interpolated from the 1990, 2000, and 2010 Census full-count data as well as the 2006-2010 American Community Survey: % of pop. black,
% of pop. under 15/over 60, % of households with children under 18, % of pop. with high
school diploma or less, % of pop. with some college, % unemployed, % of pop. in poverty,
% of K-12 children enrolled in private schools, and median income. Optimal subpopulation
includes sales with propensity scores in the interval [.075,.925].
* Significant at the 10% level
** Significant at the 5% level
*** Significant at the 1% level

61

Table 6: Capitalization Effects of Promise Programs
Dependent Variable: Price ($1990)
Panel A: Large (10 mile)
PromiseXPost
Observations
Clusters
R-squared
Panel B: Small (1 mile)
PromiseXPost

(1)

(2)

(3)

445.5
(2,244)

7,335***
(1,678)

17,966***
(1,029)

514,394
2,055
0.25

487,930
2,008
0.72

505,604
393,570
0.94

-2,451
(2,904)

5,504***
(1,732)

14,244***
(1,748)

99,212
607
0.24

93,711
595
0.75

94,925
72,656
0.94

3,018
(2,308)

8,214***
(1,595)

20,440***
(1,110)

251,321
1,465
0.27

250,229
1,461
0.71

250,229
196,877
0.95

NO
NO
YES
YES
NO
NO

YES
YES
YES
NO
YES
NO

NO
YES
YES
NO
NO
YES

Observations
Clusters
R-squared
Panel C: Optimal subpopulation
PromiseXPost
Observations
Clusters
R-squared
Building Controls
Census Controls
Market-Year-Qtr FE
School District FE
Neighborhood (Tract) FE
Property FE

Notes: Standard errors clustered at the school level (in columns 1 and 2) or the property
level (column 3) in parentheses. Sample includes arms-length transactions of owner-occupied
single family homes. All controls are interacted with housing market indicators. Building
controls in column 2 include square footage and a quadratic in building age. Census controls
include the following tract-level statistics interpolated from the 1990, 2000, and 2010 Census full-count data as well as the 2006-2010 American Community Survey: % of pop. black,
% of pop. under 15/over 60, % of households with children under 18, % of pop. with high
school diploma or less, % of pop. with some college, % unemployed, % of pop. in poverty,
% of K-12 children enrolled in private schools, and median income. Optimal subpopulation
includes sales with propensity scores in the interval [.075,.925].
* Significant at the 10% level
** Significant at the 5% level
*** Significant at the 1% level

62

Table 7: Large Metropolitan Promise Programs
Pittsburgh

Panel A: Large (10 mile)
PromiseXPost
Observations
Clusters
R-squared
Panel B: Small (1 mile)
PromiseXPost
Observations
Clusters
R-squared
Panel C: Optimal subpopulation
PromiseXPost
Observations
Clusters
R-squared
Census Controls
Market-Year-Qtr FE
Property FE

Denver

log(Price)

Price ($1990)

log(Price)

Price ($1990)

0.218***
(0.046)
52,716
46,573
0.91

13,508***
(2,619)
52,716
46,573
0.95

0.105***
(0.006)
221,198
160,455
0.89

24,784***
(1,326)
221,198
160,455
0.94

0.147**
(0.075)
14,474
12,762
0.90

8,701***
(2,763)
14,474
12,762
0.96

0.069***
(0.013)
49,445
34,241
0.9

17,841***
(2,363)
49,445
34,241
0.93

0.155**
(0.077)
13,517
11,903
0.91
YES
YES
YES

8,096***
(2,424)
13,517
11,903
0.97
YES
YES
YES

0.046***
(0.012)
36,104
24,748
0.87
YES
YES
YES

4,783***
(1,273)
36,104
24,748
0.94
YES
YES
YES

Notes: Standard errors clustered at the property level in parentheses. Sample includes armslength transactions of owner-occupied single family homes. Census controls include the following tract-level statistics interpolated from the 1990, 2000 and 2010 Census full-count data:
% of pop. black, % of pop. under 15/over 60, % of households with children under 18. In
addition, the following block tract-level statistics are interpolated between the 1990 and 2000
Census sample files and the 2006-2010 American Community Survey: % of pop. with high
school diploma or less, % of pop. with some college, % unemployed, % of pop. in poverty,
% of K-12 children enrolled in private schools, and median income. Full count statistics interpolated between 1990-2010 with years after 2010 held constant at 2010 values. Sample
statistics interpolated between 1990-2006 with years after 2006 held constant at 2006 values.
Optimal subpopulation includes sales with propensity scores in the interval [.091,.909] for
Pittsburgh and [.076,.924] for Denver.
** Significant at the 5% level
*** Significant at the 1% level

63

Table 8: Large Metropolitan Promise Programs by School Quality
High School Quality
Math
log(Price)
Panel A: Large (10 mile)
Promise x Post
-0.011*
x Quality
(0.006)
N (Clusters)
R-squared

0.91

64

Panel B: Small (1 mile)
Promise x Post
0.027**
x Quality
(0.011)
N (Clusters)
R-squared

0.93

Reading

0.92
YES
YES
YES

Math

Reading

$1990

log(Price)

$1990

log(Price)

$1990

log(Price)

$1990

-5,397***
(716.8)

0.004
(0.004)

-3,081***
(514.1)

0.084***
(0.005)

14,083***
(978.6)

0.068***
(0.005)

10,798***
-812.6

195,412 (144,002)
0.95
0.91
4,535***
(1,420)

0.046***
(0.008)

52,925 (37,750)
0.94
0.93

Panel C: Optimal subpopulation
Promise x Post
0.014*
2,579***
x Quality
(0.008)
(919.6)
N (Clusters)
R-squared
Census Controls
City-Year-Qtr
Property FE

Primary School Quality

0.023***
(0.006)

67,663 (47,838)
0.94
0.92
YES
YES
YES
YES
YES
YES

0.95

0.91

5,859***
(1,002)

0.092***
(0.008)

0.94

0.93

2,967***
(642.6)

0.060***
(0.007)

0.94
YES
YES
YES

0.91
YES
YES
YES

179,567 (131,872)
0.95
0.91
15,867***
(1,696)

0.080***
(0.007)

49,749 (35,495)
0.94
0.93
9,960***
(1,306)

0.052***
(0.006)

61,787 (43,451)
0.95
0.91
YES
YES
YES
YES
YES
YES

0.95
14,172***
(1,528)

0.94
8,885***
(1,110)

0.95
YES
YES
YES

Notes: Standard errors clustered at the property level in parentheses. Sample includes arms-length transactions of owner-occupied single
family homes. Raw school quality in 2005 is measured as the percentage of students that score proficient or advanced on state standardized tests. This raw measure is then standardized within state-school level cells such that the resulting standardized measure has mean

zero and standard deviation 1 within each cell. All controls are interacted with housing market indicators. Census controls include the
following tract-level statistics interpolated from the 1990, 2000 and 2010 Census full-count data: % of pop. black, % of pop. under 15/over
60, % of households with children under 18. In addition, the following block tract-level statistics are interpolated between the 1990 and
2000 Census sample files and the 2006-2010 American Community Survey: % of pop. with high school diploma or less, % of pop. with
some college, % unemployed, % of pop. in poverty, % of K-12 children enrolled in private schools, and median income. Full count statistics interpolated between 1990-2010 with years after 2010 held constant at 2010 values. Sample statistics interpolated between 1990-2006
with years after 2006 held constant at 2006 values. Optimal subpopulation includes sales with propensity scores in the interval [.078,.922].
** Significant at the 5% level
*** Significant at the 1% level

65

