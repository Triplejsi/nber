NBER WORKING PAPER SERIES

IN A SMALL MOMENT:
CLASS SIZE AND MORAL HAZARD IN THE MEZZOGIORNO
Joshua D. Angrist
Erich Battistin
Daniela Vuri
Working Paper 20173
http://www.nber.org/papers/w20173
NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
May 2014

Special thanks go to Patrizia Falzetti, Roberto Ricci and Paolo Sestito at INVALSI for providing the
achievement data used here and to INVALSI staffers Paola Giangiacomo and Valeria Tortora for advice
and guidance in our work with these data. Grateful thanks also go to Gianna Barbieri, Angela Iadecola,
and Daniela Di Ascenzo at the Ministry of Education (MIUR) for access to and assistance with administrative
schools data. Chiara Perricone provided expert research assistance. Our thanks to David Autor, Daniele
Checchi, Eric Hanushek, Andrea Ichino, Brian Jacob, Michael Lechner, Steve Machin, Derek Neal,
Parag Pathak, Daniele Paserman and Jona Rockoff for helpful discussions and comments, and to seminar
participants at NBER Education Fall 2013, the 2014 SOLE meeting, the University of California Irvine,
Padova University, IRVAPP, EUI, UCL, ISER (Essex), the CEP Labour Market Workshop, the Warwick
2014 CAGE conference, the 2014 Laax Labor Economics Workshop, the University of Rome Tor
Vergata, and EIEF for helpful comments. This research is supported by the Einaudi Institute of Economics
and Finance (EIEF) - Research Grant 2011 and by the Fondazione Bruno Kessler. Angrist thanks the
Institute for Education Sciences for financial support. The views expressed here are those of the authors
alone and do not necessarily reflect the views of the National Bureau of Economic Research.
NBER working papers are circulated for discussion and comment purposes. They have not been peerreviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.
© 2014 by Joshua D. Angrist, Erich Battistin, and Daniela Vuri. All rights reserved. Short sections
of text, not to exceed two paragraphs, may be quoted without explicit permission provided that full
credit, including © notice, is given to the source.

In a Small Moment: Class Size and Moral Hazard in the Mezzogiorno
Joshua D. Angrist, Erich Battistin, and Daniela Vuri
NBER Working Paper No. 20173
May 2014
JEL No. C26,C31,I21,I28,J24
ABSTRACT
An instrumental variables (IV) identification strategy that exploits statutory class size caps shows
significant achievement gains in smaller classes in Italian primary schools. Gains from small classes
are driven mainly by schools in Southern Italy, suggesting a substantial return to class size reductions
for residents of the Mezzogiorno. In addition to high unemployment and other social problems, however,
the Mezzogiorno is distinguished by pervasive manipulation of standardized test scores, a finding
revealed in a natural experiment that randomly assigned school monitors. IV estimates also show that
small classes increase score manipulation. Estimates of a causal model for achievement with two
endogenous variables, class size and score manipulation, suggest that the effects of class size on
measured achievement are driven entirely by the relationship between class size and manipulation.
Dishonest scoring appears to be a consequence of teacher shirking more than teacher cheating. These
findings show how consequential score manipulation can arise even in assessment systems with few
NCLB-style accountability concerns.
Joshua D. Angrist
Department of Economics, E17-226
MIT
77 Massachusetts Avenue
Cambridge, MA 02139
and NBER
angrist@mit.edu
Erich Battistin
School of Economics and Finance
Queen Mary University of London
Mile End Road
London E1 4NS
and IRVAPP, IZA
e.battistin@qmul.ac.uk

Daniela Vuri
Department of Economics and Finance
University of Rome Tor Vergata
via Columbia 2, building B
Rome, 00133
and IZA, CESifo, CEIS
daniela.vuri@uniroma2.it

1

Introduction

School improvement eﬀorts often focus on inputs to education production, the most important
of which is staﬃng ratios. Parents, teachers, and policy makers look to small classes to boost
learning. The question of whether changes in class size have a causal eﬀect on achievement
remains controversial, however. Regression estimates often show little gain to class size reductions, with students in larger classes sometimes appearing to do better (Hanushek, 1995).
At the same time, a large randomized study, the Tennessee STAR experiment, generated
evidence of substantial learning gains in smaller classes (Krueger, 1999). An investigation
of longer-term eﬀects of the STAR experiment also shows increases in college attendance for
treated students (Chetty et al., 2011).
Standardized tests provide the yardstick by which school quality is most often assessed
and compared. As testing regimes have proliferated, however, so have concerns about the
reliability and fidelity of assessment results (Neal, 2013, lays out the issues in this context).
In an early empirical contribution, Jacob and Levitt (2003) documented substantial cheating in Chicago public schools, while a recent system-wide cheating scandal in Atlanta now
threatens to send large numbers of administrators to jail (Severson, 2011). Of course, students may cheat as well, especially on tests with other consequences for them. In many cases,
however, the behavior of staﬀ who administer and, in some cases, grade assessments is of
primary concern. For example, Dee et al. (2011) show that scores on New York’s Regents
exams are often manipulated by the school staﬀ who grade them. In public school systems
with weak employee performance standards, such as the Italian public school system studied
here, fidelity of school staﬀ to test administration protocols and grading standards may be
especially weak.1
Our investigation of education production in Italy begins by applying the quasi-experimental
research design introduced by Angrist and Lavy (1999). This design exploits variation in class
size that originates in rules stipulating a class size cutoﬀ. In Israel, with a cutoﬀ of 40, we
1

De Paola et al. (2014) estimate the eﬀects of workplace accountability on productivity in the Italian
public sector. Ichino and Tabellini (2014) discuss possible benefits from organizational reform and increased
choice in Italian public schools.

1

expect to see a single class of 40 in a grade cohort of 40, while with enrollment of 41, the
cohort is split into two much smaller classes. Angrist and Lavy called this “Maimonides’
Rule,” after the prominent medieval scholar Moses Maimonides, who identified a similar rule
in the Talmud. Maimonides-style estimates of the eﬀects of class size on achievement for the
population of Italian second and fifth graders, most of whom attend much smaller classes
than those seen in Israel, suggest a statistically significant but modest return to decreases
in class size. Importantly, however, our estimated returns to class reductions are at least
3 times larger in data from Southern Italy than for the rest of the country. Estimates for
Northern and Central Italy are small and only marginally significantly diﬀerent from zero.
Modern Italy is characterized by a sharp North-South divide along many dimensions, a
fact that motivates our investigation of regional class size eﬀects. The South, known as the
Mezzogiorno, is distinguished by persistently higher unemployment, lower per-capita income,
higher crime rates, and lower educational attainment than are characteristic of other Italian
regions.2 The Mezzogiorno also lags the rest of Italy in financial development (Guiso et al.,
2004), political accountability (Nannicini et al., 2013), and workplace productivity (Ichino
and Maggi, 2000). Italy’s North-South divide, which is larger and more persistent than
diﬀerences seen across America’s Mason-Dixon line, has been linked to cultural diﬀerences
and diﬀerences in residents’ view of the role of government (Putnam et al., 1993).
Against a backdrop of relative under-development, the Mezzogiorno is also distinguished
by widespread manipulation on the standardized tests given in Italian primary schools. This
can be seen in Figure 1, which reproduces provincial estimates of score manipulation from
the Italian Instituto Nazionale per la Valutazione del Sistema dell’Istruzione (INVALSI), a
government agency charged with educational assessment. Classes in which scores are likely to
have been manipulated are identified through a statistical model that looks for surprisingly
high average scores, low within-class variability, and implausible missing data patterns.3
Measured in this way, about 5 percent of scores are compromised, much as reported for
Chicago elementary schools by Jacob and Levitt (2003). In Southern Italy, however, the
2

The Mezzogiorno consists of the administrative regions of Basilicata, Campania, Calabria, Puglia,
Abruzzo, Molise, and the islands of Sicily and Sardinia. Italy’s 20 Administrative regions are further divided into over 100 provinces.
3
The INVALSI testing program is described below and in INVALSI (2010). The INVALSI score manipulation variable identifies classes with substantially anomalous score distributions, imputing a probability of
manipulation for each (see Quintano et al., 2009). Figure 1 uses this variable for the 2009-11 scores of second
and fifth graders.

2

proportion of compromised exams averages about 14 percent (see Table 1) and reaches 25
percent in some provinces. Further evidence on score manipulation comes from Bertoni et
al. (2013), who analyze data generated by the random assignment of school monitors. This
analysis also uncovers evidence of a substantial regional gradient in score manipulation.
We argue here that score manipulation in Italian primary schools reflects teacher behavior and that teachers’ perceived cost of dishonest score reporting increases with class size
(institutional forces that link class size with score manipulation are detailed below). A juxtaposition of regional patterns in the causal eﬀects of class size on achievement and the causal
eﬀects of class size on score manipulation uncovers striking parallels in the two empirical relationships. This parallelism leads us to model achievement as a function of two endogenous
variables, class size and score manipulation. The model is identified by a combination of
Maimonides’ Rule and randomly assigned school monitors. The resulting estimates suggest
that the relationship between class size and INVALSI test scores is explained entirely by
score manipulation.
After showing that putative class size eﬀects come solely from score manipulation, we turn
to the nature and motivation for manipulation, arguing first that manipulation reflects the
behavior of teachers and not of students. We then lay out a model that distinguishes two sorts
of moral hazard in teacher behavior. The first - dishonesty or conventional cheating - arises in
part from the high stakes accountability pressure that appears to induce score manipulation
of various kinds in many American schools. The second is moral hazard in teacher grading
eﬀort, in other words, shirking. An item level analysis of test score diﬀerentials across
regions suggests that, in Italy and especially in the South, shirking is more important than
conventional cheating.
Why is the fact that score manipulation explains class size eﬀects in the Mezzogiorno of
general interest? The Maimonides’ Rule research design is motivated by an eﬀort to quantify
causal class size eﬀects. This design is not guaranteed to work; Urquiola and Verhoogen (2009)
show how endogenous sorting by students induces selection bias in comparisons across class
size caps in Chilean private schools. By contrast, our analysis uncovers a substantive problem
inherent in analyses of the causal eﬀects of class size, regardless of research design. We show
that even where the evidence that class size aﬀects test scores is uncompromised, this need
not signal increased learning in smaller classes. Our findings also provide evidence of moral
3

hazard in a system with weak incentives. Italian teachers work in a highly regulated public
sector, with virtually no risk of termination, and are subject to a pay and promotion structure
that’s largely independent of performance. In contrast with the unintended consequences of
test-based accountability regimes, the manipulation uncovered here arises because worker
performance standards are weak. It seems fair to say that Italian moral hazard arises from
a lack of accountability rather than an over-abundance of it. Finally, concerns with teacher
shirking are far from unique to Italy. Clotfelter et al. (2009) discusses distributional and
other consequences of American teacher absenteeism, while teacher absenteeism and other
forms of shirking are a perennial concern in developing countries (see Banerjee and Duflo,
2006 and Chaudhury et al., 2006).
The rest of the paper is organized as follows. The next section presents institutional background on Italian schools and tests. Section 3 describes our data and documents the Maimonides’ Rule first stage. Following a brief graphical analysis, Section 4 reports Maimonidesstyle estimates of eﬀects of class size on achievement and score manipulation. Section 5 uses
the monitoring experiment and Maimonides’ Rule to jointly estimated class size and manipulation eﬀects. This section also reviews possible threats to validity in our research design.
Finally, Section 6 explains how and why manipulation takes place.

2

Background

Italian Schools and Tests
Primary and Secondary schooling in Italy are compulsory from ages 6 to 16, with three stages:
5 years of elementary school (scuola elementare), lower secondary school covering grades 6-8
(scuola media), and high school (scuola superiore), which runs for 3-5 years. Schools are
organized into single- or multi-unit institutions, much as a single campus might house more
than one school in American public systems. Teachers are paid by seniority, without regard
to qualifications, performance, or conduct.
Families apply for school admission in February, well before the beginning of the new
academic year in September. Parents or legal guardians typically apply to a school in their
province, located near their home. In (rare) cases of over-subscription, distance usually
determines who has a first claim on seats. Rejected applicants contact other schools, mostly
4

nearby. School principals group students into classes and assign teachers over the summer,
but parents learn about class composition only in September, shortly before school starts.
At this point, parents who are unhappy with a teacher or classroom assignment are likely to
find it diﬃcult to change schools.
Italian schools have long used matriculation exams for tracking and placement in the
transition from elementary to middle school and throughout high school, but standardized
testing for evaluation purposes is a recent development. In 2008, INVALSI piloted voluntary assessments in elementary school; in 2009 these became compulsory for all schools and
students. INVALSI assessments cover mathematics and Italian language skills in a national
administration lasting two days in the Spring.4 Tests are proctored by local administrators
and teachers. Proctors and other teachers are expected to copy students’ original responses
onto machine-readable answer sheets (called scheda risposta), which are then sent to INVALSI. The transcription process is not entirely mechanical: some questions require teachers
to interpret a student’s original response as being correct, incorrect, or missing, in eﬀect, a
form of grading. Sample test items and a score sheet are included here in a brief appendix.
This transcription procedure opens the door to score manipulation, as does the fact that
INVALSI test administrations are typically proctored by teachers.5
Related work
Maimonides-style empirical strategies have been used to identify class size eﬀects in many
countries, including the US (Hoxby, 2000), France (Piketty, 2004 and Gary-Bobo and Mahjoub,
2006), Norway (Bonesronning, 2003 and Leuven et al., 2008) and the Netherlands (Dobbelsteen et al., 2002). On balance these results point to modest returns to size reductions,
though mostly more modest than found by Angrist and Lavy (1999) for Israel. A natural
explanation for the relatively large Israeli findings is the unusually large classes characteristic
of Israeli elementary schools. In line with this view, Woessmann (2005) finds a weak associa4

INVALSI reports school and class average scores to schools but not students. School leaders may
choose to release this information to the public. Individual test scores are not reported or released. See
http://www.invalsi.it for additional background.
5
Teacher proctoring and local grading is a feature shared with other European assessments. For example, local teachers mark the UK’s Key Stage 1 assessments (given in year 2, usually at age 7). Key
Stage 2 assessments given at the end of elementary school (usually at age 11) are locally proctored
with unannounced external monitoring and external marking (grading). See documents and links at
http://www.education.gov.uk/sta/assessment.

5

tion between class size and achievement in a cross-country panel covering Western European
school systems in which classes tend to be small.
The returns to class size in Italy have received little attention from researchers to date, in
large part because test score data have only recently become available. Among the few Italian
studies we’ve seen, Bratti et al. (2007) report regression estimates showing an insignificant
class size eﬀect. In an aggregate analysis, Brunello and Checchi (2005) look at the relationship between staﬃng ratios and educational attainment for cohorts born before 1970; they
find that higher pupil-teacher ratio at the regional level are associated with higher average
schooling attainment. We haven’t seen other quantitative explorations of Italian class size,
though Ballatore et al. (2013) use a related identification strategy to estimate the eﬀects of
immigrants in the classroom on native achievement.
Jacob and Levitt (2003) and Dee et al. (2011) quantify teacher cheating on standardized
assessments in Chicago and New York. The (natural) experiment used here to identify the
eﬀects of Italian score manipulation and class size jointly was first analyzed by Bertoni et
al. (2013). Our analysis of this experiment looks at monitoring eﬀects by region, while
also adjusting for features of the intervention sampling scheme not fully accounted for in
earlier work. The resulting estimates suggest that the presence of classroom monitors sharply
reduces score manipulation, and that manipulation boosts measured scores dramatically.
Both of these eﬀects are much larger in Southern Italy. Elsewhere in Italy, manipulation is
relatively rare.
Scholars have documented a range of economic and behavioral diﬀerences across Italian
regions. Southern Italy is characterized by low levels of social capital (Guiso et al., 2004;
Guiso et al., 2010) and more widespread opportunistic or anti-social behavior (Ichino and
Maggi, 2000; Ichino and Ichino, 1997). Diﬀerences along these dimensions have been used
to explain persistent regional diﬀerentials in economic outcomes (Costantini and Lupi, 2006)
and diﬀerences in the quality of local institutions (Putnam et al., 1993). Finally, as noted in
the introduction, our work connects with research on teacher shirking around the world.

6

3

Data and First Stage

Data and descriptive statistics
The standardized test score data used in this study come from INVALSI’s testing program
in Italian elementary schools in the 2009/10, 2010/11, and 2011/12 school years. Raw scores
indicate the number of correct answers; for the purposes of regression and two-stage least
squares (2SLS) estimation, we standardized these by subject, year of survey, and grade to
have zero mean and unit variance. Data on test scores were matched to administrative and
survey information describing institutions, schools, classes, and students. Class size can be
measured by administrative enrollment counts at the beginning of the school year as well
as the number of test-takers (we use the former). Student data include gender, citizenship,
and information on parents’ employment status and educational background. These data are
collected as part of test administration and supposed to be provided by school staﬀ when
scores are submitted. Fewer than 10 percent of Italian primary and secondary school students
who attend private schools are omitted from this study.
Our statistical analysis focuses on class-level averages since this is the aggregation level
at which the regressor of interest varies. The empirical analysis is restricted to classes with
more than the minimum number of students set by law (10 before 2010 and 15 from 2011).
This selection rule eliminates classes in the least populated areas of the country, mostly
mountainous areas and small islands. We also drop schools enrolling more than 160 students
in a grade, as these are above the threshold where Maimonides’ Rule is likely to matter
(this size cutoﬀ trims classes above the 99th percentile of the enrollment-weighted class size
distribution).
The resulting matched file includes about 70,000 classes in each of the two grades covered
by our three-year window. Table 1 shows descriptive statistics for the estimation sample,
separately by grade. Statistics are reported at the class level in Panel A, at the school level
in Panel B, and at the institution level in Panel C. Class size averages around 20 in both
grades, and is slightly lower in the South. The score means reported in Panel A give the class
average percent correct. Scores are higher in language than in math and higher in grade 5
than in grade 2. The table also shows averages for an indicator of score manipulation variable
that we’ve constructed (Section 3, below, explains how this was done). Manipulation rates
7

are higher in the South and in math.
Maimonides in Italy
Our identification strategy exploits minimum and maximum class sizes for Italy (these rules
are a consequence of a regulation known as Decreto Ministeriale 331/98 ). Until the 2008/09
school year, primary school classes were subject to a minimum size of 10 and capped at 25.
Grade enrollment beyond 25 or a multiple thereof usually prompted the addition of a class.
The rule allows exceptions, however. Principals can reduce the size of classes attended by
one or more disabled students, and schools in mountainous or remote areas are allowed to
open classes with fewer than 10 students. Finally, the law allows a 10% deviations from
the maximum in either direction (that is, the Ministry of Education will usually fund an
additional class when enrollment exceeds 22 and typically requires a new class when average
enrollment would otherwise exceed 28). A 2009/10 reform increased the nominal maximum
to 27, with a minimum size of 15, again with a tolerance of 10% (promulgated through
Decreto del Presidente della Repubblica 81/2009 ). This reform was rolled out one grade per
year, starting with grade 1. In our data, second graders in 2009/10 and fifth graders in any
year are subject to the old rule, while second graders in 2010/11 and 2011/12 are subject to
the new rule.
Ignoring discretionary deviations near cutoﬀs, Maimonides’ Rule predicts class size to be
a non-linear and discontinuous function of enrollment. Writing figkt for the predicted size of
class i in grade g at school k in year t, we have:
figkt =

[int ((rgkt

rgkt
,
1) /cgt ) + 1]

(1)

where rgkt is beginning-of-the-year grade enrollment at school k, cgt is the cap in eﬀect that
year (25 or 27) in grade g, and int(x ) is the largest integer smaller than or equal to x . Figure
2 and Figure 3 plot average class size and figkt against enrollment in grade, separately for
pre- and post-reform periods. Plotted points show the average actual class size at each value
of enrollment. Actual class size follows predicted class size reasonably closely for enrollments
below about 75, especially in the pre-reform period. Theoretical sharp corners in the class
size/enrollment relationship are rounded by the soft nature of the rule. Many classes are
split before reaching the theoretical maximum of 25. Earlier-than-mandated splits occur
8

more often as enrollment increases. In the post-reform period, class size tracks the rule
generated by the new cap of 27 poorly once enrollment exceeds about 70.
Measuring Manipulation
The score manipulation variable used here is a function of extreme values, the within-class
average and standard deviation of test scores, the number of missing items, and a Herfindahl
index of the share of students with similar response patterns. These indicators are used as inputs for a cluster analysis that flags as suspicious classes with abnormally high performance,
an unusually small dispersion of scores, an unusually low proportion of missing items, and
high concentration in response patterns. This procedure yields class-level indicators of compromised scores, separately for math and language. Our manipulation indicator is similar
to that used by Quintano et al. (2009) and in INVALSI publications (e.g., INVALSI, 2010).
The INVALSI version generates a continuous class-level probability of manipulation. The
procedure used here generates a dummy variable indicating classes where score manipulation
seems likely.6 Methods and formulas used to classify score manipulation are detailed further
in the appendix.

4

Class Size Eﬀects: Achievement and Manipulation

Graphical Analysis
We begin with plots that capture class size eﬀects near enrollment cutoﬀs. The first in this
sequence, Figure 4, documents the relationship between cutoﬀs (multiples of 25 or 27) and
class size. This figure was constructed from a sample of classes at schools with enrollment
that falls in a [-12,12] window around the first four cutoﬀs shown in Figure 2 and Figure 3.
Enrollment values in each window are centered to be zero at the relevant cutoﬀ. The y-axis
shows average class size conditional on the centered enrollment value shown on the x-axis,
reported as a 3-point moving average. Figure 4 also plots fitted values generated by local
linear regressions (LLR) fits to class-level data. In this context, the LLR smoother uses data
6

Our procedure also follows Jacob and Levitt (2003) in inferring score manipulation from patterns of
answers within and across tests in a classroom. Jacob and Levitt (2003) also compare test scores over time,
looking for anomalous changes. Values in the upper tail of the Jacob-Levitt suspicious answer index are
highly predictive of their cheating variable.

9

on one side of the cutoﬀ only, smoothed with an edge kernel and Imbens and Kalyanaraman
(2012) bandwidth.7
In view of the 2-3 student tolerance around the cutoﬀ for the addition of a class, enrollment
within two points of the cutoﬀ is excluded from the local linear fit. As a result of this
tolerance, class size can be expected to decline at enrollment values shortly before the cutoﬀ
and to continue to decline thereafter. Consistent with this expectation, the figure shows
a clear drop at the cutoﬀ, with the sharpness of the break moderated by values near the
cutoﬀ. Class size is minimized at about 3-5 students to the right of the cutoﬀ instead of
immediately after, as we would expect were Maimonides Rule to be tightly enforced. The
parametric identification strategy detailed below exploits both the discontinuous variation in
class size generated when enrollment moves across cutoﬀs and changes in slope as a cohort is
divided into classes more finely. Looking only at points immediately adjacent to the cutoﬀ,
the change in size generating by moving across a cutoﬀ is on the order of 2-3 students.
In data from the South, math and language scores plotted as a function of enrollment
values near Maimonides cutoﬀs show a jump that mirrors the drop in size seen at Maimonides
cutoﬀs, but there is little evidence of such a jump in schools outside the South. This pattern is
documented in Figure 5, which plots math and language scores against enrollment in a format
paralleling that of Figure 4. The reduced-form achievement drop for schools in Southern Italy
is about 0.02 standard deviations (hereafter, ). Assuming this reduced-form change in test
scores in the neighborhood of Maimonides cutoﬀs is driven by a causal class size eﬀect, the
implied return to a one-student reduction in class size is about 0.01 in Southern Italy (this
comes from dividing 0.02 by a rough first stage of about 2). The absence of a jump in scores
at cutoﬀs in data from schools elsewhere in the country suggests that outside the South class
size reductions leave scores unchanged.
Score manipulation also varies as a function of enrollment in the neighborhood of class
size cutoﬀs, with a pattern much like that seen for achievement. This is apparent in Figure 6,
which puts the proportion of classes identified as having compromised scores on the y-axis, in
a format like that used for Figure 4 and Figure 5. Mirroring the pattern of achievement eﬀects,
a discontinuity in score manipulation rates emerges most clearly for schools in Southern Italy.
7

The figures here plot residuals from a regression of class size on the controls included in equation (2),
below.

10

This pattern suggest the achievement gains generated by class size in Figure 5 may reflect
the manipulation behavior captured in Figure 6.
Empirical Framework
Figure 5 suggests that variation in class size near Maimonides cutoﬀs can be used to identify
class size eﬀects in a non-parametric fuzzy regression discontinuity (RD) framework. In
what follows, however, we opt for parametric models that exploit variation in enrollment
due to changes in the slope of the relationship between enrollment and class size, as well
as discontinuities. The parametric strategy gains power by combining features of both RD
and regression kink designs, while easily accommodating models with multiple endogenous
variables and covariates.8
Our parametric framework models yigkt , the average outcome score in class i in grade g
at school k in year t, as a polynomial function of the running variable, rgkt , and class size,
sigkt . With quadratic running variable controls, the specification pooling grades and years
can be written:

2
yigkt = ⇢0 (t, g) + sigkt + ⇢1 rgkt + ⇢2 rgkt
+ ✏igkt ,

(2)

where ⇢0 (t, g) is shorthand for a full set of year and grade eﬀects. This model also controls
for the demographic variables described in Table 1, as well as the stratification variables used
in the monitoring experiment to increase precision in the estimates.9 Standard errors are
clustered by institution, which we reckon to be a conservative strategy in this context.
The instrument used for 2SLS estimation of equation (2) is figkt , as defined in equation
(1). To document the sensitivity of findings to specification of running variable controls,
we also report results from models that include a full set of cutoﬀ-segment (window) main
eﬀects, while allowing the quadratic control function to diﬀer across segments. We refer to
this as the interacted specification.10 The corresponding OLS estimates for models without
interacted running variable controls are shown as a benchmark.
8

Card et al. (2012) discuss nonparametric identification in the regression kink design.
Control variables include proportion female in the class, the proportion of immigrants, the proportion of
students whose father is a high school graduate, have unemployed mothers, have mothers not in the labor
force, have employed mothers, and dummies for missing values for these variables. Stratification controls
consist of total enrollment in grade, region dummies, and the interaction between enrollment and region.
10
Pre-reform segments cover the intervals 10-37, 38-62, 63-87, 88-112, 113-137, and 138-159; post-reform
segments cover the intervals 15-40, 41-67, 68-94, 95-121, and 122-159. These segments cover intervals of
width +/- 12 in the pre-reform period and +/-13 in the post-reform period, with modifications at the lower
and upper segments to include a few larger and smaller values.
9

11

Parametric Estimates of Class Size Eﬀects
OLS estimates of equation (2) show a negative correlation between class size and achievement
for schools in the Northern and Central regions, but not in the South (class size eﬀects are
scaled for a 10 student change). Larger classes are associated with somewhat higher language
scores in the South while Southern class sizes appear to be unrelated to achievement in math.
These estimates can be seen in columns 1-3 of Table 2.
2SLS estimates using Maimonides’ Rule, reported in columns 4-9 of Table 2, suggest that
larger classes reduce achievement in both math and language. The associated first stage
estimates, which can be seen in Appendix Table A1, show that predicted class size increases
actual class size with a coeﬃcient around one-half when regions are pooled, with a first
stage eﬀect of 0.43 in the South and 0.55 elsewhere. 2SLS estimates for Southern schools,
implying something on the order of a 0.10 achievement gain for a 10-student reduction, are
2-3 times larger than the corresponding estimates for schools outside the South. The 2SLS
estimates are reasonably precise; only estimates of the interacted specification for language
scores from non-Southern schools fall short of conventional levels of statistical significance.
On balance, the results in Table 2 indicate a substantial achievement payoﬀ to class size
reductions, though the gains here are not as large as those reported by Angrist and Lavy
(1999) for Israel. A substantive explanation for this diﬀerence in findings might be concavity
in the relationship between class size and achievement, combined with Italy’s much smaller
average class sizes.
The estimates in Table 3 suggest that the causal eﬀect of class size on measured achievement reported in Table 2 need not reflect more learning in smaller classes. This table reports
estimates from specifications identical to those used to construct the estimates in Table 2,
with the modification that a class-level score manipulation indicator replaces achievement
as an outcome. The 2SLS estimates in columns 4-9 show a large and precisely-estimated
negative eﬀect of class size on manipulation rates, with eﬀects on the order of 4-6 percentage
points for a 10-student class size increase in the South. Estimates for schools outside the
South also show a negative relationship between class size and score manipulation, though
here the estimated eﬀects are much smaller and significantly diﬀerent from zero in only one
case (language scores from the non-interacted specification). Interestingly, OLS estimates of
eﬀect of class size on score manipulation, though smaller in magnitude, reflect the same neg12

ative eﬀects as 2SLS. This suggests that the relationship between class size and manipulation
may have a mechanical component, less aﬀected by the sort of selection bias that aﬀects OLS
estimates of the corresponding achievement relation.

5

Models with Two Endogenous Variables

5.1

The Monitoring Experiment

The estimates in Table 3 treat score manipulation as an outcome variable in a notional class
size experiment. We’re also interested in score manipulation as a causal channel in a multivariate model that simultaneously links both class size and manipulation with measured
achievement. We therefore turn to INVALSI’s monitoring intervention as an independent
source of quasi-experimental variation in score manipulation, unrelated to Maimonides’ Rule.
In an eﬀort to increase test reliability, INVALSI randomly selects institutions to be observed
by an external monitor. Institutions are sampled for monitoring with a probability proportional to grade enrollment in the year of the test. Sampling is also stratified by regions.
Within sampled institutions, classroom monitors are meant to be randomly assigned to one
or two classes per grade, though randomness of within-institution monitoring appears to have
been compromised in practice.
Regional education oﬃces select monitors from a pool of mainly retired teachers and
principals who’ve not worked in the towns or at the schools they are assigned to monitor for
at least two years. Monitors supervise test administration and encourage compliance with
INVALSI testing standards. Importantly, monitors also supervise score sheet transcription,
a clerical task (described further, below) that’s meant to be completed by the end of the test
day. Tests without monitors are proctored by local school staﬀ (though the math teacher for
a given grade is not supposed to be assigned to proctor that grade’s test and so on). The
eﬀect of monitoring on score manipulation in this experiment was first reported by INVALSI
(2010). We replicate some of these earlier findings, as well as those reported in a related
study by Bertoni et al. (2013), in an analysis that distinguishes between Southern Italy and
the rest of the country.
As a preliminary, Table 4 documents balance across institutions with and without ran-

13

domly assigned monitors. This table reports regression-adjusted treatment-control diﬀerences
from models that control for strata in the monitoring intervention sample design. Specifically,
these specifications include a full set of region dummies and a linear function of institutional
grade enrollment that varies by regions. Standard errors are clustered by institution. Administrative variables – generated as a by-product of school administration and INVALSI testing
– are well-balanced across groups, as can be seen in the small and insignificant coeﬃcient
estimates reported in Panel A of the table.11
Demographic data and other information provided by school staﬀ, such as parental information, show evidence of imbalance. This seems likely to reflect the influence of monitoring
on data quality, rather than a problem with the experimental design or implementation. The
hypothesis that monitors induced more careful data reporting by staﬀ is supported by the
large treatment-control diﬀerential in missing value rates documented at the bottom of the
table. Among other salutary eﬀects, randomly assigned monitors reduce item non-response
by as much as three percentage points, as can be seen in Panel C of Table 4. Monitoring
eﬀects on data quality at class size cutoﬀs are discussed in Section 5.3.
The presence of institutional monitors reduces score manipulation considerably. This
can be seen in the estimated monitoring eﬀects in columns 1-3 of Table 5, which suggest
monitoring reduces manipulation rates by about 3 percentage points for Italy, with eﬀects
twice as large in the South. These estimates come from models similar to those used to check
covariate balance with a score manipulation indicator replacing covariates as the dependent
variable. Monitoring also reduces language scores by 0.08 , while the estimated monitoring
eﬀect on math scores is about
the South, ranging from

0.11 . Here too, eﬀects of monitoring are much larger in

0.13 for language to

0.18 for math, estimates that appear in

column 6 of the table. The large eﬀect of monitoring on score manipulation suggests that
the latter reflects teacher behavior and not that of students: honest teacher-proctors should
have the same deterrent eﬀect on student cheaters as external monitors. If anything, teachers
who know their students well should curb student cheating more eﬀectively than outsiders.
We also see from Table 3 that increasing class size reduces score manipulation, a finding at
odds with the idea that students find it easier to cheat in large classes.
11

Bertoni et al. (2013) mistakenly treated institutions as schools. Their identification strategy also presumes random assignment of classroom monitors within institutions, but we find that monitors are much
more likely to be assigned to large classes.

14

The estimates reported in columns 1-3 and 4-6 of Table 5 constitute the first stage and
reduced form for a model that uses the assignment of monitors as an instrument for the
eﬀects of score manipulation on test scores. Dividing reduced form estimates by the corresponding first stage estimates produces second stage manipulation eﬀects of about 3 for the
South, with even larger second stage estimates for the North. These eﬀects seem implausibly
large, implying a boost in scores that exceeds the range of the dependent variable in some
cases. It also seems likely, however, that the score manipulation variable used to construct
the corresponding first stage eﬀects is substantially mismeasured. Because classification error attenuates first stage estimates, the resulting second stage estimates are proportionally
inflated. This and other implications of missclassification are discussed after reviewing estimation results that simultaneously capture class size and manipulation eﬀects on test scores.

5.2

Estimates with Two Endogenous Variables

The estimates in Table 2, Table 3, and Table 5 motivate a causal model in which achievement
depends on class size (sigkt ) and score manipulation (migkt ), both treated as endogenous
variables to be instrumented. This model can be written:
yigkt = ⇢0 (t, g) +

1 sigkt

+

2 migkt

2
+ ⇢1 rgkt + ⇢2 rgkt
+ ⌘igkt ,

(3)

where ⇢0 (t, g) is again a shorthand for year and grade eﬀects. We interpret equation (3)
as describing the average achievement that would be revealed by alternative assignments of
class size, sigkt , in an experiment that holds migkt fixed. This model likewise describes causal
eﬀects of changing score manipulation rates in an experiment that holds class size fixed. In
other words, (3) is a model for potential outcomes indexed against two jointly manipulable
treatments.
We estimate equation (3) by 2SLS in a setup that includes the same covariates that
appear in the models used to construct the estimates reported in Table 2. The instrument
list contains Maimonides’ Rule (figkt ) and a dummy indicating classes at institutions with
randomly assigned monitors, M igkt . The first-stage equations associated with these two
instruments can be written:
sigkt =

10 (t, g)

+ µ11 figkt + µ12 M igkt +
15

11 rgkt

+

2
12 rgkt

+ ⇠ik ,

(4)

migkt =
where

10 (t, g)

and

20 (t, g)

20 (t, g)

+ µ21 figkt + µ22 M igkt +

21 rgkt

+

2
22 rgkt

+

ik ,

(5)

are shorthand for first-stage year and grade eﬀects. First stage

estimates, reported in Table 6, show both a monitoring and a Maimonides’ Rule eﬀect on
score manipulation, both of which are considerably more pronounced in the South. The
Maimonides first stage for class size remains at around one-half, while the presence of a
classroom monitor is unrelated to class size. This is consistent with the hypothesis that
monitors are randomly assigned to institutions.
The 2SLS estimates of

2

in equation (3), reported in Table 7, show large eﬀects of ma-

nipulation on test scores. At the same time, this table reports small and mostly insignificant
estimates of

1,

the coeﬃcient on class size in the multivariate model. In an eﬀort to boost

the precision of these estimates, we estimated over-identified models that add four dummies
for values of the running variable that fall within 10% of each cutoﬀ, a specification motivated
by the non-parametric first stage captured in Figure 4.12 The most precise of the estimated
zeros reported in Table 7, generated by the over-identified specification for Italy as a whole,
run no larger than 0.022, with an estimated standard error of 0.015 (for a 10 student increase
in class size); these appear in column 4. Its also worth noting that the over-identification
p-values associated with these estimates are far from conventional significance levels.
We also report 2SLS estimates adding an interaction term, sigkt ⇤ migkt , to equation

(3), using figkt ⇤ Migkt and the extra dummy instruments interacted with Migkt as excluded

instruments. This specification is motivated by the idea that class size may matter only
in a low-manipulation subsample, while an additive model like equation (3) may miss this.
There is little evidence for interactions, however: the estimated interaction eﬀects, reported
in columns 7-9 of Table 7 are not significantly diﬀerent from zero.
The most important findings in Table 7 are the small and insignificant class size eﬀects for
the Mezzogiorno, a result that contrasts with the much larger and statistically significant class
size eﬀects for the same area reported in Table 2. In column 9 of the latter table, for example,
a 10 student reduction in class size is estimates to boost achievement by 0.10 or more. The
corresponding multivariate estimates in Table 7 are of the opposite sign, showing that larger
classes increase achievement, though not by very much. The over-identified estimates come
with estimated standard errors ranging from about 0.02 to 0.04, so that the estimated class
12

First stage estimates for the over-identified model appear in Appendix Table A2.

16

size eﬀects in Table 2 fall well outside the estimated confidence intervals associated with the
multivariate estimates. It seems reasonable, therefore, to interpret the estimated class eﬀects
in Table 7 as precise zeros. This in turn aligns with an interpretation of the return to class
size in Italy as due entirely to the causal eﬀect of class size on score manipulation, most likely
by teachers.

5.3

Threats to validity

We briefly consider three possible threats to validity in our research design. An initial concern
comes from the fact that one of the four indicators used to construct the score manipulation
dummy, unusually high average scores, may be connected to the outcome of interest for reasons unrelated to manipulation. We therefore constructed a manipulation variable excluding
this component. RD estimates of the relationship between class size, score manipulation,
and achievement, are largely unaﬀected by this change. Two other concerns relate to measurement error in score manipulation and potentially endogenous sorting around class size
cutoﬀs.
Score manipulation with misclassification
The large 2SLS estimates of manipulation eﬀects in Table 7 reflect attenuation bias in first
stage estimates if score manipulation is misreported. We show here that as long as misclassification rates are independent of the instruments, mismeasurement of manipulation leaves
2SLS estimates of class size eﬀects in the multivariate model unaﬀected. We show this in
the context of a simplified version of the multivariate model, which can be written with a
class subscript as:
yi = ⇢ 0 +

1 si

+

⇤
2 mi

+ ⇣i ,

(6)

where instruments are assumed to be uncorrelated with the error, ⇣i , as in equation (3).
Here, m⇤i is an accurate score manipulation dummy for class i, while mi is observed score
manipulation as before.
Let zi = [fi Mi ]0 denote the vector of instruments. Assuming that classification rates are
independent of the instruments conditional on m⇤i , we can write:
mi = (1

⇡0 ) + (⇡0 + ⇡1
17

1)m⇤i + !i ,

(7)

where the residual, !i , is defined by:
!i = mi

E[mi |zi , m⇤i ],

and ⇡d , the probability that score manipulation is correctly detected, satisfies:
(8)

P [mi = d|zi , m⇤i = d] = P [mi = d|m⇤i = d] = ⇡d ,
for d = 0, 1. Note that E[zi !i ] = 0 by definition of !i .
Using (7) to substitute for m⇤i , equation (6) can be rewritten:



⇡0 )
2 (1
2
+ 1 si +
m i + ⇣i
y i = ⇢0
⇡ 0 + ⇡1 1
⇡ 0 + ⇡1 1

2

!i
⇡ 0 + ⇡1

1

.

(9)

We assume that the ⇡d ’s are strictly greater than 0.5, so that reported score manipulation is
a better indicator of actual manipulation than a coin toss. This ensures that the coeﬃcient
on mi in (9) is finite and has the same sign as

2.

The 2SLS estimate of the coeﬃcient on

reported score manipulation is therefore biased upward, since ⇡0 + ⇡1
0 and 1 given these assumptions. This implies that estimates of

2

1 is strictly between
for the North/Centre

region (columns 2, 5 and 8 of Table 7), where score manipulation is lower and therefore
misclassification is higher, are more inflated than in the South. Most importantly, because
the feasible estimating equation (9) has a residual uncorrelated with the instruments and
the coeﬃcient on class size is unchanged in this model, misclassification of the sort described
by (8) leaves estimates of the class size coeﬃcient,

1,

unchanged. Similar results for the

consequences of classification error appear in Kane et al. (1999), Mahajan (2006), and Lewbel
(2007), among others, though our work focuses on the consequences for the coeﬃcient on a
variable subject to error rather than implications for other regressors in the model.13
13

We can learn whether 2SLS estimates of the coeﬃcient on mi , that is, the size of the estimated manipulation eﬀects, are plausible by experimenting with data from an area where manipulation rates are low and
assuming that true manipulators earn perfect scores. We use data from Veneto, the region with the lowest
score manipulation rate in Italy, to estimate 2 in this scenario by picking 20% of classes at random and
recoding scores for this group to be 100. The resulting estimates of 2 come out at around 2.25 . Taking
this as a benchmark, the manipulation eﬀects in Table 7 are consistent with values of ⇡j around .8 for Italy
2.25
0
(since 2⇥.8
1 = 3.75), though the implied ⇡j s are closer to .65 for math scores outside the South. These
rates seem like reasonable descriptions of the classification process.

18

Sorting near cutoﬀs
The Maimonides research design identifies causal class size eﬀects assuming that, after adjusting for secular eﬀects of the running variable, predicted class size (figkt ) is unrelated to
student or school characteristics. As in other RD-type designs, sorting around cutoﬀs poses a
potential threat to this assumption. Urquiola and Verhoogen (2009) and Baker and Paserman
(2013) note that discontinuities in student characteristics near Maimonides cutoﬀs can arise
if parents or school authorities try to shift enrollment to schools where expected class size is
small. In our setting, however, an evaluation of the sorting hypothesis is complicated by the
link between Maimonides’ Rule and score manipulation documented in Table 6. The fact that
Maimonides’ Rule predicts score manipulation, especially in the South, generates the results
in Table 7. An important channel for the link between Maimonides’ Rule and manipulation,
detailed in the next section, is the fact that monitoring rates fall as class sizes increases. If
the behavior driving manipulation also aﬀects data quality, a conjecture supported by the
eﬀects of monitoring on data quality seen in Table 4, we might expect Maimonides’ Rule to
be related to covariates for the same reason that monitoring is related to covariates.
This expectation is borne out by Table 8, which reports estimates of the link between
between Maimonides’ Rule and covariates in a format paralleling that of Table 4. These
estimates come from the reduced from specifications used to generate the 2SLS estimates
reported in Table 2, after replacing scores with covariates on the left hand side. The pattern
of covariate imbalance in Table 8 mirrors that in Table 4: covariates aﬀected by monitoring
are also correlated with Maimonides’ Rule, while administrative variables that are unrelated
to monitoring are largely orthogonal to Maimonides’ Rule. Tables 4 and 8 also reflect similar
regional diﬀerences in the degree of covariate imbalance, with considerably more imbalance in
the South. Additional evidence suggesting that the link between covariates is a data quality
eﬀect unrelated to sorting appears in Appendix Table A3. This table shows that the figkt is
largely unrelated to covariates in schools with monitors, where manipulation is considerably
diminished (though not necessarily eliminated, since some classes in monitored institutions
remain unmonitored).

19

6

Explaining Manipulation

The fact that classroom monitoring sharply reduces test scores points to teachers as the source
of manipulation and not students. Honest teacher-proctors should have the same deterrent
eﬀect as external monitors on cheating students: both are likely to catch cheaters, teachers
even more so if they recognize cheating more readily. External monitoring should therefore
have little eﬀect on student cheating unless cheating is accomplished with the collaboration
or at least assent of school staﬀ. Moreover, it seems likely that any class size eﬀect on student
cheating is positive, that is, larger classes should facilitate student cheating. Results in Table
3 showing that score manipulation decreases with class size therefore weigh against student
cheating as well. Finally, because individual scores are never disclosed, its hard to see why
students might want to cheat.
It remains to explain why large classes reduce teacher manipulation rates. An important
institutional factor generating this link is the fact that when enrollment is below 100, monitors
observe a single class, while at institutions with larger grade enrollments they observe at most
two. Consequently, conditional on enrollment, the odds a class is monitored are increasing
in class size.14 In addition, INVALSI staﬀ report that teachers help their students in many
locally proctored exams; if aid is given to individual students, increasing class size probably
reduces the proportion assisted. Larger classes also make inappropriate teacher aid less
discrete (the fact that external monitoring reduces score manipulation, as shown in Section
5.1, suggests those doing the manipulation see exposure as undesirable).
Score manipulation is almost certainly facilitated by the need for local proctors and teachers to interpret and transcribe students’ original answers onto the scheda risposta within a
few days of the test. This task requires transcribers to decide whether answers are correct
or missing. Open items require thought and interpretation, so that transcription becomes
a form of grading. Large classes therefore seem likely to reduce manipulation in the transcription process for two reasons. First, the number of teachers proctoring and transcribing
probably increases in larger classes, possibly limiting the extent of manipulation through peer
monitoring (transcription work is often assigned by allocating a fixed number of exams per
transcriber). Second, some teachers either cheat or simply shirk transcription duties by curb14

A regression like those used to construct the estimates in Table 8 shows a 10 student class size reduction
reduces monitoring rates within institutions by 3.5 points in the South and 2.8 points elsewhere.

20

stoning, that is, copying all or part of an answer key onto the scheda risposta. Curbstoning
of correct answers is probably less accurate in large classes. Of course, transcription accuracy
may fall with class size without regard to cheating. Weighing against a pure accuracy-intranscription eﬀect, however, is the fact that the relationship between class size and test
scores disappears once manipulation is taken into account. Honest transcribers would appear to do this work accurately, while shirkers grow careless as the transcription workload
grows.
This discussion focuses on the mechanics of manipulation. We turn next to the question
of motives. The relationship between class size and score manipulation would appear to
arise from behavior related to both proctoring and transcription. These behaviors seem
likely to reflect two sorts of motives: accountability concerns that lead to inappropriate aid
while proctoring, as well as curbstoning of correct answers in grading and transcription, and
curbstoning as a strategy to minimize transcription or grading eﬀort while maintaining high
levels of apparent achievement.

6.1

Why Manipulate? An Item-Level Analysis

We use a model of item-level achievement in an eﬀort to discriminate between accountability
and shirking motives for manipulation. To this end, items are characterized by diﬃculty and
grading eﬀort. Let pj be the percent correct on item j in a non-cheating reference group,
honestly transcribed, so 1

pj measures item diﬃculty. To capture the fact that some items

require more work in transcription, let ej be a indicator for open, high-grading-eﬀort items.
Class i’s percent correct on item j, yij , can now be written as:
yij = pj + (g(ej )

pj )mij +

(10)

ij ,

where mij is an indicator for manipulation of item j in class i and

ij

is an error term. In the

absence of manipulation, the expected score is pj . Manipulators score a value, g (ej ), that
depends on grading eﬀort, implying that the eﬀect of manipulation on scores is g(ej )
15

pj .15

Dee et al. (2011) similarly distinguish between open response items and others where grading is less
discretionary.

21

Accountability Concerns
Manipulators motivated by accountability considerations probably see manipulation as costly
since they care about how they are perceived. A desire to limit exposure and make proctoring
aid eﬃcient motivates assistance and curbstoning on items where scores are otherwise likely
to be low. In other words, accountability considerations motivate manipulation targeting
diﬃcult items.
We capture this behavior by modeling manipulation rates and manipulated scores as
follows:
mij = 0 + 1 pj ,
where 1 < 0 and

0

g (ej ) =

(11)

0,

is arguably close to one. Substituting (11) into (10) and rearranging

generates an expression for item-level scores as a function of diﬃculty and its square:
yij =

0 0

+ [ 0 1 + (1

1 p2j +

0 )]pj

(12)

ij .

This equation shows that diﬃculty-related manipulation induces non-linearity in the relation
between scores and item diﬃculty, where average scores flatten as diﬃculty grows, while
without this form of manipulation they would decline.
Eﬀort-related Shirking
Dishonest or lazy transcribers may be especially likely to copy answers to open items that
require more work to grade. They may also transcribe high-eﬀort items less accurately. We
parametrize eﬀort-related shirking using:
mij = 0 + 1 ej

g(ej ) =

0

+

1 ej ,

where the likelihood of manipulation is assumed to increase with eﬀort (1 > 0), while
transcription accuracy declines (
yij = 0

0

+ (0

1

1

< 0). Equation (10) then becomes:

+ 1

0

+ 1 1 ) ej + (1

0 )pj

 1 pj e j +

ij ,

(13)

so that eﬀort-related shirking generates a main eﬀect and interaction for grading eﬀort in
the item-level conditional mean function for scores. In contrast with (12), equation (13)
describes a linear relationship between item diﬃculty and scores, although the slope of this
relationship is shallower for high-eﬀort items.
22

Wholesale Curbstoning
Finally, we consider wholesale curbstoning: copying an entire answer key. This form of
manipulation is unrelated to item characteristics and can therefore be described as follows:
mij = 0 ,
with

0

g(ej ) =

0,

again close to one. The curbstoning model implies:
yij =

0 0

+ (1

0 ) pj + ⌫ij ,

(14)

describing a linear relationship between scores and diﬃculty, with no interactions or higherorder terms. Here, the coeﬃcient on pj is one minus the manipulation rate.
Testing alternative models
In this framework, a linear relationship between scores and item diﬃculty rules out diﬃcultyrelated manipulation, while curbstoning related to grading eﬀort generates an interaction
term between item diﬃculty and eﬀort. We use these predictions to disentangle alternative
explanations for score manipulation. Item diﬃculty, 1

pj , is taken from response data from

classrooms with monitors in Veneto, an area where manipulation rates are low. Grading eﬀort
is summarized by distinguishing between closed multiple choice questions and unstructured,
open questions in which the student responds in his or her own words (the Appendix gives
examples). The eﬀort variable, ej , indicates open questions.16
As a first pass, Figure 7 plots item-level responses in Sicily, a high-manipulation region,
against the Veneto response rate standardized to have mean zero and unit variance by grade
and survey year in that region. We also standardize Sicily’s item-level responses by grade and
school year with respect to national figures (excluding Veneto). In addition to raw data, the
figure shows linear and local linear regression fitted values, separately for math and language
scores. The linear model fits remarkably well, a fact that weighs against the notion that
manipulation is related to item diﬃculty.
The possibility of an eﬀort interaction of the sort described by equation (13) is explored
16

We can allow for regional variation in ability by parameterizing diﬃculty as proportional to the Veneto
score. This leaves the key predictions of our framework unchanged, i.e. nonlinearity and an eﬀort interaction
in equations (12) and (13), while the coeﬃcient on percent correct in Veneto in the wholesale curbstoning
model in equation (14) becomes this factor of proportionality times 1 0 .

23

in Figure 8. This figure plots the Sicily-Veneto relation separately for items with high and
low-grading-eﬀort. These estimates indeed show a shallower diﬃculty slope for high-eﬀort
items, especially for language.
The relations in these figures are quantified with an empirical version of equation (10).
Specifically we estimate:
yj = ↵0 + ↵1 pj + ↵2 p2j +

0 ej

+

1 e j pj

+

(15)

j,

a regression of item-level response data for Sicily and Southern Italy on item diﬃculty and
its square, grading eﬀort, and the interaction between grading eﬀort and diﬃculty. These
estimates control for grade and year eﬀects, with standard errors clustered by item (models
for all Southern regions also include region eﬀects).
This item-level analysis oﬀers little evidence of selective manipulation, as can be seen
in the insignificant squared terms in columns 3 and 4 of Table 9. On the other hand,
models allowing an eﬀort interaction generate substantial negative estimates of the interaction
term,

1,

significantly diﬀerent from zero in the case of language, though smaller and only

marginally significant for math. Thus, wholesale curbstoning appears to give a reasonable
account of score manipulation for math, while the language results reveal evidence of selective
manipulation on high-grading-eﬀort items. The results in columns 5 and and 6 are also
consistent with modest eﬀort-related sloppiness in transcription. To see this, suppose
equation (13) is about

0.05 and that transcription is otherwise nearly perfect, so

0

1

in

⇡ 0.95.

Using data for language scores from the South, the estimate of 0 (the baseline manipulation
rate) for the South implied by the item diﬃculty coeﬃcient (1

0 in equation (12)) is

around 0.15. The grading-eﬀort main eﬀect should therefore be about 0.15 ⇥ ( 0.05) +

0.951 + 1 ( 0.05). With an estimate of ̂1 = 0.116 in column 6, this comes out at 0.097,
close to the value of the estimated grading-eﬀort main eﬀect seen in the table.

7

Summary and Directions for Further Work

The causal eﬀects of class size on Italian primary schoolers’ test scores are identified by
quasi-experimental variation arising from Italy’s version of Maimonides’ Rule. The resulting
estimates show small classes boost test scores in Southern provinces, an area known as the
24

Mezzogiorno, but not elsewhere. Analyses of data on score manipulation and a randomized classroom monitoring experiment reveal substantial manipulation in the Mezzogiorno,
most likely by teachers. For a variety of institutional and behavioral reasons, teacher score
manipulation is inhibited by larger classes as well as by monitoring. Estimates of a model
that jointly captures the causal eﬀects of class size and score manipulation on measured
achievement suggest the returns to class size in the Mezzogiorno are explained by the causal
eﬀects of class size on score manipulation, with no apparent gains in learning. These findings
show how class size eﬀects can be misleading even where internal validity is probably not an
issue. Our results also show how score manipulation can arise as a result of shirking in an
institutional setting where standardized assessments are divorced from accountability.
These findings raise a number of questions, including those of why teacher manipulation
is so much more prevalent in the Mezzogiorno, and what can be done to enhance accurate
assessment in Italy and elsewhere. Manipulation in the Mezzogiorno arises in part from local
exam proctoring and local transcription of answer sheets, a strategy meant to lower costs.
New York’s venerable Regent’s exams were also graded locally until 2013, an arrangement
that likewise appears to have facilitated score manipulation. Moreover, as with INVALSI
assessments, manipulation of Regent’s scores appears to be unrelated to NCLB-style accountability pressure (Dee et al., 2011). By contrast, the UK’s Key Stage 2 primary-level
assessments are marked by external examiners, a costly but probably worthwhile eﬀort.17 It’s
also worth asking why class size reductions fail to enhance learning in Italy, while evidence
from the US, Israel, and a number of other countries suggest class size reductions increase
learning. We hope to answer these questions in future work.

17

See https://home.edexcelgateway.com/pages/job_search_view.aspx?jobId=537 for information on Key
Stage 2 marking costs.

25

Table1:I. Descriptive
Descriptive statistics
Table
Statistics

Female*
Immigrant*
Father HS*
Mother employed*
Pct correct: math
Pct correct: language
Class size
Score manipulation: math
Score manipulation: language

Grade 2 (2009-2011)
Grade 5 (2009-2011)
Italy North/Centre South
Italy North/Centre South
(1)
(2)
(3)
(4)
(5)
(6)
A. Class Characteristics
0.49
0.49
0.49
0.49
0.49
0.49
(0.50)
(0.50)
(0.50)
(0.50)
(0.50)
(0.50)
0.10
0.14
0.03
0.10
0.14
0.03
(0.30)
(0.35)
(0.17)
(0.30)
(0.34)
(0.18)
0.34
0.34
0.33
0.32
0.33
0.30
(0.47)
(0.48)
(0.47)
(0.47)
(0.47)
(0.46)
0.57
0.68
0.39
0.55
0.66
0.38
(0.49)
(0.47)
(0.49)
(0.50)
(0.47)
(0.49)
47.9
46.1
51.1
64.2
63.3
65.6
(14.6)
(12.9)
(16.7)
(12.9)
(10.9)
(15.5)
69.8
69.2
70.8
74.2
74.3
74.1
(10.9)
(9.2)
(13.3)
(8.9)
(7.5)
(10.8)
20.1
20.3
19.9
19.7
19.9
19.3
(3.40)
(3.35)
(3.48)
(3.72)
(3.67)
(3.76)
0.06
0.02
0.14
0.07
0.02
0.14
(0.24)
(0.13)
(0.35)
(0.25)
(0.15)
(0.34)
0.05
0.02
0.11
0.06
0.02
0.11
(0.23)
(0.14)
(0.31)
(0.23)
(0.15)
(0.31)

Number of classes

67,453

42,747

Number of classes

1.95
(1.10)
40.5
(25.2)

1.87
(1.01)
38.8
(23.0)

34,591

22,863

2.00
(1.05)
3.89
(1.97)
86.0
(40.6)
0.22
(0.41)

C. Institution Characteristics
2.32
1.57
2.10
(1.13)
(0.74)
(1.09)
4.33
3.31
4.07
(1.95)
(1.85)
(1.95)
95.3
73.7
85.2
(39.5)
(38.7)
(40.5)
0.20
0.23
0.22
(0.40)
(0.42)
(0.41)

Enrollment
Number of schools
Number of schools
Number of classes
Enrollment
External monitor

24,706

72,536

B. School Characteristics
2.11
1.94
(1.27)
(1.10)
43.8
38.9
(28.6)
(25.2)
11,728

37,476

44,739

27,797

1.85
(0.98)
37.3
(22.8)

2.10
(1.28)
41.7
(28.9)

24,225

13,251

2.42
(1.17)
4.48
(1.91)
94.0
(39.1)
0.20
(0.40)

1.69
(0.81)
3.55
(1.88)
73.9
(39.3)
0.23
(0.42)

Number of institutions
17,333
9,866
7,467
17,830
9,997
7,833
“Mean” and “s.d.” for class characteristics are computed using one observation per class; “Mean”
and “s.d.” for school characteristics are computed using one observation per school; “Mean” and
“s.d.” for institutions are computed using one observation per institution. * conditional on nonmissing survey response.
26

Table 2:Table
OLS2.and
Estimates
Class
Size
on Test
Scores
OLSIV/2SLS
and IV/2SLS
Estimatesofofthe
the Eﬀect
Effect ofofClass
Size
on Test
Scores
Italy
(1)

Class size

Enrollment
Enrollment squared
Interactions
N

-0.0078
(0.0070)

OLS
North/Centre
(2)

-0.0224***
(0.0067)

South
(3)

0.0091
(0.0146)

Italy
(4)

North/Centre
(5)
A. Math

-0.0519***
(0.0134)

-0.0436***
(0.0115)

IV/2SLS
South
Italy
(6)
(7)

-0.0957***
(0.0362)

-0.0609***
(0.0196)

North/Centre
(8)

-0.0417**
(0.0171)

South
(9)

-0.1294**
(0.0507)

✗
✗

✗
✗

✗
✗

✗
✗

✗
✗

✗
✗

✗
✗
✗

✗
✗
✗

✗
✗
✗

140,010

87,498

52,512

140,010

87,498

52,512

140,010

87,498

52,512

27

B. Language
Class size

Enrollment
Enrollment squared
Interactions
N

0.0029
(0.0055)

-0.0188***
(0.0053)

0.0328***
(0.0114)

-0.0395***
(0.0106)

-0.0313***
(0.0092)

-0.0641**
(0.0289)

-0.0409***
(0.0155)

-0.0215
(0.0136)

-0.0937**
(0.0403)

✗
✗

✗
✗

✗
✗

✗
✗

✗
✗

✗
✗

✗
✗
✗

✗
✗
✗

✗
✗
✗

140,010

87,498

52,512

140,010

87,498

52,512

140,010

87,498

52,512

Notes: Columns 1-3 report OLS estimates of the effect of class size on scores. Columns 4-9 report 2SLS estimates using Maimonides' Rule as an
instrument. The unit of observation is the class. Class size coefficients show the effect of 10 students. Models with interactions allow the quadratic
running variable control to differ across windows of ±12 students around each cutoff. Robust standard errors, clustered on school and grade, are shown
in parentheses. Control variables include: % female students, % immigrants, % fathers at least high school graduate, % employed mothers, %
unemployed mothers, % mother NILF, grade and year dummies, and dummies for missing values . All regressions include sampling strata controls
(grade enrollment at institution, region dummies and their interactions). * significant at 10%; ** significant at 5%; *** significant at 1%.

Table 3: Table
OLS3.and
Estimates
ofofthe
ofClass
ClassSize
Size
Score
Manipulation
OLSIV/2SLS
and IV/2SLS
Estimates
the Eﬀect
Effect of
on on
Score
Manipulation
Italy
(1)
Class size
Enrollment
Enrollment squared
Interactions
N

-0.0163***
(0.0025)

OLS
North/Centre
(2)
-0.0074***
(0.0017)

South
(3)
-0.0309***
(0.0058)

Italy
(4)

North/Centre
(5)
A. Math

-0.0186***
(0.0047)

-0.0042
(0.0031)

IV/2SLS
South
Italy
(6)
(7)
-0.0542***
(0.0143)

-0.0179***
(0.0069)

North/Centre
(8)
-0.0053
(0.0045)

South
(9)
-0.0471**
(0.0202)

✗
✗

✗
✗

✗
✗

✗
✗

✗
✗

✗
✗

✗
✗
✗

✗
✗
✗

✗
✗
✗

139,996

87,491

52,505

139,996

87,491

52,505

139,996

87,491

52,505

28

B. Language
Class size
Enrollment
Enrollment squared
Interactions
N

-0.0166***
(0.0023)

-0.0120***
(0.0018)

-0.0244***
(0.0051)

-0.0202*** -0.0116***
(0.0043)
(0.0032)

-0.0400***
(0.0128)

-0.0161**
(0.0063)

-0.0059
(0.0048)

-0.0379**
(0.0177)

✗
✗

✗
✗

✗
✗

✗
✗

✗
✗

✗
✗

✗
✗
✗

✗
✗
✗

✗
✗
✗

140,003

87,493

52,510

140,003

87,493

52,510

140,003

87,493

52,510

Notes: Columns 1-3 report OLS estimates of the effect of class size on score manipulation. Columns 4-9 report 2SLS estimates using Maimonides'
Rule as an instrument. Class size coefficients show the effect of 10 students. Models with interactions allow the quadratic running variable control to
differ across windows of ±12 students around each cutoff. The unit of observation is the class. Robust standard errors, clustered on school and grade,
are shown in parentheses. Control variables include: % female students, % immigrants, % fathers at least high school graduate,% employed mothers,
% unemployed mothers, % mother NILF, grade and year dummies, and dummies for missing values. All regressions include sampling strata controls
(grade enrollment at institution, region dummies and their interactions). * significant at 10%; ** significant at 5%; *** significant at 1%.

TableTable
4: Covariate
in the
theMonitoring
Monitoring
Experiment
4. CovariateBalance
Balance in
Experiment
Italy
Control Mean
Treatment
Difference
(1)
(2)
Class size
Grade enrollment at school
% in class sitting the test
% in school sitting the test
% in institution sitting the test

Immigrant students
Father HS
Mother employed

Missing data on father's education
Missing data on mother's occupation
Missing data on country of origin

South
Treatment
Control Mean
Difference
(5)
(6)

A. Administrative Data on Schools
20.031
0.0179
[3.511]
(0.0374)
49.804
-0.5477
[27.562]
(0.3913)
0.934
0.0006
[0.066]
(0.0006)
0.933
0.0005
[0.055]
(0.0006)
0.932
0.0005
[0.043]
(0.0005)

19.456
[3.646]
58.483
[34.437]
0.947
[0.062]
0.946
[0.051]
0.945
[0.045]

0.0623
(0.0515)
-0.1410
(0.5909)
-0.0007
(0.0008)
-0.0010
(0.0008)
-0.0010
(0.0007)

0.0012
(0.0009)
0.0010
(0.0010)
0.0060***
(0.0016)
0.0085***
(0.0024)

B. Data Provided by School Staff
0.483
0.0004
[0.1179]
(0.0011)
0.137
0.0004
[0.13]
(0.0014)
0.258
0.0061***
[0.163]
(0.0019)
0.532
0.0067**
[0.258]
(0.0031)

0.479
[0.126]
0.031
[0.056]
0.238
[0.176]
0.295
[0.210]

0.0027*
(0.0016)
0.0020***
(0.0007)
0.0056**
(0.0027)
0.0117***
(0.0035)

-0.0217***
(0.0034)
-0.0168***
(0.0033)
-0.0115***
(0.0013)

C. Non-Response Indicators
0.225
-0.0186***
[0.340]
(0.0043)
0.196
-0.0083**
[0.325]
(0.0042)
0.025
-0.0078***
[0.143]
(0.0014)

0.221
[0.343]
0.194
[0.333]
0.045
[0.192]

-0.0271***
(0.0057)
-0.0316***
(0.0054)
-0.0178***
(0.0026)

19.812
[3.574]
53.119
[30.663]
0.939
[0.065]
0.938
[0.054]
0.937
[0.045]

0.0348
(0.0303)
-0.4011
(0.3289)
0.0001
(0.0005)
-0.0001
(0.0005)
-0.0001
(0.0004)

0.482
[0.121]
0.097
[0.120]
0.25
[0.168]
0.441
[0.267]
0.223
[0.341]
0.195
[0.328]
0.033
[0.163]

29
Female students

North/Centre
Treatment
Control Mean
Difference
(3)
(4)

N
140,010
87,498
52,512
Notes: Columns 1, 3 and 5 show means and standard deviations for variables listed at left. Other columns report coefficients from
regressions of each variable on a treatment dummy (indicating classroom monitoring), grade and year dummies, and sampling strata
controls (grade enrollment at institution, region dummies and their interactions). Standard deviations for the control group are in square
brackets, robust standard errors are in parentheses. * significant at 10%; ** significant at 5%; *** significant at 1%.

5. MonitoringEﬀects
Effects on
on Score
and and
Test Scores
TableTable
5: Monitoring
ScoreManipulation
Manipulation
Test Scores
Italy
(1)

Score manipulation
North/Centre
South
(2)
(3)

Italy
(4)

Test scores
North/Centre
(5)

South
(6)

A. Math
Monitor at institution (Migkt)

-0.029***
(0.002)

-0.010***
(0.001)

-0.062***
(0.004)

-0.112***
(0.006)

-0.075***
(0.005)

-0.180***
(0.012)

Means
(sd)

0.064
(0.246)

0.020
(0.139)

0.139
(0.346)

0.007
(0.637)

-0.074
(0.502)

0.141
(0.796)

N

139,996

87,491

52,505

140,010

87,498

52,512

B. Language

30

Monitor at institution (Migkt)

-0.025***
(0.002)

-0.012***
(0.001)

-0.047***
(0.004)

-0.081***
(0.004)

-0.054***
(0.004)

-0.131***
(0.009)

Means
(sd)

0.055
(0.229)

0.023
(0.149)

0.110
(0.313)

0.01
(0.523)

-0.005
(0.428)

0.035
(0.649)

N

140,003

87,493

52,510

140,010

87,498

52,512

Notes: Columns 1-3 report first stage estimates of the effect of a classroom monitor on score manipulation. Columns
4-6 show the reduced form effect of a monitor on test scores. All models control for a quadratic in grade enrollment,
segment dummies and their interactions. The unit of observation is the class. Robust standard errors, clustered on
school and grade, are shown in parentheses. Control variables include: % female students, % immigrants, % fathers
at least high school graduate, % employed mothers, % unemployed mothers, % mother NILF, grade and year
dummies, and dummies for missing values in these variables. All regressions include sampling strata controls (grade
enrollment at institution, region dummies and their interactions). * significant at 10%; ** significant at 5%; ***
significant at 1%.

Table6:6.Twin
Twin First
Table
FirstStages
Stages
A. Score Manipulation
Italy
(1)
Maimonides' Rule (figkt)
Monitor at institution (Migkt)
N

31
Maimonides' Rule (figkt)
Monitor at institution (Migkt)
N

-0.0009**
(0.0004)
-0.029***
(0.002)

Math
North/Centre
(2)
-0.0003
(0.0002)
-0.010***
(0.001)

South
(3)
-0.0019**
(0.0009)
-0.062***
(0.004)

139,996

87,491

52,505

Italy
(1)

B. Class size
North/Centre
(2)

South
(3)

0.513***
(0.0006)
0.013
(0.024)

0.555***
(0.0008)
0.032
(0.027)

0.433***
(0.0011)
-0.009
(0.045)

140,010

87,498

52,512

Italy
(4)
-0.0008**
(0.0003)
-0.025***
(0.002)
140,003

Language
North/Centre
(5)
-0.0003
(0.0003)
-0.012***
(0.001)
87,493

South
(6)
-0.0015**
(0.0008)
-0.047***
(0.004)
52,510

Notes: Panel A report first stage estimates of the effect of the Maimonides' Rule and a classroom monitor on score
manipulation. Panel B report first stage estimates of the effect of the Maimonides' Rule and a classroom monitor on
class size. All models control for a quadratic in grade enrollment, segment dummies and their interactions. The unit of
observation is the class. Robust standard errors, clustered on school and grade, are shown in parentheses. Control
variables include: % female students, % immigrants, % fathers at least high school graduate, % employed mothers, %
unemployed mothers, % mother NILF, grade and year dummies, and dummies for missing values in these variables. All
regressions include sampling strata controls (grade enrollment at institution, region dummies and their interactions). *
significant at 10%; ** significant at 5%; *** significant at 1%.

Table 7:Table
IV/2SLS
Estimates
of the
Sizeand
and
Score
Manipulation
Test Scores
7. IV/ 2SLS
Estimates
of theEﬀect
Effectof
of Class
Class Size
Score
Manipulation
on TestonScores
Italy
(1)
Class size
Score manipulation

0.0075
(0.0213)
3.82***
(0.19)

IV/2SLS
North/Centre
(2)

South
(3)

-0.0029
0.0062
(0.0298)
(0.0441)
7.33*** 2.88***
(0.79)
(0.16)

IV/2SLS (overidentified)
Italy North/Centre South
(4)
(5)
(6)
A. Math
0.0024
(0.0190)
3.82***
(0.19)

-0.0113
0.0133
(0.0251)
(0.0378)
7.02*** 2.87***
(0.73)
(0.16)

[0.914]
139,996

[0.600]
87,491

Class size * Score manipulation
Overid test [P-value]
N

139,996

87,491

52,505

[0.541]
52,505

IV/2SLS (overidentified-interacted)
Italy
North/Centre South
(7)
(8)
(9)
0.0116
(0.0316)
4.10***
(0.96)
-0.1464
(0.4814)
[0.914]
139,996

0.0136
(0.0482)
9.21**
(4.41)
-1.2700
(2.1598)
[0.475]
87,491

0.0473
(0.0675)
3.33***
(0.86)
-0.2273
(0.4304)
[0.476]
52,505

B. Language

32

Class size

0.0121
(0.0173)
3.29***
(0.18)

0.0049
0.0127
(0.0196)
(0.0385)
4.50*** 2.80***
(0.45)
(0.18)

0.0218
(0.0153)
3.21***
(0.18)

0.0109
0.0491
(0.0174)
(0.0329)
4.34*** 2.74***
(0.42)
(0.18)

0.0325
0.0098
0.1337*
(0.0308)
(0.0320)
(0.0800)
Score manipulation
3.59***
4.31*
4.18***
(1.03)
(2.25)
(1.30)
Class size * Score manipulation
-0.2130
-0.0029
-0.7058
(0.4980)
(1.0898)
(0.6214)
Overid test (P-value)
[ 0.129]
[0.796]
[0.036]
[0.216]
[0.844]
[0.109]
N
140,003
87,493
52,510
140,003
87,493
52,510
140,003
87,493
52,510
Notes: Columns 1-3 show 2SLS estimates using Maimonides' Rule and classroom monitor as instruments. Columns 4-6 show overidentified 2SLS
estimates which also use dummies for grade enrollment being in a 10 percent window below and above each cutoff (2 students) as instrument.
Columns 7-9 add the interaction between class size and score manipulation and use the interaction of Maimonide's Rule with classroom monitor
and the interactions of dummies for grade enrollment being in a 10 percent window below and above each cutoff with classroom monitor as
instruments. Class size coefficients show the effect of 10 students. All models control for a quadratic in grade enrollment, segment dummies and
their interactions. The unit of observation is the class. Robust standard errors, clustered on school and grade, are shown in parentheses. Control
variables include: % female students, % immigrants, % fathers at least high school graduate,% employed mothers, % unemployed mothers, %
mother NILF, grade and year dummies, and dummies for missing values in these variables. All regressions include sampling strata controls (grade
enrollment at institution, region dummies and their interactions). * significant at 10%; ** significant at 5%; *** significant at 1%.

Table
Maimonides' Rule
Rule and
Balance
Table
8: 8.
Maimonides’
andCovariate
Covariate
Balance
Italy

% in class sitting the test
% in school sitting the test
% in institution sitting the test

Female
Immigrant

33

Father HS
Mother employed

Missing data on father's education
Missing data on mother's occupation
Missing data on country of origin

North/Centre

Control Mean

Treatment
Difference

(1)

(2)

0.9392
[0.0643]
0.9386
[0.0534]
0.9374
[0.0436]

0.0000
(0.0001)
0.0001
(0.0001)
-0.0001
(0.0001)

0.482
[0.1205]
0.0981
[0.1198]
0.2546
[0.1678]
0.4503
[0.2658]

0.0000
(0.0002)
-0.0007***
(0.0002)
0.0006**
(0.0003)
0.0012***
(0.0004)

0.2187
[0.3361]
0.1925
[0.3239]
0.0296
[0.1544]

0.0003
(0.0006)
0.0002
(0.0006)
-0.0001
(0.0002)

South

Control Mean

Treatment
Difference

Control Mean

Treatment
Difference

(3)

(4)

(5)

(6)

A. Administrative Data on Schools
0.9345
0.0001
[0.0657]
(0.0001)
0.9339
0.0001
[0.0548]
(0.0001)
0.9327
-0.0001
[0.0426]
(0.0001)

0.9471
[0.061]
0.9464
[0.05]
0.9451
[0.0441]

0.0000
(0.0001)
0.0001
(0.0001)
-0.0000
(0.0001)

B. Data Provided by School Staff
0.4836
0.0002
[0.1176]
(0.0002)
0.1375
-0.0007***
[0.1298]
(0.0003)
0.2613
0.0002
[0.1626]
(0.0003)
0.5356
0.0010*
[0.2574]
(0.0005)

0.4792
[0.1251]
0.0324
[0.0572]
0.2434
[0.1755]
0.3082
[0.2138]

-0.0002
(0.0003)
-0.0004***
(0.0001)
0.0013***
(0.0005)
0.0016***
(0.0006)

C. Non-Response Indicators
0.2216
0.0015**
[0.3358]
(0.0007)
0.1963
0.0014**
[0.3231]
(0.0007)
0.0232
-0.0001
[0.1361]
(0.0003)

0.2139
[0.3367]
0.1861
[0.3251]
0.0401
[0.1804]

-0.0018*
(0.0010)
-0.0019*
(0.0010)
-0.0000
(0.0005)

N
140,010
87,498
52,512
Notes: Columns 1, 3 and 5 show means and standard deviations for variables listed at left. Other columns report coefficients from
regressions of each variable on predicted class size (Maimonides' Rule), a quadratic in grade enrollment, segment dummies and their
interactions, grade and year dummies, and sampling strata controls (grade enrollment at institution, region dummies and their interactions).
Standard deviations for the control group are in square brackets, robust standard errors are in parentheses. * significant at 10%; **
significant at 5%; *** significant at 1%.

9: Testing
Alternative
ModelsofofScore
Manipulation
Table 9:Table
Testing
Alternative
Models
Manipulation
Sicily
(1)

South
(2)

Sicily
(3)

South
(4)

Sicily
(5)

South
(6)

A. Math
Percent correct (pj)

0.698***
(0.017)

0.769***
(0.015)

Percent correct squared (pj2)

0.643***
(0.109)
0.047
(0.086)

0.713***
(0.090)
0.047
(0.071)

Open (ej)
Percent correct (pj) * open (ej)
N

229

1832

229

1832

0.725***
(0.021)

0.792***
(0.018)

0.040
(0.024)
-0.066*
(0.035)

0.038*
(0.020)
-0.054*
(0.029)

229

1832

34

B. Language
Percent correct (pj)

0.790***
(0.020)

0.829***
(0.017)

Percent correct squared (pj2)

0.650***
(0.132)
0.107
(0.092)

0.735***
(0.113)
0.072
(0.078)

Open (ej)
Percent correct (pj) * open (ej)
N

314

2,512

314

2,512

0.812***
(0.019)

0.851***
(0.015)

0.094**
(0.038)
-0.115**
(0.047)

0.100***
(0.030)
-0.116***
(0.037)

314

2,512

Notes: This table shows item-level analysis that discriminates among different manipulation behaviors. The
outcome is the average score across classes computed for each item, after standardizing by grade and school
year in Sicily (columns 1, 3 and 5) and South (columns 2, 4 and 6). Columns 3 and 4 test for selective
manipulation (dishonesty related to item difficulty), columns 5 and 6 test for selective shirking and sloppiness.
All regressions include grade and year fixed effects. Columns 2, 4 and 6 also control for region fixed effects.
Standard errors are clustered by item. * significant at 10%; ** significant at 5%; *** significant at 1%.

Figure 1: Manipulation Rates by Province

35

Figure 2: Class Size by Enrollment in Pre-reform Years

10

15

20

25

30

Grade 2 (before 2010)

25

50

75
enrollment

actual class size

100

125

150

Maimonides' Rule

10

15

20

25

30

Grade 5

25

50

75
enrollment

actual class size

100

125

150

Maimonides' Rule

Notes: The figure shows actual class size and as predicted by Maimonides' Rule in
pre-reform years
36

Figure 3: Class Size by Enrollment in Post-reform Years

10

15

20

25

30

Grade 2 (after 2010)

26

52

78
enrollment

actual class size

104

130

150

Maimonides' Rule

Notes: The figure shows actual class size and as predicted by Maimonides' Rule in
post-reform years

37

Figure 4: Class Size and Enrollment, centered at Maimonides Cutoﬀs
Grade 2

3
1
-1
-3
-5

-5

-3

-1

1

3

5

South

5

North and Centre

-12 -10 -8 -6 -4 -2 0 2 4
enrollment

6

8 10 12

-12 -10 -8 -6 -4 -2 0 2 4
enrollment

6

8 10 12

6

8 10 12

Note: graphs computed from residuals

Grade 5

3
1
-1
-3
-5

-5

-3

-1

1

3

5

South

5

North and Centre

-12 -10 -8 -6 -4 -2 0 2 4
enrollment

6

8 10 12

-12 -10 -8 -6 -4 -2 0 2 4
enrollment

Note: graphs computed from residuals

Notes: The solid line shows a one-sided LLR fit.

38

Figure 5: Test Scores and Enrollment, centered at Maimonides Cutoﬀs
Math Score

.08
.06
.04
.02
0
−.1 −.08 −.06 −.04 −.02

−.1 −.08 −.06 −.04 −.02

0

.02

.04

.06

.08

.1

South

.1

North and Centre

−12−10 −8 −6 −4 −2 0 2 4
enrollment

6

8 10 12

−12−10 −8 −6 −4 −2 0 2 4
enrollment

6

8 10 12

Note: graphs computed from residuals

Language Score

.08
.06
.04
.02
0
−.1 −.08 −.06 −.04 −.02

−.1 −.08 −.06 −.04 −.02

0

.02

.04

.06

.08

.1

South

.1

North and Centre

−12−10 −8 −6 −4 −2 0 2 4
enrollment

6

8 10 12

−12−10 −8 −6 −4 −2 0 2 4
enrollment

Note: graphs computed from residuals

Notes: The solid line shows a one-sided LLR fit.

39

6

8 10 12

Figure 6: Score Manipulation and Enrollment, centered at Maimonides Cutoﬀs
Math Score Manipulation

.02
0
−.02
−.04

−.04

−.02

0

.02

.04

South

.04

North and Centre

−12−10 −8 −6 −4 −2 0 2 4
enrollment

6

8 10 12

−12−10 −8 −6 −4 −2 0 2 4
enrollment

6

8 10 12

6

8 10 12

Note: graphs computed from residuals

Language Score Manipulation

.02
0
−.02
−.04

−.04

−.02

0

.02

.04

South

.04

North and Centre

−12−10 −8 −6 −4 −2 0 2 4
enrollment

6

8 10 12

−12−10 −8 −6 −4 −2 0 2 4
enrollment

Note: graphs computed from residuals

Notes: The solid line shows a one-sided LLR fit.

40

Figure 7: Looking for Nonlinearity

.2
Percent right
−.2
0
−.4
−.6

−.6

⤴

⤴

−.4

Percent right
−.2
0

.2

.4

Language

.4

Math

−.6

−.4

−.2
0
item difficulty
linear

.2

.4

non−parametric

−.6

−.4

−.2
0
item difficulty
linear

.2
non−parametric

Notes: The figure plots average percent correct by item in Sicily against average percent correct in Veneto.

41

.4

Figure 8: The Eﬀect of Grading Eﬀort

.2
Percent right
−.2
0
−.4
−.6

−.6

⤴

⤴

−.4

Percent right
−.2
0

.2

.4

Language

.4

Math

−.6

−.4

−.2
0
item difficulty

fitted to open

.2

.4

fitted to closed

−.6

−.4

−.2
0
item difficulty

fitted to open

.2

.4

fitted to closed

Notes: The figure plots average percent correct by item in Sicily against average percent correct in Veneto, with
linear fit of the lines separately by item grading effort. Points plotted with a "×" refer to open question, points plotted
with a "!" refer to closed questions.

42

References
Angrist, J. D., and V. Lavy (1999): “Using Maimonides’ Rule to Estimate the Eﬀect of
Class Size on Scholastic Achievement,” Quarterly Journal of Economics, 114(2), 533–575.
Baker, O., and D. Paserman (2013): “Grade Enrollment Sorting under an IncentivesBased Class Size Reduction Program,” Unpublished mimeo.
Ballatore, R., M. Fort, and A. Ichino (2013): “The Tower of Babel in the classroom:
immigrants and natives in Italian schools,” Unpublished mimeo.
Banerjee, A., and E. Duflo (2006): “Addressing Absence,” Journal of Economic Perspectives, 20(1), 117–132.
Bertoni, M., G. Brunello, and L. Rocco (2013): “When the cat is near, the mice won’t
play: The eﬀect of external examiners in Italian schools,” Journal of Public Economics,
104, 65–77.
Bezdek, J. (1981): Pattern Recognition with Fuzzy Objective Function Algorithms. Plenum
Press, New York.
Bonesronning, H. (2003): “Class size eﬀects on student achievement in Norway: Patterns
and explanations,” Southern Economic Journal.
Bratti, M., D. Checchi, and A. Filippin (2007): “Territorial diﬀerences in Italian students’ mathematical competences: Evidence from PISA,” Giornale degli Economisti e Annali di Economia, 66(3), 299–335.
Brunello, G., and D. Checchi (2005): “School quality and family background in Italy,”
Economics of Education Review, 24, 563–577.
Card, D., D. S. Lee, Z. Pei, and A. Weber (2012): “Nonlinear Policy Rules and the
Identification and Estimation of Causal Eﬀects in a Generalized Regression Kink Design,”
NBER Working Paper, 18564.
Chaudhury, N., J. Hammer, M. Kremer, K. Muralidharan, and F. H. Rogers
(2006): “Missing in Action: Teacher and Health Worker Absence in Developing Countries,”
Journal of Economic Perspectives, 20(1), 91–116.
43

Chetty, R., J. Friedman, N. Hilger, E. Saez, D. Schanzenbach, and D. Yagan
(2011): “How Does Your Kindergarten Classroom Aﬀect Your Earnings? Evidence from
Project STAR,” Quarterly Journal of Economics, 126(4), 1593–1660.
Clotfelter, C. T., H. F. Ladd, and J. L. Vigdor (2009): “Are Teacher Absences Worth
Worrying About in the United States?,” Education Finance and Policy, 4(2), 115–149.
Costantini, M., and C. Lupi (2006): “Divergence and long-run equilibria in Italian regional
unemployment,” Applied Economics Letters, 13(14), 899–904.
Dee, T. S., B. A. Jacob, J. McCrary, and J. Rockoff (2011): “Rules and Discretion in the Evaluation of Students and Schools: The Case of the New York Regents Examinations,” Columbia Business School Research Paper. Available at SSRN:
http://ssrn.com/abstract=1915387.
DePaola, M., V. Scoppa, and V. Pupo (2014): “Absenteeism in the Italian Public Sector:
The Eﬀects of Changes in Sick Leave Policy,” Journal of Labor Economics, 32(2), 337–360.
Dobbelsteen, S., J. Levin, and H. Oosterbeek (2002): “The causal eﬀect of class
size on scholastic achievement: Distinguishing the pure class size eﬀect from the eﬀect of
changes in class composition,” Oxford Bulletin of Economics and Statistics, 64(1), 17–38.
Gary-Bobo, R. J., and M.-B. Mahjoub (2006): “Estimation of class-size eﬀects, using
Maimonides’ rule: the case of French junior high schools,” CEPR Discussion Papers 5754.
Guiso, L., P. Sapienza, and L. Zingales (2004): “The Role of Social Capital in Financial
Development,” American Economic Review, 94(3), 526–556.
(2010): “Civic Capital as the Missing Link,” in Handbook of Social Economics, ed.
by A. B. Jess Benhabib, and M. Jackson. North Holland.
Hanushek, E. A. (1995): “Interpreting recent research on schooling in developing countries,”
The World Bank Research Observer, X, 227–246.
Hoxby, C. (2000): “Peer Eﬀects in the Classroom: Learning from Gender and Race Variation,” NBER Working paper 7867.
44

Ichino, A., and P. Ichino (1997): “Culture, Discrimination and Individual Productivity:
Regional Evidence from Personnel Data in a Large Italian Firm,” CEPR Discussion Papers
1709.
Ichino, A., and G. Maggi (2000): “Work Environment and Individual Background: Explaining Regional Shirking Diﬀerentials in a Large Italian Firm,” Quarterly Journal of
Economics,, 115(3), 933–959.
Ichino, A., and G. Tabellini (2014): “Freeing the Italian School System,” forthcoming,
Labour Economics.
Imbens, G., and K. Kalyanaraman (2012): “Optimal Bandwidth Choice for the Regression Discontinuity Estimator,” Review of Economic Studies, 79(3), 933–959.
INVALSI (2010): “Sistema Nazionale di Valutazione - A.S. 2009/2010, Rilevazione degli
apprendimenti,” Technical Report.
Jacob, B., and S. Levitt (2003): “Rotten Apples: An Investigation of the Prevalence and
Predictors of Teacher Cheating,” Quarterly Journal of Economics, 118(3), 843–77.
Kane, T. J., C. E. Rouse, and D. Staiger (1999): “Estimating Returns to Schooling
When Schooling is Misreported,” NBER Working Paper 7235.
Krueger, A. (1999): “Experimental estimates of education production functions,” Quarterly
Journal of Economics, 114, 497–532.
Leuven, E., H. Oosterbeek, and M. Ronning (2008): “Quasi-experimental estimates of
the eﬀect of class size achievement in Norway,” The Scandinavian Journal of Economics,
110(4), 663–693.
Lewbel, A. (2007): “Estimation of Average Treatment Eﬀects with Misclassification,”
Econometrica, 2(3), 537–551.
Mahajan, A. (2006): “Identification and Estimation of Regression Models with Misclassification,” Econometrica, 74(3), 631–665.

45

Nannicini, T., A. Stella, G. Tabellini, and U. Troiano (2013): “Social Capital and
Political Accountability,” American Economic Journal: Economic Policy, 5, 1957–1969.
Neal, D. (2013): “The Consequences of Using One Assessment System to Pursue Two
Objectives,” NBER Working paper 19214.
Piketty, T. (2004): “Should we reduce class size or school segregation? Theory and evidence from France,” presentation at the Roy Seminars, Association pour le dévelopement de la recherche en économie et en statistique (ADRES), 22 November, available at:
http://www.adres.polytechnique.fr/SEMINAIRE/221104b.pdf.
Putnam, R., R. Leonardi, and R. Nanetti (1993): Making Democracy Work. Princeton
University Press, Princeton.
Quintano, C., R. Castellano, and S. Longobardi (2009): “A Fuzzy Clustering Approach to Improve the Accuracy of Italian Student Data. An Experimental Procedure to
Correct the Impact of the Outliers on Assessment Test Scores,” Statistica & Applicazioni,
Vol.VII(2), 149–171.
Severson,
lanta’s

K.

(2011):

School

System,”

“Systematic
New

York

Cheating
Times,

Is

July

Found
11,

in

Accessed

Atat:

http://www.nytimes.com/2011/07/06/education/06atlanta.html.
Urquiola, M., and E. Verhoogen (2009): “Class size caps, sorting, and the regression
discontinuity design,” American Economic Review, 99(1), 179–215.
Woessmann, L. (2005): “Educational production in Europe,” Economic Policy, 43, 445–493.

46

Appendix
Score Manipulation Imputation
Our imputation is closely related to that used by INVALSI and described in Quintano et al.
(2009). INVALSI assigns a manipulation probability to each class in three steps.
The first step computes the following four summary statistics.
(1) Within-class average score:
Ni
X

pji

j=1

,
(16)
Ni
where pji denotes the score of student j in class i; Ni denotes the number of test-takers in
p̄i =

class i.
(2) Within-class standard deviation of scores:
v
u Ni
uX
u
(pji p̄i )2
u
t j=1
.
i =
Ni
(3) Within-class average percent missing

M Ci =

Ni
X

(17)

Mji

j=1

,
Ni
where Mji is the fraction of test items skipped by student j in class i.

(18)

(4) Within-class index of answer homogeneity:
Q
X

Eqi

q=1

,
(19)
Q
where q = 1, .., Q indexes test items and Eqi is a Gini measure of homogeneity that equals
Ēi =

value zero if all students in class i provide the same answer to item q. This can be interpreted
as the Herfindahl index of the share of students with similar response patterns in the class.
In the second step, the first two principal components are extracted from the 4 ⇥ 4 cor-

relation matrix determined by these indicators, yielding a percentage of explained variance

which is - across years, subjects and grades - well above 90%. Denote these principal com47

ponents by

1i

and

2i .

The third step consists of a cluster analysis that creates G groups

from the distribution of (

1i ,

2i ).

INVALSI sets G = 8, yielding a matrix whose elements

are, for each class, eight group membership probabilities. This procedure is known as “fuzzy
clustering” (see Bezdek, 1981), since data elements (classes, in our setting) can be assigned
to one or more groups. With “hard clustering”, data elements belong to exactly one cluster.
INVALSI identifies likely manipulators as those in the group with values of (

1i ,

2i )

that

are most extreme (see Figure 8 in Quintano et al. 2009). In practice, the suspicious group is
characterized by (i) abnormally large values of p̄i , and (ii) small values of

i,

M Ci and Ēi ,

relative to the population average of these indicators. This group is flagged as the “outlier”
or manipulating cluster. The INVALSI manipulation indicator gives, for each class, the
membership probability for this cluster. Our hard clustering computations codes a dummy
for manipulating classes. This dummy indicates classes whose values of (
the manipulating cluster identified by INVALSI.

48

1i ,

2i )

belong to

A1. Reduced
Form Estimates
of the
EffectofofMaimonides’
Maimonides' Rule
Class
Size,Size,
Test Test
Scores,
and Score
Table A1:Table
Reduced
Form Estimates
of the
Eﬀect
Ruleonon
Class
Scores,
andManipulation
Score Manipulation
Italy
(1)

Math
North/Centre
(2)

South
(3)

Italy
(4)

Language
North/Centre
(5)

South
(6)

A. Class size
Maimonides' Rule

0.513***
(0.006)

0.555***
(0.008)

0.433***
(0.011)

Means
(sd)

19.88
(3.58)

20.07
(3.52)

19.58
(3.64)

140,010

87,498

52,512

N

B. Test Scores
Maimonides' Rule

-0.0031***
(0.0010)

-0.0023**
(0.0009)

-0.0056**
(0.0022)

-0.0021***
(0.0008)

-0.0012
(0.0008)

-0.0041**
(0.0017)

49

Means
(sd)

0.007
(0.637)

-0.074
(0.502)

0.141
(0.796)

0.01
(0.523)

-0.005
(0.428)

0.035
(0.649)

N

140,010

87,498

52,512

140,010

87,498

52,512

C. Score Manipulation
Maimonides' Rule

-0.0009***
(0.0004)

-0.0003
(0.0002)

-0.0020**
(0.0009)

-0.0008**
-0.0003

-0.0003
-0.0003

-0.0016**
-0.0008

Means
(sd)

0.065
(0.246)

0.02
(0.139)

0.139
(0.346)

0.055
(0.229)

0.023
(0.149)

0.110
(0.313)

N

139,996

87,491

52,505

140,003

87,493

52,510

Notes: This table shows the reduced form effect of the Maimonides' Rule on class size (Panel A), test scores (Panel B), score
manipulation (Panel C). All models control for a quadratic in grade enrollment, segment dummies and their interactions. The unit
of observation is the class. Robust standard errors, clustered on school and grade, are shown in parentheses. Control variables
include: % female students, % immigrants, % fathers at least high school graduate, % employed mothers, % unemployed
mothers, % mother NILF grade and year dummies, and dummies for missing values in these variables. All regressions include
sampling strata controls (grade enrollment at institution, region dummies and their interactions). * significant at 10%; **
significant at 5%; *** significant at 1%.

Table A2:Table
First
Estimates
for for
Over-Identified
A2.Stage
First Stage
Estimates
Over-Identified Models
Models
Class size

Maimonides' Rule (figkt)
Monitor at institution (Migkt)
2 students below cutoff
1 student below cutoff

50

1 student above cutoff
2 students above cutoff

N

Score manipulation math

Score manipulation language

Italy

North/Centre

South

Italy

North/Centre

South

Italy

North/Centre

South

(1)

(2)

(3)

(4)

(5)

(6)

(7)

(8)

(9)

0.704***
(0.0059)
0.010
(0.023)
-1.427***
(0.083)
-2.258***
(0.093)
2.411***
(0.097)
1.247***
(0.083)

0.753***
(0.0069)
0.029
(0.026)
-1.154***
(0.101)
-2.053***
(0.116)
3.026***
(0.132)
1.546***
(0.114)

0.617***
(0.0107)
-0.013
(0.044)
-1.865***
(0.138)
-2.580***
(0.150)
1.519***
(0.138)
0.826***
(0.120)

140,010

87,498

52,512

-0.0009**
(0.0005)
-0.029***
(0.002)
0.002
(0.005)
0.001
(0.005)
0.000
(0.006)
0.001
(0.006)
139,996

-0.0003
(0.0003)
-0.010***
(0.001)
-0.002
(0.003)
0.001
(0.004)
0.003
(0.005)
-0.004
(0.004)
87,491

-0.0021*
(0.0011)
-0.062***
(0.004)
0.008
(0.012)
0.000
(0.012)
-0.004
(0.013)
0.007
(0.013)
52,505

-0.0014***
(0.0004)
-0.025***
(0.002)
0.010**
(0.005)
0.007
(0.005)
-0.001
(0.005)
-0.007
(0.005)
140,003

-0.0008**
(0.0003)
-0.012***
(0.001)
0.005
(0.004)
0.009**
(0.004)
-0.001
(0.004)
-0.005
(0.004)
87,493

-0.0024**
(0.0010)
-0.047***
(0.004)
0.018
(0.011)
0.002
(0.011)
-0.001
(0.012)
-0.012
(0.009)
52,510

Notes: Columns 1-3 report first stage estimates of the effect of the Maimonides' Rule, a classroom monitor and dummies for grade enrollment being in a 10
percent window below and above each cutoff on class size. Columns 4-9 show first stage estimates of the effect of the Maimonides' Rule, a classroom
monitor and dummies for grade enrollment being in a 10 percent window (2 students) above and below each cutoff on score manipulation. All models
control for a quadratic in grade enrollment, segment dummies and their interactions. The unit of observation is the class. Robust standard errors, clustered
on school and grade, are shown in parentheses. Control variables include: % female students, % immigrants, % fathers at least high school graduate, %
employed mothers, % unemployed mothers, % mother NILF, grade and year dummies, and dummies for missing values in these variables. All regressions
include sampling strata controls (grade enrollment at institution, region dummies and their interactions). * significant at 10%; ** significant at 5%; ***
significant at 1%.

Table
A3.A3:
Covariate
Balanceand
in Maimonides'
RuleRule
for Institutions
and without
External
Monitor
Table
Covariates
Maimonides’
with andwith
without
External
Monitors

% in class sitting the test
% in school sitting the test
% in institution sitting the test

Female
Immigrant

51

Father HS
Mother employed

Missing data on father's education
Missing data on mother's occupation
Missing data on country of origin
N

Institutions with Monitor
Institutions without Monitor
Italy
North/Centre
South
Italy
North/Centre
South
(1)
(2)
(3)
(4)
(5)
(6)
A. Administrative Data on Schools
0.0001
0.0002
0.0000
0.0000
0.0000
0.0000
(0.0002)
(0.0002)
(0.0003)
(0.0001)
(0.0001)
(0.0002)
0.0003
0.0003
0.0002
0.0001
0.0001
0.0001
(0.0002)
(0.0002)
(0.0003)
(0.0001)
(0.0001)
(0.0002)
-0.0000
-0.0000
0.0001
-0.0001*
-0.0002*
-0.0000
(0.0001)
(0.0002)
(0.0003)
(0.0001)
(0.0001)
(0.0001)
B. Data Provided by School Staff
-0.0003
-0.0006
0.0001
0.0001
0.0005*
-0.0003
(0.0003)
(0.0004)
(0.0006)
(0.0002)
(0.0002)
(0.0003)
-0.0005
-0.0002
-0.0007**
-0.0007*** -0.0009*** -0.0003*
(0.0003)
(0.0005)
(0.0003)
(0.0002)
(0.0003)
(0.0002)
-0.0005
-0.0002
-0.0014
0.0010***
0.0003
0.0020***
(0.0005)
(0.0006)
(0.0010)
(0.0003)
(0.0004)
(0.0005)
0.0001
0.0003
-0.0004
0.0015***
0.0012**
0.0022***
(0.0008)
(0.0010)
(0.0012)
(0.0004)
(0.0006)
(0.0006)
C. Non-Response Indicators
0.0014
0.0012
0.0019
0.0000
0.0016**
-0.0026**
(0.0011)
(0.0013)
(0.0020)
(0.0007)
(0.0008)
(0.0012)
0.0018*
0.0017
0.0020
-0.0002
0.0012
-0.0028**
(0.0011)
(0.0013)
(0.0019)
(0.0007)
(0.0008)
(0.0011)
0.0006
0.0003
0.0011
-0.0002
-0.0002
-0.0003
(0.0004)
(0.0004)
(0.0008)
(0.0003)
(0.0003)
(0.0006)
34,325

22,174

12,151

105,685

65,324

40,361

Notes: This table reports coefficients from regressions of the variables listed at left on Maimonides' Rule, controlling for a
quadratic in grade enrollment, enrollment segment dummies and their interactions, grade and year dummies, and sampling
strata controls (grade enrollment at institution, region dummies and their interactions). Columns 1-3 show results for the
sample with monitors; columns 4-6 show results for the sample without monitors. Robust standard errors, clustered on school
and grade, are shown in parentheses. * significant at 10%; ** significant at 5%; *** significant at 1%.

Figure A1: Example of open-ended question in math test - V grade 2010/11

52

Figure A2: Example of open-ended question in language test - V grade 2010/11

C4.

Nella frase che segue inserisci le parole mancanti scegliendole da
questa lista: così, dove, perché, però, se, siccome.
…………….   non   conoscevo   la  strada,  ho   chiesto   a  una   signora   ……….    
dovevo  andare;;  ……………..  non  mi  sono  perso.

53

Figure A3: Answer sheet for V grade in 2010/11
Servizio Nazionale di Valutazione a.s. 2010/11
CLASSE:

Scheda Risposte Studente n°

Risultati delle prove
Codice istituto:

Codice Scuola:

Codice plesso:

Livello:

Codice Classe:

NON CAMPIONE

Codice studente:

Numero progressivo studente:

PROVA ITALIANO (1)
A1
A2
A3
A4
A5
A6
A7
A8
A9
A10
A11
A12
A13
A14
A15
A16
A17
B1
B2
B3
B4
B5
B6
B7
B8
B9
B10
B11
B12
B13
B14
B15

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B

C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C

D
D
D
D
D
D
D
D
D
D
D
D
D
D
D
D
D
D
D
D
D
D
D
D
D
D
D
D
D
D
D
D

NV
NV
NV
NV
NV
NV
NV
NV
NV
NV
NV
NV
NV
NV
NV
NV
NV
NV
NV
NV
NV
NV
NV
NV
NV
NV
NV
NV
NV
NV
NV
NV

C1_a1
C1_a2
C1_b1
C1_b2
C1_b3
C2
C3_a
C3_b
C3_c
C3_d
C3_e
C3_f
C3_g
C3_h
C3_i
C3_l
C3_m
C3_n
C3_o
C3_p
C3_q
C3_r
C4
C5
C6
C7
C8
C9
C10

PROVA MATEMATICA (1)

0
0
0
0
0
A
Nome
Nome
Nome
Nome
Nome
Nome
Nome
Nome
Nome
Nome
Nome
Nome
Nome
Nome
Nome
Nome

1
1
1
1
1
B

0
0
A
0
A
A
0

1
1
B
1
B
B
1

NV
NV
NV
NV
NV
C

D

Non_Nome
Non_Nome
Non_Nome
Non_Nome
Non_Nome
Non_Nome
Non_Nome
Non_Nome
Non_Nome
Non_Nome
Non_Nome
Non_Nome
Non_Nome
Non_Nome
Non_Nome
Non_Nome

NV
NV
C
NV
C
C
NV

NV
NV
NV
NV
NV
NV
NV
NV
NV
NV
NV
NV
NV
NV
NV
NV
NV

D

NV

D
D

NV
NV

D1_a
D1_b
D1_c
D1_d
D2
D3
D4_a
D4_b
D5
D6
D7
D8
D9
D10
D11
D12
D13
D14
D15
D16_a
D16_b
D17_a
D17_b
D17_c
D17_d
D18
D19
D20
D21_a
D21_b
D22
D23_a
D23_b
D24_a
D24_b
D24_c
D25
D26
D27
D28_a
D28_b
D28_c
D29_a
D29_b
D29_c
D29_d
D30

V
V
V
V
A

F
F
F
F
B

NV
NV
NV
NV
C

D

NV

0
A

1
B

NV
C

D

NV

0
A
A
A
A

1
B
B
B
B

NV
C
C
C
C

D
D
D
D

NV
NV
NV
NV

0
A
A

1
B
B

NV
C
C

D
D

NV
NV

0
A
A
A

1
B
B
B

NV
C
C
C

D
D
D

NV
NV
NV

0
0
V
V
V
V
A

1
1
F
F
F
F
B

NV
NV
NV
NV
NV
NV
C

D

NV

0
A

1
B

NV
C

D

NV

0
0
A

1
1
B

NV
NV
C

D

NV

0
0
0
0
0
0
A
A
km
km
km
V
V
V
V
A

1
1
1
1
1
1
B
B
m
m
m
F
F
F
F
B

NV
NV
NV
NV
NV
NV
C
C
cm
cm
cm
NV
NV
NV
NV
C

D
D
mm
mm
mm

NV
NV
NV
NV
NV

D

NV

(1) Barrare NV per risposta non valida (2 risposte o risposta incomprensibile) e non barrare nulla in caso di risposta omessa
(ATTENZIONE Non spillare, non modificare per nessun motivo i dati precompilati della scheda)

54

