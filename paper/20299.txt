NBER WORKING PAPER SERIES

THE FISCAL COST OF WEAK GOVERNANCE:
EVIDENCE FROM TEACHER ABSENCE IN INDIA
Karthik Muralidharan
Jishnu Das
Alaka Holla
Aakash Mohpal
Working Paper 20299
http://www.nber.org/papers/w20299
NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
July 2014
We are especially grateful to Michael Kremer for his involvement as a collaborator in the early stages
of this project and for subsequent discussions. We thank Julie Cullen, Roger Gordon, Gordon Hanson,
Paul Niehaus, and Adam Wagstaff for useful comments. We thank the Bill and Melinda Gates Foundation
for financial support for the data collection and analysis. Additional funds for data collection were
made available by the Governance Partnership Facility grant provided through the Human Development
Network of the World Bank. We are grateful to Pratap Bhanu Mehta and the Center for Policy Research,
New Delhi for hosting the project and providing logistical support and infrastructure. We thank Sreela
Dasgupta, Anvesha Khandelwal, and L. Ravi for project management support, and Monisha Ashok,
Jack Liebersohn, Prerna Mukharya, and Anand Shukla for outstanding research assistance. The project
would not have been possible without the efforts of Charu Sheela, Trilok Sisodiya, AV Surya, K. Venugopal,
and other staff of the Social and Rural Research Institute (SRI) in New Delhi who oversaw the field
work and primary data collection. The findings, interpretations, and conclusions expressed in this
paper are those of the authors and do not necessarily represent the views of any of the organizations
that financially supported the project or the views of the World Bank, its Executive Directors, the governments
they represent, or the National Bureau of Economic Research.
NBER working papers are circulated for discussion and comment purposes. They have not been peerreviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.
© 2014 by Karthik Muralidharan, Jishnu Das, Alaka Holla, and Aakash Mohpal. All rights reserved.
Short sections of text, not to exceed two paragraphs, may be quoted without explicit permission provided
that full credit, including © notice, is given to the source.

The Fiscal Cost of Weak Governance: Evidence from Teacher Absence in India
Karthik Muralidharan, Jishnu Das, Alaka Holla, and Aakash Mohpal
NBER Working Paper No. 20299
July 2014
JEL No. H52,I21,M54,O15
ABSTRACT
We construct a new nationally-representative panel dataset of schools across 1297 villages in India
and find that the large investments in public primary education over the past decade have led to substantial
improvements in input-based measures of school quality, including infrastructure, pupil-teacher ratios,
and monitoring. However, teacher absence continues to be high, with 23.6 percent of teachers in public
schools across rural India being absent during unannounced visits to schools. Improvements in school
infrastructure and service conditions are not correlated with lower teacher absence. We find two robust
correlations in the nationally-representative panel data that corroborate findings from smaller-scale
experiments. First, reductions in pupil-teacher ratios are correlated with increased teacher absence.
Second, increases in the frequency of inspections are strongly correlated with lower teacher absence.
We estimate that the fiscal cost of teacher absence in India is around $1.5 billion per year, and that
investing in better governance by hiring more inspectors to increase the frequency of monitoring could
be over ten times more cost effective at increasing teacher-student contact time (net of teacher absence)
than hiring more teachers.
Karthik Muralidharan
Department of Economics, 0508
University of California, San Diego
9500 Gilman Drive
La Jolla, CA 92093-0508
and NBER
kamurali@ucsd.edu
Jishnu Das
The World Bank
jdas1@worldbank.org

Alaka Holla
World Bank
alaka.holla@gmail.com
Aakash Mohpal
University of Michigan
amohpal@umich.edu

1. Introduction
India has the largest primary education system in the world, catering to over 200 million
children. During the past decade, the Government of India has made substantial investments in
primary education under the Sarva Shiksha Abhiyan (SSA) or "Universal Education Campaign".
Partly financed by a special education tax, this national program sought to correct historical
inattention to primary education and led to a substantial increase in annual spending on primary
education across several major categories of inputs including school infrastructure, teacher
quality, pupil-teacher ratios, and school feeding programs.
However, the public education system in India also faces substantial governance challenges
that may limit the extent to which this additional spending translates into improved education
outcomes. One striking indicator of weak governance is the high rate of teacher absence. A
nationally-representative study of over 3,000 government-run primary schools across 19 major
Indian states found that over 25 percent of teachers were absent from work on a typical working
day in 2003 (Kremer et al. 2005). Thus, while administrative data from the government's
official records1 suggest that SSA has led to an improvement in various observed measures of
school quality, there is very little evidence on whether these investments have translated into
improvements in education system performance, both with respect to intermediate metrics such
as teacher absence and final outcomes such as test scores.
In this paper, we study the impact of this nationwide campaign to improve school quality in
India using a new nationally-representative panel dataset of education inputs and outcomes. We
constructed this data by revisiting (in 2010) a randomly-sampled subset of the villages that were
originally surveyed in 2003 and collecting detailed data on school facilities, teachers, community
participation, and monitoring visits by officials. We also measure teacher absence rates. Thus,
in addition to reporting updated estimates of teacher absence, and independently-measured
summary statistics on input-based measures of school quality, we are able to correlate changes in
input-based measures of school quality with changes in teacher absence. The panel data help
mitigate concerns arising from fixed unobserved heterogeneity at the village-level, and our
results provide the best available estimates using nationwide data of how the sharp increases in
public education spending of the past decade have improved school quality.
1

These come from the “District Information System for Education” and are commonly referred to as the DISE data.

1

We find significant improvements in almost all input-based measures of school quality
between 2003 and 2010. The fraction of schools with toilets and electricity more than doubled,
and the fraction serving mid-day meals nearly quadrupled. There were significant increases in
the fraction of schools with drinking water, libraries, and a paved road nearby. The fraction of
teachers with college degrees increased by 40 percent, and pupil-teacher ratios (PTR) fell by 16
percent. The fraction of teachers not paid on time fell from 51 to 22 percent, and the fraction of
teachers aware of recognition programs increased from 49 to 81 percent. Finally, the frequency
of school inspections and parent-teacher association (PTA) meetings increased significantly.
Reductions in teacher absence rates were more modest. The all-India weighted average
teacher absence in rural areas fell from 26.3 to 23.6 percent.2 While increased teacher hiring
brought the PTR down to below 40, the effective PTR (after accounting for teacher absence) was
over 52. The variation in teacher absence across states remains high. At one end, top performing
states like Tamil Nadu, Punjab, Maharashtra, Chhatisgarh, and Orissa all have teacher absence
rates below 15 percent, while at the other, the poorest performing state, Jharkhand, has a teacher
absence rate of 46 percent. We estimate legitimate absence rates to be in the range of 8-10
percent; thus, the variation among states in unauthorized teacher absence rates is even higher.
While the cross-sectional correlations in the original teacher absence study (Kremer et al.
2005) suggested a negative relationship between school infrastructure and teacher absence, we
find no significant correlation between changes in infrastructure and changes in teacher absence
in the panel data. We do, however, find two robust correlations in the panel data.3
First, reductions in the school-level pupil-teacher ratio (PTR) are correlated with an increase
in teacher absence, suggesting that the potential benefits from investing in more teachers and
smaller class sizes may be partly offset by an increase in teacher absence. Second, better topdown administrative monitoring is strongly correlated with lower teacher absence. Villages with
regular public school inspections had teacher absence rates that were 6.5 percentage points lower
than villages without inspections (a 25% reduction in overall absence, and a 40% reduction in
2

While the all-India weighted average teacher absence estimated in 2003 was 25.2 percent, the corresponding figure
for the rural sample was 26.3 percent. The panel survey only covered the rural sample.
3
As we discuss further in the results section, we consider 'robust' correlations to be those where the point estimates
are significant and similar in both binary and multiple regressions, and in specifications with no fixed effects, with
state fixed effects, and with district fixed effects. These results are therefore unlikely to be confounded with omitted
variables at the state or district level.

2

illegitimate absence). We find that changes in inspection frequency over time are not correlated
with reductions in either authorized leave or official duty but are mainly correlated with
reductions in unauthorized absence rates. We also show that the changes in inspections are not
correlated with changes in other teacher or school characteristics.
We combine our estimates of illegitimate teacher absence with data on the number of
teachers employed and their salaries to calculate a fiscal cost of teacher absence over $1.5 billion
per year. This represents 60 percent of the entire revenue collected from the special education
tax used to fund SSA (in 2010).4 How can this fiscal cost of teacher absence be reduced? Using
the most conservative panel-data estimate of the correlations between increased inspections and
reduced teacher absence, and assuming that these effects were causal, we estimate that a
marginal increase in the frequency of school monitoring and supervision would yield a ten-fold
return on investment of the cost of increased inspections in terms of the salary cost saved through
reduced teacher absence. Finally, we consider two policy options for increasing effective
teacher-student contact time – hiring more inspectors, and hiring more teachers – and find that
the former would be over twelve times more cost effective. Hiring more teachers entails an
additional cost because of the increase in absence rates of existing teachers when additional
teachers are hired. These results highlight the large fiscal costs of weak governance in Indian
primary education and the potential returns to investing in better monitoring.
This paper makes several contributions to the literature on public economics in developing
countries. First, teacher absence is now widely used as a governance indicator in education in
middle- and low-income countries.5 We update the estimates of teacher absence in rural India
from 2003 and show that in spite of substantial increases in spending on education inputs over
the last decade, improvements on this key measure of governance have been more modest. Our
estimates of the large fiscal cost of teacher absence (accounting for 60 percent of the collections
from the special education tax) highlight the importance of governance issues that lead to
significant amounts of 'passive' waste and inefficiency on an ongoing annual basis, but may not
obtain as much media attention as one-off corruption scandals (Bandiera, Pratt and Valleti 2009).
4

http://indiabudget.nic.in/budget2012‐2013/ub2012‐13/rec/tr.pdf
The World Bank's World Development Report 2004 provided estimates of provider absence in both health and
education for a sample of developing countries (World Bank 2003; Chaudhury et al. 2006). These numbers have
been widely cited in policy discussions, and reduction in provider absence rates is often included as an objective in
aid agreements between donors and aid recipients.

5

3

Second, our results showing that decreases in PTRs are correlated with increased teacher
absence underscores the importance of distinguishing between average and marginal rates of
corruption and waste in public spending. Niehaus and Sukhtankar (2013) propose this
terminology in the context of wages paid to beneficiaries in a public-works program in India and
find that marginal rates of leakage are much higher than average rates. We find the same result
in the context of teachers and show that the effective absence rate of the marginal teacher hired is
considerably higher than the average absence (because of the increased absence among existing
teachers). This result, from a large all-India sample mirrors smaller-sample experimental
findings in multiple settings: Duflo, Dupas, and Kremer (2012) and Muralidharan and
Sundararaman (2013) present experimental evidence (from Kenya and India) showing that
provision of an extra teacher to schools led to an increase in the absence rate of existing teachers.
Third, we find that improvements in top-down administrative monitoring (inspections) are
significantly more correlated with reduced teacher absence than improvements in bottom-up
community monitoring (PTA meetings), which is consistent with experimental evidence on the
relative effectiveness of administrative and community audits on reducing corruption in road
construction in Indonesia (Olken 2007). More broadly, a growing body of experimental
evidence points to the effectiveness of audits and monitoring (accompanied by rewards or
sanctions) in improving the performance of public-sector workers and service providers
(including Olken 2007 in Indonesia; Duflo et al. 2012 in India; and Zamboni and Litschig 2013
in Brazil). Our panel-data estimates using data from an "as is" nationwide increase in monitoring
of schools provide complementary evidence to smaller-scale experiments and suggest that
investing in better governance and monitoring of service providers may be an important
component of improving state capacity for service delivery in low-income countries (Besley and
Persson 2009; Muralidharan, Niehaus, and Sukhtankar 2014).
Finally, recent research has pointed to 'misallocation' of capital and labor in developing
countries as an important contributor to lower total factor productivity (TFP) in these settings
(Hsieh and Klenow 2009). Aiming to increase teacher-pupil contact time in classrooms, central
and state governments in India plan to spend an additional $5 billion/year to hire new teachers to
reduce PTR from 40:1 to 30:1 under the recently passed Right to Education (RtE) Act. Our
results suggest that reallocating education spending from hiring more teachers to hiring more
4

inspectors may be a more cost effective way of increasing effective teacher-student contact time.
Thus, misallocation is likely to be a first-order issue in this setting, and reallocating education
spending may substantially increase TFP in publicly-produced education.
The policy implications of our results depend on the priors of the policy maker. For some
policy makers, our results (estimated using a village-level panel data set representing over a
billion people) may suggest that expanding the frequency of inspections would be desirable. In
section 6, we argue that even a policy maker who thought there was only a 1% chance that our
panel-data estimates reflected a causal effect, and a 99% chance that they reflected omitted
variable bias, with the true effect being zero, would find it worthwhile to implement a substantial
nationwide expansion of school inspections in the context of an experimental evaluation.
From a policy perspective, it is also worth noting that several of the innovative approaches to
improving teacher performance in developing countries that have been examined in recent years
using experimental evaluations (including teacher performance-linked pay, and monitoring
teacher attendance with cameras)6 require fixed costs to set up, and often face political and
administrative hurdles in implementation. In contrast, inspection systems are already in place in
most countries, but schools are often not inspected because of staffing shortages. It should
therefore be administratively easy to expand the frequency of school inspections by hiring staff
to fill these shortages (and to conduct an experimental evaluation of such an expansion).
The rest of this paper is organized as follows: Section 2 discusses our empirical methods and
analytical framework. Section 3 reports summary statistics on school inputs and teacher absence.
Section 4 presents the cross-sectional and panel regression results. Section 5 discusses the fiscal
costs of weak governance and compares the returns to investing in better monitoring with that
from hiring more teachers. Section 6 discusses policy implications, and section 7 concludes.
2. Data and Analytic Framework
The nationally-representative sample used for the 2003 surveys, which our current study uses
as a base, covered both urban and rural areas across the 19 most populous states of India, except
Delhi. This represented over 95 percent of the country’s population. The 2010 sample covered
only rural India. The sampling strategy in 2010 aimed to maintain representativeness of the
6

See Muralidharan and Sundararaman (2011), and Duflo, Hanna, and Ryan (2012) for examples.

5

current landscape of schools in rural India and to maximize the size of the panel. We met these
twin objectives (representativeness and panel) by retaining the villages in the original sample to
the extent possible, while re-sampling schools from the full universe of schools in these villages
in 2010, and by conducting the panel analysis at the village level.7
Enumerators first conducted school censuses in each village, from which we sampled up to
three schools per village for the absence surveys. During fieldwork, enumerators made three
separate visits to each sampled school over a period of 10 months from January – October 2010.8
Data on school infrastructure and accessibility, finances (income and expenditure), and teacher
demographics were collected once for each school (typically during the first visit, but completed
in later visits if necessary), while data on time-varying metrics such as teacher and student
attendance and dates of the most recent inspections and PTA meetings were collected in each of
the three visits. We also assessed student learning with a test administered to a representative
sample of fourth grade students in sampled schools. See Appendix A and Appendix Tables 1-3
for further details on sampling and construction of the village-level panel data set.
Teacher absence was measured by direct physical verification of teacher presence within the
first fifteen minutes of a survey visit. Data collected during the school census were used to prepopulate teacher rosters for the sampled schools, so that enumerators could look for teachers and
record their attendance and activity immediately after their arrival at the school.9 Once teacher
attendance was recorded, all other data were collected using interviews of head teachers and
individual teachers.10

7

This is also why the 2010 wave did not include urban areas. Since school-level identifiers from the 2003 survey
were not preserved (for confidentiality reasons), the panel needed to be constructed at the town/village level.
However, since the fraction of urban schools covered in 2003 (relative to the total number of schools in the sampled
towns) was very small, it was not possible to construct a credible panel-data estimate of school quality in towns. In
rural areas, this was not a concern because we typically covered all the public schools in a village (in 84.2 percent of
the cases) and had a mean coverage rate of 82.7 percent of public schools in the sampled villages.
8
While the exact timing of the school year is not identical across states, the typical school year runs from mid-June
to mid-April. The three visits therefore spanned two academic years, with the first visit being made during JanuaryMarch 2010, the second visit being made during June – August, and the third visit during August – October 2010.
9
This was important given the widespread possession of cell phones among teachers, which would allow them to
call up absent colleagues as soon as they saw external visitors in the school, who were measuring teacher absence.
10
Of course, not all interviews could be successfully completed. Most non-responses were at the teacher as opposed
to the school level (since absent teachers could not be interviewed, whereas school data could be obtained from
either the head teacher or any other senior teacher). These non-responses do not affect the analysis in this paper
because the panel-data analysis will focus on aggregated data at the village level as opposed to the individual data at
the teacher level.

6

We record teachers as absent on a given visit if they were not found anywhere in the school
in the first fifteen minutes after enumerators reached a school. We consider all the teachers in
the school to be absent if the school was closed during regular working hours on a school day,
and respondents near the school did not know why the school was closed or mentioned that the
school was closed because no teacher had arrived or they had all left early.11 To be conservative
in our measure of absence, we exclude all school closures due to bad weather, school
construction/repairs, school functions and alternative uses of school premises (for instance,
elections). We also exclude all part-time teachers, teachers who were transferred or deputed
elsewhere, or teachers reportedly on a different shift.
We construct a school infrastructure index by adding binary indicators for the presence of
four indicators of school facilities – drinking water, toilets, electricity and a library. We
construct a remoteness index by taking the average of nine normalized indicators of distance to
various amenities including a paved road, bus station, train station, public health facility, private
health clinic, university, bank, post-office and Ministry of Education office. A lower score on the
remoteness index represents a better connected school.
During each survey visit, we record the date of the most recent school inspection. We
measure the extent of monitoring and supervision as the mean probability of being inspected in
the past three months across all three visits. We used a similar procedure for constructing the
mean probability of a parent-teacher association (PTA) meeting. Average parental education of
children in a school is computed from the basic demographic data collected for the sample of
fourth-grade students chosen for assessments of learning outcomes.
For most of the analysis in this paper, we use the village as our unit of analysis and examine
mean village-level indicators of both inputs and outcomes because a large number of new
schools had been constructed between 2003 and 2010, including in villages that already had
schools. This school construction resulted from a policy designed to improve school access by
ensuring that every habitation with over 30 school-age children had a school within a distance of
one kilometer. Thus, to ensure that our sample was representative in 2010, and at the same time
amenable to panel data analysis relative to the 2003, we constructed the panel at the village level,
11

Field teams obtained lists of state and national school holidays in advance of creating the field plans and ensured
that no visits were conducted on these days.

7

with a new representative sample of schools drawn in the sampled villages.12 All the results
reported in this paper are population weighted and are thus representative of the relevant
geographic unit (state or all-India).
3. Summary Statistics
3.1 Changes in inputs
The data show considerable improvements in school inputs between 2003 and 2010 along
three broad categories – teacher qualifications and working conditions, school facilities, and
monitoring (Table 1). The fraction of teachers with a college degree increased by over 40
percent (from 41 to 58 percent), the fraction reporting getting paid regularly rose by around 60
percent (from 49 to 78 percent), and the fraction reporting the existence of teacher recognition
schemes rose by over 60 percent (50 to 81 percent). While the fraction of teachers who report a
formal teaching credential fell by 12 percent (77 to 68 percent), the main contributor to this
decline was the large increase in the hiring of contract teachers in several large states, which led
to an increase in the fraction of contract teachers from 6 to 30 percent. The pupil-teacher ratio
also fell by around 16 percent (from 47.2 to 39.8)
School facilities and infrastructure improved on almost every measure. The fraction of
schools with toilets and electricity more than doubled (from 40 percent to 84 percent for toilets
and 20 percent to 45 percent for electricity); the fraction of schools with functioning midday
meal programs nearly quadrupled (from 21 percent to 79 percent); the fraction of schools with a
library increased by over 35 percent (from 51 percent to 69 percent), and almost all schools now
have access to drinking water (96 percent). Initiatives outside the education ministry to increase
road construction have also led to increased proximity of schools to paved roads increasing the
accessibility of schools for teachers who choose to live farther away. Relative to the distribution
observed in 2003, a summary index of school infrastructure improved by 0.9 standard deviations.
Table 1 also documents improvements in both ‘top-down’ administrative and ‘bottom-up’
community monitoring of schools over this period. The fraction of schools inspected in the three
months prior to a survey visit increased by over 40 percent (from 39 percent to 56 percent). This

12

Even in the absence of school construction, the survey firm did not retain school and teacher level identifiers from
the 2003 survey (complying with data protection norms), which would have made it difficult to construct a schoollevel panel (especially for villages with multiple schools).

8

increase in inspection probability is even more pronounced over shorter time windows,
increasing by over 60 percent for the previous two months and over 70 percent for the previous
month. Finally, the extent of community oversight of schools, measured by the frequency of
PTA meetings also increased: The probability that a PTA meeting took place during the three
months prior to a survey visit increased by 50 percent (from 30 percent to 45 percent). Overall,
Table 1 confirms that the Government of India’s increased focus on primary education in the
past decade did lead to significant improvements in input-based measures of school quality.
3.2 Changes in teacher absence
We now turn to changes in teacher absence. Table 2 (Column 2) shows teacher absence rates
by state as well as the weighted average national absence rate for rural India. It also shows the
corresponding figures for 2003 to facilitate comparison (Column 1). The population-weighted
national average teacher absence rate for rural India fell from 26.3 percent to 23.6 percent, a
reduction of 10 percent or 2.65 percentage points.
Considerable variation remains in teacher absence rates across states with estimates ranging
from 12.9 percent in Tamil Nadu to a high of 45.8 percent in Jharkhand. Teacher absence rates
declined in 14 out of 19 states with significant reductions in 12 states. Five states (Tamilnadu,
Punjab, Maharashtra, Orissa, and Chhatisgarh) now report teacher absence rates below 15
percent. On a population-weighted basis, the largest contributor to reductions in all-India teacher
absence was Bihar, which is consistent with the widely-reported improvement in governance in
the state during this period (Chakrabarti 2013). In contrast, the significant increase in teacher
absence in India’s most populous state Uttar Pradesh (population over 200 million), partly offset
the reduction in other states.
Since Chaudhury et al. (2006) find a strong negative correlation between GDP/capita and
teacher absence rates (both across countries and within Indian states), one way to interpret the
magnitude of these changes is to compare them with the expected reduction in teacher absence
that may be attributed simply to the economic growth that has taken place in this period. Using a
growth accounting (as opposed to causal) framework, we can decompose the change in teacher
absence into a component explained by changes in GDP/capita (as a proxy for ‘inputs’) and one
explained by a change in governance (a proxy for TFP). Cross-sectional estimates from the 2003
data suggest that a 10 percent increase in GDP/capita is associated with a 0.6 percentage point
9

reduction in teacher absence.13 In the period between 2002 and 2010, real GDP/capita in India
has grown 38 percent. Thus, growth in GDP/capita over this period should have by itself
contributed to a reduction in teacher absence of 2.4 percent. Our estimate of the change in
teacher absence rate is exactly in this range, and suggests that the reduction of teacher absence
we document is consistent with a proportional increase in ‘inputs’ into education, but a limited
improvement in TFP in this period. We discuss the policy implications of this in the conclusion.
Finally, to interpret the cost of teacher absence to students, we note that the effective
attention a student receives from a teacher can be increased both by reducing teacher absence as
well as by hiring more teachers. To account for the reduced attention that students receive when
teachers are absent, we define the “effective pupil teacher ratio (EPTR)” as:
.
We use official DISE data on total enrollment and total number of teachers, combined with the
absence rates from our survey to calculate both the PTR and EPTR by state in 2003 and 2010
(Table 2 – columns 4-9). We see that though all-India PTR had been reduced to below 40 in this
period, the effective PTR after accounting for teacher absence was over 52. The effective PTR in
2010 in three of India’s most educationally backward states (Bihar, Jharkhand, and Uttar
Pradesh) was as high as 97, 79, and 69. These figures illustrate that teacher absence can sharply
increase the effective PTR experienced by students relative to the PTR calculated using statelevel figures on enrollment and number of teachers.
3.3 Official records, teaching activity, and stated reasons for absence
Enumerators recorded whether a teacher had been marked as present in the log-books on the
day of the visit and also on the previous day, and we see in Table 3 - Panel A that going by these
records would suggest a much lower teacher absence rate of 16 percent using the same day's
records, or as low as 10.2 percent using the previous day's records (this was not collected in
2003). These data suggest that official records can be easily manipulated, and highlight the

13

The cross-sectional relationship is estimated by regressing village-level teacher absence on the log of district-level
per-capita consumption (from the National Sample Survey) in the 2003 survey. Estimates without state fixed effects
are larger (and equal -1.17) whereas estimates with state fixed effects are smaller but still significant (and equal to 0.63). Our default estimate is based on using state-fixed effects since cross-state variation in per-capita income is
much more likely to be correlated with unmeasured governance quality. Tables are available on request.

10

importance of measuring teacher absence by direct physical verification as opposed to official
records on log books.
Enumerators also recorded the activity that teachers were engaged in at the point of
observation, and we see that 53 percent teachers on the payroll were found to be actively
teaching, and another 4 percent were coded as passively teaching (defined as minding the class
while students do their own work). Just over 19 percent of teachers were in school but were
either not in the classroom or not engaged in teaching activity while in the classroom. Thus a
total of 42 percent of teachers on the payroll were either absent or not teaching at the time of
direct observations (Table 3 - Panel B).14
In cases where a teacher was not found in the school, enumerators asked the head teacher (or
senior-most teacher who was present) for the reason for absence. These stated reasons are
summarized in Table 3 (Panel C). Two categories of clearly unauthorized absence (school
closure during working hours and no valid reason for absence) account for just under half the
cases of teacher absence (48 percent), which provides a lower bound on the extent of
unauthorized absences of 11.3 percentage points. The two other categories of stated absence
(authorized leave and other official duties) that account for 52 percent of the observed absence
are plausibly legitimate but cannot be verified.
While head teachers may overstate the extent of official duties to shield absent colleagues15,
they should have no reason to understate it. We can, therefore, reasonably treat the stated
reasons for absence as an upper bound for duty-induced absence. This yields the important
finding that one commonly cited reason for teacher absence - namely, that teachers are often
asked to perform non-teaching related duties such as conducting censuses and monitoring
elections - is a very small contributor to the high rates of observed teacher absence. Table 3 Panel C shows that official non-teaching duties account for less than 1 percent of the
observations and under 4 percent of the cases of teacher absence (these results are unchanged
from 2003).

14

This is almost surely an underestimate (and hence a lower bound) because in many cases it is easy for a teacher
who may not have been teaching to pick up a book and look like he or she is actively teaching when it is known that
someone is visiting the school (see Muralidharan and Sundararaman 2010 for evidence documenting this).
15
We see this most clearly in Table 3 - Panel A, where over 7.5 percent of teachers who were not found in the
school during the direct observation were marked present in the official log books, suggesting collusion among
teachers in the reporting of absence in official records.

11

4. Cross-section and Panel Regression Results
4.1. Correlates of teacher absence in 2010
Table 4 presents cross-sectional correlations between indicators of school quality and teacher
absence in 2010. As discussed in section 2.4, this analysis is done at the village-level since our
panel analysis must be done at the village-level. Column 1 shows the mean level of each
covariate in the sample, columns 2-4 present the coefficients on each indicator in binary
regressions with the dependent variable being teacher absence, while columns 5-7 do so in
multiple regressions that include all the variables shown in Table 1.
We first show the correlations with no fixed effects, then with state fixed effects, and finally
with district fixed effects. The comparison of results with and without state fixed effects is
important for interpretation. Many indicators of school quality vary considerably across states in
a manner that is likely to be correlated with other measures of governance and development as
well as the history of education investments in these states. On a similar note, while primary
education policy is typically made at the state level, there is often important variation across
districts within a state based on historical as well as geographical factors (Banerjee and Iyer
2005; Iyer 2010). Thus, specifications with district fixed effects that are identified using only
within-district variation are least likely to be confounded by omitted variables correlated with
historical or geographical factors. However, there may still be important omitted variables
across villages (such as the level of interest in education in the community) that are correlated
with both measured quality of schools and teachers as well as teacher absence. We therefore
present the correlations in Table 4 for completeness and focus our discussion on the panel
regressions presented in Table 5.
Without any fixed effects, teachers who have formal training, who are paid more regularly,
who are eligible for recognition schemes, and who are in schools with better infrastructure are
less likely to be absent (Table 4 – Column 2 and 5). However, none of these correlations are
significant with state or district fixed effects suggesting that states that have a longer history of
investing in education may have better indicators of school and teacher quality and lower teacher
absence, but that these metrics of teacher quality do not predict teacher absence within states or
districts. Overall, there are few robust correlations across all specifications except that schools
12

that have been inspected recently have significantly lower rates of absence. One important result
in the correlations is that there appears to be no significant relationship between teacher salary
and the probability of teacher absence. Since salary data were not collected in the 2003 survey,
this variable is not included in the panel analysis below.
4.2. Correlates of changes in teacher absence between 2003 and 2010
The main identification challenge in the cross-sectional correlations presented in Table 4
(and in Kremer et al. 2005) is that we cannot rule out the possibility that the results are
confounded with village-level omitted variables. The use of panel data helps mitigate these
concerns since our correlations are now identified using changes in village-level measures of
school inputs. Table 5 (columns 4-6) presents results from the following regression:
∆
where ∆

∙∆

∙∆

∙

(1)

is the change in the mean teacher absence rate in government schools in village i

between 2003 and 2010, ∆
attributes, ∆

∙∆

is the change in village-level means of measures of teacher

is the change in village-level means of measures of school facilities, and ∆

is

the change in village-level means of measures of school monitoring and supervision.
represents different levels of fixed effects (state or district) and

is the error term. Since

changes in the measures of school quality included above may be correlated, we report both
binary regressions with only covariate at a time (columns 1-3) as well as multiple regressions
that include all of these covariates (columns 4-6).
The results in Table 5 suggest that several anecdotal narratives for the reasons for teacher
absence are not supported in the panel data regressions. In particular, we find no correlation
between changes in school infrastructure or proximity to a paved road and teacher absence. We
also find no correlation between changes in teacher professional qualifications or professional
conditions (such as regularity of pay) and changes in teacher absence.
We find two robust relationships in the panel regressions, where we define 'robust' as
correlations that are significant in both binary and multiple regressions; significant in all our
three main specifications (no fixed effects, state fixed effects, and district fixed effects) and

13

consistent across all these specifications (we cannot reject that the estimates are the same across
all these specifications).
First, villages that saw a reduction in pupil-teacher ratio (PTR)16 have significantly higher
rates of teacher absence. This is a potentially counterintuitive result because a common narrative
for teacher absence is that their working conditions are poor, with high PTRs cited as a
prominent example of burdensome working conditions. However, the most common outcome
for students when their teacher is absent is that they are combined with other classes (typically
from other grades) whose teachers are present.17 Our results therefore suggest that having more
teachers may make it easier for teachers to be absent (since other teachers can handle their class),
and that the impact of hiring additional teachers may be partially offset through increased teacher
absence. The estimates suggest that a 10 percent reduction in PTR is correlated with a 0.5
percent increase in average teacher absence.
The estimates remain stable when we include state and district fixed effects and are
unchanged even when we introduce a full set of controls (also measured in changes). These
results are consistent with the hypothesis that the relationship is causal. Some identification
challenges in a cross-section are less salient in the panel. Decisions on teacher placement are
largely based on administrative criteria of whether schools are above or below the PTR norms
and are unlikely to be correlated with contemporaneous changes in teacher absence.18 Indeed, a
causal relationship between increased teacher hiring and increased absence of existing teachers
has been established experimentally in other developing countries, such as Kenya (Duflo, Dupas,
and Kremer 2012) and India (Muralidharan and Sundararaman 2013). Our estimates provide
complementary evidence and greater external validity to these experimental results and suggest
that they generalize to nationally scaled-up programs of reducing class sizes by hiring more
teachers in contexts with weak teacher accountability.

16

We focus on the school-level pupil-teacher ratio (PTR) because the policy goals for teacher hiring are stated in
terms of PTR. But in practical terms, lowering PTR is equivalent to lowering class-sizes.
17
Doing so does not deviate from the norm in the context of rural Indian government-run primary schools because
our data show that close to 80 percent of schools practice multi-grade teaching (where one teacher simultaneously
teaches students across multiple grades at the same time in the same classroom) in any case.
18
The most likely omitted variable concern would in fact go the other way. If communities that cared more about
education were more likely to be able to get additional teachers, they would also be more likely to ensure better
teacher attendance, suggesting that our results may be a lower bound on the magnitude of this effect.

14

The second robust result in the panel data estimates is the strong negative correlation
between improved school monitoring and teacher absence. In each of the three visits to a school,
enumerators recorded the date of the most recent inspection, and we average across the three
visits to construct the "Inspected in last 3 months" variable which ranges from zero (not
inspected in the prior three months in any of the three visits) to one (inspected in the prior three
months in all of the three visits). The results suggest that villages where the probability of
inspection in the past three months increased from zero to one had a reduction in average teacher
absence of between 8.2 percentage points (with no fixed effects and no controls) and 6.4
percentage points (district fixed effects and a full set of controls). The estimates are remarkably
consistent across all 6 specifications, and even the most conservative estimate suggests that
teacher absence rates in schools that are regularly inspected are over 25 percent lower than in
schools that are not.
To further check for patterns in the data that could support a causal interpretation of this
result, Table 6 breaks down the dependent variable (teacher absence) by the various categories of
stated reasons for absence (official duty, authorized leave, and unauthorized absence), and shows
the coefficient on the "inspections" variable on each of these dependent variables. Panel A
shows the cross-section estimates (corresponding to Table 4) while Panel B shows the panel ones
(corresponding to Table 5). We see that increases in inspections are correlated with reductions in
unauthorized teacher absence, but that there is no significant relationship between inspections
and reductions in teacher absence due to either official duty or authorized leave.19 These results
are consistent with the interpretation that improved 'top down' administrative monitoring can
have a significant and substantial impact on reducing unauthorized teacher absence.
In contrast, there is little evidence that increases in 'bottom up' monitoring by the community
(measured by whether the PTA had met in the past 3 months) are correlated with reductions in
teacher absence (Table 5). This is consistent with the experimental results reported in Olken
(2007) on the impacts of monitoring corruption in Indonesia. These results should not be
19

The point estimates on these categories suggest that increasing inspections may reduce the fraction of teacher
absence that is recorded as "official duty" and increase the fraction that is recorded as "authorized leave". These
results are consistent with head teachers and teachers colluding to some extent to record absences as being due to
official duty that do not count against a teacher's quota of authorized leave. Increased inspections may make it
difficult to sustain this collusion (since the inspector will be able to verify if the teacher is away on official duty) and
require more of the absences to be counted against a teacher's official leave quota.

15

interpreted as suggesting that bottom-up monitoring cannot be effective, since it is also likely
that they reflect differences in the effective authority over teachers possessed by administrative
superiors (high) versus parents (low). PTAs in India typically do not have authority to appoint or
retain regular civil-service teachers, and they cannot sanction teachers for absence or nonperformance. Inspectors and administrative superiors, on the other hand, do possess authority
over teachers, including the ability to demand explanations for absence, to make adverse entries
in teachers’ performance record, and in extreme cases to initiate disciplinary proceedings. These
actions do not take place very often, but the administrative rules provide inspectors with the
powers to take these actions, whereas PTAs do not have any such powers. 20
As in the case of the changes in PTR, the stability of the estimates to the introduction of state
and district fixed effects as well as a full set of controls helps mitigate concerns about omitted
variables bias. To further address identification concerns, we examine the extent to which
changes in inspection frequency can be explained by other observables, and find that there are no
correlations between changes in inspections and changes in other measures of school quality that
are significant across our three standard specifications (Table 7). Finally, these results are also
consistent with experimental evidence from India that finds significant reduction in teacher
absence in response to improved monitoring and professional consequences that are linked to
better attendance (Duflo et al. 2012). Since the experimental study was carried out in a small
sample of informal schools in one state in India, our estimates using a nationally-representative
panel dataset of rural public schools provides complementary evidence on the likely role of
improved monitoring on reducing teacher absence.
In interpreting the result on school inspections, it is useful to consider why there might be
variation in the frequency of inspections across villages and what this would imply for
interpreting the results causally. One obvious explanation is that inspectors are more likely to

20

In addition to the possibility of formal disciplinary action against absent teachers, an additional channel for the
deterrence effect of increased inspections on teacher absence may stem from the possibility that inspectors can
extract side payments from absent teachers in return for not making a formal adverse entry on their service record
(World Bank 2003). Social norms would make it difficult to 'extort' such payments from teachers who are actually
present, but it would be much easier to demand a payment from an absent teacher. Thus, even if the costs of
initiating formal disciplinary action are high (and the incidence of such action is low), there may be other informal
channels through which more frequent inspections serve as a disincentive for teacher absence.

16

visit more accessible villages, but the data do not support this hypothesis since there is no
correlation between changes in the remoteness index and changes in inspection rates (Table 7).
Detailed interviews on school governance in India conducted at the district level suggest two
important reasons for the variation in inspection frequency (Center for Policy Research 2012).21
The first is staffing. Districts are broken down further into administrative blocks, and schools
within blocks are organized into clusters. School supervision is typically conducted by "block
education officers" and "cluster resource coordinators". We find that a significant fraction of
these posts are often unfilled. For instance, in 19 percent of the cases (where we have data) even
the position of the "District Education Officer (DEO)", the senior-most education official in a
district, was vacant. Further, there is high turnover in education administration (the average
DEO had a tenure in office of just one year) creating periods when the positions are vacant
during transitions. The lack of supervisory staff at the block-level is even more acute, as 32% of
these positions were estimated to be vacant in 2010 (the year of our survey) by official
government documents (13th JRM Monitoring Report 2011). Our interviews suggest that these
staffing gaps at the block and cluster level are the most important source of variation in
inspection frequency within districts, since blocks and clusters without supervisory staff are
much less likely to get inspected.
The second source of variation in inspections is the diligence of the concerned supervisory
officer. Even if all the positions of supervisory staff were filled, there would be variation in the
zealousness with which these officers visited villages/schools, which might lead to some areas
being inspected more often than others based on whether they were in the coverage area of a
more diligent officer or not. However, since inspectors are typically assigned a coverage area of
clusters or blocks that comprise many villages, variation in inspection frequency that is driven by
inspector-level unobservable characteristics is unlikely to be correlated with other village-level
characteristics that are also correlated with absence (and as a result, the estimated coefficients on
“inspected in the last 3 months” using village-level panel data are unlikely to be biased). Of
21

This module was designed to complement the school surveys by allowing us to create quantitative measures of
district-level education governance. Unfortunately, the non-completion rate for these interviews was very high
(over 40 percent) due to non-availability, and non-response of district-level administrators. Since this non-response
is clearly not random, we do not use the quantitative measures in regressions. Nevertheless, important qualitative
insights can be obtained from these interview transcripts. These results are summarized in a companion policy
report (Center for Policy Research 2012).

17

course, this source of variation has implications for thinking about the likely effectiveness of
hiring new staff (some of whom may be less diligent). We discuss these in section 5.3.
4.3. Correlates of changes in student outcomes
While the focus of our analysis has been on teacher absence, we also briefly consider the
correlations between improvements in school quality (seen in Table 1) and learning outcomes.
Table 8 presents panel regressions of the form in equation (1), where changes in normalized
mean math test scores at the village level are regressed on changes at the village-level, including
teacher absence, school facilities, and monitoring. The only variables that are significantly
correlated with changes in test scores are changes in mean parental education and changes in the
fraction of students taking private tuition. School-level variables are not consistently significant,
though higher PTRs and higher teacher absence are both correlated with lower test scores (and
significant in some specifications). However, there is no positive correlation between the
improvements in most of the standard measures of school quality and student learning outcomes
- including school infrastructure, mid-day meals, and teacher qualifications and training.
We only treat these results as suggestive because the data (with a seven-year gap in mean
village-level test scores) is not ideal for testing the impact of school characteristics on test scores.
The ideal specifications would use annual panel data on student test scores matched to these
characteristics and estimate value-added models of student learning. Nevertheless, the main
findings here are consistent with those in studies set in developing countries using data sets that
are better suited to study student learning outcomes, which find that teacher absences
significantly hurt student learning, and that school infrastructure, teacher qualifications, and
training are not correlated with improved student learning.22

22

Duflo et al (2012) show experimentally that lower teacher absence raises test scores, while Muralidharan (2012)
shows this in value-added estimates with five years of annual panel data on test scores in the state of Andhra
Pradesh matched with the absence rate of the teacher of each student that year. Das et al. (2007) show that high
teacher absences in Zambia (mainly due to teachers falling sick) lead to significantly lower student test score gains.,
Muralidharan (2012) also shows that school infrastructure and teacher qualifications are not correlated with
improvements in learning outcomes in the control schools (which represent the 'business as usual' scenario).

18

5. The Fiscal Cost of Weak Governance
5.1. The fiscal cost of teacher absence
High levels of teacher absence translate into considerable waste of public funds since teacher
salaries are the largest component of education spending in most countries, including India.23
Calculating these fiscal costs requires us to estimate and exclude the extent of legitimate absence
from our calculations. As part of the institutional background work for this project, we obtained
teacher policy documents from several states across India. Analysis of these documents indicates
that the annual allowance for personal and sick leave is 5 percent on average across states. This
is close to the survey estimate of 5.9 percent (Table 3), but we use the official data since the
stated reasons may be over-reported.
Estimating the extent of legitimate absence due to ‘official duty’ (outside the school) is more
difficult because there are no standard figures for the ‘expected’ level of teacher absence for
official duties. Policy norms prescribe minimal disruption to teachers during the school day and
stipulate that meetings and trainings be carried out on non-school days or outside school hours.
Since we are not able to verify the claim that teachers were on official duty, and there is evidence
that head teachers try to cover up for teacher absences by claiming that these are due to ‘official
duties’, our default estimate treats half of these cases as legitimate. This gives us a base case of
legitimate absence of 8 percent (5 percent authorized leave, and 3 percent official duty). We also
consider a more conservative case where the legitimate rate of absence is 10 percent. This 8-10
percent range of legitimate absence also makes sense because the fraction of teacher
observations that are classified as either ‘authorized leave’ or ‘official duty’ is in this range for
the five states with the lowest overall absence rates – even treating the stated reasons for absence
as being fully true (tables available on request).
To estimate the fiscal cost of teacher absence, we use teacher salary data from our surveys
and use administrative (DISE) data on the total number of primary school teachers by state
(columns 1 and 2 of Table 9).24 We provide three estimates of the fiscal cost of teacher absence

23

This waste is especially costly in developing countries because they typically have low tax/GDP ratios and hence
face greater fiscal constraints on mobilizing resources for public investment.
24
The salary figures in our surveys do not include the fiscal cost of the benefits provided to civil service teachers.
Imputing the value of these benefits is difficult for the majority of teachers who are on a defined benefits pension

19

in columns 3 to 5 of Table 9 (based on assuming the rate of legitimate teacher absence to be 8, 9,
and 10 percent respectively), and these calculations suggest that the annual fiscal cost of teacher
absence is around Rs. 81 to 93 billion (1.4 – 1.6 billion US dollars/year).
5.2. Calculating the returns to better governance in education
The results in Table 5-7 suggest that of all the investments made in improving school quality
in the period from 2003 to 2010, the only one that had a significant impact on reducing teacher
absence was increased administrative monitoring and supervision. In this section, we calculate
the returns to a marginal increase in the probability of a school being inspected. We make the
following assumptions: (a) enough inspectors are hired to increase the probability of a school
being inspected in the past 3 months by 10 percentage points (relative to a current probability of
56 percent); (b) increasing inspection probability by 10 percentage points would reduce mean
teacher absence across the schools in a village by 0.64 percentage points (the most conservative
estimate of the correlation between increased inspection probability and reduced teacher absence
from Table 5); (c) the full cost (salary and travel) of an inspector is 2.8 times that of a teacher;
(d) an inspector works 200 days per year and can cover 2 schools per day. 25
The results of this estimation are presented in Table 10 and we see in column 3 that the cost
of hiring enough inspectors to increase the probability of a school being inspected by 10
percentage points is Rs. 448 million/year. However, the reduction in wasted salary from this
investment in terms of reduced teacher absence amounts to Rs. 4.5 billion/year, suggesting that
the returns to investing in better governance are ten times greater than the cost. Thus, improving
school governance by hiring enough staff to increase the frequency of monitoring could be a
highly cost-effective investment (on the current margin).
5.3. Hiring more inspectors vs. more teachers

program. However, newer cohorts of government employees are covered by a (less generous) defined contribution
retirement program where the government contributes 10% of pay to a retirement account. We use this conservative
estimate and add 10% to the average salary figures. No adjustment is made for medical benefits.
25
We use DISE data on the number of schools in each state to calculate the number of inspectors who will be
required to increase the probability of inspections in a 3-month interval by 10 percentage points. The cost estimates
are conservative and assume that the salary costs are double that of a teacher and that the travel costs are equal to 80
percent of a full months’ salary (which is higher than the typical travel and daily allowance provided to education
department employees to travel to/from a village to district headquarters).

20

Column 5 of Table 10 shows the extent to which the effective PTR (EPTR) can be reduced
by hiring enough inspectors to increase the probability that a school was inspected in the past
three months by 10 percentage points (the same magnitude used in the calculations in the
previous section). To compare the relative cost effectiveness of hiring more inspectors versus
hiring more teachers, we calculate the salary cost of hiring more teachers to achieve the same
reduction in EPTR and report these numbers in column 6. Comparing columns 3 and 6, we see
that hiring more inspectors would be 12.8 times more cost effective at reducing EPTR than doing
so by hiring more teachers. The difference between the estimates in columns 4 and 6 stems from
accounting for the fact that hiring more teachers will increase the absence rates of the existing
teachers, which is the other robust result in the panel regressions presented in Table 5 (again, we
use the most conservative estimate). Thus, the estimates in column 6 account for the fact that the
marginal rate of absence from hiring an extra teacher is higher than the average absence rate (as
in Niehaus and Sukhtankar 2013).
The difference in the relative cost effectiveness of the two policy options is large enough,
that the policy recommendation of hiring more inspectors rather than teachers (on the current
margin) would be unchanged even if the inspectors were to work less efficiently than assumed in
these calculations. For instance, if inspectors were absent at the same rate as teachers (say 25
percent), allocating marginal funds to hire an additional inspector would still be nearly ten times
more cost effective at reducing EPTR than using those funds to hire an additional teacher.
6. Policy Implications
The main caveat to using our results to recommend a universal policy of hiring more
inspectors to scale up the frequency of school inspections is that our estimates are based on
correlations and may not be convincing enough to warrant a universal scale up. Nevertheless, it
is worth noting that both our key results – the correlation between increased monitoring and
reduced teacher absence, and the correlation between lower PTR and increased teacher absence –
are consistent with experimental evidence from smaller-scale, which increases our confidence in
their validity. Further, our estimates are based on an “as is” expansion of inspections, and use
nationwide panel data (which mitigates concerns of fixed cross-sectional omitted variables)
representing close to a billion people, and thus have advantages over smaller-scale experiments,
whose external validity may be limited for several reasons.
21

First, there is evidence that experimentally-estimated positive results of interventions that are
implemented by NGOs may not be replicated when the programs are implemented by
governments (Banerjee, Glennerster, and Duflo 2008). Second, there is also evidence of siteselection bias where implementing partners are more likely to be willing to rigorously evaluate
programs in locations where they are more likely to be successful (Alcott 2014). Finally, even in
the absence of such a bias, most experiments are conducted in very few sites, and may yield
imprecise treatment effects (for inference over a larger population) in a setting where unobserved
site-specific covariates may interact with the treatment (Pritchett and Sandefur 2013).26
Thus, even if small-scale experiments are unbiased within sample, they may be biased and
also imprecise for population-level inference. In other words, there is likely to be a trade-off
between the potential omitted variable bias in our panel-data estimates on one hand, and the
advantages of greater precision, “as is” implementation, and unbiased site selection on the other.
We do not attempt to quantify this trade-off in this paper (since we have no objective basis of
doing so). However, one way of reconciling this trade-off is to conduct a substantial nationwide
expansion of school inspections by hiring more staff in the context of a large experimental
evaluation. We show below that from a decision-theoretic perspective, our results are strong
enough to support such a policy even if there is only a 1% chance that our estimates are causal.
Formally, consider a simple binary policy regarding the number of inspectors to be hired that
can take the values {0, 1}, where the current policy is {0} and {1} represents a ‘new’ policy of
hiring enough inspectors to ensure that all schools are inspected once in three months. The costs
of the new policy are the additional salary and operational costs of hiring inspectors and the
benefits are the reduced fiscal cost of teacher absence. Denote these by C{1} and B{1}
respectively, and assume that it is optimal to implement the policy if B{1} > C{1}. However,
while C{1} is known, there is uncertainty around B{1} and thus a randomized trial in the context
of a policy movement towards {1} would reduce the uncertainty around B{1}.

26

The largest education experiments to date that we know of have been conducted over five districts in one state of
India (Muralidharan and Sundararaman 2010, 2011, 2013). While these experiments feature random assignment in
representative samples of schools (in a state with over 80 million people), they still come from just one state,
compared to the estimates in this paper that use panel data from 190 districts across 19 states.

22

Suppose that after the trial, the likelihood that the optimal policy switches from {0} to {1} is
p and that the expected per-period benefit of such a switch is q. Denote the cost of data
collection and analysis of a trial as C{data} and let the discount rate be r. Let the period of the
trial be one year and the fraction of the population participating in the trial be N. Half of those in
the trial are allocated to a treatment group and the other half to a control group. Since data
collection will be based on a representative sample of trial sites, we assume that C{data} does
not vary with the size of the trial. The one period cost of the trial is then C{data} + (N/2)*C{1}.
The benefits of the trial are the expected one-period benefit of the new policy (during the trial)
and the discounted benefits of switching to a new policy (in perpetuity), weighted by the
probability that the trial will lead to a switch in the policy. Thus, the trial should be conducted as
long as:
C{data} + (N/2)*C{1} < (N/2)*B{1}+ [{1/(1-r)}pq] * [1/(1+r)].
To focus on the benefits of learning if the optimal policy should be {1} instead of {0}, we
abstract away from the benefit of the policy during the trial period and the one-period delay in
implementing the new policy (if found to be optimal), in which case the trial should be
conducted as long as:
C{data} + (N/2)*C{1} < [{1/(1-r)}pq].
Using our results to calibrate these quantities, it is straightforward to see that the expected
benefits of a trial are very large even under extremely conservative assumptions. The estimates
in Table 10 suggest that the marginal cost of {1} would be $33 million and that the marginal
benefit would be $331 million (using our panel data estimates).27 Thus, if our estimates are true,
q would be around $300 million/year, and using a discount rate of 10%, the net present value of
moving to {1} would be $3 billion. Now suppose there is only a 1% chance that the causal
impacts of inspections on teacher absence are as great as the panel data estimates presented here
and that there is a 99% chance that the causal impacts of inspection are not significantly different
from zero (i.e. p = 0.1). Even then, we see that [{1/(1-r)}pq] is $30 million.
27

The estimates in Table 10 are based on hiring enough inspectors to increase the probability of a school being
inspected in the previous 3 months by 10 percentage points. Since the current probability of a school being
inspected in the previous 3 months is 56 percent (Table 1), we scale up the estimates in Table 10 by a factor of 4.4
since moving to {1} would imply that the other 44 percent of schools should also be inspected. We use an exchange
rate of 1 US Dollar equals 60 Indian Rupees.

23

On the cost side, we conservatively estimate (using data from our own field costs) that a
highly-powered trial would have C{data} in the range of $1 million. A trial with an N of 0.06
would be a very large trial and could cover a nationally-representative sample across all major
Indian states, but would only cost $ 1 million/year.28 Thus, even including all costs of data
collection, the upper bound of the costs of such a trial would be $2 million compared to a likely
lower-bound expected benefit of $30 million.29 An expansion of school inspections in the
context of an experimental evaluation would therefore make sense even if there was only a 1%
chance of the true effects being the same as our panel-data estimates.
If we use a medical ethics perspective in this setting, we also need to consider the costs of not
providing a treatment that is known (or highly likely) to be effective. In this case, that would be
the foregone one-period benefit of scaling up the treatment immediately (which we estimate to
be around $300 million). Thus, depending on their prior beliefs, and the extent to which our
panel data estimates shift these priors, some policy makers may choose to switch the policy
regime from {0} to {1} immediately. However, the point of our exercise above is to show that
policy makers, depending on their beliefs, should either implement {1} immediately or do a
large expansion in the context of an RCT as described above, but it would only be under an
extreme set of beliefs (that there is less than a 1% chance of our panel-data estimates being truly
causal) that a policy maker would do nothing based on our results.
7. Conclusion
The central and state governments in India have considerably increased spending on primary
education over the past decade. We contribute towards understanding the impact of these
substantial nationwide investments in primary education in India by constructing a unique
nationally-representative panel data set on education quality in rural India. We find that there
has been a substantial improvement in several measures of school quality including
28

India has around 600,000 villages, 44% of which would be 264,000 villages. An N of 0.06 with half the sample
getting the treatment would imply that an additional 7900 villages would be treated (3% of 264,000), which would
be a very large trial by the standards of most experiments. Since covering all the remaining 264,000 villages is
estimated to cost $33 million, the cost of covering 3% of the villages would be $1 million.
29
Note that we use extremely conservative estimates for p assigning only a 1% probability of true estimates as large
as our panel-data based estimates and assigning the rest of the 99% probability to finding a zero effect. If we were
to assign a uniform distribution of likely point estimates between zero and our panel-data estimates (this is also
conservative because we would not assign any probability to the true estimate being larger than the panel-data
estimate), the expected benefit would be even larger.

24

infrastructure, pupil-teacher ratios, and monitoring. However, teacher absence rates continue to
be high, with 23.6 percent of teachers in public schools across rural India being absent during
unannounced visits to schools.
Using village-level panel data, we find no correlation between improved school infrastructure
and other measures of working conditions on teacher absence. We do find two robust
correlations in the panel data that provide external validity in nationally-representative data to
results established in smaller-scale experiments. First, reductions in pupil-teacher ratios are
strongly correlated with increased teacher absence, suggesting that the impact of hiring
additional teachers on education outcomes may be partly offset by increased absence of existing
teachers. Second, increases in the frequency of inspections are strongly correlated with lower
teacher absence, suggesting that of all the investments in improving school quality, the one that
was most effective in reducing teacher absence was improved administrative monitoring of
schools and teachers. We calculate that the fiscal cost of teacher absence is over $1.5 billion per
year, and estimate that investing in improved governance by increasing the frequency of
monitoring would be over twelve times more cost effective at increasing student-teacher contact
time than doing so by hiring additional teachers.
In interpreting our results, it may be useful to think of the performance of the education
system (measured by the level of teacher absence) as comprising two components – ‘inputs’ into
the production of education that expand with income growth (such as school infrastructure, class
size, and teacher salaries), and the efficiency of the use of these inputs (which would correspond
to the TFP of education production). Our results suggest that the Indian education system has
made significant progress on the former, but made less progress on the latter. Using this growth
accounting perspective, we see that the reduction in teacher absence observed between 2003 and
2010 is exactly in line with what we would expect from the growth in per-capita income that has
taken place during this period. This is consistent with the growth in income enabling an
expansion of a broad range of inputs into education that was for the most part a proportional
increase along existing spending patterns. On the other hand, a strategic reallocation of
resources to governance and monitoring (as indicated by our results) may achieve a greater
reduction in effective pupil-teacher ratio for a given level of GDP/capita. Such a reduction of
misallocation of spending may significantly improve the TFP of public spending on education.
25

Our results suggest that a promising way of improving school governance and achieving such
a reallocation of resources would be to simply expand the existing system of administrative
monitoring of teachers and schools by hiring more supervisory staff. Our calculations indicate
that such an expansion could (on the current margin) have a significant impact on reducing
teacher absence, and that this would be highly cost effective in terms of reducing the fiscal cost
of weak governance. More broadly, our results suggest that the returns to investing in state
capacity to better monitor the implementation of social programs in developing countries may be
quite high, and that at the very least there is a strong case for expanding such programs in the
context of large experimental evaluations of "as is" implementation to obtain more precise
estimates of their benefits.30

References:
ALLCOTT, H. (2014): "Site Selection Bias in Program Evaluation," New York University.
BANDIERA, O., A. PRAT, and T. VALLETTI (2009): "Active and Passive Waste in Government
Spending: Evidence from a Policy Experiment," American Economic Review, 99, 12781308.
BANERJEE, A., and L. IYER (2005): "History, Institutions, and Economic Performance: The
Legacy of Colonial Land Tenure Systems in India," American Economic Review, 95,
1190-1213.
BANERJEE, A., E. DUFLO, and R. GLENNERSTER (2008): "Putting a Band-Aid on a Corpse:
Incentives for Nurses in the Indian Public Health Care System," Journal of the European
Economic Association, 6, 487-500.
BESLEY, T., and T. PERSSON (2009): "The Origins of State Capacity: Property Rights, Taxation,
and Politics," American Economic Review, 99, 1218-44.
CHAKRABARTI, R. (2013): Bihar Breakthrough: The Turnaround of a Beleaguered State. New
Delhi: Rupa Publications.
CHAUDHURY, N., J. HAMMER, M. KREMER, K. MURALIDHARAN, and F. H. ROGERS (2006):
"Missing in Action: Teacher and Health Worker Absence in Developing Countries,"
Journal of Economic Perspectives, 20, 91-116.
CPR (2012): "Quality of Education in Rural India (Queri): Governance Report," New Delhi:
Center for Policy Research.

30

Muralidharan, Niehaus, and Sukhtankar (2014) is an example of just such an experimental evaluation, in the
context of an ambitious initiative by the Government of Andhra Pradesh (AP) to improve governance in public
welfare programs through biometric payments infrastructure. Working with the government of AP, they randomize
the rollout of the new payments infrastructure over a potential universe of 20 million beneficiaries, and estimate that
the program reduced ‘leakage’ in the rural employment guarantee scheme by an amount that was eight times the cost
of the program. Interestingly, this effect is of a similar magnitude to the returns that we estimate to investing in
better monitoring of teachers in this paper.

26

DAS, J., S. DERCON, J. HABYARIMANA, and P. KRISHNAN (2007): "Teacher Shocks and Student
Learning: Evidence from Zambia," Journal of Human Resources, 42, 820-862.
DUFLO, E., P. DUPAS, and M. KREMER (2012): "School Governance, Teacher Incentives, and
Pupil-Teacher Ratios: Experimental Evidence from Kenyan Primary Schools," National
Bureau of Economic Research. Working Paper 17939.
DUFLO, E., R. HANNA, and S. RYAN (2012): "Incentives Work: Getting Teachers to Come to
School," American Economic Review, 102, 1241-78.
HSIEH, C.-T., and P. KLENOW (2009): "Misallocation and Manufacturing Tfp in China and India
" The Quarterly Journal of Economics, 124, 1403-1448.
IYER, L. (2010): "Direct Versus Indirect Colonial Rule in India: Long-Term Consequences,"
Review of Economics and Statistics, 92, 693-713.
KREMER, M., K. MURALIDHARAN, N. CHAUDHURY, F. H. ROGERS, and J. HAMMER (2005):
"Teacher Absence in India: A Snapshot," Journal of the European Economic Association,
3, 658-67.
MURALIDHARAN, K. (2012): "Long Term Effects of Teacher Performance Pay: Experimental
Evidence from India," UC San Diego.
MURALIDHARAN, K., P. NIEHAUS, and S. SUKHTANKAR (2014): "Payments Infrastructure and the
Performance of Public Programs," NBER Working Paper 19999.
MURALIDHARAN, K., and V. SUNDARARAMAN (2010): "The Impact of Diagnostic Feedback to
Teachers on Student Learning: Experimental Evidence from India," Economic Journal,
120, F187-F203.
— (2011): "Teacher Performance Pay: Experimental Evidence from India," Journal of Political
Economy, 119, 39-77.
— (2013): "Contract Teachers: Experimental Evidence from India," NBER Working Paper
19440.
NIEHAUS, P., and S. SUKHTANKAR (2013): "The Marginal Rate of Corruption in Public
Programs: Evidence from India," Journal of Public Economics, 104, 52-64.
OLKEN, B. (2007): "Monitoring Corruption: Evidence from a Field Experiment in Indonesia,"
Journal of Political Economy, 115, 200-249.
PRITCHETT, L., and J. SANDEFUR (2013): "Context Matters for Size: Why External Validity
Claims and Development Practice Don’t Mix," Washington DC: Center for Global
Development Working Paper 336.
THIRTEENTH JOINT REVIEW MISSION REPORT OF SARVA SHIKSHA ABHIYAN (2011): Govt. of
India.
WORLD BANK (2003): World Development Report 2004: Making Services Work for Poor
People. Washington, DC: Oxford University Press for the World Bank.
ZAMBONI, Y., and S. LITSCHIG (2013): "Audit Risk and Rent Extraction: Evidence from a
Randomized Evaluation in Brazil," Universitat Pompeu Fabra.

27

Table 1. Changes in Key Variables Between 2003 and 2010, Village-Level Data
Summary Statistics
Year 2003
Year 2010

Difference
(Ho: No diff)

TEACHER VARIABLES
Have bachelors degree
Have teacher training
Are contract teachers
Are paid regularly
Recognition scheme exists

0.41
0.77
0.06
0.49
0.50

0.58
0.68
0.30
0.78
0.81

0.174***
-0.085***
0.233***
0.285***
0.309***

SCHOOL VARIABLES
Pupil-teacher ratio (PTR)
Mid-day meals
Infrastructure index (0-4)
Has drinking water
Has toilets
Has electricity
Has library

47.19
0.22
2.14
0.80
0.40
0.22
0.51

39.80
0.79
3.35
0.96
0.84
0.45
0.69

-7.388***
0.576***
1.205***
0.160***
0.440***
0.236***
0.183***

MONITORING & COMMUNITY VARIABLES
Road is within 1km
0.69
0.78
0.092***
Inspected in last 3 months
0.38
0.56
0.176***
Inspected in last 2 months
0.31
0.50
0.189***
Inspected in last 1 month
0.22
0.38
0.155***
PTA met in last 3 months
0.30
0.45
0.153***
Mean parental education (1-7 scale)
2.03
2.43
0.394***
State per-capita GDP (thousands of Rs.)
14.74
30.21
15.473***
Notes:
1) Summary statistics (except PTR) are weighted by rural population of Socio-Cultural Regions (SCRs) in Census 2001
2) Pupil-teacher ratio is weighted by SCR school enrolment
3) Data for number of days since inspection and truncated at 99th percentile
4) State per-capita GDP figures are in 2004-2005 prices; obtained from Central Statistical Organization, India
5) *** Significant at 1%, ** Significant at 5%, * Significant at 10%

Table 2. Absence Rate of Teachers & Pupil-Teacher Ratios in Rural Public Schools by State by Year
Absence Rates (%)

Pupil-Teacher Ratio

Effective Pupil-Teacher Ratio

Year 2003

Year 2010

Change

Year 2003

Year 2010

Change

Year 2003

Year 2010

Change

Andhra Pradesh
Assam
Bihar
Chattisgarh
Gujarat
Haryana
Himachal Pradesh
Jharkhand
Karnataka
Kerala
Madhya Pradesh
Maharastra
Orissa
Punjab
Rajasthan
Tamilnadu
Uttar Pradesh
Uttaranchal
West Bengal

23.38
36.15
39.42
30.47
17.92
21.07
22.67
43.50
22.60
19.60
18.19
15.43
21.69
36.66
25.13
20.43
26.72
32.29
26.41

21.48
26.26
28.69
14.20
16.14
17.75
30.74
45.84
23.93
15.79
26.34
14.12
14.24
13.54
22.72
12.92
31.21
21.02
20.97

-1.90
-9.89***
-10.73***
-16.28***
-1.77*
-3.31**
8.07***
2.34
1.33
-3.81***
8.16***
-1.31
-7.46***
-23.13***
-2.42*
-7.51***
4.49***
-11.27***
-5.44***

27.51
28.21
72.44
42.12
40.42
34.40
18.04
52.30
29.07
24.84
37.19
34.54
47.01
30.80
38.91
29.56
69.37
24.49
58.23

25.79
36.07
69.01
33.05
31.94
36.34
21.73
42.84
23.62
24.49
46.57
28.66
36.63
31.43
32.05
25.85
47.40
31.02
41.61

-1.71
7.86***
-3.43
-9.07***
-8.48***
1.94
3.69**
-9.47***
-5.45***
-0.36
9.39***
-5.88***
-10.38***
0.63
-6.86***
-3.71**
-21.97***
6.54**
-16.62***

35.90
44.18
119.57
60.59
49.24
43.58
23.33
92.57
37.56
30.90
45.45
40.84
60.04
48.63
51.97
37.15
94.66
36.17
79.12

32.85
48.92
96.78
38.52
38.09
44.18
31.38
79.09
31.05
29.08
63.23
33.38
42.72
36.36
41.47
29.69
68.90
39.28
52.65

-3.05
4.74
-22.79
-22.07
-11.15
0.60
8.04
-13.48
-6.51
-1.82
17.78
-7.47
-17.32
-12.28
-10.50
-7.47
-25.76
3.12
-26.47

India

26.29

23.64

-2.64***

47.19

39.80

-7.39***

64.02

52.13

-11.89

Notes:
1) All figures are weighted by SCR's rural population
2) The absence figures for 2003 differ slightly from the figures in the Kremer et al (2005) paper. This is because the urban schools are removed from the sample
3) We do not conduct inference on the changes in "Effective Pupil-Teacher Ratio" because the data on total number of teachers are obtained from administrative (DISE) data
4) *** Significant at 1%, ** Significant at 5%, * Significant at 10%

Table 3. Teacher Activity and Reasons for Absence
PANEL A: PHYSICAL VERIFICATION & LOGBOOK
RECORDS OF ABSENCE
Physical
verification (%)

Log-book
records (today)

Logbook
records (last
working day)

26.29
23.64

19.07
15.94

10.24

Year 2003
Year 2010

PANEL B: PHYSICAL VERIFICATION & TEACHER ACTIVITY
Teacher Found in Classroom (%)
Actively teaching Passively teaching

Year 2003
Year 2010

42.93
53.08

5.56
4.16

Teacher Found
outside
classroom (%)

Absent (%)

9.35
10.15

26.29
23.64

Not Teaching

15.88
8.96

PANEL C. STATED REASONS FOR ABSENCE
School
Closed (%)

On Official Duty (%)
Total

Official nonOfficial other
Offical teacher
teaching related
(panchayat
related (trainings,
(elections, health meetings, political
meetings, etc.)
campaigns, etc.)
meetings, etc.)

7.19
6.08
Year 2003
6.43
6.60
Year 2010
Notes:
1) All figures are weighted by SCR's rural population

5.93
5.21

0.95
0.93

0.31
0.29

Authorized
Leave (%)

No Reason (%)

7.62
5.91

5.40
4.70

2) In 2003, log-book records of last working day were not recorded in the survey
3) In 0.37 percent of cases, respondents said that a log-book was not maintained in the school, 0.23 percent refused to show log-book
4) Full list of activities under for not teaching are - doing administrative/paper work, talking to/accompanying the surveyor, chatting/talking (with
teachers, others), reading magazines/newspapers, sleeping, watching TV/listening to radio, doing other personal work, idle
5) Reasons for school closed are - opening hours but no one has arrived yet, opening hours but everyone left, and no reason

Table 4. Cross-section OLS Regressions Results, Village Level, 2010 Data
(Dependent Variable: Village-Level Teacher Absence Rate)
SUMMARY
STATISTICS
(1) Year 2010

BINARY REGRESSIONS
(2) no fixed (3) w/ state
effects
fixed effects

(4) w/ district
fixed effects

MULTIPLE REGRESSIONS
(5) no fixed (6) w/ state
effects
fixed effects

(7) w/ district
fixed effects

TEACHER VARIABLES
Have bachelors degree
Have teacher training
Are contract teachers
Are paid regularly
Recognition scheme exists
Log of salary

0.58

-1.03

-6.20***

-7.51***

0.68

-11.95***

-3.48

-2.92

0.30

10.97***

0.78

-7.72***

0.81

-6.53***

9.25

-3.70***

(0.32)
(0.31)
(0.30)
(0.39)
(0.37)
(0.62)

(1.94)

(2.39)

-1.96

-5.78**

-2.39

-2.43

(2.57)

(1.76)

(2.45)

-6.84***
(2.59)

-2.09

(2.38)

(2.39)

(2.73)

(2.81)

(2.69)

(2.87)

(2.37)

(2.48)

(2.97)

(2.83)

(2.71)

(3.21)

(1.95)

(1.92)

(2.20)

(2.00)

(1.95)

(2.17)

(2.12)

(1.86)

(2.07)

(2.08)

(1.81)

(2.01)

(1.08)

(0.88)

(0.96)

(1.01)

(0.94)

(0.99)

1.88

-2.31**

-4.07***

-2.42**

-1.65*

-3.29***

0.77

0.57

2.62

0.49

0.47

0.46

-1.51
-1.43

-0.58

-1.12

-1.24
-1.72

-0.30

-2.25

-2.53
-2.25
0.43

-0.27

-1.10
-0.19

-0.18

-2.32

-0.60
-0.94

-0.15

SCHOOL VARIABLES
Log pupil-teacher ratio
Mid-day meals
Infrastructure index (0-4)
Remoteness index (normalized)

3.50

(0.59)

(1.26)

(0.38)

(1.74)

(1.80)

(2.07)

(1.70)

(1.77)

(2.03)

(0.56)

(0.70)

(0.80)

(0.68)

(0.69)

(0.77)

(0.95)

(0.68)

(0.59)

(0.64)

(0.64)

(0.61)

(0.65)

0.56

-10.47***

-7.87***

-7.63***

-6.64***

-6.32***

-6.20***

0.45

-6.72***

-2.80**

-3.22**

-2.59*

-1.77

2.43

-3.16***

3.29

-11.01***

0.79
3.35

(1.30)

0.04

-3.44***
0.26

(1.15)

-0.23
0.58

(1.40)

-0.31
0.76

(1.10)

-0.89
0.19

(0.99)

0.07
0.17

(1.24)

2.01
0.07
0.14

MONITORING & COMMUNITY
VARIABLES
Inspected in the last 3 months
PTA met in last 3 months
Mean parental education (1-7 scale)
Log state per-capita GDP

(0.29)
(0.48)
(0.74)
(0.49)

(2.07)
(1.51)
(1.00)
(1.51)

(2.08)
(1.17)

0.37

(0.97)

(2.39)
(1.32)

-0.46

(1.08)

(1.90)

(2.04)

(2.37)

-2.13

(1.33)

(1.13)

(1.32)

(1.00)

(0.95)

(1.07)

38.50***

47.55***

-0.90

-9.27***

0.64

-0.82

(2.50)

REGRESSION STATISTICS
Constant

74.58***
(11.76)

(10.04)

(11.17)

0.139
0.231
0.394
R-squared
0.126
0.211
0.273
Adjusted R-squared
3.186*
3.450*
2.024
F-statistic (Inspected = PTA met)
1,555
1,555
1,555
Number of villages
Notes:
1) In summary statistics, standard deviations are in parentheses; in binary and multiple regressions, robust standard errors clustered at the district-level are in
parentheses
2) In binary regressions, each cell is a separate regression of the row variables with the dependent variable being the percentage of teacher absence
3) The binary dependent variable (0=Present, 1=Absent) has been multiplied by 100 to allow the coefficients to be read as percentage changes
4) The infrastructure index variable uses availability of four items (as in Table 1) with higher values being better; the remoteness index uses distances to nine sets
of facilities, with higher values being more remote
5) Summary statistics and regressions are weighted by SCR's population
6) *** Significant at 1%, ** Significant at 5%, * Significant at 10%

Table 5. Panel OLS Regression Results
(Dependent Variable: Percentage Points Change in Village-Level Teacher Absence)
BINARY REGRESSIONS
(1) no fixed
(2) w/ State
(3) w/ district
effects
fixed effects
fixed effects
CHANGES IN TEACHER VARIABLES
Have bachelors degree
Have teacher training
Are contract teachers
Are paid regularly

-0.42

-1.69

-3.69

MULTIPLE REGRESSIONS
(4) no fixed
(5) w/ State
(6) w/ district
effects
fixed effects
fixed effects
-1.68

-2.31

-4.71

(2.55)

(2.52)

(2.91)

(2.51)

(2.57)

(3.04)

(2.51)

(2.76)

(3.12)

(2.81)

(2.85)

(3.19)

(3.20)

(3.41)

(3.52)

(3.37)

(3.60)

(4.03)

(1.70)

(1.81)

(2.11)

(1.67)

(1.77)

(2.24)

1.10

-4.89
-0.18

1.12

-3.39
-0.83

0.52

-0.86
-1.47

1.08

-5.26
-0.28

0.79

-3.84
-0.97

-0.83
-0.56

Recognition scheme exists

-3.87**

-3.34*

-3.69**

-3.06*

CHANGES IN SCHOOL VARIABLES
Log pupil-teacher ratio

(1.71)

(1.69)

(2.23)

-5.33***

-4.89***

-4.48**

-5.56***

-4.95***

-4.69***

1.31

1.81

4.19

1.62

0.95

Mid-day meals
Infrastructure index (0-4)
Remoteness index (normalized)

(1.76)

(1.83)

(1.75)

(1.68)

Mean parental education (1-7 scale)
Log state per-capita GDP
REGRESSION STATISTICS
Constant

(1.91)

(1.81)

(1.57)

-3.34

(1.78)

2.14

(1.73)

(2.09)

(2.59)

(1.73)

(2.08)

(2.85)

(0.66)

(0.69)

(0.76)

(0.66)

(0.66)

(0.78)

(1.05)

(1.06)

(1.08)

(1.00)

(0.95)

(1.13)

(1.94)

(1.98)

-6.60***

-7.35***

-6.56***

-6.41***

-3.80**

-1.71

-2.08

-1.10*
-1.16

-0.97

-0.93

CHANGES IN MONITORING & COMMUNITY VARIABLES
-8.23***
-7.31***
Inspected in the last 3 months
PTA met in last 3 months

(1.87)

-2.03

1.53

-1.65

(1.74)

-1.29

(1.40)

-4.69

-3.18*
(1.63)

-0.09

(1.38)

(7.39)

R-squared
Adjusted R-squared
F-statistic (Inspected = PTA met)
Number of villages
Notes:
1) Robust standard errors clustered at the district-level are in parentheses
2) The infrastructure and remoteness index are as defined in Table 4
3) Regressions are weighted by SCR's population
4) *** Significant at 1%, ** Significant at 5%, * Significant at 10%

-1.01

-0.55

(1.91)

-0.97

-1.25

(1.83)

-0.68

-1.04

(1.83)

-0.96

-0.81

(2.01)

-2.96

(1.72)

(1.67)

(1.64)

(2.02)

(1.44)

(1.29)

(1.32)

(1.46)

0.48

-1.13

-6.18

-0.46

0.51

(7.18)

3.43

(5.50)

0.071
0.054
4.419**
1,297

-0.62

(2.26)

0.143
0.115
2.921*
1,297

-1.95

(2.72)

0.346
0.188
1.268
1,297

Table 6. Correlation between Inspection Frequency and Teacher Absence by Reason
BINARY REGRESSIONS
(1) w/o fixed
(2) w/ State fixed
(3) w/ district
effects
effects
fixed effects

Dependent Variable: Village-Level Teacher Absence by Reason (2010)

PANEL A. CROSS-SECTION ANALYSIS
(Coefficient on Inspection Reported)
On Official Duty

-2.16**

-2.51**

Authorized Leave

2.35***

1.65**

-10.67***

-7.02***

Unauthorized Absence
PANEL B: PANEL ANALYSIS
(Coefficient on Change in Inspection Reported)
On Official Duty
Authorized Leave
Unauthorized Absence

MULTIPLE REGRESSIONS
(4) w/o fixed
(5) w/ State fixed
(6) w/ district
effects
effects
fixed effects

(1.01)
(0.78)
(1.96)

(1.02)
(0.84)
(1.84)

-2.48*

-1.55

-2.16**

1.26

2.28***

1.44*

-6.41***

-7.39***

-5.59***

(1.29)
(1.05)
(2.10)

(1.03)
(0.82)
(1.77)

-2.06

(1.04)

(1.30)

(0.85)

(1.08)

(1.81)

1.17

-5.30**
(2.12)

Dependent Variable: Change in Village-Level Teacher Absence by Reason between 2003 and 2010
-1.77*

-1.05

-1.45

-1.43

-1.00

-1.49

(0.92)

(0.85)

(0.97)

(0.91)

(0.83)

(0.96)

(0.83)

(0.84)

(0.91)

(0.85)

(0.84)

(0.91)

0.77

-7.22***
(1.69)

0.42

-6.68***
(1.86)

0.59

-5.74***
(1.78)

0.59

-6.51***
(1.66)

Notes:
1) Robust standard errors clustered at the district-level are in parenthesis
2) The binary dependent variable (0=Present, 1=Absent) has been multiplied by 100 to allow the coefficients to be read as percentage changes
3) Regressions are weighted by SCR's population
4) *** Significant at 1%, ** Significant at 5%, * Significant at 10%

0.33

-6.07***
(1.79)

0.50

-5.41***
(1.75)

Table 7. Panel OLS Regression Results, Village-Level
(Dependent Variable: Change in Village-Level Inspection Frequency)
BINARY REGRESSIONS
(1) no fixed (2) w/ State (3) w/ district
effects
fixed effects
fixed effects
CHANGES IN TEACHER VARIABLES
Have bachelors degree
Have teacher training
Are contract teachers
Are paid regularly

-0.003

(0.051)

(0.055)

(0.056)

(0.057)

(0.054)

(0.053)

(0.055)

(0.061)

(0.053)

(0.073)

(0.069)

(0.059)

(0.070)

(0.082)

(0.030)

(0.035)

(0.035)

(0.031)

(0.035)

(0.041)

(0.031)

(0.032)

(0.031)

(0.037)

0.041

0.055

-0.036

(0.028)

0.054

0.063

-0.010

0.062**
0.032

REGRESSION STATISTICS
Constant

0.085

-0.040

-0.010
0.020

0.029

0.029

0.108*
-0.037

0.067**
(0.028)

0.049

0.046

0.088

-0.005

0.060*
0.024

0.064

-0.009

-0.004
0.023

0.012

(0.031)

(0.032)

(0.034)

(0.030)

(0.031)

(0.037)

(0.032)

(0.041)

(0.046)

(0.034)

(0.042)

(0.050)

(0.012)

(0.013)

(0.015)

(0.013)

(0.013)

(0.015)

(0.022)

(0.022)

(0.020)

(0.021)

(0.021)

(0.024)

(0.023)

(0.024)

0.033

0.053**

0.070**

(0.026)

(0.026)

-0.04

-0.04*

-0.05**

-0.13

0.13***

0.18***

0.051
0.034
1,300

0.093
0.065
1,300

0.315
0.152
1,300

0.007

0.010

-0.023

-0.008
0.011

-0.026

CHANGES IN MONITORING & COMMUNITY VARIABLES
0.018
0.052**
PTA met at least once in last 3 months

Log state per-capita GDP

0.030

(0.046)

0.055*

Mean parental education (1-7 scale)

0.037

(0.050)

CHANGES IN SCHOOL VARIABLES
Log pupil-teacher ratio

Remoteness index (normalized)

0.006

(0.053)

0.069**

Infrastructure index (0-4)

0.039

(0.046)

Recognition scheme exists

Mid-day meals

0.042

MULTIPLE REGRESSIONS
(4) no fixed (5) w/ State (6) w/ district
effects
fixed effects
fixed effects

-0.03
-4.69

-0.04

(7.392)

R-squared
Adjusted R-squared
Number of villages
Notes:
1) Robust standard errors clustered at the district-level are in parentheses
2) The infrastructure and remoteness index are as defined in Table 4
3) Regressions are weighted by SCR's population
4) *** Significant at 1%, ** Significant at 5%, * Significant at 10%

-0.024
0.005

-0.032

0.068**
(0.029)

-0.04**
(0.022)

0.018

0.006

-0.024

(0.023)
(0.023)

0.40**

-0.008
0.011

-0.024

(0.024)
(0.024)

-0.017
0.004

-0.028

(0.027)
(0.025)

(0.167)

(0.138)

(0.051)

(0.048)

Table 8. Panel OLS Regression Results, Village-Level
(Dependent Variable: Change in Normalized Math Score)
BINARY REGRESSIONS
(1) no fixed
(2) w/ State
(3) w/ district
effects
fixed effects
fixed effects
CHANGES IN STUDENT VARIABLES
Average age
Proportion male

0.09**

(0.05)

(0.15)

(0.15)

(0.17)

(0.13)

(0.18)

0.14

0.29**

CHANGES IN TEACHER VARIABLES
Have bachelors degree

-0.22**

Are contract teachers
Are paid regularly
Recognition scheme exists
CHANGES IN SCHOOL VARIABLES
Absence rate of teachers
Log pupil-teacher ratio
Mid-day meals
Infrastructure index (0-4)
Remoteness index (normalized)
Inspected in the last 3 months

(0.13)

0.13

0.27**
-0.13

Log state per-capita GDP
REGRESSION STATISTICS
Constant

0.14

0.10**

(0.05)

(0.15)

(0.15)

(0.17)

(0.13)

(0.18)

0.07

0.03

-0.28**

(0.12)

(0.12)

(0.11)

(0.15)

0.09

(0.04)

0.26**

(0.12)

0.07

(0.05)

0.19

(0.12)

(0.12)

0.10

0.30**
-0.17

0.10

0.21

-0.02

(0.11)

(0.12)

(0.12)

(0.13)

(0.12)

(0.11)

(0.13)

(0.15)

(0.18)

(0.16)

(0.15)

(0.19)

(0.08)

(0.07)

(0.08)

(0.08)

(0.07)

(0.08)

(0.08)

(0.08)

(0.09)

(0.08)

(0.08)

(0.09)

-0.005***

-0.004***

-0.002

-0.006***

-0.005***

-0.07

-0.11*

-0.09

-0.13*

-0.05

-0.13

-0.04
-0.05

(0.002)
(0.08)

-0.23*

-0.02
0.10

0.11
0.04

0.03

-0.07
0.12
0.03

(0.002)

(0.002)

(0.07)

(0.08)

-0.06

-0.13*
-0.05

(0.08)

(0.09)

(0.12)

(0.03)

(0.03)

(0.05)

-0.06
0.07

-0.02
-0.03

(0.002)
(0.08)

-0.16*

0.06

0.12

0.10
0.02

0.07

-0.05
0.11
0.01

-0.002

(0.002)

(0.002)

(0.07)

(0.08)

-0.05

-0.15*
-0.04

(0.08)

(0.09)

(0.11)

(0.04)

(0.03)

(0.03)

(0.04)

(0.04)

(0.05)

(0.05)

(0.04)

(0.05)

(0.08)

(0.08)

(0.09)

(0.09)

(0.08)

(0.09)

(0.07)

(0.07)

(0.08)

0.00

0.05

-0.01

-0.03
0.04

-0.06

CHANGES IN MONITORING & COMMUNITY VARIABLES
-0.06
0.01
PTA met at least once in last 3 months
Mean parental education (1-7 scale)

0.07

(0.04)

Private tuition

Have teacher training

0.05

(0.05)

MULTIPLE REGRESSIONS
(4) no fixed
(5) w/ State
(6) w/ district
effects
fixed effects
fixed effects

0.17***
(0.05)

-5.91

0.15***
(0.04)

(7.59)

R-squared
Adjusted R-squared
Number of villages
Notes:
1) Robust standard errors clustered at the district-level are in italics
2) The infrastructure and remoteness index are as defined in Table 4
3) Regressions are weighted by SCR's population
4) *** Significant at 1%, ** Significant at 5%, * Significant at 10%

0.01

0.03

-0.10
0.07

0.16***
(0.06)

-0.01
0.03

-0.02

-0.03

(0.08)

0.17***
(0.05)

0.71

-0.02
0.04

-0.07
0.01

(0.07)

0.15***
(0.05)

0.00

0.03

-0.12
0.06

(0.08)

0.17***
(0.06)

(0.44)

-0.86**

-0.52**

0.066
0.042
1,155

0.180
0.146
1,155

(0.41)

(0.25)

-0.40

(0.32)

0.434
0.277
1,155

Table 9. The Fisal Cost of Absence (in 2010 Prices and Salaries)
Average Monthly
Number of Teachers
Teacher Salary (Rs.)

Andhra Pradesh
10,299
347,875
Assam
9,567
167,161
Bihar
8,645
336,359
Chattisgarh
8,290
155,573
Gujarat
15,804
198,584
Haryana
16,236
77,980
Himachal Pradesh
12,199
48,507
Jharkhand
9,734
135,690
Karnataka
10,897
195,929
Kerala
10,751
54,976
Madhya Pradesh
9,294
267,846
Maharastra
17,246
288,914
Orissa
9,382
192,119
Punjab
12,654
105,930
Rajasthan
14,165
271,205
Tamilnadu
18,489
150,820
Uttar Pradesh
10,370
491,455
Uttaranchal
17,155
45,782
West Bengal
10,555
416,633
India
11,368
3,949,338
Notes:
1) 2010 Teacher Salaries are from Teacher Long and School Census Data
2) Data on total number of teachers is obtained from DISE State Report Cards
3) All figures are in 2010 prices

Total Loss Due to Absence (millions of Rs.)
Allowed Absence:
8%
6,374
3,855
7,942
1,055
3,374
1,630
1,776
6,598
4,489
608
6,027
4,025
1,484
980
7,463
1,811
15,615
1,350
7,527
92,699

Allowed Absence:
9%
5,901
3,644
7,559
885
2,960
1,463
1,698
6,423
4,207
529
5,698
3,367
1,246
803
6,956
1,443
14,942
1,246
6,946
86,773

Allowed Absence:
10%
5,428
3,433
7,175
715
2,546
1,296
1,620
6,249
3,925
451
5,370
2,710
1,008
626
6,448
1,075
14,269
1,143
6,366
80,847

Table 10. Marginal Returns to Investing in Governance (in 2010 Prices and Salaries)
Pupil-Teacher Ratio (2009-2010)

Pupil-teacher Ratio

Effective Pupil
Teacher Ratio

Effect of Increasing Probability of Inspection in Past 3 months by 10
percentage points

Cost to Produce Equal Effect
Through Teacher Hiring

Annual Savings From
Reduced Teacher
Absence (Rs. millions)

Expected Effective
Pupil-teacher Ratio

Annual Cost (Rs. millions)

22.5
33.0
80.8
28.3
35.3
32.3
22.0
75.3
30.8
23.1
53.5
29.7
34.1
23.5
33.6
32.3
57.7
25.8
40.5
41.1

433.5
204.2
374.9
135.0
336.2
139.8
79.2
236.3
257.7
64.5
332.1
546.8
199.7
153.2
454.5
293.2
697.1
90.0
502.5
5,742.0

Annual Cost
(Rs. millions)

17.8
22.7
31.0
350.8
Andhra Pradesh
24.5
33.2
15.9
154.5
Assam
58.2
81.6
21.2
273.6
Bihar
24.5
28.5
13.9
120.1
Chattisgarh
29.8
35.5
19.1
291.8
Gujarat
26.8
32.5
8.8
118.9
Haryana
15.4
22.2
6.8
56.0
Himachal Pradesh
41.3
76.2
14.8
127.9
Jharkhand
23.6
31.0
18.5
201.6
Karnataka
19.6
23.2
2.0
56.3
Kerala
39.8
54.0
40.6
250.9
Madhya Pradesh
25.7
29.9
45.0
486.8
Maharastra
29.4
34.3
20.5
177.5
Orissa
20.5
23.7
10.2
137.4
Punjab
26.2
33.9
40.0
361.6
Rajasthan
28.3
32.5
24.6
264.9
Tamilnadu
40.1
58.2
58.4
489.4
Uttar Pradesh
20.6
26.0
10.7
73.3
Uttaranchal
32.3
40.8
30.1
409.4
West Bengal
India
31.7
41.5
448.0
4,509.6
Notes:
1) Number of schools, number of teachers, and enrollment figures are from administrative (DISE) data
2) Simulation assumes that one inspection every 3 months reduces absence linearly by 6.4 percentage points
3) Inspector costs are assumed to be two times teacher salaries, travel costs are assumed to be 80 percent of monthly salary
4) An inspector is assumed to work 200 days a year and inspect two schools every day

Appendix A: Sampling and Construction of Village-Level Panel Dataset

The original survey in 2003 covered the 19 largest states of India by population (except
Delhi). Within each state, 10 districts were sampled using Probability Proportional to Size (PPS)
and within each district, 10 primary sampling units PSUs (which could be villages or towns)
were sampled by PPS, thereby yielding a nationally representative sample of 1,900 PSUs across
190 districts (including towns and villages). The exception is Uttar Pradesh where 11 districts
were sampled and Uttaranchal where 9 districts were sampled (since Uttaranchal had only 9
districts, and Uttar Pradesh is the largest state in India). Additionally, to account for the
considerable geographic diversity within Indian states, the sample was stratified by geographic
socio-cultural region (SCRs), and the 10 districts in each state were allocated to SCRs
proportional to the population of the SCRs. Similarly, the 10 PSUs within each district were
allocated to villages/towns proportional to the rural/urban population split in the district. All
sampling was done on the basis of the 1991 census, since that was the latest Census data
available at the time of the study.
The 2003 sample was augmented to include 241 villages from the REDS survey (Foster and
Rosenzweig 1996). Since the REDS villages are drawn as a representative sample within
districts, including these villages does not change the representativeness of the sample. If a
REDS district was in our main sample, the REDS villages were included (typically 2 to 4 per
REDS district) and additional villages were sampled randomly to make up the total desired
sample size. If a REDS district was not in our sample, those villages were covered in addition to
our core sample. Including these villages provides more precise estimates of outcomes in the
SCRs where they are located, but all analysis is weighted by SCR populations and so the final
estimates continue to be nationally-representative on a population weighted basis.
The final sample in 2003 comprised of 2,141 rural and urban PSUs across 19 states of India.
In 2010, since the survey only covered rural areas, the sample size was reduced from 10 to 8
villages per district. All districts in the 2003 sample were retained in the 2010 study, with three
exceptions where full-urban districts sampled in 2003 were replaced with a new PPS sampled
district from the same SCR. The three replaced districts are Hyderabad in Andhra Pradesh,
Ahmedabad in Gujarat, and Greater Bombay in Maharashtra, which are highly urban districts
containing their respective state capitals.

As we highlight in the paper, to meet our objective to maintain both representativeness of the
current landscape of schools in rural India and to maximize the size of the panel, we retain
villages from the 2003 study to the extent possible. In Column 1 of Table A1, we provide statewise counts of rural PSUs that were sampled in the 2003 study. After removing PSUs in the three
replaced districts altogether and all other urban PSUs from the 2003 study, the maximum panel
size we could draw, including the REDS villages was 1,668. We sampled a 2003 village by
default as long as the village had a population between 250 and 10,000 as per the 1991 Census,
and we could locate the village in the 2001 Census1. In districts where we had more than 8 rural
PSUs in 2003, we sampled 8 PSUs randomly. The lower cutoff on population was based on the
Government of India’s mandate that all rural habitations exceeding 250 people should have a
school with 1 km. Since villages and hamlets can be absorbed into expanding cities over time,
we match the originally sampled 1991 village to the villages in the 2001 Census to make sure
that the sampled village still exists
From the 2003 list of 1,668 villages, we had to remove 249 from the 2010 sampling frame
for reasons we discuss below (see Columns 5 through 9 of Table A1 for the distribution of these
villages across states). 69 villages were dropped because they fall in districts that had more than
8 villages in the 2003 round. A further 129 villages were removed either because their population
was below 250, or had far exceeded 10,000 in the 2001 Census (20,000 for Kerala). A total of 36
villages could not be located in the 2001 Census (suggesting that they had either been
depopulated or absorbed into nearby towns). Finally, 15 villages were replaced due to safety,
logistical and accessibility reasons. Thus, our sample consists of 1,419 villages from 2003
(Table A1 - column 3).
In districts where we had fewer than 8 villages in the 2003 sample (recall that the rural/urban
sampling within districts was done on the basis of population ratios, and thus districts where over
25% of the population in 1991 was urban would have fewer than 8 villages), we sample more
villages as required to reach a minimum sample size of 8 villages per district for the 2010 survey.
The new villages were sampled PPS from the universe of eligible villages in the 2001 Census
that were not already sampled. The cross-section sample (including REDS villages) thus consists
of 1,650 villages (Table A1 - column 2).

1

The exception to this is Kerala, which has a much higher population density, where the upper cut-off was 20,000

Of the 1,650 villages that comprise our 2010 sample, data from 1,555 villages were included
in the analysis presented in this paper (Table A2 - column 2). First, we found that 29 of the
1,650 villages have no schools in the village. A large proportion of these villages (12 out of 29)
are in Himachal Pradesh, which is a sparsely populated mountainous state, with many small
habitations. Another 39 villages did not have a public school within the village, but did have a
private school. Since this paper focuses on changes in public schools, these villages are not
included in the analysis. In Kerala, we lose another 12 villages, because all schools in the village
refused to be allowed to be surveyed.2 Finally, we drop 15 more villages from our analysis
because in these villages, schools were either not functional or closed in all three visits, which
means we were unable to complete surveys. A state-level breakdown of these 95 villages is
provided in Columns 4-7 of Table A2. The decline in the cross-section sample size for reasons
we discussed above, also reduces the number of villages for which we have panel data. After
accounting for the above 95 villages and 53 villages in 2003 for which we have no data (for
similar reasons as outlined for the 2010 survey round), our final panel size is 1,297 villages.
These 1,297 villages form the core of our analysis.
To ensure a representative sample of schools, enumerators first conducted a full mapping of
all public and private schools in each sampled village. Enumerators conducted “Participatory
Resource Assessments” with households at multiple locations (at least three) within each village
to obtain a list of all primary schools within the boundary of the village. All enumerated schools
were administered a short survey that included questions on school administration such as
management (public or private), enrollment, infrastructure etc. Enumerators also collected a list
of all teachers in the school and their demographic characteristics. This school listing in each
sampled village provided the frame for school sampling. We sampled up to three schools per
village. If the village had three or fewer schools, all schools were sampled. If the village had
more than three schools, we stratified the schools by management type and randomly sampled
two public schools and one private school to the extent possible. In the event that there were only
one public school and two or more private schools, one government and two private schools
were sampled. Table A3 provides the state-level breakdown of the number of schools and
teachers in the final (public school) sample used in this paper (both cross section and panel).

2

Permission to survey was refused in spite of the survey team possessing the required permission documents.
Kerala has a history of strong unions and it was not possible for the field teams to overcome this opposition.

Table A1. Description of Sample: Panel Construction
Number of Villages
Year 2003
Sample

Year 2010
Sample

Panel
Sample

Reduction in
Panel Size

Reasons for Reduction in Panel Size
More than
Village
Village
Village not
8 panel
population population found in
villages in less than more than
Census
district
250
10,000
2001
3
0
4
1
5
3
0
10
10
0
0
0
1
0
1
2
2
2
2
0
3
1
1
1
2
22
0
4
7
4
0
1
2
3
2
0
0
0
40
0
3
1
2
1
2
0
3
0
4
5
1
3
0
0
1
2
1
1
0
4
5
0
6
4
9
1
0
0
6
14
1
2
4
3
5
1
69
60
69
36

Andhra Pradesh
81
87
73
8
Assam
98
87
77
21
Bihar
94
84
84
10
Chattisgarh
85
80
76
9
Gujarat
82
88
74
8
Haryana
81
81
75
6
Himachal Pradesh
89
80
60
29
Jharkhand
87
84
73
14
Karnataka
91
89
84
7
Kerala
83
83
43
40
Madhya Pradesh
88
90
81
7
Maharastra
85
91
80
5
Orissa
92
87
79
13
Punjab
78
82
75
3
Rajasthan
91
98
85
6
Tamilnadu
84
87
69
15
Uttar Pradesh
114
113
104
10
Uttaranchal
80
72
57
23
West Bengal
85
87
70
15
India
1,668
1,650
1,419
249
Notes:
1) The upper population cutoff for all states was 10,000 as per the 1991 census, except Kerala where the cutoff was 20,000

Other
Reasons
0
3
0
5
2
0
1
2
0
0
0
0
0
0
0
0
0
0
2
15

2) The category others include: replaced because high Naxalite activity (6 villages), replaced because duplicate in 2003 sample (2 villages), replaced because
district was replaced (2 villages) replaced because village too remote (1 village), replaced because name missing in 2003 list (1 village), replaced because of
floods in village (2 village), replaced because village could not be located (1 village)

Table A2. Description of Sample: Data and Attrition
Year 2010 Sample
Sampled

Included in
Analysis

Attrition

Reasons for Attrition (Year 2010)
No school in
village

No public
school in
village

School(s)
refused to
survey

Other
reasons

Reasons for Attrition
(Panel)

Panel Sample
Sampled

Included in
Analysis

Attrition

Andhra Pradesh
87
86
1
0
0
0
1
73
70
3
Assam
87
83
4
1
3
0
0
77
72
5
Bihar
84
81
3
1
1
0
1
84
77
7
Chattisgarh
80
75
5
2
1
0
2
76
69
7
Gujarat
88
85
3
0
3
0
0
74
71
3
Haryana
81
80
1
0
1
0
0
75
63
12
Himachal Pradesh
80
59
21
16
5
0
0
60
43
17
Jharkhand
84
81
3
2
1
0
0
73
58
15
Karnataka
89
88
1
0
1
0
0
84
82
2
Kerala
83
65
18
0
5
12
1
43
31
12
Madhya Pradesh
90
88
2
0
1
0
1
81
78
3
Maharastra
91
83
8
1
3
0
4
80
73
7
Orissa
87
83
4
2
1
0
1
79
73
6
Punjab
82
80
2
1
1
0
0
75
71
4
Rajasthan
98
94
4
1
2
0
1
85
83
2
Tamilnadu
87
79
8
1
5
0
2
69
62
7
Uttar Pradesh
113
111
2
0
2
0
0
104
100
4
Uttaranchal
72
67
5
1
3
0
1
57
52
5
West Bengal
87
87
0
0
0
0
0
70
69
1
1,650
1,555
95
29
39
12
15
1,419
1,297
122
India
Notes:
1) The category others include: high Naxalite activity, village not reachable, schools not functional, schools closed in all three visits
2) In 2003, if a village did not have any schools, surveyors went to the neighboring village. In 2010, the village was simply recorded as having no school

No data for No data for
year 2010
year 2003

1
3
3
4
3
0
16
3
1
8
2
7
3
2
2
5
2
4
0
69

2
2
4
3
0
12
1
12
1
4
1
0
3
2
0
2
2
1
1
53

Table A3. Description of Sample: Final Sample
Year 2010 Sample

Andhra Pradesh
Assam
Bihar
Chattisgarh
Gujarat
Haryana
Himachal Pradesh
Jharkhand
Karnataka
Kerala
Madhya Pradesh
Maharastra
Orissa
Punjab
Rajasthan
Tamilnadu
Uttar Pradesh
Uttaranchal
West Bengal
India
Notes:

Panel

Number of
villages

Number of
schools

Number of
teachers

Number of
villages

86
83
81
75
85
80
59
81
88
65
88
83
83
80
94
79
111
67
87
1,555

130
150
124
100
119
105
70
132
120
105
146
98
114
88
141
96
135
73
151
2,197

509
525
757
450
944
520
270
493
572
608
476
495
483
469
671
445
616
207
668
10,178

70
72
77
69
71
63
43
58
82
31
78
73
73
71
83
62
100
52
69
1,297

Number of
schools in
2003
107
122
112
94
101
85
44
76
117
57
116
96
88
75
132
124
131
61
108
1,846

Number of
schools 2010
107
134
119
92
98
83
51
94
112
50
133
88
101
76
121
75
119
57
121
1,831

Number of
Teachers in
2003
372
437
341
259
419
386
172
244
598
353
367
441
295
355
497
455
442
177
331
6,941

Number of
Teachers in
2010
405
473
731
412
798
395
205
374
530
307
427
451
439
417
565
363
542
151
531
8,516

