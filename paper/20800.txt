NBER WORKING PAPER SERIES

LEVELING UP: EARLY RESULTS FROM A RANDOMIZED EVALUATION OF
POST-SECONDARY AID
Joshua Angrist
David Autor
Sally Hudson
Amanda Pallais
Working Paper 20800
http://www.nber.org/papers/w20800

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
December 2014, Revised March 2017

We are grateful to Enrico Cantoni, Sydnee Caldwell, Olivia Kim, Brendan Malone, Kemi
Oyewole, and Karen Scott for superb research assistance, and to the staff of the Susan Thompson
Buffett Foundation for their expert assistance in implementing the evaluation described here. We
also thank the Provost’s Office at the University of Nebraska, the Nebraska State College System,
and Nebraska’s community colleges for their support for this effort and for sharing their data. We
thank Raj Chetty, Amy Finkelstein, Nathan Hendren, Lisa Kahn, Lawrence Katz, Danielle Li and
seminar participants at NBER Summer Institute, IIES, Harvard, MIT and Yale for their many
helpful comments and suggestions. We acknowledge financial support from the Susan Thompson
Buffett Foundation and the MIT SEII seed fund. The views expressed here are those of the
authors alone and do not necessarily reflect those of the institutions or funders involved with this
work, nor those of the National Bureau of Economic Research. This RCT was registered with the
American Economic Association under trial number AEARCTR-0000125.
NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.
© 2014 by Joshua Angrist, David Autor, Sally Hudson, and Amanda Pallais. All rights reserved.
Short sections of text, not to exceed two paragraphs, may be quoted without explicit permission
provided that full credit, including © notice, is given to the source.

Leveling Up: Early Results from a Randomized Evaluation of Post-Secondary Aid
Joshua Angrist, David Autor, Sally Hudson, and Amanda Pallais
NBER Working Paper No. 20800
December 2014, Revised March 2017
JEL No. H52,I21,I22,I23,I28,J24
ABSTRACT
Does financial aid increase college attendance and completion? Selection bias and the high
implicit tax rates imposed by overlapping aid programs make this question difficult to answer.
This paper reports initial findings from a randomized evaluation of a large privately-funded
scholarship program for applicants to Nebraska’s public colleges and universities. Our research
design answers the challenges of aid evaluation with random assignment of aid offers and a
strong first stage for aid received: randomly assigned aid offers increased aid received markedly.
This in turn appears to have boosted enrollment and persistence, while also shifting many
applicants from two- to four-year schools. Awards offered to nonwhite applicants, to those with
relatively low academic achievement, and to applicants who targeted less-selective four-year
programs (as measured by admissions rates) generated the largest gains in enrollment and
persistence, while effects were much smaller for applicants predicted to have stronger postsecondary outcomes in the absence of treatment. Thus, awards enabled groups with historicallylow college attendance to ‘level up,’ largely equalizing enrollment and persistence rates with
traditionally college-bound peers, particularly at four-year programs. Awards offered to
prospective community college students had little effect on college enrollment or the type of
college attended.
Joshua Angrist
Department of Economics, E52-436
MIT
77 Massachusetts Avenue
Cambridge, MA 02139
and IZA
and also NBER
angrist@mit.edu
David Autor
Department of Economics, E52-438
MIT
77 Massachusetts Avenue
Cambridge, MA 02139
and NBER
dautor@mit.edu

Sally Hudson
Garrett Hall L032
235 McCormick Road
Charlottesville, VA 22904-4893
USA
sally.hudson@virginia.edu
Amanda Pallais
Department of Economics
Harvard University
Littauer Center
Cambridge, MA 02138
and NBER
apallais@fas.harvard.edu

1

Introduction

Every year, U.S. government agencies and many private groups distribute billions of dollars in
college financial aid. The federal government spends about $32 billion annually on Pell Grants
alone (Congressional Budget Office 2013). A large body of research attempts to determine if this
aid a↵ects college choice and attendance (see, for example, Abraham and Clark (2006); Avery
et al. (2006); Goodman (2008); Kane (2007); Bound and Turner (2002); Dynarski (2000); Cornwell,
Mustard and Sridhar (2006)).1 As Deming and Dynarski (2009) explain, however, selection bias
and the complicated nature of college aid programs make the relationship between financial aid and
post-secondary outcomes hard to interpret. Perhaps not surprisingly in view of these challenges,
empirical assessments have produced a wide range of impact estimates, many of which appear
sensitive to the underlying assumptions used to identify causal e↵ects.
This paper reports initial results from a randomized evaluation of one of the largest private aid
programs in the country. For decades, the Susan Thompson Bu↵ett Foundation (STBF) has o↵ered
grants to Nebraska high school seniors who express interest in attending the state’s public colleges
and universities. The largest STBF awards are worth more than $60,000, covering tuition and fees
for up to five years of study at any Nebraska public college. Interested students apply for STBF aid
as high school seniors. Awardees are selected on the basis of financial need, high school GPA, and
a review of personal statements and reference letters. STBF aid recipients, called Bu↵ett Scholars,
can use their awards to cover costs at any University of Nebraska campus (known collectively as
NU), any of the six Nebraska community colleges, or at a set of three four-year state colleges outside
the NU system. Bu↵ett Scholars who attend NU also participate in Learning Communities (LCs),
a Foundation-supported academic services intervention similar to other Learning Communities programs around the country.2 The Bu↵ett program supports more than 3,000 students each year,
with annual spending running more than $25 million.
In an e↵ort to gauge the e↵ectiveness of grant aid and Learning Community access, we implemented a randomized evaluation of the STBF program, awarding more than 2,000 scholarships via
random assignment. The results reported here include applicants applying for college entry in the
Fall of 2012 and in the Fall of 2013, covering a follow-up window that extends into sophomore year
1
2

Leslie and Brinkman (1987) and Deming and Dynarski (2009) survey this literature.
See Weiss et al. (2015b) for a review of research on LC impacts.

1

for the 2012 cohort.
Our first important finding is that STBF scholarship o↵ers substantially increased the amount
of financial aid Bu↵ett Scholars received. This result is far from automatic: as a rule, federal
and institutional grants fall in response to increased outside financial support, implicitly taxing
away the added funds. In this case, however, agreements between STBF and Nebraska’s public
colleges minimize o↵setting reductions in institutional aid. As a result, STBF award o↵ers increased
students’ grant aid by about $6,200 on average in the first year and $6,400 in the second. This
represents a net increase of 91 cents in grant aid for every STBF dollar awarded, with o↵setting
reductions in government loans and Federal Work Study aid of 29 cents and six cents per dollar
awarded, respectively.3
STBF support also changed students’ enrollment behavior. Aid o↵ers increased the probability
that a student enrolled in any college in the first year by only two percentage points, but there was
little room for improvement on this margin since 97 percent of control students enrolled in college
even without STBF support. At the same time, STBF support substantially altered students’
college choices: the fraction of applicants matriculating at four-year colleges rose by almost eight
points.
Gains in sophomore enrollment were more substantial: aid o↵ers increased overall sophomore
enrollment by 7.2 points, with four-year enrollment gains of 14 points. Persistence increased most
among groups that typically have low persistence rates: we find a remarkable 20-plus point gain in
four-year enrollment for nonwhite applicants and for those with ACT scores below the state median.
Persistence e↵ects were also larger for male applicants and students with low high school GPAs. On
balance, STBF scholarships substantially equalized enrollment and persistence rates across groups,
enabling students with low expected persistence to ‘level up’ with their traditionally college-bound
peers. In contrast, applicants who targeted community colleges were largely una↵ected by STBF
awards.
To distinguish the e↵ects of STBF’s financial aid from those of LC services, our second experimental cohort included a group that was o↵ered aid without access to LCs. This aid-only treatment,
known to applicants as the College Opportunity Scholarship (COS), o↵ered financial support to NU
3

Reported o↵set amounts are from the first year of enrollment. O↵sets of grants and government loans were slightly
smaller in the second year, while the o↵set of work-study aid was similar.

2

applicants in the same amounts and under the same conditions as full STBF awards, but without
o↵ering seats in the STBF LC programs operating on NU campuses. Initial findings from the aidonly treatment show e↵ects similar to those generated by full award o↵ers, with some evidence the
LC treatment induced applicants to enroll and persist at more selective colleges than would have
otherwise been the case. Because the COS cohort enrolled in 2013, comparisons between COS and
traditional full STBF awards are still provisional.
Our study contributes to the burgeoning literature on the causal e↵ects of college financial aid
on aid recipients. Like the STBF program, much of the new wave of government aid for college
is merit- as well as need-based. Dynarski (2004) reviews research on state merit aid programs
modeled on Georgia’s HOPE Scholarship. Most of this work exploits state-by-cohort variation in
access to government aid. Dynarski concludes that the HOPE program had large and significant
e↵ects on college attendance. She also reports positive (though smaller) e↵ects for similar merit
aid programs across the South. The e↵ects of these programs, however, vary widely across racial
and socioeconomic groups, with three out of the four programs studied showing larger gains among
minorities and the HOPE program itself seeming to generate smaller gains for minorities.
In contrast with the di↵erences-in-di↵erences style evaluations that feature in many recent impact evaluations of aid, Marx and Turner (2015) use discontinuities in the Pell Grant formula to
evaluate aid e↵ects on City University of New York (CUNY) students. Regression discontinuity
estimates suggest Pell aid reduces CUNY students’ borrowing without a↵ecting their schooling.
Like most regression discontinuity designs, these results are most relevant for students with running
variable values near kinks and cuto↵s. It’s also worth noting that most CUNY students attend
campuses that are more selective than the Nebraska schools targeted by our sample.
Our work is also closely related to a recent randomized evaluation of need-based grant aid at
Wisconsin’s public colleges by Goldrick-Rab et al. (2016). The Wisconsin Scholars Grant (WSG)
o↵ered an additional $3,500 to Pell-eligible Wisconsin residents who were already enrolled as fulltime freshmen at four-year public institutions. Results from the Wisconsin evaluation suggest WSGs
had modest e↵ects on sophomore enrollment, with no evidence of e↵ects beyond the second year.
Our intervention similarly uses a randomized research design, but STBF awards are more than
twice as large as the Wisconsin grant. In addition, our intervention targets high school students
who have yet to make their initial enrollment decisions. Our design therefore reveals aid e↵ects on
3

whether and where students go to college.
Finally, a large literature examines the value of post-secondary support services. A recent
randomized evaluation of Learning Communities interventions at Kingsborough Community College
in New York shows only modest impacts (Bloom and Sommo 2005), though Weiss et al. (2015a)
find stronger e↵ects. Two randomized evaluations of traditional support services for Canadian
college students show some benefits from services combined with merit aid, though only for women
(Angrist, Lang and Oreopoulos 2009; Angrist, Oreopoulos and Williams 2014). A recent randomized
evaluation of mentoring and coaching (Bettinger and Baker 2014) suggests this sort of intervention
can be highly cost-e↵ective.
The next section describes the STBF program and our experimental design. Section 3 discusses the scholarships’ e↵ects on students’ financial aid packages. Section 4 reports reduced-form
estimates of the e↵ect of aid o↵ers on college matriculation and persistence, including e↵ects in
important subgroups. Section 5 combines the reduced-form and first-stage analysis to estimate and
compare cost e↵ectiveness across target institutions. In a calculation that builds on the pioneering evaluation of federal BEOG grants in Fuller, Manski and Wise (1983), we also show how the
experimental estimates can be used to distinguish program spending that changes behavior from
infra-marginal spending that amounts to a pure transfer. Provisional results from the aid-only arm
of the experiment are discussed in Section 6. Finally, Section 7 summarizes the findings and briefly
discusses our work in progress.

2

Background

2.1

The STBF Scholarship Program

The Susan Thompson Bu↵ett Foundation has o↵ered financial aid to Nebraska college students
since 1965. The Foundation is the largest private grant provider in the state and among the largest
in the country, supporting more than 3,000 students each year. STBF aid can be applied toward
expenses at any public undergraduate institution in Nebraska, including two- and four-year colleges.
As with federal Pell Grants, STBF award criteria consider financial need; like many state aid
programs, STBF awards are also partly based on merit. The STBF program is distinct from government programs, however, in that the STBF merit assessment considers both quantitative and
4

qualitative inputs, including financial need, high school transcripts, essays, and letters of recommendation. STBF awards are also unusually generous and available to some students who are ineligible
for federal Pell grants. The STBF-eligible applicant pool consists of Nebraska-resident high school
seniors or graduates of in-state high schools who have not yet been to college. STBF gauges financial need using the Expected Family Contribution (EFC) determined by the government’s Free
Application for Federal Student Aid (FAFSA).4 EFC cuto↵s for Bu↵ett Scholarships were $15,000
in 2012 and $10,000 in 2013, while Pell cuto↵s were much lower ($5,081 in 2013). STBF also considers college readiness, requiring a minimum 2.5 high school GPA. The scholarship application asks
students to indicate which schools they plan to attend should they receive awards. Although this
is a non-binding declaration, in practice, most applicants attend the school they identify as their
target. Applicants’ target schools also figure importantly in the review process: after applications
are scored, students are ranked against those who have indicated the same target.
STBF award amounts vary by campus but are calibrated to match the cost of tuition and fees
for a full-time student plus a $500 allotment for books. For example, 2013 awards provided up
to $8,500 per academic year for full-time students at the University of Nebraska-Lincoln campus,
where full-time resident tuition and fees ran to $8,060. STBF provides an additional semester’s
worth of funding for summer enrollment, so that the maximum 2013 award was $12,750.5 The
maximum annual award for attending a two-year program was $5,400 in 2013. Though tuition prices
determine the value of STBF awards, the award money can be used to cover any of the federallydefined components of cost-of-attendance (COA), including room, board, books, and supplies.6
This flexibility further boosts the scholarship’s value relative to many aid programs, which often
cover only tuition and fees. Because most Bu↵ett Scholars qualify for public need-based aid like Pell
Grants, STBF awards often cover the remaining balance of students’ COA, eliminating the need
4
Home-schooled students are eligible for Bu↵ett aid, as are GED recipients who earned their credentials in Nebraska.
Undocumented immigrants are also eligible, but legal residents of other U.S. states are not. Undocumented immigrants
can apply for Bu↵ett aid without completing a FAFSA.
5
As far as we know, the only state program that approaches this level of generosity is California’s merit-based Cal
Grant A, studied in Kane (2003). See Table 1 of Deming and Dynarski (2009) for a review of financial aid programs.
In comparison, the maximum Pell Grant was $5,550 in 2012-13, while the average Pell award was $3,650 (College
Board 2014).
6
Post-secondary schools that receive federal aid report COA figures to the federal government. COA includes
tuition and fees, room and board, books and supplies, and personal costs such as transportation. STBF transfers
scholarship funds directly to schools, who then apply the funds to awardees’ college bills. Since COA components
like o↵-campus housing and supplies do not appear on college bills, colleges distribute unused STBF award money by
writing checks to students with credit balances. The total value of aid received cannot exceed COA, however. Awards
are prorated for less than full-time attendance.

5

for loans or out-of-pocket contributions to college costs. Bu↵ett awards are renewable for up to five
years provided students meet minimal academic standing requirements, though no more than three
years of funding can be paid toward two-year college expenses (Students enrolled for fewer than
nine credits per semester or with a cumulative GPA below 2.0 risk losing their scholarships).
Bu↵ett Scholars who attend one of NU’s three campuses—Lincoln (UNL), Omaha (UNO), or
Kearney (UNK)—are required to participate in the Thompson Scholars Learning Community (LC)
programs during their first and second years. These programs are designed to promote academic
success and social engagement. While the LC programs di↵er somewhat by campus, they all include
specialized classes with other Bu↵ett scholars, academic and social activities, peer mentoring, and
academic advising services from LC faculty and sta↵. In two of the LC programs (UNK and UNL),
the majority of scholarship recipients live together in a residence hall. Bu↵ett Scholars who fail to
participate in LC activities risk losing their scholarships.

2.2

Research Design

For the purposes of this research, STBF applicants for 2012 and 2013 matriculation were divided
into three groups based on reviewer ranks. The most highly-ranked applicants (301 out of 1,430
eligible applicants in 2012 and 356 out of 2,267 in 2013) were guaranteed awards, while the lowestscoring applicants (127 in 2012 and 273 in 2013) were removed from consideration. The rest were
subject to random assignment, with award rates determined by STBF preferences for award counts
at the target schools in each cohort. (The estimated program impacts discussed below control for
a full set of target school by year of application dummies—what we call strata dummies—to reflect
di↵erential award rates across strata). The 2012 randomization group included 1,003 applicants,
504 of whom were o↵ered aid. The 2013 randomization group included 1,638 applicants, 697 of
whom were o↵ered aid. Appendix Table A1 reports further information on sample size and target
colleges.
Among the 2013 randomized applicants who targeted NU, there were two types of aid o↵ers,
as noted above: a full scholarship with mandatory LC participation for those matriculating at
NU and an equivalent aid award with no LC requirement. Of the 697 random awards o↵ered in
2013, 210 were aid-only College Opportunity Scholarships (COS). We focus here on the e↵ect of full
awards, reporting results primarily from a 2013 analysis sample that includes the 1,428 experimental
6

applicants not o↵ered the COS. Section 6 reports briefly on the ongoing comparison of COS and
full awards.

2.3

Data and Descriptive Statistics

Data for this project come primarily from the STBF scholarship application, the administrative
records of Nebraska’s public colleges, and the National Student Clearinghouse (NSC). The application provides a rich set of baseline characteristics, including high school transcripts, ACT scores,
and detailed demographic and financial information from federal Student Aid Reports. The application did not ask students to report their race; we obtained race data from state driver’s license
records.
More than 90 percent of applicants who enrolled in college attended a Nebraska public institution. These colleges and universities provided information on their students’ enrollment, aid
packages, and academic outcomes. To capture enrollment at private and out-of-state colleges, we
supplemented school-provided data with information from the NSC, which captures 92 percent of
enrollment nationwide (Dynarski, Hemelt and Hyman 2015). NSC records report institution attended and enrollment status (full-time, half-time, etc.) We provide additional information about
data sources and data processing in the appendix.
STBF applicants in 2012 and 2013 were, on average, from substantially poorer households than
the general population of Nebraska high school seniors. This can be seen in the first two columns
of Table 1, which compare descriptive statistics for scholarship applicants and high school students
statewide. STBF applicants were also disproportionately female and less likely to have collegeeducated mothers. ACT scores among applicants were similar to those of other Nebraska ACT
test-takers, though applicants were more likely than other Nebraska seniors to have taken the ACT.
Column 3 of Table 1 reveals that STBF’s top-ranked applicants, those who received awards
without being subject to random assignment, had academic credentials similar to those in the
randomization group. The most important di↵erence between the automatically-funded and randomized groups was socioeconomic status: students who received STBF awards without random
assignment had lower family incomes and less educated mothers. This group also contained a higher
proportion of Hispanic applicants. At the other end of the applicant pool, those disqualified before
random assignment had lower high school grades and ACT scores than those in the randomization
7

group.
Random assignment successfully balanced the characteristics of those in the randomization group
who were and were not o↵ered aid. This is documented in column 6 of Table 1, which reports strataadjusted di↵erences in treatment and control characteristics, along with the associated standard
errors. Appendix Table A2 reports balance estimates separately for the two randomization cohorts,
while Appendix Table A3 reports balance estimates within strata. Treatment and control students
in the randomization group had family incomes around $50,000 per year and Expected Family
Contributions of just over $3,000. Roughly two-thirds of those randomized are white and about 60
percent are female.

3

How Awards Changed Aid Packages

We begin by describing the e↵ect of STBF awards on Bu↵ett Scholars’ financial aid packages. This
analysis is necessarily limited to the sample of students who attended Nebraska public colleges since
our administrative aid data come from these colleges. Because STBF awards a↵ect the likelihood
of being part of this sample, the analysis here may be compromised by selection bias. In practice,
however, the e↵ect of STBF awards on the likelihood of having detailed aid data is small—awards
change the probability of attending a Nebraska public college by no more than six percentage
points—and the e↵ects of STBF award packages on aid composition are large. It therefore seems
likely that the picture painted here, though in principle more descriptive than causal, still provides
a useful gauge of the value of aid for recipients.
As a benchmark, the first column of Table 2 describes the first-year financial aid packages of
control group students who attended Nebraska public colleges. Aid amounts averaged over $11,500,
of which roughly $7,250 is grant aid, with the remainder divided between government loans (about
$3,500) and work study (about $800). Our aid figures omit private loans, a category for which we
have limited data; however, subsidized public loans are the primary source of borrowed funds for
this low-income population.
Estimates of the e↵ects of scholarship o↵ers on aid packages come from regression models of the
form:

8

Ai = Si +

X

sc risc

+

0

X i + "i ,

(1)

s,c

where Ai is the dollar amount of aid student i received and Si is an indicator for whether student i
was (randomly) o↵ered an STBF scholarship. The dummies risc indicate whether applicant i from
cohort c listed school s as her intended college. These cohort-specific strata dummies account for
di↵erential award rates by target college and application year. The covariate vector, Xi , includes
family income, EFC, high school GPA, and ACT composite score. To the extent that selection into
Nebraska public colleges varies with these traits, Xi mitigates the associated bias. Finally, "i is a
person-specific error term. To estimate the e↵ect of a dollar of STBF aid on dollars of other aid
received, we replace Si in equation (1) with the dollar amount of each STBF scholarship.
Scholarship winners received an average of $6,924 in STBF grant aid in their first year (Because
a few students turned down STBF scholarships in favor of other named awards, this is an intentto-treat contrast between treatment and control subjects.) STBF awards increased total grant aid
by $6,225, from a base of $7,251 in the control group. The less than one-for-one aid pass-through
reflects a $698 decline in institutional awards and private grants and a (statistically insignificant)
decrease of one dollar in federal grants. For some students, the reduction in institutional aid reflects
the COA cap on total aid disbursed, rather than a discretionary reduction on the part of institutional
aid officers.
Increased grant aid substantially reduced students’ reliance on student loans and use of work
study programs. Column 2 of Table 2 shows that aid o↵ers reduced government loans by $2,220
and Federal Work Study aid by $486 (both around 60 percent of the corresponding control group
means). Total aid—the sum of grants, federal loans, and work study—averaged $11,608 in the
control group and was just over $3,300 higher in the treatment group. The estimates in column 4
of Table 2 show that each dollar of STBF grant aid increased students’ total grant aid by $0.91,
while reducing loans by $0.29 and reducing work study by $0.06, for a net gain of $0.53 per dollar
awarded.
These results capture two countervailing e↵ects of scholarship o↵ers on the amount of aid received. At any given college, scholarship money crowds out aid from other sources, reducing award
e↵ects on total aid received. But awards also change students’ college choices. In particular, as we

9

explore in detail below, STBF awards caused many applicants who would have otherwise gone to
two-year schools to attend four-year schools at a higher cost. This shift is captured in the first row
of Table 2, which shows Bu↵ett Awards increasing students’ cost of attendance by $0.24 per dollar
of aid received. Though four-year colleges cost more, they also provide more grant aid: the average
control group student attending a four-year college received $7,600 in grant aid, $4,000 more than
the average control student attending a two-year college. Scholarship money therefore “crowds in”
aid by moving students to more expensive campuses that o↵er more financial aid.
To disentangle the crowd-out and crowd-in e↵ects, columns 3 and 5 of Table 2 (labeled “campus
adjusted”) report estimates of a version of equation (1) that includes campus controls, that is,
a set of variables that count the number of full-time equivalent terms students attended at each
Nebraska public college in the aid year. These campus-adjusted regressions isolate the extent to
which, at a given college, STBF aid crowds out other forms of aid. The results in column 5 show
that, at a given college, students lost $0.22 in total grants for each scholarship dollar awarded, an
e↵ect that’s more than twice as large as the loss estimated without campus controls. Of course,
these results should be interpreted cautiously, since campus choice is an outcome a↵ected by STBF
awards. Results from models with campus controls therefore combine causal e↵ects on aid packages
for those whose choices are unchanged by STBF awards with compositional e↵ects that result from
treatment-induced changes in college attended. These compositional e↵ects, a form of selection bias
generated by conditioning on outcomes, arise if, conditional on observed characteristics like EFC,
treatment and control students attending the same college would be o↵ered di↵erent financial aid
packages in the absence of treatment. Because institutional awards are in large part a mechanical
function of student traits like EFC, the extent of selection bias in this case is likely to be modest.
Bu↵ett awards changed financial aid packages even more substantially in year two than in year
one, with smaller o↵setting reductions in aid from other sources. These and other results for secondyear aid packages appear in Table 3, again for a sample of those enrolled in Nebraska public colleges.7
The net increase in total aid generated by a dollar of STBF money in year two was 73 cents, while
the campus-adjusted increase was 41 cents. STBF awards also reduced loans and work study in
year two. Appendix Table A4 extends the results in Tables 2 and 3 with an analysis of e↵ects on
7

Aid data in year two is necessarily missing for those who leave college. Year two aid data is missing for about ten
percent of the year one control sample and for about five percent of the year one treatment sample for which aid is
available in year one.

10

more detailed aid categories.

4

E↵ects on Enrollment and Persistence

4.1

College Enrollment

The vast majority of STBF applicants attended college in the first year after application whether or
not they won STBF awards. This is apparent in Table 4, which shows control means for enrollment
outcomes and estimated e↵ects of scholarship o↵ers using data from the first year of potential
enrollment. Although 97 percent of control students enrolled in college, STBF awards increased
this rate by a statistically significant two percentage points. This estimate and others in Table
4 come from a regression model similar to that described by equation (1), where, instead of aid
awarded, the dependent variables are enrollment outcomes. All students in the experimental group
are included in these regressions regardless of whether they attended Nebraska public colleges.
Covariates are included in an e↵ort to increase precision.
Bu↵ett awards increased four-year college attendance by 7.8 points above a control mean of
75 percent. Two-year attendance, in contrast, fell by about six points. The increase in four-year
attendance therefore reflects a shift from two to four-year schools. This institutional upgrading
is likely a consequence of the tuition subsidy implicit in the STBF award scheme: Bu↵ett awards
cover tuition at any Nebraska public college, and the four-year colleges cost twice as much.
STBF awards decreased the fraction of students attending out-of-state or private colleges from
seven percent to about three. Importantly, however, and in contrast with findings for the Massachusetts’s Adams Scholarship reported by Cohodes and Goodman (2014), the shift to Nebraska
public schools was concomitant with a shift towards more selective institutions. Specifically, STBF
awards increased the proportion of students attending selective colleges (colleges with admission
rates below 75 percent) by nearly four points. The fraction of students attending moderatelyselective four-year colleges (with admissions rates between 75 and 90 percent) increased by a similar
amount.8 Most STBF applicants students who chose out-of-state colleges attended less selective
colleges close to the Nebraska border; STBF aid pushed some of them to more selective NU cam8

UNL’s admission rate is below 75%, while UNK and UNO both have admissions rates between 75% and 90%.
The remaining Nebraska public colleges have admissions rates above 90%.

11

puses.
E↵ects in target college strata capture di↵erences across groups of applicants with more or less
ambitious higher education plans. Those targeting relatively-selective UNL were almost certain to
enroll in college, so STBF awards changed overall enrollment status little in this group. Even among
these relatively ambitious students, however, the scholarship increased the fraction of students
attending four-year colleges by 6.5 points and increased the fraction of students attending selective
colleges by 12 points.
Overall enrollment e↵ects were larger for applicants targeting UNO and UNK. In this group,
STBF awards boosted post-secondary enrollment by 3.4 points and the proportion enrolling on a
four-year campus by an impressive 13 points. STBF o↵ers in the UNO/UNK strata also increased
attendance in moderately-selective colleges by 15 points. This change is due in part to awardees’
shift from two-year programs to their target colleges.
We see little evidence of scholarship-induced changes in first-year enrollment outcomes for applicants targeting state and community colleges. Estimated enrollment e↵ects in both groups are
small and none are significantly di↵erent from zero. Unlike students targeting NU campuses, few
who targeted community colleges chose to attend four-year programs as a result of award receipt.

4.2

College Persistence

Many interventions produce short-lived gains, but STBF awards generated a large and growing
impact on students’ college enrollment. This can be seen in Table 5, which shows estimates analogous
to those in Table 4 for the second year after scholarship application. STBF awards appear to have
substantially reduced dropout rates between freshman and sophomore years. Enrollment among
treated students decreased just four points, from 99 percent in the first year to 95 percent in the
second. The dropout rate was twice as large among control students, whose enrollment rate fell
from 97 percent in year one to 88 percent in year two. Thus, STBF awards increased year-two
enrollment by more than seven points. The awards also led enrolled students to take more credits.
By the end of year two, treated students had amassed an additional 0.37 semester equivalents of
college enrollment, about twice the e↵ect we would expect to see if enrolled treated students took
the same number of credits as enrolled control students.9 Year-two e↵ects on four-year college going
9

The data appendix details the link between credit completion and semester equivalents.

12

were even larger: STBF awards increased four-year enrollment by 14 points in year two, twice the
e↵ect in year one.
As with the first-year results, those for year two show important di↵erences across target-school
strata. The largest e↵ects on four-year enrollment are for applicants who targeted UNO and UNK,
the less selective of the three NU campuses. STBF awards boosted four-year enrollment for these
applicants by a remarkable 24 points in year two, with the entire gain coming from enrollment in
moderately-selective colleges (a group which includes these targets). Again, these estimates are
about twice as large as the e↵ects on first-year enrollment. Though STBF awards had no impact on
initial enrollment in the state college strata, awards increased second-year enrollment in this group
by 13 points. By the end of year two, treated students targeting state colleges had amassed about
two-thirds of a semester more than the control group. Again, however, awards did little to alter
enrollment outcomes in the group targeting community colleges.
Why do STBF award e↵ects increase so markedly in year two? Table 6 sheds light on this
question by reporting e↵ects on the joint distribution of enrollment in the first two years of followup for the 2012 cohort. The first column and first row report marginal e↵ects on enrollment in
years one and two, respectively, while the remaining rows and columns report joint e↵ects. Control
means are reported in braces in each cell. The first cell in row 1 shows that 88 percent of control
group students enrolled in post-secondary schooling in the second year of the experiment and that
award o↵ers raised this probability by 7.2 points. The estimate in row 2, column 2 shows that the
scholarship o↵er raised the joint probability of any post-secondary enrollment in both year one and
year two by 7.6 percentage points. The cell in row 5, column 2 reveals that second year enrollment
is e↵ectively zero conditional on non-enrollment in year one. Hence, the treatment-induced gains in
year two enrollment seen in Table 5 are due almost entirely to retention of those who start college
in year one.
Many control group students drop out of college, especially those enrolling initially in four-year
programs. While 76 percent of control group students enrolled in four-year colleges in year one,
just 63 percent enrolled in four-year colleges in both years. About 60 percent of four-year college
dropouts were not enrolled anywhere in year two, while the remainder were enrolled in two-year
colleges. Because STBF awards increased the number of students enrolling in four-year colleges
in year one, we would have expected the number of students dropping out of four-year colleges in
13

year two to increase unless awards also raised persistence rates. Row 3, columns 4 and 5 reveal,
however, that the fraction of students who started at four-year colleges and dropped out is about
half as large in the treatment group. This implies that the scholarship caused some students who
were infra-marginal for four-year enrollment in year one to persist in four-year enrollment in year
two.
Table 6 weighs against the view that those induced to attend four-year colleges are ill-prepared
for more challenging courses and therefore at increased risk of dropping out, a version of the college
mismatch hypothesis (see, for example, Arcidiacono, Aucejo and Hotz 2016). If STBF awards had
induced students to enroll in four-year colleges for which they were ill-prepared, we might have
seen an increase in the number of students initially enrolling in four-year colleges and subsequently
transferring to two-year schools or dropping out of college entirely. As it turns out, however, the
findings go the other way: the odds of starting a four year program and dropping out or transferring
in year two decline in the treatment group, with the largest drop seen for the combination of a fouryear start and second-year non-enrollment (a 4.4 point decline).

4.3

For Whom Does Aid Matter Most?

Estimates of e↵ects in demographic subgroups reveal important di↵erences in program impacts. This
is apparent in Figure 1, which plots year-two enrollment by race, gender, and treatment status. In
this figure and those that follow, the treatment group mean was constructed by adding the control
mean and treatment e↵ect, estimated from a model that includes strata dummies and covariates
as in equation (1). (Whiskers depict the 95 percent confidence interval for the treatment e↵ect.)
Nonwhites in the control group were much less likely to attend college in year two than were whites,
with an especially large race gap in four-year enrollment (compare 55 percent for nonwhites with
71 percent for whites). Yet STBF awards nearly equalized these rates across races by generating
especially large gains for nonwhite awardees. Figure 1 documents a similar, but less stark, pattern
for male and female applicants. Among students who were not awarded scholarships, males were
less likely to enroll in four-year colleges than females (60 percent versus 69 percent), a gap that
disappears in the treatment group.
Figures 2 and 3 reveal similarly striking leveling-up patterns in e↵ects estimated conditional
on ACT scores and high school GPA, both strong predictors of enrollment and persistence. In
14

these figures, the darker lines plot enrollment rates for treated applicants, and the lighter lines
depict control group enrollment.10 Not surprisingly, control students with lower baseline academic
achievement were much less likely to attend college in year two than their higher scoring peers. In
particular, Figure 2 shows a 23 point gap in year-two enrollment between students in the highest
and lowest GPA bins (95 percent versus 72 percent), while Figure 3 shows a 12 point enrollment
gap between the highest and lowest ACT bins (91 percent versus 79 percent). STBF scholarships
virtually closed these gaps: in the treatment group, the high-low gap in year-two enrollment by
GPA is just two points (98 percent versus 96 percent), while the high-low gap by ACT score is just
four points (99 percent versus 95 percent).11
The lower panels of Figures 2 and 3 show the same general pattern of subgroup e↵ects for
four-year college enrollment in year two, though here leveling-up is incomplete. The high-low gap
in four-year enrollment by high school GPA is a whopping 57 points in the control group (28
percent versus 85 percent) as compared with 39 points in the treatment group (66 percent versus 95
percent), a one third reduction. Comparing four-year enrollment by ACT score, the high-low gap
is 47 percent among controls (42 percent versus 89 percent), but only 29 percent in the treatment
group (96 percent versus 67 percent), a reduction of more than 40 points. Thus, while award o↵ers
increase four-year college attendance at all levels of baseline achievement, students who are least
prepared gain more.
Though award impacts vary by race, gender, and academic achievement, we see little evidence
of di↵erential impact by financial need. If anything, e↵ects on four-year enrollment are somewhat
larger at higher EFC levels, a result that can be seen in Figure 4. This pattern may reflect the
interaction between STBF aid and other need-based financial aid systems. Students with EFCs
above about $5,000 were ineligible for federal Pell grants in 2012 and 2013. Consequently, among
applicants with EFCs low enough to qualify for Bu↵ett aid, STBF awards tended to generate larger
net aid gains for those with EFCs above the Pell cuto↵.
Our “leveling up” hypothesis is supported by the pattern of subgroup treatment e↵ects showing
the largest gains for applicants whose enrollment rates are likely to be lowest in the absence of
10

E↵ects here are estimated in 10 GPA bins of width 0.15 ranging from 2.50-2.64 to 3.85-4.00. The ACT bins
correspond to single point scores ranging from the 10th to the 90th percentile of the score distribution in our sample.
11
Table A5 compares OLS and logit specifications of estimates in subgroups. Logit marginal e↵ects are virtually
indistinguishable from the corresponding OLS estimates.

15

treatment. We further substantiate this by showing how treatment e↵ects vary with a single index of
expected college persistence. As suggested by Abadie, Chingos and West (2013), such “endogenous
stratification” estimates are best computed using leave-out fitted values. (Otherwise persistence
outcomes are mechanically correlated with predicted persistence, which may bias estimates of causal
e↵ects, particularly at extreme predicted values.) In this case, we use the control group data to fit
regressions

Yj = ⇡(0

i) Wj

+ "j ; j 6= i,

for outcome Yj and covariates Wj in leave-out samples omitting each observation i. The vector Wj
contains gender, race, parental education, EFC, family income, high school GPA, and composite
ACT score—all strong predictors of persistence. The resulting leave-out fitted values are given by
ˆ(0
Ŷi = ⇡

i) Wi

for each applicant in the control sample.
Estimates of the e↵ect of STBF awards on four-year enrollment conditional on Ŷi appear in
panel A of Figure 5. This figure plots control group means for a range of Ŷi running from 0.2 1.0 (excluding a small number of applicants with predicted enrollment rates outside this range.)
Treatment group means are constructed as in Figures 1 to 4.12 Figure 5 reinforces the finding
that scholarship e↵ects are substantially larger for groups with lower predicted persistence. Among
students whose expected year-two four-year enrollment rate falls below 30 percent, awards increased
four-year enrollment by 30 points, nearly doubling the 35 percent enrollment rate in the control
group. In the highest bin, the estimated treatment e↵ect is a modest six points on a base of 86
percent. Again, we see considerable leveling up: the high-low gap in four-year college enrollment
for the control group is 52 points, and Bu↵et awards cut this roughly in half.
In the same spirit, we also examined the relationship between conditional treatment e↵ects and
STBF reviewer assessments. These subjective ratings draw on personal essays and reference letters
as well as quantitative criteria like grades and test scores. As Table 1 shows, reviewers tend to favor
12

Note that predictions using leave-out means need not fit empirical conditional means perfectly, even if the underlying conditional mean function is correctly specified. This is evident in Figure 5 for predictions at low and high
quantiles.

16

applicants with higher ACT scores, higher GPAs, and lower family incomes. Here too, therefore,
we might expect to see the same sort of negative relationship between reviewer predictions and
program impacts seen in the pattern of treatment e↵ects estimated conditional on fitted values
from our empirical model of college readiness.
Treatment e↵ects conditional on STBF reviewer scores are, indeed, negatively related with
program impact. Scores are reported here on a seven-point scale.13 Among those ranked one to
three (the bottom of the random assignment group), STBF awards boosted four-year enrollment
in year two by 14 to 25 points. By contrast, among those ranked five to seven, estimated impacts
were just 10 points, and only marginally significantly di↵erent from zero.
These results highlight a challenging trade-o↵ between increasing program-induced gains and
the desire to reward past achievement. Students who appear most meritorious based on grades and
test scores are also those most likely to persist in college absent the STBF scholarship; this group
is relatively skilled and highly motivated for post-secondary schooling. Conversely, awards made to
groups of applicants who appear more likely to struggle in college benefit most dramatically from
merit aid when they’re lucky enough to get it.

5

Bang for Buck Awarded

STBF awards boosted college matriculation, with even larger e↵ects on sophomore outcomes. Here,
we compare these estimated gains with the associated scholarship costs. Specifically, to gauge cost
e↵ectiveness (bang for buck), we scale treatment e↵ects using a two-stage least squares (2SLS)
procedure that takes the endogenous variable to be STBF program spending. The 2SLS second
stage equation in this case can be written

Yi = Ai +

X

⇢sc risc +

0

X i + "i ,

(2)

s,c

where the outcome, Yi , is cumulative semesters of enrollment (through year two) at a given college
type. The endogenous variable, Ai , is STBF aid received, measured in thousands of dollars. For
students with full awards who attend NU, this includes the per pupil cost of LC services, estimated
13
The raw reviewer scores for these students range from 15 to 21; we relabel these as one to seven in the figure.
Two percent of students in the experimental group received scores either below 15 or above 21. These students are
excluded from the graph.

17

to be $2,920 in 2013. As before, the model includes strata dummies, risc , to account for di↵erential
awards rates across strata, and covariates, Xi , to increase precision. The instrument used to construct 2SLS estimates of equation (2) is a dummy for an STBF o↵er. The first stage for this 2SLS
procedure is a version of Equation (1), with Ai on the left hand side.
We interpret this 2SLS cost-benefit calculation using the potential outcomes and potential assignments notation introduced by Imbens and Angrist (1994). For each applicant (omitting i subscripts), let S indicate o↵ers as before, and let D2 (S) and D4 (S) count the applicant’s semesters
of enrollment at two- and four-year schools. These are potential outcomes indexed by S. In other
words, D4 (1) counts an applicant’s four-year semesters enrolled if o↵ered a scholarship, and D4 (0)
counts four-year semesters enrolled if not o↵ered an award. STBF spending, A(S), is a potential
treatment indexed by S. Potential outcomes and treatments are independent of aid o↵ers, S, by
virtue of random assignment.
Ignoring covariates, the first-stage e↵ect of scholarship o↵ers on program spending is E[A(1)
A(0)]. Students not awarded scholarships generate no STBF spending, so A(0) = 0. Scholarship
winners receive A(1) = c2 D2 (1) + c4 D4 (1) each, where c2 and c4 are per-term program costs at twoand four-year colleges, respectively (with c2 < c4 ). We can therefore write the first stage for the
impact of aid o↵ers on program costs as follows:

A(0)] = E [c2 D2 (1) + c4 D4 (1)]

E [A(1)

= c2 E [D2 (1)
⌘ c2
Here,
2

and

2

and
4

4

2

+ c4

D2 (0)] + c4 E [D4 (1)
4

+

2

+

D4 (0)] + c2 E [D2 (0)] + c4 E [D4 (0)] (3)

4.

(4)

denote treatment e↵ects on semesters enrolled at two- and four-year schools, while

capture spending on two- and four-year enrollment that occurs in the absence of awards.

The corresponding reduced form e↵ect of aid o↵ers on total semesters attended is therefore

E[D2 (1)

D2 (0)] + E[D4 (1)

D4 (0)] =

2

+

4.

As always, a just-identified instrumental variables estimand is given by the ratio of reduced form

18

to first stage estimates. The 2SLS specification in (2) therefore estimates the ratio
2SLS
total

=

c2

2

2

+

+ c4

4

4

+

2

+

.

(5)

4

The ratio of treatment e↵ects to spending is readily computed, of course, but the 2SLS version of
this calculation neatly adjusts for covariates and immediately provides appropriate standard errors
for the ratio. The formulation in equation (5) also highlights the fact that

2

and

4 —money

spent

on enrollment that would have occurred with or without scholarships—are key determinants of bang
for buck.
The overall first stage estimate for 2SLS estimates of equation (2) shows that STBF spent about
$15,000 per awarded applicant in the two years after award receipt. As can be seen in the first row
of Table 7, this overall spending figure varies across strata, reaching as high as about $18,000 per
applicant in the UNL stratum. (Bang for buck calculations for the community college stratum are
not shown separately since treatment e↵ects in this stratum are essentially zero).
The treatment e↵ects generated by these expenditures, reported in panel B of Table 7, show
gains in total semesters enrolled (

2+

4)

ranging from 0.29 in the UNL stratum to a high of 0.68 in

the state college stratum. Gains in four-year enrollment (

4)

are largest in the UNO/UNK stratum:

for these applicants, STBF awards generated nearly a full semester of additional enrollment by the
end of year two. Importantly, in two out of three strata, gains in semesters enrolled reflect both
an increase in four-year terms and a decline in two-year terms (that is, negative values of

2 ).

The UNO/UNK stratum, for example, experienced almost a half a semester decrease in two-year
enrollment. Only the state college stratum saw gains in both two- and four-year terms completed.
Bu↵ett program spending increased net semesters attended by 0.025 per thousand dollars spent.
In other words, STBF spent almost $40,000 ($1,000 divided by 0.025) for each added semester. Bang
for buck is highest among students who targeted the least selective four-year colleges, a consequence
of lower costs and larger treatment e↵ects at these schools. Each semester’s gain among applicants
targeting UNL cost over $60,000, while each semester gained generated program costs about half
as large for those targeting UNO/UNK. Measured in terms of net semesters completed, bang for
buck is largest among applicants targeting state colleges, a finding that reflects the fact that the
treatment in this stratum increased two- as well as four-year enrollment. As suggested by our

19

subgroup comparisons, the high costs of enrollment gains in the UNL stratum reflect the fact that
applicants targeting UNL have high enrollment rates even without scholarship support. In terms
of the 2SLS estimand (equation (5)) most spending on these students contributes to

4

rather than

4.

5.1

Marginal Money

The bang for buck estimates in Table 7 reveal that, because many scholarship awards leave their
recipients’ enrollment unchanged, the cost of increasing enrollment by a semester far exceeds the
nominal award amounts (c2 or c4 ). This feature of college aid was first highlighted in a pioneering
analysis by Fuller, Manski and Wise (1983) of the federal Basic Educational Opportunity Grant
(BEOG, later, known as Pell grants). Using a structural model of college choice estimated for a
sample of high school seniors in 1972 (the National Longitudinal Study of the High School Class of
1972 data set), Fuller, Manski, and Wise simulate college enrollment rates by income group in the
absence of the BEOG program. They estimate that a quarter of BEOG recipients were induced
to go to college by the program, while three quarters would have enrolled with or without awards.
Disaggregating by family income, 90 percent of BEOG awards made to students from middle and
upper income families seem to have gone to students who would have enrolled anyway.
We would similarly like to isolate the marginal share of STBF spending, that is spending that
changes behavior, either by increasing total enrollment or by shifting students across schools. At
first blush, the terms c2
Indeed, c4

4,

2

+ c4

4

in equation (4) would appear to capture marginal spending.

is marginal spending on four-year terms. But c2

2

is a negative number in our data:

this term mixes spending on increased two-year enrollment with the savings in two-year tuition from
those who shifted from two- to four-year programs. Spending on the four-year enrollment increase
generated by the latter group is accounted for in c4

4.

It remains, however, to extract an estimate

of spending on new two-year enrollment from the gross change in two-year semesters. Otherwise,
we overestimate the extent to which STBF awards are pure transfers.14
To facilitate the distinction between marginal and infra-marginal spending, we assume that
14
Suppose, for example, that the scholarship switches 10 percent of students from two- to four-year schools and
another 10 percent from no college to a two-year school. Suppose also that everyone who enrolls completes four
semesters by the end of year two. In this case, marginal money is spending on the 20 percent of students who
changed their behavior: c2 (0.10 ⇥ 4) + c4 (0.10 ⇥ 4) But the net change in two-year enrollment, 2 , is zero, so
c2 2 + c4 4 = c4 (0.10 ⇥ 4) only.

20

1. Aid doesn’t reduce total terms enrolled for any applicant: D4 (1) + D2 (1)
2. Aid doesn’t reduce four-year terms enrolled for any applicant: D4 (1)

D4 (0) + D2 (0).

D4 (0)

0.

3. There is no dual enrollment among scholarship winners: D2 (1)D4 (1) = 0.
These assumptions allow aid o↵ers to increase total terms enrolled and to shift students from two- to
four-year institutions. However, they preclude the possibility that aid o↵ers reduce total enrollment
or shift students from four- to two-year programs.
It is useful at this point to define a binary indicator d4 (1) ⌘ 1 {D4 (1) > 0} that identifies
students who enroll in four-year colleges when o↵ered scholarships. We use this to split c2

2

into

two pieces:

c2 E [D2 (1)

D2 (0)] = c2 E {[D2 (1)

D2 (0)] [1

d4 (1)]} + c2 E {[D2 (1)

= c2 E {[D2 (1)

D2 (0)] [1

d4 (1)]}

D2 (0)] d4 (1)}

c2 E [D2 (0)d4 (1)] .

(6)

The first term here captures increased spending on new two-year enrollment, while the second
captures reductions in two-year spending due to shifting from two- to four-year schools. (The
second equality follows from Assumption 3, which requires that D2 (1)d4 (1) = 0, meaning treated
students don’t simultaneously enroll in two- and four-year colleges.) Substituting equation (6) into
the first stage expression in (3) and combining like terms provides a useful decomposition of the aid
first stage:

E [A(1)

A(0)] = c2 E {D2 (0) [1

d4 (1)]} + c4 E [D4 (0)]

+c2 E {[D2 (1)

D2 (0)] [1

d4 (1)]} + c4 E [D4 (1)

D4 (0)] .

(7)

Equation (7) distinguishes four types of spending:
1. c2 E {D2 (0) [1

d4 (1)]} is spending on two-year enrollment that occurs with or without awards.

(This term is positive when D2 (0) > 0 and d4 (1) = 0, that is, for students who attend two
year-colleges without awards but don’t attend four-year colleges with awards.)
2. Similarly, c4 E [D4 (0)] is spending on four-year enrollment that occurs with or without awards.

21

(Students for whom D4 (0) 6= 0 attend four-year colleges in the absence of awards. By Assumption 2, they must also attend four-year colleges if awarded scholarships.)
3. c2 E {[D2 (1)

D2 (0)] [1

d4 (1)]} is spending on new two-year enrollment among students

who do not attend four-year colleges when awarded scholarships (that is, students for whom
d4 (1) = 0).
4. c4 E [D4 (1)

D4 (0)] is spending on the increase in four-year enrollment generated by awards.

(This follows from Assumption 2, which says that D4 (1)

D4 (0) must be non-negative.) This

term includes new enrollment, enrollment that’s shifted from two- to four-year programs,
and increased four-year enrollment among students who would have otherwise attended fewer
four-year terms.
Terms 1 and 2 above capture spending on enrollment that is unchanged by awards and is therefore
infra-marginal. The remaining two terms reflect spending on new two-year and four-year enrollment,
that is, marginal money. The sum of these marginal terms is

c2 E {[D2 (1)

D2 (0)] [1

D4 (0)] ⌘ c2 µ + c4

d4 (1)]} + c4 E [D4 (1)

Marginal money due to four-year spending is simply c4

4,

4

a quantity easily computed. But c2 µ

isn’t non-parametrically identified because we don’t observe the joint outcome µ ⌘ [D2 (1)

D2 (0)] [1

We therefore construct bounds under alternative assumptions about two-year enrollment in the absence of award o↵ers. In pursuit of these bounds, it helps to rewrite µ as follows:

µ ⌘ E {[D2 (1)
= E [D2 (1)

D2 (0)] [1

d4 (1)]}

D2 (0) | d4 (1) = 0] E [1

d4 (1)] .

Given Assumptions 1 and 2, this term is bounded below by zero: the scholarship can only increase
two-year enrollment among students who would never attend four-year schools. We obtain an upper
bound for µ by assuming that all two-year enrollment among those who would never attend four15
As always, we observe the marginal distribution of potential outcomes, D2 (S) and D4 (S), but not their joint
distribution. Here, for example, whether a treated four-year college student would have attended a two-year school
in the absence of treatment.

22

d4 (1)].15

year schools is induced by awards. This in turn implies D2 (0) = 0 for all those with d4 (1) = 0, in
which case µ = E [D2 (1) | d4 (1) = 0] E [1
M (µ) ⌘
for µ 2 {0, E [D2 (1) | d4 (1) = 0] E [1

d4 (1)]. The resulting marginal money bounds are

c2

c 2 µ + c4
+
c4 4 +
2

4
2

+

(8)
4

d4 (1)]}.

As can be seen in panel C of Table 7, marginal money is estimated to fall between about 14
and 19 percent of total program spending. Thus, like Fuller, Manski and Wise (1983), most of the
financial aid awarded through Bu↵ett scholarships goes to applicants whose behavior is unchanged
in response to an award. The largest marginal money share, between 22 and 23 percent of total
spending, is for applicants in the UNO/UNK stratum. This finding reflects the especially large
program-induced boost in relatively expensive four-year enrollment found for applicants targeting
the UNO and UNK campuses. By contrast, the large bang for buck for state college applicants
seen in panel C of the table doesn’t translate into a large marginal money share for this group.
The discrepancy between the bang for buck and marginal money statistics among state college
applicants is explained by the fact that half of the bang for buck figure in the state college stratum
comes from spending on relatively inexpensive two-year colleges. Spending on four-year support in
the state college stratum was mostly infra-marginal. Policy-makers who value four-year enrollment
over two-year enrollment might therefore see support of applicants to NU’s least selective campuses
as being most cost-e↵ective.

6

Distinguishing Aid E↵ects from Learning Communities

As we’ve seen, STBF awards made to students targeting NU generated larger initial gains in fouryear enrollment than did STBF o↵ers made to students who targeted state and community colleges.
To what extent is this result a reflection of the LC support o↵ered to Bu↵et scholars at NU? The
second arm of our randomized evaluation quantifies the contribution of LC by o↵ering a second aidonly treatment, known to applicants as the College Opportunity Scholarship (COS). COS awards,
which were first o↵ered to the 2013 cohort, match the aid component of full awards without o↵ering
access to the LC services enjoyed by Bu↵ett Scholars at NU. Paralleling the LC-including treatment,
COS awards were made only to applicants targeting an NU campus.
23

Table 8 o↵ers a first look at treatment e↵ects for the COS intervention, comparing these with
estimates for the group of 2013 applicants who targeted NU and were o↵ered full awards. This table
also reports preliminary results for a few second-year outcomes for the 2013 cohort; we expect to
expand the list of outcomes as well as the COS sample in the near future. These initial findings show
COS treatment e↵ects close to, though somewhat below, those generated by full awards. Estimates
of the di↵erence in e↵ects generated by full and COS awards are not significantly di↵erent from
zero.
Because the COS experimental cohort has faced only one full year of potential college enrollment
to date, comparisons between COS and traditional STBF awards are provisional. We expect to be
able to sharpen these findings in the near future, as more data on enrollments in the academic year
2014-15 become available.

7

Summary and Conclusions

STBF awards induced a clear shift from two- to four-year schools and a marked increase in secondyear college enrollment. These gains are driven by strong persistence among award winners, coupled
with high rates of attrition in the control group. Second-year gains and shifts into four-year programs
are largest for nonwhite applicants, for those with relatively low ACT scores, and for applicants who
indicated an interest in four-year programs other than the most-selective Nebraska public college.
Scholarships generated the largest enrollment and persistence gains in demographic groups that
would otherwise have been predicted to fare poorly—that is, they enabled disadvantaged students
to ‘level up.’ These findings highlight the paradox of merit aid: awards based on past achievement
are likely to generate smaller gains than awards made to applicants who appear less likely to be
college-ready.
These results are preliminary and limited to outcomes available in a two-year follow-up. As the
current cohorts age and new cohorts enter the study, we expect to be able to examine e↵ects on
longer-term persistence and college completion. We also anticipate a sharpening of the contrast
between estimates of the e↵ects of aid o↵ered with Learning Community services and estimates of
the e↵ects of aid alone. Evidence on di↵erential e↵ects across subgroups and, in particular, the
pattern that shows larger gains for less well-prepared students, should also grow more conclusive.

24

Ultimately, we expect to be able to measure e↵ects in the labor market as well as on completed
schooling.

25

References
Abadie, Alberto, Matthew M. Chingos, and Martin R. West. 2013. “Endogenous Stratification in Randomized Experiments.” National Bureau of Economic Research Working Paper
19742, December.
Abraham, Katharine G., and Melissa A. Clark. 2006. “Financial Aid and Students’ College
Decisions Evidence from the District of Columbia Tuition Assistance Grant Program.” Journal
of Human Resources, 41(3): 578–610.
Angrist, Joshua D., Daniel Lang, and Philip Oreopoulos. 2009. “Incentives and Services for
College Achievement: Evidence from a Randomized Trial.” American Economic Journal: Applied
Economics, 1(1): 136–163.
Angrist, Joshua D., Philip Oreopoulos, and Tyler Williams. 2014. “When Opportunity
Knocks, Who Answers? New Evidence on College Achievement Awards.” Journal of Human
Resources, 49(3): 572–610.
Arcidiacono, Peter, Esteban M. Aucejo, and V. Joseph Hotz. 2016. “University Di↵erences
in the Graduation of Minorities in STEM Fields: Evidence from California.” American Economic
Review, 106(3): 525–562.
Avery, Christopher, Caroline M. Hoxby, Clement Jackson, Kaitlin Burek, and Glenn
Pope. 2006. “Cost Should Be No Barrier: An Evaluation of the First Year of Harvard’s Financial
Aid Initiative.” National Bureau of Economic Research Working Paper 12029, February.
Bettinger, Eric P., and Rachel Baker. 2014. “The E↵ects of Student Coaching in College:
An Evaluation of a Randomized Experiment in Student Mentoring.” Educational Evaluation and
Policy Analysis, 36(1): 3–19.
Bloom, Dan, and Colleen Sommo. 2005. “Building Learning Communities: Early Results from
the Opening Doors Demonstration at Kingsborough Community College.” MDRC report, June.
Available at http://www.mdrc.org/publication/building-learning-communities (accessed March
10, 2017).

26

Bound, John, and Sarah E. Turner. 2002. “Going to War and Going to College: Did World
War II and the G.I. Bill Increase Educational Attainment for Returning Veterans?” Journal of
Labor Economics, 20(4): 784–815.
Cohodes, Sarah R., and Joshua S. Goodman. 2014. “Merit Aid, College Quality, and College
Completion: Massachusetts’ Adams Scholarship as an In-Kind Subsidy.” American Economic
Journal: Applied Economics, 6(4): 251–285.
College

Board.

2014.

“Maximum

and

Average

Pell

Grant

Over

Time.”

Available

at http://trends.collegeboard.org/student-aid/figures-tables/fed-aid-maximum-and-averagepellgrant-over-time (accessed December 1, 2014).
Congressional
Growth

and

Budget

Office.

Policy

Options.”

2013.

“The

CBO

Federal

Publication

Pell
4451,

Grant

Program:

September.

Recent

Available

at

http://www.cbo.gov/sites/default/files/cbofiles/attachments/44448 PellGrants 9-5-13.pdf
(accessed March 16, 2017).
Cornwell, Christopher, David B. Mustard, and Deepa J. Sridhar. 2006. “The Enrollment
E↵ects of Merit-Based Financial Aid: Evidence from Georgia’s HOPE Program.” Journal of
Labor Economics, 24(4): 761–786.
Deming, David, and Susan Dynarski. 2009. “Into College, Out of Poverty? Policies to Increase
the Postsecondary Attainment of the Poor.” National Bureau of Economic Research Working
Paper 15387, September.
Dynarski, Susan M. 2000. “Hope for Whom? Financial Aid for the Middle Class and Its Impact
on College Attendance.” National Tax Journal, 53(3): 629–662.
Dynarski, Susan M. 2004. “The New Merit Aid.” In College Choices: The Economics of Where
to Go, When to Go, and How to Pay For It. Vol. I, eds. Caroline M. Hoxby, 67–93. Chicago: University of Chicago Press.
Dynarski, Susan M., Steven W. Hemelt, and Joshua M. Hyman. 2015. “The Missing Manual: Using National Student Clearinghouse Data to Track Postsecondary Outcomes.” Educational
Evaluation and Policy Analysis, 37: 53S–79S.
27

Fuller, Win, Charles F. Manski, and David A. Wise. 1983. “Enrollment E↵ects of the BEOG
Program.” In College Choice in America. eds. Charles F. Manski, and David A. Wise, Chapter
7, 118–128. Cambridge: Harvard University Press.
Goldrick-Rab, Sara, Robert Kelchen, Douglas N. Harris, and James Benson. 2016.
“Reducing Income Inequality in Educational Attainment: Experimental Evidence on the Impact
of Financial Aid on College Completion.” American Journal of Sociology, 121(6): 1762–1817.
Goodman, Joshua S. 2008. “Who Merits Financial Aid?: Massachusetts’ Adams Scholarship.”
Journal of Public Economics, 92(10): 2121–2131.
Imbens, Guido W., and Joshua D. Angrist. 1994. “Identification and Estimation of Local
Average Treatment E↵ects.” Econometrica, 62(2): 467–475.
Kane, Thomas J. 2003. “A Quasi-Experimental Estimate of the Impact of Financial Aid on
College-Going.” National Bureau of Economic Research Working Paper 9703, May.
Kane, Thomas J. 2007. “Evaluating the Impact of the D.C. Tuition Assistance Grant Program.”
Journal of Human Resources, 42(3): 555–582.
Leslie, Larry L., and Paul T. Brinkman. 1987. “Student Price Response in Higher Education:
The Student Demand Studies.” The Journal of Higher Education, 58(2): 181 – 204.
Marx, Benjamin M., and Lesley J. Turner. 2015. “Borrowing Trouble? Student Loans, the
Cost of Borrowing, and Implications for the E↵ectiveness of Need-Based Grant Aid.” National
Bureau of Economic Research Working Paper 20850, January.
U.S.
Aid

Department
Handbook.”

of
Office

Education.
of

Federal

2012.
Student

“Federal
Aid.

Student

Available

at

https://ifap.ed.gov/ifap/byAwardYear.jsp?type=fsahandbook&awardyear=2012-2013 (accessed
December 21, 2016).
Weiss, Michael J., Alexander Mayer, Dan Cullinan, Alyssa Ratledge, Colleen Sommo,
and John Diamond. 2015a. “A Random Assignment Evaluation of Learning Communities
at Kingsborough Community College: Seven Years Later.” Journal of Research on Educational
E↵ectiveness, 8(2): 189–217.
28

Weiss, Michael J., Mary G. Visher, Evan Weissman, and Heather D. Wathington. 2015b.
“The Impact of Learning Communities for Students in Developmental Education: A Synthesis of
Findings from Randomized Trials at Six Community Colleges.” Education Evaluation and Policy
Analysis, 37(4): 520–541.

29

Table 1
Descriptive Statistics
(2012 & 2013 Cohorts)
Non-Experimental
Sample
Not
Funded
Funded
(3)
(4)

Experimental
Sample
Treatment Control
All
(6)
(5)

Nebraska
HS Seniors
(1)

All Eligible
Applicants
(2)

Female

.50

.62

.67

.56

.62

.017
(.020)

White

.77

.61

.45

.57

.66

-.009
(.019)

Black

.07

.06

.06

.10

.06

-.008
(.010)

Hispanic

.11

.12

.21

.10

.10

.001
(.013)

Other nonwhite
or unreported race

.04

.20

.28

.23

.18

.016
(.016)

EFC ($)

---

2,890
(3,293)

1,680
(2,474)

3,427
(3,924)

3,127
(3,298)

-69
(137)

72,594

48,253
(28,855)

37,922
(23,651)

50,516
(29,855)

50,547
(29,334)

725
(1,270)

Urban resident

.38

.41

.51

.46

.38

.003
(.018)

Mother attended college

.57

.41

.29

.42

.44

.001
(.021)

Parents are married

.58

.58

.47

.57

.61

.014
(.020)

High school GPA

---

3.45
(.42)

3.52
(.38)

3.15
(.42)

3.48
(.42)

-.007
(.017)

Composite ACT score

22.0

22.0
(4.4)

21.9
(4.3)

20.6
(4.3)

22.2
(4.4)

-.27
(.18)

Took ACT

.70

.93

.91

.91

.94

.003
(.010)

Family income ($)

.68

F-statistic
p-value
Sample size

.76
3,487

657

399

2,431

2,431

Notes: Family income is the sum of the applicant's personal, parental, and spousal adjusted gross incomes. Urban residency is
defined as attending high school in a city of at least 250,000 residents. Data for Column (1) come from SEER (gender and race), ACS
(family income, mother's education, and marital status), NCES (urban residency), and the ACT. Statewide EFC and GPA data were
unavailable. Treatment-control differences are from regressions that control for strata (target college by year of application)
dummies.
*** p < 0.01, ** p < 0.05, * p < 0.10

30

Table 2
Effect on Year One Financial Aid Packages
for Nebraska Public College Students
(2012 & 2013 Cohorts)

Control
Mean
(1)

Per Award
Covariate
Adjusted
(2)

Campus
Adjusted
(3)

Per Dollar Awarded
Covariate
Campus
Adjusted
Adjusted
(4)
(5)

Cost of attendance

17,469

1,129 ***
(196)

104
(147)

.24 ***
(.02)

.02
(.02)

Total aid

11,608

3,319 ***
(234)

2,168 ***
(202)

.53 ***
(.03)

.30 ***
(.03)

Total grants

7,251

6,225 ***
(184)

5,467 ***
(167)

.91 ***
(.02)

.78 ***
(.02)

Government grants

3,162

-1
(86)

-226
(82)

.02 *
(.01)

-.03 **
(.01)

Institutional grants

2,904

-380 ***
(111)

-635 ***
(111)

-.06 ***
(.02)

-.12 ***
(.02)

0

6,924 ***
(77)

6,744 ***
(77)

1.00 ***
(.00)

1.00 ***
(.00)

-318
(80)

-417
(84)

***

-.05 ***
(.01)

-.07 ***
(.01)

STBF grant

***

Other private grants

1,185

Total government loans

3,529

-2,220 ***
(148)

-2,524 ***
(153)

-.29 ***
(.02)

-.37 ***
(.02)

Subsidized government loans

1,894

-1,488 ***
(69)

-1,635 ***
(71)

-.20 ***
(.01)

-.24 ***
(.01)

Unsubsidized government loans

1,635

-732 ***
(112)

-889 ***
(116)

-.09 ***
(.02)

-.13 ***
(.02)

-486
(45)

-580
(46)

-.06 ***
(.01)

-.08 ***
(.01)

Federal Work Study

829

Campus controls
Sample size

1,093

***

***

***

No

Yes

No

Yes

1,928

1,928

1,928

1,928

Notes: This table reports effects of the STBF scholarship offer on students' financial aid packages. The sample is restricted to
students enrolled in Nebraska public colleges. Aid data are currently unavailable for the 309 students at state colleges and
Mid-Plains Community College. Columns (2) and (3) report results from regressions of the financial aid awarded in each
category on a dummy for winning a scholarship, while Columns (4) and (5) report results from regressions of the same
dependent variables on the dollar value of scholarships awarded. The regressions in Columns (3) and (5) control for
cumulative enrollment at each campus. All regressions control for target college, cohort, and baseline covariates. Baseline
covariates include high school GPA and EFC, as well as bins for family income and ACT composite score. Government grants
include federal and state grants. Government loans include subsidized and unsubsidized loans, where subsidized is the sum
of Perkins and subsidized Stafford loans, and unsubsidized is the sum of PLUS and unsubsidized Stafford loans.
*** p < 0.01, ** p < 0.05, * p < 0.10

31

Table 3
Effect on Year Two Financial Aid Packages
for Nebraska Public College Students
(2012 Cohort)
Control
Mean
(1)

Per Award
Covariate
Adjusted
(2)

Campus
Adjusted
(3)

Per Dollar Awarded
Covariate
Campus
Adjusted
Adjusted
(4)
(5)

Cost of attendance

17,104

1,650 ***
(388)

-30
(277)

.42 ***
(.04)

.04
(.03)

Total aid

8,957

4,155 ***
(421)

2,619 ***
(379)

.73 ***
(.05)

.41 ***
(.05)

Total grants

5,233

6,439 ***
(320)

5,341 ***
(294)

1.00 ***
(.03)

.82 ***
(.04)

Government grants

2,590

-60
(151)

-343 **
(151)

.04 **
(.02)

-.03
(.02)

Institutional grants

2,305

-456 **
(184)

-803 ***
(191)

-.03
(.02)

-.12 ***
(.03)

0

7,034 ***
(144)

6,625 ***
(144)

1.00 ***
(.00)

1.00 ***
(.00)

-80
(75)

-138 *
(82)

-.01
(.01)

-.02 *
(.01)

STBF grant
Other private grants
Total government loans

338
3,239

-1,674 ***
(257)

-2,025 ***
(274)

-.19 ***
(.03)

-.30 ***
(.04)

Subsidized government loans

1,707

-1,134 ***
(125)

-1,331 ***
(130)

-.13 ***
(.02)

-.20 ***
(.02)

Unsubsidized government loans

1,532

-540 ***
(195)

-693 ***
(213)

-.06 ***
(.02)

-.11 ***
(.03)

485

-272 ***
(63)

-372 ***
(67)

-.03 ***
(.01)

-.05 ***
(.01)

No

Yes

No

Yes

777

777

777

777

Federal Work Study

Campus controls
Sample size

365

Notes: Variables and specifications are defined in Table 2. The sample is restricted to students enrolled in
Nebraska public colleges from the 2012 cohort, where we have two complete years of outcome data. Aid data are
currently unavailable for the 94 students at state colleges and Mid-Plains Community College.
*** p < 0.01, ** p < 0.05, * p < 0.10

32

UNK & UNO
Control Treatment
Effect
Mean
(5)
(6)

Table 4
Effect on Year One Enrollment by Target College
(2012 & 2013 Cohorts)
UNL
Treatment
Effect
(4)

State Colleges
Control Treatment
Effect
Mean
(7)
(8)

.984
.065 ***
(.015)

.014 *
(.007)

.838

.959

-.097 ***
(.018)

.131 ***
(.020)

.034 ***
(.011)

.060

.905

.965

-.015
(.021)

.011
(.031)

-.004
(.025)

.872

.077

.949

-.019
(.036)

.030
(.030)

.010
(.022)

Community Colleges
Control Treatment
Effect
Mean
(9)
(10)

.019 ***
(.007)
.914

.120

Control
Mean
(3)

.967
.078 ***
(.011)

-.052 ***
(.014)

All Strata
Control Treatment
Effect
Mean
(1)
(2)

Any post-secondary
.753
.069

A. Enrollment and Program Type

Any four-year college
-.058 ***
(.010)

.022
(.020)

.004
(.012)

.026

.033
(.029)

.009
.005
(.038)

.906

.012
(.027)

.021
(.025)
.075

-.005
(.039)

.927

-.022
(.019)

.030

.900

-.010
(.038)

.043

-.002
(.016)

-.018
(.015)

B. Selectivity
.057

.088 ***
(.018)

.915

.001
(.032)

.021

.120 ***
(.024)

.215

.786

.876

.074 ***
(.017)

.065

.006
(.030)

.039 ***
(.011)

.051 ***
(.016)

.895

-.054 ***
(.015)

.050

.151 ***
(.026)

.916

.032 **
(.013)

.083

-.040 ***
(.013)

.755

.057 ***
(.011)

.943

-.038 ***
(.015)

.063

-.055 ***
(.019)

.899

.041 ***
(.010)

.068

-.019
(.011)

.110

.922

-.038 ***
(.009)

.040

.037 ***
(.013)

.068

-.022 ***
(.007)

C. Ownership and Location

.046

.297

.322

Two-year college only

Less than 75% admitted
75 - 90% admitted

Nebraska public college
Public college
Out-of-state or private college
Private college

2,431
876
855
304
396
Sample size
1,440
547
458
201
234
Notes: Year one enrollment includes any enrollment spells that occur between the July 1 after scholarship application and June 30 of the following calendar
year. Selectivity categories are defined by IPEDS according to 2012 admissions rates. UNL admitted less than 75% of applicants; UNK and UNO admitted 75 90%; state colleges admitted more than 90%. All regressions control for target college, cohort, and baseline covariates as defined in Table 2.
*** p < 0.01, ** p < 0.05, * p < 0.10

33

UNK & UNO
Treatment
Control
Effect
Mean
(5)
(6)

Table 5
Effect on Year Two Enrollment by Target College
(2012 Cohort)
UNL
Treatment
Effect
(4)

.072 ***
(.018)
4.50

.897

.069 *
(.037)

.29 **
(.12)

.057 **
(.027)

.180

.678

3.92

.859

-.130 ***
(.032)

.236 ***
(.038)

.48 ***
(.12)

.106 ***
(.028)

.104

.750

4.23

.854

.020
(.055)

.114 *
(.069)

.68 **
(.27)

.134 **
(.055)

.746

.141

4.35

.887

-.075
(.084)

.056
(.060)

.18
(.33)

-.019
(.064)

Community Colleges
Treatment
Control
Effect
Mean
(9)
(10)

.876
.37 ***
(.08)
.806

-.013
(.029)

State Colleges
Treatment
Control
Effect
Mean
(7)
(8)

Any post-secondary
4.21
.144 ***
(.023)
.091

Control
Mean
(3)

Semester equivalents
enrolled
.653
-.072 ***
(.021)

All Strata
Treatment
Control
Effect
Mean
(1)
(2)

Any four-year college
.222

A. Enrollment and Program Type

Two-year college only

75 - 90% admitted

Less than 75% admitted

499

.315

.257

1,003

.065 ***
(.024)

.068 ***
(.020)

175

.177

.623

350

-.118 ***
(.034)

.180 ***
(.045)

205

.571

.073

411

.261 ***
(.044)

-.010
(.026)

48

.146

.021

98

-.100
(.061)

.022
(.033)

71

.028

.042

144

.060
(.037)

.013
(.039)

B. Selectivity

Sample size

Notes: Year two enrollment includes any enrollment spells that occur between the second July 1 after scholarship application and the following June 30. A
semester equivalent is 12 credit hours of enrollment. Selectivity categories are defined by IPEDS according to 2012 admissions rates. UNL admitted less than 75%
of applicants; UNK and UNO admitted 75 - 90%; state colleges admitted more than 90%. The sample is restricted to the 2012 cohort, where we have two
complete years of outcome data. All regressions control for target college, cohort, and baseline covariates as defined in Table 2.
*** p < 0.01, ** p < 0.05, * p < 0.10

34

Table 6
Effect on Retention
(2012 Cohort)

Any PostSecondary
(2)

Year One Enrollment

Marginal
Outcomes
(1)

Year Two Enrollment
Any
Two-Year
Four-Year
College
(3)
(4)

Not
Enrolled
(5)

Row
Total

.072 ***
(.018)
{.876}

.144 ***
(.023)
{.653}

-.072 ***
(.021)
{.222}

-.072 ***
(.018)
{.124}

1,003

Any Post(2)
Secondary

.024 **
(.010)
{.964}

.076 ***
(.018)
{.868}

.144 ***
(.023)
{.651}

-.067 ***
(.020)
{.216}

-.053 ***
(.016)
{.096}

979

Any Four(3)
Year

.081 ***
(.017)
{.758}

.125 ***
(.020)
{.685}

.146 ***
(.023)
{.631}

-.021
(.013)
{.054}

-.044 ***
(.014)
{.072}

799

Two-Year
(4)
College

-.057 ***
(.016)
{.206}

-.048 ***
(.017)
{.182}

-.002
(.009)
{.020}

-.046 ***
(.017)
{.162}

-.009
(.009)
{.024}

180

Not
Enrolled

-.024 **
(.010)
{.036}

-.005
(.005)
{.008}

.000
(.003)
{.002}

-.005
(.004)
{.006}

-.019 **
(.008)
{.028}

24

915

727

188

Column
Total

(5)

1,003

88

Notes: Year one enrollment includes any enrollment spells that occur between the July 1 after scholarship
application and June 30 of the following calendar year. Year two enrollment includes any enrollment spells
that occur between the subsequent July 1 and June 30. This table shows treatment effects on joint year one
and year two outcomes, e.g., any four-year enrollment in both years. Standard errors are in parentheses, and
control means for the given outcomes are in braces. Row and column totals report counts for year one and
year two outcomes, respectively. The sample is restricted to the 2012 cohort, where we have two complete
years of outcome data. All regressions control for target college, cohort, and baseline covariates as defined in
Table 2.
*** p < 0.01, ** p < 0.05, * p < 0.10

35

Table 7
Cost Effectiveness Through Year Two
(2012 Cohort)
All Strata
(1)

UNL
(2)

UNO & UNK
(3)

State Colleges
(4)

A. First Stage Effect on Program Spending
Total spending

14.77
(.29)

17.74
(.49)

***

***

15.79
(.44)

***

11.57
(.71)

***

B. Reduced Form Effects on Semesters Enrolled
Total semesters

.37
(.08)

***

.29
(.12)

**

.48
(.12)

***

.68
(.27)

Four-year semesters

.65
(.09)

***

.58
(.14)

***

.97
(.15)

***

.35
(.32)

Two-year semesters

-.28
(.09)

***

-.29
(.12)

**

-.49
(.13)

***

.32
(.27)

**

C. Bang Per Thousand Bucks of Program Spending
.025 ***
(.005)
{40,234}

.016 **
(.007)
{61,140}

.030 ***
(.007)
{32,999}

.059 ***
(.021)
{17,016}

D. Marginal Spending Share
13.5 - 18.8%

7.2 - 7.4%

21.9 - 23.1%

5.5 - 9.0%

1,003

350

411

98

Sample size

Notes: Panel A reports first stage regressions of program spending on a dummy for the STBF
scholarship offer. Program spending is measured in thousands of dollars and includes both scholarship
money and the per pupil cost of LC services for NU students. Panel B reports the corresponding reduced
form effects on semester equivalents, as defined in Table 5, and Panel C reports the associated 2SLS
estimates. The average cost of each added semester---equal to $1,000 divided by the 2SLS point estimate--is reported in braces. Panel D presents the marginal money estimates detailed in Section 7. The sample
is restricted to the 2012 cohort, where we have two complete years of outcome data. All regressions
control for target college, cohort, and baseline covariates as defined in Table 2.
*** p < 0.01, ** p < 0.05, * p < 0.10

36

Table 8
Full Awards vs. Aid-Only Awards
(2013 Cohort, NU Strata)
Year One Enrollment

Year Two Fall Enrollment
Difference

(5)

Mean

(6)

Full Awards

(7)

Aid-Only

(8)

Difference

Treatment Effect

Aid-Only
(4)

Control

Full Awards
(3)

Treatment Effect

Mean
(2)

Control
(1)

.886

.973

-.070 ***
(.014)

.096 ***
(.016)

.026 ***
(.008)

-.058 ***
(.016)

.077 ***
(.019)

.019 *
(.010)

-.011
(.014)

.019
(.016)

.008
(.007)

.120

.778

.898

-.080 *
(.018)

.135 *
(.024)

.055 *
(.017)

-.084 *
(.018)

.108 *
(.027)

.024
(.022)

.004
(.017)

.027
(.027)

.031
(.022)

A. Enrollment and Program Type

Any four-year college
.086

Any post-secondary

Two-year college only

75 - 90% admitted

Less than 75% admitted

625

.370

.490

1,180

.042 **
(.021)

.069 ***
(.020)

1,180

.022
(.026)

.048 *
(.025)

1,180

.020
(.026)

.021
(.024)

625

.333

.416

1,180

.074 *
(.026)

.077 *
(.025)

1,180

.042
(.030)

.049 *
(.027)

1,180

.032
(.032)

.028
(.029)

B. Selectivity

Sample size

Notes: The results reported here are from pooled regressions that distinguish the effects of full aid offers (including financial aid and access to LC
services) from those of aid-only awards. These results are available for the 2013 cohort only. Year one enrollment includes any enrollment spells that
occur between the July 1 after scholarship application and June 30 of the following calendar year. Year two fall enrollment includes any enrollment
spells that occur between the subsequent July 1 and October 31, when the most recent enrollment data were reported. All regressions control for target
college, cohort, and baseline covariates as defined in Table 2.
*** p < 0.01, ** p < 0.05, * p < 0.10

37

2012 Cohort
Non-Experimental
Sample
Not
All Eligible
Applicants Funded Funded
(1)
(2)
(3)

Table A1
Sample Selection
(2012 & 2013 Cohorts)
2013 Cohort
Non-Experimental
Sample

273

941

Control
(9)

487

Full
Award
(10)

210

AidOnly
(11)

Experimental
Sample

356

Experimental
Sample
Any
Award
(5)

2,267

Not
All Eligible
Applicants Funded Funded
(6)
(7)
(8)

Control
(4)
504

126

499

301

210
51
89
70
0

1,430

345
67
154
124
0

All Strata

625
72
372
181
0

380
63
175
142
0

27
85
77
7

107
26
33
46
2

285
33
140
108
4

242
36
113
91
2

1,661
250
840
560
11

1,110
189
496
421
4

381
64
175
142
0

University of Nebraska
Kearney
Lincoln
Omaha
NCTA

0
0
0
0

50
9
6
35

53
11
8
34

48
9
5
34

153
32
21
100

4
1
0
3

20
3
3
14

12
1
1
10

7
4
11
6

33
3
6
24

114
20
12
82

347
72
68
10
79
100
18

259
49
38
172

State Colleges
Chadron
Peru
Wayne

73
20
13
0
20
17
3

38

71
20
12
0
20
16
3

0
0
0
0
0
0
0

15
1
5
2
2
3
2

89
20
15
0
21
28
5

47
9
15
4
4
12
3

163
36
28
0
37
53
9

206
50
45
6
46
48
11

57
10
18
6
10
13
0

Community Colleges
Central
Metropolitan
Mid-Plains
Northeast
Southeast
Western

Notes: This table reports sample sizes by target college. The experimental sample contains applicants who were subject to random assignment.

38

Table A2
Descriptive Statistics: Cohort Comparison
Experimental Samples
2012 Cohort
All
(1)

2013 Cohort
Full Award
Aid-Only
TreatmentTreatmentAll
All
Control
Control
(4)
(6)
(3)
(5)

Treatment Control
(2)

Female

.62

.009
(.031)

.61

.024
(.027)

.60

-.036
(.040)

White

.66

.031
(.028)

.66

-.041
(.027)

.64

-.055
(.039)

Black

.08

-.011
(.017)

.05

-.006
(.012)

.06

.006
(.020)

Hispanic

.11

-.009
(.019)

.10

.009
(.017)

.10

-.001
(.025)

Other nonwhite race
or unreported race

.15

-.011
(.022)

.19

.037
(.023)

.20

.050
(.034)

EFC ($)

3,366

-52
(235)

2,960

-83
(161)

3,032

213
(240)

Family income

50,564

339
(2,170)

50,535

1,026
(1,501)

51,397

Urban resident

.42

-.007
(.027)

.35

.010
(.024)

.41

.006
(.037)

Mother attended college

.43

.024
(.031)

.45

-.017
(.028)

.47

.033
(.040)

Parents are married

.58

-.010
(.031)

.63

.032
(.027)

.63

.056
(.038)

High school GPA

3.44

.005
(.026)

3.51

-.017
(.022)

3.57

.022
(.031)

Composite ACT score

21.9

-.37
(.27)

22.5

-.19
(.24)

23.3

-.45
(.38)

Took ACT

.06

-.002
(.015)

.06

-.005
(.012)

.03

-.012
(.013)

F-statistic
p-value
Sample size

.44
.94
1,003

.84
.60

1,003

1,428

1,428

4,623 *
(2,394)

1.27
.23
835

835

Notes: Variable definitions and specifications are detailed in Table 1. The 2013 aid-only sample contains the NU strata
only and excludes students who were offered full awards.
*** p < 0.01, ** p < 0.05, * p < 0.10

39

All

Table A3
Descriptive Statistics by Target College
(2012 & 2013 Cohorts)

Community Colleges
Treatment All
Control
(10)

White

Female

.06

.66

.61

.001
(.013)

-.008
(.010)

-.009
(.019)

.017
(.020)

3,247

.16

.06

.07

.71

.59

-312
(2,553)

102
(243)

.037
(.028)

.027
(.019)

-.012
(.018)

-.053
(.034)

-.009
(.035)

.48

48,599

3,025

.21

.17

.08

.55

.62

.008
(.033)

-.014
(.029)

980
(1,824)

-120
(223)

.007
(.028)

-.017
(.025)

-.011
(.018)

.021
(.033)

.027
(.033)

.60

.54

.19

52,477

3,389

.15

.06

.03

.76

.64

.025
(.052)

.104 *
(.057)

-.098
(.062)

-.046
(.045)

-74
(3,136)

2
(414)

-.001
(.041)

-.049 ***
(.019)

-.006
(.026)

.056
(.050)

.000
(.060)

19.5

3.33

.62

.35

.21

46,117

2,859

.17

.10

.03

.71

.59

-.01
(.41)

.028
(.041)

.021
(.050)

.037
(.049)

.014
(.033)

2,957
(2,880)

-365
(304)

.001
(.038)

.022
(.033)

.007
(.017)

-.030
(.045)

.064
(.050)

(9)

Black
.10
.016
(.016)

52,613

.031
(.035)

.36

.024
(.034)

3.53

.18

State Colleges
Treatment All
Control
(8)

Hispanic
.17
-69
(137)

.42

.009
(.036)

.59

-.010
(.028)

21.8

.20
(.48)

(7)

Other nonwhite race
or unreported race
3,133
725
(1,270)

.52

-.031
(.035)

3.43

.04

UNO & UNK
Treatment All
Control
(6)

EFC ($)
50,291
.003
(.018)

.63

-.031
(.028)

22.1

-.53
(.30)

(5)

Family income
.37
.001
(.021)

3.60

.04

-.025
(.039)

UNL
Treatment Control
(4)

Urban resident
.44

.014
(.020)

23.9

-.25
(.30)

-.021
(.017)

1.23
.039

(3)

Mother attended college
.61

-.007
(.017)

.03

.017
(.014)

1.15
.017

396

All Strata
Treatment All
Control
(2)

Parents are married
3.49

-.27
(.18)

-.009
(.012)

.89
.014

304

(1)

High school GPA

22.4

-.003
(.010)

.93
.012

855

*

Composite ACT score

.06

.68
.010

876

Took ACT

2,431

F-statistic
p-value
Sample Size

Notes: This table reports descriptive statistics by NU target campus or college type. Variable definitions and specifications are detailed in Table 1.
*** p < 0.01, ** p < 0.05, * p < 0.10

40

Table A4
First Stage Effect on Year One and Year Two Financial Aid Packages
for Nebraska Public College Students
(2012 & 2013 Cohorts)
Year One Aid Packages
Covariate
Campus
Control
Adjusted
Adjusted
Mean
(2)
(3)
(1)
Cost of attendance

17,469

1,129
(196)

***

104
(147)

Total aid

11,608

3,319
(234)

***

2,168
(202)

Total grants

7,251

6,225
(184)

***

2,635

Year Two Aid Packages
Covariates
Campus
Control
Adjusted
Adjusted
Mean
(5)
(6)
(4)
17,104

1,650
(388)

***

-30
(277)

***

8,957

4,155
(421)

***

2,619
(379)

***

5,467
(167)

***

5,233

6,439
(320)

***

5,341
(294)

***

25
(67)

-135
(63)

**

2,255

58
(131)

-173
(130)

2,541

42
(64)

-109
(61)

*

2,185

74
(127)

-141
(125)

94

-18
(10)

-26
(10)

***

70

-16
(16)

-32
(17)

*

527

-25
(42)

-91
(42)

**

335

-118
(52)

**

-171
(55)

***

2,904

-380
(111)

***

-635
(111)

***

2,305

-456
(184)

**

-803
(191)

***

0

6,924
(77)

***

6,744
(77)

***

0

7,034
(144)

***

6,625
(144)

***

Other private grants

1,185

-318
(80)

***

-417
(84)

***

338

-80
(75)

-138
(82)

*

Total government loans

3,529

-2,220
(148)

***

-2,524
(153)

***

3,239

-1,674
(257)

***

-2,025
(274)

***

Subsidized Stafford

1,586

-1,241
(60)

***

-1,359
(61)

***

1,549

-1,017
(114)

***

-1,184
(118)

***

907

-166
(66)

**

-252
(66)

***

866

-55
(111)

Perkins

308

-246
(21)

***

-276
(23)

***

158

-117
(29)

***

-147
(32)

***

PLUS

728

-566
(80)

***

-637
(86)

***

666

-485
(135)

***

-575
(153)

***

829

-486
(45)

***

-580
(46)

***

485

-272
(63)

***

-372
(67)

***

Federal grants
Pell
Other federal grants
State grants
Institutional grants
STBF grant

Unsubsidized Stafford

Federal Work Study

Campus controls
Sample size

1,093

*

No

Yes

1,928

1,928

365

-118
(115)

No

Yes

777

777

Notes: This table reports effects of the STBF scholarship offer on students' financial aid packages, showing results for detailed aid
categories. Samples, specifications, and variable definitions are detailed in Tables 2 and 3.
*** p < 0.01, ** p < 0.05, * p < 0.10

41

Table A5
Comparing OLS and Logit Marginal Effects on Year Two Enrollment
(2012 Cohort)

Nonwhite
(4)

Female

(5)

Male

Gender

White
(3)

Race

(2)

.125 ***
(.029)
{552}

.105 ***
(.019)
{1,496}

.039 ***
(.014)
{1,496}

.151 ***
(.026)
{935}

.090 ***
(.021)
{935}

.067 ***
(.019)
{1,246}

.027 *
(.014)
{1,246}

.188 ***
(.024)
{1,185}

.096 ***
(.019)
{1,185}

ACT Score
Above
Below
Median
Median
(6)
(7)

.033 **
(.014)
{1,599}

.191 ***
(.037)
{552}

Full
Sample
(1)

Any post-secondary

.059 ***
(.012)
{2,431}
.094 ***
(.018)
{1,599}

A. OLS

Any four-year college

.125 ***
(.015)
{2,431}

Any post-secondary

.063 ***
(.013)
{2,413}

.099 ***
(.019)
{1,581}

.034 **
(.015)
{1,581}

.213 ***
(.038)
{502}

.152 ***
(.037)
{525}

.109 ***
(.020)
{1,485}

.040 ***
(.015)
{1,478}

.166 ***
(.029)
{878}

.099 ***
(.025)
{921}

.071 ***
(.021)
{1,211}

.030 *
(.017)
{1,153}

.194 ***
(.024)
{1,174}

.103 ***
(.022)
{1,178}

B. Logit Marginal Effects

Any four-year college

.130 ***
(.016)
{2,407}

Notes: This table reports OLS and average logit marginal effects for year two enrollment outcomes. The OLS estimates for race and gender are
plotted in Figure 1. Figure 3 plots OLS effects by ACT score. All regressions control for target college, application year, and baseline covariates, as
defined in Table 2. Standard errors are in parentheses and sample sizes are in braces. The logit estimates exclude strata in which outcomes do not
vary in the given subsample. The sample is restricted to the 2012 cohort, where we have two complete years of outcome data.
*** p < 0.01, ** p < 0.05, * p < 0.10

42

Figure 1: E↵ect on Year Two Enrollment by Subgroup
A. Any Post−Secondary
1

fraction enrolled

.9

.8

.7

.6

.5
White

Nonwhite

Female

Male

B. Any Four−Year College
1

fraction enrolled

.9

.8

.7

.6

.5
White

Nonwhite

Female

Control

Male

Treated

Notes: Results are for the 2012 full award sample. Treated bars plot the sum of the control mean and estimated
treatment e↵ect. Whiskers show 95 percent confidence intervals.

43

Figure 2: E↵ect on Year Two Enrollment by GPA

.9
.8
.7
.6
.2

.3

.4

.5

fraction enrolled

1

A. Any Post−Secondary

2.50

2.65

2.80

2.95

3.10

3.25

3.40

3.55

3.70

3.85

4.00

3.70

3.85

4.00

high school GPA

.9
.8
.7
.6
.5
.2

.3

.4

fraction enrolled

1

B. Any Four−Year College

2.50

2.65

2.80

2.95

3.10

3.25

3.40

3.55

high school GPA

Control

Treated

Notes: Results are for the 2012 full award sample. Treated points plot the sum of the control mean and estimated
treatment e↵ect. Whiskers show 95 percent confidence intervals.

44

Figure 3: E↵ect on Year Two Enrollment by ACT

.9
.8
.7
.6
.5
.2

.3

.4

fraction enrolled

1

A. Any Post−Secondary

17

18

19

20

21

22

23

24

25

26

27

28

25

26

27

28

ACT score

.9
.8
.7
.6
.5
.2

.3

.4

fraction enrolled

1

B. Any Four−Year College

17

18

19

20

21

22

23

24

ACT score

Control

Treated

Notes: Results are for the 2012 full award sample. Treated points plot the sum of the control mean and estimated
treatment e↵ect. Whiskers show 95 percent confidence intervals. The x axis ranges from 17 to 28, the 10th and 90th
percentiles of the score distribution among ACT test takers in the sample.

45

Figure 4: E↵ect on Year Two Enrollment by EFC

.9
.8
.7
.6
.2

.3

.4

.5

fraction enrolled

1

A. Any Post−Secondary

0

1,000

2,000

3,000

4,000

5,000

6,000

7,000

8,000

9,000

10,000

8,000

9,000

10,000

EFC

.9
.8
.7
.6
.2

.3

.4

.5

fraction enrolled

1

B. Any Four−Year College

0

1,000

2,000

3,000

4,000

5,000

6,000

7,000

EFC

Control

Treated

Notes: Results are for the 2012 full award sample. Treated points plot the sum of the control mean and estimated
treatment e↵ect. Whiskers show 95 percent confidence intervals.

46

Figure 5: Year Two Enrollment E↵ects Conditional on Estimated College Readiness

.9
.8
.7
.6
.5
.2

.3

.4

fraction enrolled

1

A. By Predicted Enrollment Propensity

0.2

0.3

0.4

0.5

0.6
0.7
0.8
propensity to enroll
in a four−year college in year two

0.9

1.0

.9
.8
.7
.6
.5
.2

.3

.4

fraction enrolled

1

B. By Scholarship Examiner Score

1

2

3

4

5

6

7

scholarship examiner score

Control

Treated

Notes: Results are for the 2012 full award sample. Treated points plot the sum of the control mean and estimated
treatment e↵ect. Whiskers show 95 percent confidence intervals. In panel A, the x axis is propensity to enroll in a
four-year college in year two, estimated using the leave-one-out procedure proposed by Abadie, Chingos and West
(2013).

47

A

Data Appendix

This appendix describes our data sources and details the variables used in our analysis.

A.1

Application Data

The STBF scholarship application provides detailed data on applicants’ baseline characteristics.
The academic measures come primarily from high school transcripts, which report GPA and ACT
scores. We standardize GPAs to a 4.0 scale using grade conversion formulae provided by the
University of Nebraska-Lincoln. Since not all high schools report ACT scores on their transcripts,
we supplement transcript data with self-reported scores from the application survey for 54 percent
of the experimental sample.16
Most of our financial and demographic data come from applicants’ Student Aid Reports (SARs).
These reports are available for all STBF applicants who filed the Free Application for Federal Student Aid (FAFSA). SARs contain responses to more than 100 FAFSA questions regarding students’
financial resources and family structure, including family income, parents’ marital status, and parents’ education. Roughly three percent of scholarship applicants are undocumented immigrants,
who are ineligible for federal financial aid and therefore cannot file the FAFSA. STBF permits these
students to submit an alternate form called the College Funding Estimator (CFE). The CFE is
published by the EducationQuest Foundation, a non-profit organization in Nebraska, and o↵ers a
similar, though less detailed, set of information.
Neither SARs nor CFEs report students’ race, and the scholarship application did not collect
this variable until the 2014 cohort. For the 2012 and 2013 cohorts, we acquired these data from the
Nebraska Department of Motor Vehicles. We matched more than 85 percent of the randomization
sample to their state driver’s license records.

A.2

Enrollment Data

More than 90 percent of experimental subjects enrolled in Nebraska public colleges, which provide
administrative records for this research. We match applicants to these data using name, date of
birth, and the last four digits of Social Security Numbers. To measure enrollment at out-of-state
16

In Nebraska, the vast majority of students take the ACT rather than the SAT. For the 2012 cohort, 70 percent
of Nebraska high school students took the ACT, compared to the national average of 52 percent.

48

and private institutions, we match applicants to National Student Clearinghouse (NSC) data using
name and date of birth. Though the NSC captures more than 91 percent of enrollment nationwide
(and more than 99 percent at four-year public institutions), its name-based match has limitations,
as Dynarski, Hemelt and Hyman (2015) detail. Roughly four percent of experimental applicants
have enrollment at Nebraska public colleges that does not appear in our NSC-matched sample.
These students are disproportionately nonwhite and, in particular, Hispanic.
Most of the enrollment outcomes reported in this paper are binary measures. Table 4, for
example, reports e↵ects on the probability of enrollment in year one. We define follow-up windows
to match the federal financial aid year, which runs from July 1 to June 30. Year one begins on
the July 1 following scholarship application and ends on the following June 30 (U.S. Department of
Education 2012).Within each window, we force binary enrollment outcomes to be mutually exclusive.
Students who enroll at both two- and four-year institutions are coded as “any four-year”. Likewise,
those who enroll at in-state public colleges do not contribute to the out-of-state or private categories,
and selectivity outcomes are defined by the most selective institution attended.
We also report cumulative enrollment outcomes in Tables 5 and 7. The ideal measure would
be total semester credits enrolled, but not all schools use semester calendars and we don’t observe
credits for the seven percent of applicants who attend out-of-state or private colleges. For these
schools, we impute credits per term from the NSC’s coarse enrollment status variable, which indicates whether students were enrolled full-time, half-time, or less than half-time. Imputed credits
is the mean of credits taken by Nebraska public college students with the same enrollment status,
college attended, and academic term. Less than 2% of applicants attend out-of-state or private
schools that do not report the full-time enrollment indicator to the NSC. We code these students
as enrolled full-time if IPEDS reports that over 85% of the students attending in the same college
are full-time. Once we have imputed credits per term for each enrollment period, we convert all
credits to semester credit equivalents using the conversion factors outlined in the Federal Student
Aid Handbook. Credits from colleges with quarter-based calendars, for instance, are worth twothirds of a semester credit because there are three quarters and two semesters in the academic year,
excluding summer. Finally, we convert semester credit equivalents to full-time semester equivalents
by dividing by 12, the minimum credit hour requirement for full-time enrollment status. In these
units, a student who enrolls for two semesters each year and 15 credits per semester will accumulate
49

five full-time semester equivalents by the end of year two.

A.3

Financial Aid Data

Nebraska’s public colleges also provide detailed information on their students’ financial aid packages,
which we analyze in Tables 2, 3, and A4. These data report costs of attendance, grants, loans, and
Federal Work Study aid. While all schools report federal loans, most do not report private loans,
which may be obtained directly from lenders without involving financial aid officers. We therefore
exclude private loans from our analysis. For most students in our sample, however, federal loans
o↵er the lowest available interest rate and therefore account for the vast majority of borrowing.

50

