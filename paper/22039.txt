NBER WORKING PAPER SERIES

TRANSPARENCY AND NEGOTIATED PRICES:
THE VALUE OF INFORMATION IN HOSPITAL-SUPPLIER BARGAINING
Matthew Grennan
Ashley Swanson
Working Paper 22039
http://www.nber.org/papers/w22039

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
February 2016, Revised February 2018

The data used in this paper were generously provided, in part, by the ECRI Institute
(www.ecri.org). We are grateful to our editors, three helpful reviewers, Mike Dickstein, Robin
Lee, Amanda Starc, Robert Town, Ali Yurukoglu, and numerous seminar participants for helpful
comments. We gratefully acknowledge financial support from the Wharton Dean's Research Fund
and Public Policy Initiative, the Wolpow Family, and NSF Grant 30067535. Biruk Bekele, Stuart
Craig, Robin Kim, Donato Onorato, and Mihir Trivedi provided excellent research assistance.
Any errors are our own. The views expressed herein are those of the authors and do not
necessarily reflect the views of the National Bureau of Economic Research.
NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.
© 2016 by Matthew Grennan and Ashley Swanson. All rights reserved. Short sections of text, not
to exceed two paragraphs, may be quoted without explicit permission provided that full credit,
including © notice, is given to the source.

Transparency and Negotiated Prices: The Value of Information in Hospital-Supplier Bargaining
Matthew Grennan and Ashley Swanson
NBER Working Paper No. 22039
February 2016, Revised February 2018
JEL No. D40,D82,D83,I11,L14
ABSTRACT
Using a detailed dataset of hospitals' purchase orders, we find that information on purchasing by
peer hospitals leads to reductions in the prices hospitals negotiate for supplies. Identification is
based on staggered access to information across hospitals over time. Within coronary stents,
reductions are concentrated among hospitals previously paying relatively high prices and for
brands purchased in large volumes, and are consistent with resolving asymmetric information
problems. Estimates across a large number of other important product categories indicate that the
effects of information are largest in both absolute and relative terms for physician preference
items (PPIs). Among PPIs, high-price, high-quantity hospital-brand combinations average 3.9
percent savings, versus 1.6 percent for commodities.

Matthew Grennan
The Wharton School
University of Pennsylvania
3641 Locust Walk
Philadelphia, PA 19104
and NBER
grennan@wharton.upenn.edu
Ashley Swanson
The Wharton School
University of Pennsylvania
3641 Locust Walk
Philadelphia, PA 19104
and NBER
aswans@wharton.upenn.edu

Transparency and Negotiated Prices:
The Value of Information in Hospital-Supplier Bargaining
Matthew Grennan∗
University of Pennsylvania, The Wharton School & NBER

Ashley Swanson
University of Pennsylvania, The Wharton School & NBER

February 2, 2018

Abstract
Using a detailed dataset of hospitals’ purchase orders, we find that information on
purchasing by peer hospitals leads to reductions in the prices hospitals negotiate for
supplies. Identification is based on staggered access to information across hospitals
over time. Within coronary stents, reductions are concentrated among hospitals previously paying relatively high prices and for brands purchased in large volumes, and
are consistent with resolving asymmetric information problems. Estimates across a
large number of other important product categories indicate that the effects of information are largest in both absolute and relative terms for physician preference items
(PPIs). Among PPIs, high-price, high-quantity hospital-brand combinations average
3.9 percent savings, versus 1.6 percent for commodities.

1

Introduction

Business-to-business markets make up a large part of the economy, but they often lack
transparency. Suppliers negotiate different contracts with different buyers, potentially with
widely varying prices, and a buyer typically has limited information regarding other buyers’
contracts. Many business-to-business markets have seen the entry of information intermedi∗

The data used in this paper were generously provided, in part, by the ECRI Institute (www.ecri.org).
We are grateful to our editors, three helpful reviewers, Mike Dickstein, Robin Lee, Amanda Starc, Robert
Town, Ali Yurukoglu, and numerous seminar participants for helpful comments. We gratefully acknowledge
financial support from the Wharton Dean’s Research Fund and Public Policy Initiative, the Wolpow Family,
and NSF Grant 30067535. Biruk Bekele, Stuart Craig, Robin Kim, Donato Onorato, and Mihir Trivedi
provided excellent research assistance. Any errors are our own.

1

aries who facilitate buyers’ ability to benchmark the prices they negotiate.1 In this paper,
we empirically examine the effect of transparency in the form of benchmarking information
on negotiated prices between hospitals and their suppliers.
There is substantial variation in the prices of hospital supplies, including medical devices, across hospitals. For the top hospital supplies in our data, the average coefficient of
variation across hospitals for the same exact brand-month is 0.18. This input price variation
is approximately half the coefficient of variation for common procedure prices charged by
hospitals in different markets (Cooper et al. 2015). It is also near the top of the range of
coefficients of variation found in consumer goods markets (Scholten and Smith 2002). In
the short run, these costs come directly from hospitals’ profit margins.2 In the longer run,
increasing supply costs tend to increase health care costs (see, e.g., Maeda et al. 2012).
Prior research in consumer goods markets has largely confirmed the intuition that information can facilitate search and better decisions for buyers with imperfect information
regarding product quality or costs (Sorensen 2000; Jin and Leslie 2003; Hendricks et al. 2012;
Bronnenberg et al. 2015) or supplier willingness to accept lower prices (Zettelmeyer et al.
2006; Scott Morton et al. 2011). However, the mechanisms via which information impacts
consumer goods may not extend to business-to-business markets where there is often no
search across sellers (when products are purchased directly from manufacturers), and negotiators are professionals employed by firms and thus with different expertise and incentives
than the typical consumer. Recent empirical research in business-to-business bargaining
(Draganksa et al. 2009; Crawford and Yurukoglu 2012; Grennan 2013, 2014; Gowrisankaran
et al. 2015; Lewis and Pflum 2015; Ho and Lee 2017) explains variation in prices across buyers using full information models, but in doing so also documents substantial heterogeneity
in bargaining ability parameters, which could include variation in information available to
negotiators.3 Our work contributes to these literatures by extending our understanding of
transparency to the business-to-business setting and by offering information as one explanation for the large unexplained heterogeneity documented in negotiated prices.
Our empirical analysis utilizes new data containing all purchase orders issued by more
than fifteen percent of US hospitals that purchased subscription to a web-based benchmark1

This trend is due in part to technology improvements that have made data easier to collect, distribute,
and analyze. In addition to the hospital purchasing context, we are aware of business-to-business “transparency” benchmarking services emerging in areas as diverse as home appliances and television advertising.
2
According to the American Hospital Association 2015 Trendbook, the average hospital operating margin
in 1993-2013 was 3.8 percent (http://www.aha.org/research/reports/tw/chartbook/ch4.shtml).
3
There are two exceptions of which we are aware. Larsen (2014) estimates a bargaining game of twosided incomplete information about valuations in the used car wholesale market; we argue that uncertainty
over bargaining parameters better fits our context. Backus et al. (2015) study cheap talk in bargaining with
asymmetric information for collectibles on eBay, but in our case price seems to be the dominant factor of
concern for negotiators, decreasing the scope for the trade-offs required for signaling.

2

ing database. Section 2 details the data and hospital purchasing context. The majority of
our analysis focuses on price negotiations for coronary stents in 508 facilities with cardiac
catheterization services.4 We also estimate our main specification using data on 52 other
product categories that are important in terms of total spend or utilization.
Motivated by discussions with industry experts, Section 3 outlines two candidate mechanisms through which benchmarking information might have an impact in the hospital purchasing context: (1) an asymmetric information model in which hospitals face uncertainty
about suppliers’ costs or bargaining parameters, so that transparency reduces uncertainty
and the equilibrium dispersion in negotiated prices; and (2) an agency model in which price
transparency allows hospital managers to better observe purchasing agents’ effort and, in
turn, provide improved incentives to purchasing agents to reduce prices.
Section 4 clarifies our research design for testing empirical predictions from these models.
We use two sources of variation to provide plausibly causal identification. First, the database
is generated by monthly submissions of member hospitals’ transactions, and new members
are asked when they join to submit twelve months of retrospective, pre-benchmarking data.
We use variation in timing of hospitals’ joining the database to construct difference-indifferences estimators. Exogeneity of join timing with respect to price trends is supported
by the institutional details of the setting, and by event studies that show no statistically
significant divergence of pre-trends for coronary stents.
Second, we develop a set of tests focusing on new brands entering the market during our
sample period. We compare prices between hospitals pre- and post-join immediately upon
a brand’s introduction, before either hospital type has access to information, in order to
remove any persistent sources of bias around join timing. New brand introductions also offer
a strategy to investigate theoretical mechanisms. The asymmetric information mechanism
wherein hospitals use benchmarking information to learn about suppliers relies upon concurrent availability of data on others’ prices, but the agency mechanism wherein hospitals use
benchmarking information to create better contracts for their purchasing negotiators relies
on the fact that such information will be available in the future. Thus, the delayed release
of benchmarking data after new brand entry allows us to separate the two.
4

Stents are especially useful as a place to focus for several reasons: they are representative of the
“physician preference items” (PPIs) central to many policy discussions; PPIs are products where doctor
usage decisions are relatively insensitive to price, making negotiating lower prices the main mechanism via
which a hospital can obtain savings; stents are important in their own right, comprising two percent of
sample hospital spend; and stents typically have simple linear contracts, so the price we observe is the
contracted price. As discussed in Appendices C and F, we observe no evidence of standardization (e.g.,
exclusive dealing or contracts based on market share) affecting prices or usage in our data, and we find no
effect of benchmarking information on quantities. This motivates our focus on the effects of information on
linear prices (rather than quantities) in the remainder of the paper.

3

Section 5 presents our main results. Focusing on stents, we find that access to the
database information has heterogeneous effects across hospitals and brands. The average
treatment effect across all hospital-brand-months is small and noisy, but high-price hospitalbrand combinations exhibit unit price declines of -$27 upon accessing database information.
The price declines are larger for hospital-brands with larger purchase volumes – price effects
increase to -$71 for high-quantity hospital-brands that are also high-price prior to joining the
database, compared to -$17 for hospital-brands with lower volumes. The specifications leveraging brand entry suggest that these effects are largely explained by a mechanism wherein
benchmarking solves an asymmetric information problem, helping hospitals learn about suppliers. Evidence for the agency mechanism is noisier and less robust across specifications.
Each of the above-described results is an estimate of the treatment effect of benchmarking
on prices, which will be an underestimate of the treatment effect of benchmarking on prices
negotiated in a given contract. We find price effects are generated by increasing the likelihood
of renegotiation and by generating larger price decreases conditional on renegotiation. This
suggests that the benefits of transparency are dampened somewhat by stickiness of contracts
and other costs of putting information to use in business-to-business settings.
In Section 6, we extend our difference-in-differences analysis to consider the effects of
access to benchmarking information for a wide variety of important product categories, from
commodities (e.g., surgical gloves) to other physician preference items (PPIs) beyond stents
(e.g., prosthetic hips). We find that the effects of information are broadly similar across
product categories. Average treatment effects are often negative, but tend to be small and
statistically insignificant; however, among hospital-brands in the top quartile of quantity
and quintile of price at the time of join, treatment effects tend to be larger in magnitude
and more often statistically significant. Effects are largest among PPIs, where our treatment
effect estimates indicate four percent savings due to benchmarking information for high-price
and high-quantity hospital-brands.
These estimates are of direct interest for considering the impact of information intermediaries on the prices buyers negotiate in previously opaque business-to-business markets.
They also provide a first step toward thinking about the transparency policies that have been
proposed for medical technology markets. In Section 7, we conclude and discuss potential
directions for future research on information in business-to-business bargaining.

2

Data

The primary data used in this study come from a unique database of all supply purchases
made by over fifteen percent of US hospitals during the period 2009-2014. The data are from
4

TM

the PriceGuide benchmarking service (hereafter, “PriceGuide data”) offered by the ECRI
Institute, a non-profit healthcare research organization. We observe unique, anonymous
hospital identifiers and several hospital characteristics: Census region, facility type, and
number of beds. For each transaction, we observe price, quantity, transaction month, and
supplier for a wide range of product categories, including commodities (e.g., cotton swabs
and gloves) as well as physician preference items (e.g., stents and orthopedic implants).5
Our analyses consider price negotiations between hospitals and suppliers for a large number of important product categories. The contracting environment is described in detail in
Appendix C. Included products were the top 50 product categories by either total spending or transactions, for a total of 52.6 As detailed in Appendix A, the data are at the
stock-keeping-unit (SKU) level, requiring us to use manufacturer catalogs and classification
algorithms to group SKUs that belong to the same manufacturer-brand.7
Table A5 summarizes the data for the 52 product categories of interest. Spending per
month varies dramatically across product class: hospitals typically spend only $11 thousand
per year on bandages, vs. over $1.1 million on coronary drug-eluting stents. Some product
categories are used fairly universally – 618 sample hospitals purchased hypodermic injection
needles – and some are used only in highly specialized facilities – only 249 sample hospitals
purchased biological cardiac valve prostheses.
Our sample facilities are discussed in detail in Appendix A.3. Overall, our regression
samples include 775 facilities spending an average of $1.8 million per month across 774
product categories. We return to the full set of important products in Section 6, but our
main analyses focus on 508 sample facilities that purchase drug-eluting coronary stents.8
Stent purchasing patterns are presented in Table A1. Briefly, the average sample facility
spends $3.4 million per month on 1,143 categories of supplies, $73 thousand of which is
dedicated to coronary drug-eluting stents. During our sample period 2009-2014, there are
5
The reported data are of high quality because they are typically transmitted as a direct extract from a
hospital’s materials management database. Hospitals have strong incentives to report accurately because the
analytics the benchmarking service’s web portal provides are based on comparing the hospital’s submitted
data to that of others in the database.
6
There are 80 “top” categories total, but we omit product categories that are too broad or with missing
or inconsistent data. See Appendix A for details.
7
Note that we use the term “brand” to refer to the “product” level at which prices are negotiated –
e.g., Medtronic Resolute Integrity drug-eluting coronary stent. The use of “brand” is not meant to connote
any particular marketing strategy. We use “product category” to refer to the “Universal Medical Device
Nomenclature System (UMDNS) code” grouping included in the transaction files. The UMDNS system
classifies devices by intended purpose and mechanism of action (e.g. drug-eluting coronary stents have
UMDNS code 20383). Finally, we use “product class” to refer to broad groupings of product categories:
commodities, physician preference items, and other medical/surgical products.
8
The database includes a few other healthcare facilities such as clinics and surgical centers, but hospitals
constitute 97 percent of the stent sample and 73 percent of the extended sample by count; more by spend.
For the remainder of the paper, we use the terms hospital and facility interchangeably.

5

thirteen branded products sold by four manufacturers – Abbott, Cordis, Medtronic, and
Boston Scientific, with Cordis exiting the market in 2011. The average hospital purchases
48 drug-eluting stents per month.
The hospitals in the purchase order data voluntarily joined a subscription service that
allows them to benchmark their own prices and quantities against those of other hospitals
in the database. We consider the effect of potential non-representativeness of our sample in
our discussion of identification in Section 4. In Appendix A.1, we also compare our sample
hospitals along observable dimensions to two outside samples of US hospitals – all American
Hospital Association (AHA) member hospitals with cardiac catheterization, and Millennium
TM
Research Group’s (MRG) Markettrack survey of a geographically representative sample
of catheter labs. The west region is overrepresented in our benchmarking database sample,
while the south is underrepresented. The average PriceGuide hospital is larger than the average US hospital with cardiac catheterization. Similarly, member facilities in our PriceGuide
estimation sample purchased in higher volumes and obtained slightly lower prices than MRG
hospitals in overlapping periods.
2.1

Price Variation Across Hospitals and Brands

The left panel of Figure 1 displays the distributions of drug-eluting stent prices across hospitals and hospital-brands, respectively. It illustrates the wide variation in prices across
sample PriceGuide hospitals in their pre-benchmarking transactions, with a standard deviation of $164 and mean of $1,615, for a coefficient of variation of 0.10. Hospital-product
effects explain much of this variation with R2 = 0.89 for the residual price variation (after
brand-month detrending). Hospital effects in turn explain almost half of the hospital-brand
variation, with R2 = 0.44. Thus, our price variation is driven in part by some hospitals
consistently paying more than others for all drug-eluting stents, and in equal part by some
hospitals paying more for particular stents.9 As shown in Appendix A.1, these patterns
are shared by the representative MRG sample, though the MRG sample has slightly higher
prices on average. This implies that hospitals joining the database have slightly less to gain
than the representative sample in terms of raw price differentials.
Observable hospital characteristics do not explain much of the variation in prices. Hospital bed size has no explanatory power. Total volume of stents purchased has more explanatory power: 10th decile hospitals by purchase volume (188 stents per month) achieve prices
that are 7 percent lower than those obtained by 1st decile hospitals (7 stents per month).
9

Though in a different context with likely different mechanisms, these amounts of price variation, distributional shapes, and variance decomposition patterns are remarkably similar to those found in Kaplan and
Menzio (2015) in the context of price variation for consumer goods across stores.

6

Figure 1: Price Distribution Across Hospitals, Brands, and Information State
(b) Phjt , Pre- vs. Post-Information

1000

.002

Density

.001
0

0

.002

Density

.004

.006

.003

(a) P̄h and P̄hj , Pre-Information

1500

2000

2500

1000

Price (within brand-month variation)
Brand-hospital variation

1500

2000

2500

3000

Price

Hospital variation

Pre-join

Post-join

Authors’ calculations from PriceGuide and MRG data. Left panel shows estimated hospital-brand and hospital fixed
effects, obtained from regressions of price per stent, controlling for brand-month fixed effects. Right panel shows raw price
distributions pre- and post- access to benchmarking information.

However, we observe substantial dispersion in prices even conditional on facility size and
purchase volume; see Appendix A.1 for details.
In a different data set, Grennan (2013, 2014) found evidence that heterogeneity in stent
prices across hospitals could be explained in part by heterogeneity in physician brand loyalty,
but this left a large residual heterogeneity in hospital-product bargaining ability.10 Our
analysis explores the possibility that part of this heterogeneity in bargaining abilities may
be due to heterogeneity in information among hospitals, and that transparency in the form
of benchmarking information on other hospitals’ prices might affect this.
2.2

The Benchmarking Information Treatment

The information treatment considered in this study is one in which hospitals log in to a
database and receive information about their relative performance in purchasing. The basic
interface members access upon logging in presents graphical analytics for “potential savings”
opportunities at the supplier level, defined as the total dollars that might have been saved in
the previous year based on the hospital’s volume of purchase and the mean/min prices paid
by other hospitals at the manufacturer-SKU level. By clicking through, the hospital could
observe these potential savings broken down by SKU, filter by geography and bed size, or
even access the full (de-identified) purchase order microdata. We obtained clickstream data
10

In these and other studies of empirical bargaining, bargaining ability is parameterized by Nash weights
in a structural model of full-information bargaining. These terms represent heterogeneity in prices after
controlling for variation in competitive environment, captured by factors such as the outside option.

7

on the timing of all members’ website logins; this allows us to reconstruct each member’s
benchmarking information set at each point in time.
In order to preview our approach and results in a simple graphical manner, the right panel
of Figure 1 displays the histograms of prices paid for drug-eluting stents across the entire
sample, splitting the sample into pre- and post-join observations. The raw data clearly
suggests the primary impact of access to the benchmarking information: hospitals with
information are much less likely to pay the highest prices. In the Sections that follow,
we consider what theoretical mechanisms might drive this result in business-to-business
negotiations as well as the research designs and regression specifications that will allow
us to establish causal treatment effects and the mechanisms behind them.11

3

Theory: Bargaining and Benchmarking Information

While knowledge of others’ prices could potentially affect negotiations in many direct and
indirect ways, the policy and economics literature on this setting (see, e.g., Pauly and Burns
2008), as well as our conversations with market participants, suggest that there are two
primary mechanisms for how benchmarking information could be useful to hospital buyers.
First, benchmarking could reduce asymmetric information about the price a supplier is
willing to concede. Second, benchmarking could help solve the agency problem between the
hospital and its procurement negotiators by providing a tool for the hospital to monitor
negotiator performance relative to a market aggregate. In this Section, we outline models
that capture each of these effects and use them to motivate our empirical predictions.
Our models build on the Rubinstein (1982) model of alternating offers bargaining.12
The model has a single buyer negotiating with a single supplier over a per-unit surplus
V = wtp − c equal to the buyer’s willingness-to-pay for a unit of the supplier’s product,
minus the supplier’s marginal cost of manufacturing and distributing a unit of the product.13
11
We focus on the potential effect of information on negotiated prices. In Appendix F, we also estimate
the effects of information on quantities and find no effect, consistent with stents being “physician preference
items” where physician demand is based on strong preferences and is relatively insensitive to price.
12
This model underpins a large theoretical literature on bargaining (Rubinstein 1985; Binmore et al.
1986; Horn and Wolinsky 1988; Collard-Wexler et al. 2017) as well as a more recent empirical literature
on bargaining (Draganksa et al. 2009; Crawford and Yurukoglu 2012; Grennan 2013, 2014; Gowrisankaran
et al. 2015; Lewis and Pflum 2015; Ho and Lee 2017). The predictions of the model extend well to empirical
settings because the “discount factors” that parameterize bargaining strength in the Rubinstein model can
be thought of more generally as proxies for a host of factors that might affect a real-world negotiation such
as impatience, opportunity costs of time, laziness, or fear of negotiation breakdown.
13
Vhjt (subscripts suppressed in text) should be thought of as the incremental value created by stent j
for the set of patients for which the doctors at hospital h choose to use j over alternative stents or nonstent treatments, given physician preferences over all stents available at time t. For the sake of parsimony,
we abstract here from externalities across negotiations. Appendix B provides a prediction regarding such
externalities, which we test in Appendix D.3.

8

Beginning with the buyer, each player in turn makes a proposal for the division of the surplus.
After one player has made an offer, the other must decide to accept or reject it and make
a counteroffer in the next round. Players discount continued rounds of bargaining with
discount factors δ B ∈ (0, 1) for the buyer and δ S ∈ (0, 1) for the supplier. In the institutional
setting of bargaining over medical devices like stents, the typical negotiation occurs between
a purchasing agent of the hospital and a sales representative of the device manufacturer.
Each discount factor should be thought of as coming from a combination of negotiator skill
and the incentives negotiators face as agents of their respective employers.
The unique subgame perfect equilibrium of this game is for it to end immediately with the
buyer making an offer and seller accepting. The resulting complete information (CI) price is
1−δ B
pCI := c + δ S 1−δ
B δ S V . Thus, the observed variation in prices in our data could be generated
in a full information model by wide heterogeneity in discount factors and valuations across
buyer-supplier pairs, in which case there may be no effect of benchmarking information.
3.1

Asymmetric Information about Bargaining Parameters

In order to introduce asymmetric information into the baseline bargaining framework, we
follow Rubinstein (1985), in which hospital buyers have uncertainty about the bargaining
parameter of a given supplier. The model departs from the complete information model
outlined above in that the supplier is either of weak type with discount factor δwS or strong
type with discount factor δsS (1 > δsS > δwS > 0). The supplier knows his own type, but the
buyer has only a subjective prior ω of the probability that the supplier is the weak type.14
Rubinstein (1985) shows that, in this asymmetric information (AI) game, if the buyer
is sufficiently pessimistic about the seller being the weak type, then there exists a pooling
equilibrium wherein the buyer simply offers what she would offer the strong type in a complete information game: pCI
s , and both seller types accept this offer. If the buyer is more
optimistic, then there exists a separating equilibrium wherein the buyer offers a low price
pAI
w , which the weak seller type accepts. But the strong seller type will reject this offer and
CI
AI
AI
counteroffer with pAI
s (where ps > ps > pw ), which the buyer accepts.
14

This model focuses on the case where uncertainty is embodied only in the discount factors and not the
value over which negotiations occur, which is not directly testable without data on breakdown or beliefs
because the surplus and bargaining parameters enter the price multiplicatively. However, this seems to fit
the primary potential source of uncertainty in coronary stent negotiations, where doctor preferences are
typically quite well known by those involved in the negotiation and marginal costs are small relative to
the surplus created. It is also consistent with anecdotal evidence of little if any equilibrium breakdown in
negotiations or destruction of surplus, which are central predictions of models of incomplete information
about values (thanks to Brad Larsen for this observation). See Ausubel et al. (2002) for a review of the
literature focused on informational asymmetries in values. Of particular note in that literature is Cramton
(1992), which extends a model similar to the one here to a continuum of types and two-sided asymmetric
information, and where information revelation arises endogenously through the timing of initial offers.

9

For simplicity, assume that access to benchmarking information fully reveals a seller’s
type. Several empirical predictions for the effects of information on negotiated prices follow
directly (Appendix B provides more detailed analysis and further predictions of the theory):
Prediction 1 (Direct Information Effect on High Prices) If information is costless,
pessimistic buyers will always become informed. This information will cause the highest
CI
prices pCI
s to fall to the complete information weak-supplier price pw , for those cases
where the supplier was in fact the weak type.
Prediction 2 (Direct Information Effect on High Prices with High Quantity) If information is costly to obtain (e.g. searching and analyzing the data takes time that
could be used on other productive activity), a pessimistic buyer will become informed
CI
whenever the expected benefit of information ω(pCI
s − pw )q exceeds the cost.
Put plainly, Prediction 1 is that exposure to benchmarking information should lead to
some of the highest prices falling (cases where the supplier was the weak type). Prediction 2
is that this effect will be more likely among those brands with the highest quantity used.15
3.2

Negotiator Agency

Another mechanism via which benchmarking information could be valuable to buyers would
be through providing aggregate information to help the buying firm solve a moral hazard
problem with its purchasing agent. We expect this mechanism to be relevant in the cardiac
unit context. McConnell et al. (2013) present survey data documenting that hospitals’
cardiac units vary substantially in their focus on performance measurement, and the Centers
for Medicare and Medicaid Services recently found that cardiac and orthopedic units in
hospitals responded to bundled payments (which entail higher-powered financial incentives)
by improving contracting with suppliers.16
Extending the model presented thus far, suppose that instead of the hospital negotiator’s
bargaining parameter being exogenous, the price will be a function of the hospital agent’s
choice of discount factor δ B . Further, suppose that in addition to uncertainty as to whether
the supplier is a strong type or a weak type, there is an additional i.i.d. shock to the supplier’s
15
Alternative models that could generate similar empirical predictions might include models wherein one
party has preferences over relative as well as absolute performance. See, e.g., Card et al. (2012) regarding
pay transparency, in which workers learning they have relatively low salaries have reduced satisfaction and
are more likely to leave their jobs.
16
See Calsyn and Emanuel (2014). The role of incentives in purchasing has also been examined in the
broader government contracting context – e.g., in Bandiera et al. (2009), Italian public bodies’ prices for
generic goods vary with institutional characteristics and poor performance is attributed to passive wastefulness rather than corruption.

10

bargaining parameter that is buyer-specific (see Appendix B for details in the case where
hospital h faces a supplier bargaining parameter equal to δhS ∈ {δwS h , δsS h } for h ∼ U [0, 1]).
Supplier bargaining strength is then observable to the hospital negotiating agents, but not
to the principals who manage them.
A moral hazard problem arises in this setting because bargaining effort is costly and
provides the agent disutility. Under the usual assumption that the agent is risk averse,
the optimal employment contract involves risk sharing between the principal and the agent.
Holmstrom (1982) shows that if agents face some common parameter which is uncertain
from the principals’ perspectives (here, the portion of the bargaining parameter δ S that
reflects whether the supplier is a strong or weak type), then relative performance evaluation
compared to some aggregate sufficient statistic can be used to write a stronger incentive
contract with each agent.
In our interviews with industry participants, we did not encounter a single case where
purchasing agent contracts were formal functions of a quantitative performance metric based
on benchmarking information or otherwise.17 However, we did learn that some hospitals
use performance in terms of decreasing prices as part of a broader performance review or
employee recognition program. When benchmarking information was available, we also heard
cases of such data being used to quantify relative performance and opportunities for savings.
This is in keeping with the spirit of the model above, motivating the following Predictions:
Prediction 3 (Monitoring Effect on Prices) If buyer negotiators are imperfect agents
of the buying firm, then benchmarking information (observing the distribution of price
realizations across hospitals) allows the principal to estimate whether the seller is the
weak or strong type, and thus reduces the risk to which the agent is exposed in a
higher-powered contract. The higher-powered contract induces more bargaining effort
and a lower price than the case where only the buyer’s own price is observed.
Prediction 4 (Monitoring Effect on Prices with High Quantity) Further, information will be used in this way when the expected benefit E[(pN oInf o − pInf o )]q exceeds
the cost of information use.
In sum, Prediction 3 suggests prices will decrease on average upon the introduction of
benchmarking; Prediction 4 suggests this affect will be more likely when greater purchase
quantities are at stake.
17

See Appendix C.2 for details.

11

3.3

New Brand Entry and Timing of Information Effects

Although the asymmetric information about supplier bargaining type mechanism and the
negotiator agency mechanism can generate similar empirical predictions, an interesting feature that differs between the two mechanisms is the timing during which benchmarking
information is valuable to the buyer. In the asymmetric information case, benchmarking is
only useful if data on other buyers’ prices for the same brand are currently available in the
database at the time of negotiation. By contrast, even if there is no current data on others’
prices for a given brand, agents may be incentivized today based on performance assessments
taking place in the future.
This difference between the timing of information required for the two mechanisms is
especially relevant when new brands enter the market. There will be no data in the benchmarking database on a brand for the first month or two it is on the market, and little data
for the first few quarters. Thus, those who engage in their first negotiation for a new brand
soon after its release do so without current benchmarking information, even if they have
access to the database. This motivates our final theoretical prediction:
Prediction 5 (New Brand Entry Separates Asymmetric Information and Agency)
For newly introduced brands, when they are first released to the market, differences
between prices negotiated in the first (uninformed) round of negotiation and the second (informed) round of negotiation must be due to informing negotiators about the
seller’s bargaining parameter, rather than altering moral hazard.
Our empirical implementation of this idea identifies the effects of any contract redesign
that negotiators are made aware of upon the firm joining the database and that incentivizes
effort prior to benchmarking realizations. This structure, in which today’s performance
impacts tomorrow’s information and, accordingly, compensation, is the approach taken in
most explicit pay-for-performance schemes in health care markets (see James (2012)). In
more general compensation schemes, relative performance evaluation can be part of employee
compensation contracts with explicit bonuses (e.g., sales force compensation) or rewards can
be focused on raises and promotion (see Lazear and Oyer (2012) for a review).
3.4

Other Considerations

In the interest of clearly illustrating the fundamental ideas behind the two theoretical mechanisms of interest, we have abstracted from some realities of hospital purchasing. Here
we touch on some key features omitted from the model and how they affect the empirical
analysis that is the focus of the paper.
12

First, to the extent that renegotiation is not frictionless, it will take time and effort to
get to the negotiating table and come to a new deal: prices will be “sticky”. This will tend
to bias the short-run effect of information toward zero. We consider these dynamics in our
empirical analyses using event studies and direct examination of recontracting.
Second, the same supplier salesperson may be in charge of negotiating contracts for a
bare-metal and a drug-eluting stent, or for subsequent generations of a branded drug-eluting
stent. To the extent that learning about types in the models above captures something
that is specific and unchanging over time about that salesperson and the incentives she
faces, there will be less asymmetric information and scope for learning, biasing the effect of
benchmarking information toward zero.
Finally, while demand side effects of information are generally null or beneficial to buyers, to the extent that suppliers know when buyers join the benchmarking database (or
transparency is imposed via public policy), then the model may omit supply side responses
that may negate or overturn these effects through greater obfuscation (Ellison and Ellison
2009), facilitating collusion (Albek et al. 1996; Cutler and Dafny 2011), or forcing suppliers
not to price discriminate via secret discounts (Duggan and Morton 2006; Grennan 2013).
We return to this issue, and the extent to which our empirical estimates may capture these
various supplier responses, in our discussion of results.

4

Identification of Information Treatment Effects

The key features of the data that allow us to estimate causal treatment effects of price
transparency for the hospitals in our sample are: (1) that new members submit one year of
retrospective data when they first join the benchmarking database, and continue to submit
monthly data thereafter; (2) that new members join over time in a staggered (and seemingly
random) fashion; and (3) that new brands enter the market at points in time that are
seemingly uncorrelated with members’ information states.
For hospitals that joined during the 2009-14 period, we observe data before and after
they were first able to access the benchmarking information available in the database. The
left panel of Figure 2 shows the time series of hospitals joining the database between 2010
and 2014. Beginning in Q2 2010, 14 hospitals join the database in each quarter, on average.
4.1

Using Join Date to Identify Price Effects

We leverage this variation using a series of difference-in-differences strategies. In our sample,
all hospitals by definition access the benchmarking data at some point. The “control hospitals” for analyzing the price trend of hospital h in a window around h’s joining the database
13

are those hospitals k ∈ H \ h that subscribe either prior to or after that window. Under
the standard assumption of parallel trends, we can isolate the treatment effect of joining the
database on prices by comparing the price trends between treatment and control hospitals
for their overlapping time periods.
Figure 2: Identifying Variation and Graphical Example of Identification

Number of Hospitals (First Login)
0
100
200
300

(a) Timing of Join and New Brand
Entry

20

(b) Identifying Information Effects from New
Brands
=%
'%

'%

!"#$%#%&'%(%&)%*%+),%*%+-./0%

!"#1%#%&'%(%&)%*%+),%
'%
)%

!"#<%#%&'%(%&)%
)%

e q1 ity
q1
ier 4q1 Alp.
rim 12 egr
13 n
em 01
ce
20ditio
e P 20 Int
Pr 2
c
en
e
s
e
t
en
Xi
Xp
mu
Xi
olu
o
e
,
s
r
c
P
P
Re
en
sE
Xi
mu

q1

10

)%

q1 Ion

11

20

Pr

)%203.4%

o

5"6."%%
6."674%
%!+,%&"'(%

89"9%
76:6946;%
%!"#$%&"'(%

%'%203.4%

"%

%!"#$%)(*"%

Left panel: authors’ calculations from PriceGuide data, 2010-2014. “Join” defined by member’s first associated login. New
brand entry indicated with vertical red lines. Note: PriceGuide rolled out a new version of its web interface in the
beginning of 2010 and re-invited all current members to “join”; members’ whose first associated login is in Q1 2010 may
have subscribed in 2009 or earlier. All such members’ “pre-join” data is excluded from empirical analyses. Right panel:
graphical illustration of “new brand” identification strategy.

The primary concern with this identification strategy is that timing of a hospital joining
the database may be correlated with other contemporaneous factors that impact price trends
at that hospital.18 However, there are several institutional features which one might expect
to dampen potential join-time bias for any particular focal brand. First, our conversations
with industry participants indicate that it is unlikely for a hospital to join the database due
to any single product category. PPIs such as stents are important purchases for hospitals, but
subscription is costly and meant to cover a large number of product categories. Second, many
determinants of price trends are specific to a product category market, limiting the degree of
correlation in price trends across, for example, coronary stents and artificial knees. Finally,
hospital purchasing tends to be separated across groups of product categories, implying
18

For example, a hospital may be inspired to join the database due to concerns about upward price trends,
which could induce a positive bias in our results – we would be underestimating the counterfactual prices
joining hospitals would face if they did not join. On the other hand, a joining hospital might concurrently
be undertaking other initiatives intended to constrain prices, such as hiring new personnel or contracting
other outside consulting services. Conflating the effects of these other initiatives with the effect of access to
the benchmarking information could induce a negative bias in our results.

14

that, for example, organizational changes regarding purchasing in the catheter lab need not
correlate with changes in orthopedic surgery. Thus any particular product category or brand
within a category is likely to be a “bystander” to the join timing. This is consistent with
the event studies in Section 5, which show no evidence of differential pre-trends in price in
the months before hospitals join the database.
4.2

New Brand Entry, Mechanisms, and Bias

New brand entry provides another opportunity to identify the above information effect, and
further allows us to identify a treatment effect of having joined the database but not yet
having access to concurrent data on other hospitals’ purchases. After new brand entry,
there is a lag before members may access benchmarking data on the new brand due to lags
in data submission and loading: in the months following new brand entry, the count of
members purchasing that brand exceeds the count of members with transactions loaded in
the database by 56 on average. Moreover, we observe transactions for new brands for some
members before and after they join the benchmarking database: in the year following brand
entry, 9 percent of members whose transactions are observed in the average month are prejoin (details in Appendix A.2). The time period for our study contains many drug-eluting
stent brand introductions. In panel (a) of Figure 2, we note the timing of entry of seven new
brands between 2010 and 2014, of the thirteen brands sold during this time period overall.
This variation allows us to identify a treatment effect of access to benchmarking information via a mechanism that does not require concurrent access to data on other hospitals’
purchases. In our analysis, we term this the agency (“Ag”) effect to denote its relation to
the mechanism outlined in Section 3 in which the benchmarking database allows hospitals
to resolve a negotiator agency problem. Panel (b) of Figure 2 illustrates this identification
strategy graphically. In this stylized example, we have hospital A joining the database well
before the brand enters the market; hospital B joins after the brand enters. Once the brand
enters, each hospital negotiates prices; hospital B is untreated, while hospital A is treated
(“Ag”) in the sense that it has joined but has no concurrent data on other hospitals. In the
next period, after price data are submitted, loaded, and released to database members, nonmember hospital B remains untreated, but hospital A receives another treatment (“Info”) in
the form of information on other hospitals’ prices. In the final period, hospital B has joined
the database and received the full treatment effect of access to benchmarking data (“Ag” +
“Info”); hospital A retains both treatments in the final period as well.19
19

Formally: in the final period, we identify the fixed hospital differences (∆t=3 ); in the penultimate period,
we identify the fixed differences plus the “agency” and “information” effects (∆t=2 ); and in the first period,
we identify the fixed differences plus the “agency” effect only (∆t=1 ). These three differences allow us to

15

Entering brands also allow us to investigate potential bias due to timing of join. Any
persistent bias associated with factors beyond information at hospitals that have joined will
be included in the difference between pre- and post-join hospitals in the first few months
after new brand introduction (β Ag ). Thus, our estimate of any “asymmetric information”
effect where hospitals use information concurrently available in the database to negotiate
better prices (β Inf o ) would be free of such bias.

5

Results: How Information Affects Negotiated Prices

In this Section, we estimate regressions based on the research design just described to more
carefully measure and understand the effect of information suggested by Figure 1, accounting
for time-invariant differences across hospitals (or hospital-brand combinations) and trends in
prices over time. All of the regressions we present are extensions of a baseline specification
implementing our difference-in-differences design around the timing of hospital access to
benchmarking information.20 Letting Phjt denote the price observed for brand j, hospital h,
and month t, our preferred specification controls for hospital-brand fixed effects [θhj ], month
fixed effects [θt ], and separate linear time trends for each brand [γj ∗ (t − tminj )]:21
Phjt = β Inf o ∗ 1{posthjt } + θhj + θt + γj ∗ (t − tminj ) + εhjt .

(1)

Here, 1{posthjt } is an indicator equal to one after a hospital first accesses benchmarking
information for the given brand and zero prior, making the coefficient β Inf o an estimator
for the treatment effect. All of the regressions and results below extend this specification
to allow for varying types of heterogeneity in this treatment effect. Results with alternative
fixed effects and time trends are discussed as well.
5.1

Effects of Information throughout the Price Distribution

Our first result, shown in Table 1, regards the average treatment effect of information across
all hospital-brand-months. Results are shown for a variety of different specifications of
control variables. The estimates are significantly smaller when we control for hospital-bybrand (rather than hospital and brand) fixed effects. This may be due to our effectively
separately identify the agency (β Ag = ∆t=1 − ∆t=3 ) and information (β Inf o = ∆t=2 − ∆t=3 − β Ag ) effects.
20
This includes information upon joining and when new brands enter. We show results estimated only
from “timing of join” variation in Appendix A.3 and find our discussion unaffected.
21
tminj is the first period in which we observe data for brand j: either the beginning of our sample or the
month of entry of brand j into the market. To address concerns that linear trends do not adequately account
for price trends at the beginning of a brand’s life cycle, refer to Appendix D.1 for results with brand-month
fixed effects, which are qualitatively similar.

16

controlling for an unknown source of hospital-brand specific heterogeneity; or hospital-brand
fixed effects may introduce attenuation bias towards zero, as there are some hospital-brands
for which there are relatively few observations. We generally find that Version (3) treatment
effects are smaller in magnitude and more precise than Version (4), so we focus on these
results in the main text for the sake of brevity.22
Table 1: Average Treatment Effects of Information across All Hospital-Brand-Months
Version of Controls
β Inf o

[1]
-12†

[2]
-21†

[3]
-3

[4]
-7
(5)

(5)

(7)

(3)

Hospital+Brand FEs

Y

Y

N

N

Hospital×Brand FEs

N

N

Y

Y

Linear Brand Trends

Y

N

Y

N

Brand×Month FEs

N

Y

N

Y

Authors’ calculations from PriceGuide data, 2009-2014. N = 32, 453 member-brand-months. Includes 508 members.
Standard errors clustered at hospital (Versions 1 and 2) or hospital-brand (Versions 3 and 4) level shown in parentheses.
Superscript (†) indicates significant difference from zero at the 1% level; (**) at the 5% level; (*) at the 10% level.

The preferred specification finds that prices decrease by only -$3 on average when benchmarking data are accessed. This average treatment effect (ATE) is also imprecisely estimated, with a standard error of $3.23 In keeping with the empirical predictions derived
from theory, the remainder of our analyses will allow for heterogeneity in treatment effects depending on each hospital-brand pair’s place in the price distribution for that brand
at the time the hospital gains access to information. Upon member h’s first login to the
database (t = τh ), we compare Phj,preh for each brand j purchased in the year prior to login
(preh := {t ∈ [τh − 13, ..., τh − 1]}) to the full distribution of prices {Ph0 j,preh }h0 ∈H across
all hospitals H during (preh ). We assign each pair hj to a quintile k of the pre-join price
distribution. We then re-estimate (1), such that coefficient βkInf o represents the estimated
treatment effect of accessing information in the benchmarking service for quintile k of the
pre-information price distribution 1{Phj,pre ∈quintile(k,{P 0
.
h j,preh }h0 ∈H )}
h
Panel (a) of Figure 3 shows the results. The treatment effects exhibit substantial heterogeneity depending on the pre-information price the hospital was paying for a brand relative
to others. The treatment effects are statistically zero in all but the top quintile of the
pre-information price distribution, where the effect is -$27. This evidence is consistent with
Prediction 1 that, absent benchmarking, pessimistic hospitals would pay suppliers high prices
22

See Appendix D for all versions of heterogeneous treatment effect and mechanism results. The results
are similar, with the primary difference being that effects in the top of the price distribution roughly double
in size with hospital instead of hospital-brand fixed effects. This difference is due to a significant negative
“agency” effect in the hospital fixed effect specifications, which does not appear in the specifications that
control for hospital-brand fixed effects.
23
Detailed tables and figures on the timing of the effect are available in Appendix D.1.

17

75

2

3

4

5

0

Treatment Effect, $
1

-175 -150 -125 -100 -75 -50 -25

0
-25
-50

Treatment Effect, $

25

50

25

regardless of those suppliers’ true bargaining parameters, leading those hospitals to negotiate lower prices after joining. Under the asymmetric information mechanism, there is little
reason to expect transparency to affect prices that are relatively good. It is also worth noting
that we do not see evidence that the lower part of the distribution shifts upward significantly,
as might happen in the presence of mean reversion.

-10

Quintile of Pre-Join Price

-5

0

5

10

Month Relative to Treatment Date

(a) DiD Estimates by Quintile

(b) Top Quintile Event Study

Authors’ calculations from PriceGuide data, 2009-2014. Panel (a): N = 32, 453 member-brand-months; includes 508
members. Panel (b): N = 23, 016 member-brand-months; includes 507 members, twelve months pre- and post-join only.
Standard errors clustered at hospital-brand level.

Figure 3: Treatment Effect Estimates Throughout the Price Distribution

We also performed an event study analysis separately for each quintile of the price distribution. The results for the top quintile of the pre-information price distribution are shown
in panel (b) of Figure 3.24 The pre-trends in the six months pre-information are essentially
zero, while there is a steady decline in prices after information access – a year after join, the
treatment effect is -$96 relative to the “info” date. The estimates for the 6-12 months prior
to information access are negative, though not significant. If one were to lend weight to the
noisy point estimates, pre-trends prior to joining the database would lead the difference-indifferences estimates to be an understatement of the effects of information on price. This
lack of pre-trends is strong suggestive evidence that the estimated treatment effects are due
to accessing the information in the benchmarking data rather than to any potential sources
of bias due to join timing.25
24

Results estimated using alternative fixed effects are available in Figures A10 and A11.
Indeed, the evidence of steeper negative price trends after join in the top quintile of the price distribution
than there are in average prices suggests that, if there are factors that cause prices to decrease after join
that are unrelated to information access, they must disproportionately impact hospital-brands whose prices
are relatively high in the pre-period, a fact which would be unknown to parties whose behavior impacts
prices without them accessing the database. For the reader who prefers a more skeptical interpretation, any
25

18

For the sake of statistical power and for expositional simplicity, we return to estimating
pre-/post-treatment effects, rather than breaking them down by month relative to information access. However, it is noteworthy that treatment effects become larger over the course
of the year after information access. We see this as evidence of price “stickiness” as a friction
that limits gains from transparency, and we return to this issue in Section 5.2.3.
5.2

Mechanisms: Where and Why Does Information Matter Most?

The above results establish that transparency in the form of access to benchmarking information leads to lower prices for hospital-brand cases where the hospital is in the upper quintile
of the price distribution for that brand. In this Section, we test the further predictions
from Section 3 to better understand the mechanisms behind these price reductions. We first
allow for treatment effects to vary with purchase volume so that we may investigate whether
hospital-brands with high expenditures at stake experience larger changes, in keeping with
Predictions 2 and 4. Next, we utilize the fact that, for new brands, no benchmarking information is available in the database until several months after brand entry; this allows
us to separate the asymmetric information mechanism from the agency mechanism (Prediction 5). Finally, we decompose the estimated price effects into price effects conditional on
renegotiation and price effects due to greater likelihood of renegotiation. The estimates are
summarized in Table 2 here and discussed in turn below.26
5.2.1

Costs of putting information to use: treatment effects and quantity

To the extent that using benchmarking information to identify opportunities and then engage in renegotiation (of supply contracts or employment contracts) is costly, Predictions 2
and 4 suggest that transparency will have the largest effect for hospitals and brands with
high quantities involved. To investigate these predictions, we generate dummy variables
q
1{lowhj,pre
} , 1{highqhj,pre } that divide the sample into hospital-brands with monthly purchase
volume below and above the 75th percentile in the months prior to join, and we estimate a
Inf o
model that allows for treatment effects to vary by pre-join price and quantity where βk,low
q
Inf o
now estimates the treatment effect, for quintile k, for lower volume brands; and βk,highq now
estimates the treatment effect, for quintile k, for higher volume brands.
The estimates in Panel (1) of Table 2 show that the price treatment effect is largest
for high-volume hospital-brands in the upper part of the price distribution. At -$71, the
remaining bias due to timing of join will be absorbed with our measure of the agency effect in our mechanism
test, so that we are able to obtain a “clean” asymmetric information effect.
26
Detailed results with alternative fixed effects specifications are available for each of the below panels in
Figures A12, A13, and A14 in Appendix D.1.

19

Table 2: Treatment Effects of Information: Mechanisms
(1) Treatment Effect Variation with Quantity Purchased:
Inf o
Inf o
High quantity: βquintile,high
Low quantity: βquintile,low
q
q
Pquintile :
1
2
3
4
5
1
2
3
4
−4
9
9
5
−17∗∗
−11
0
0
−9
(6)

(6)

(6)

(6)

(7)

(9)

(8)

(7)

(2) Agency vs. Asymmetric Information Mechanisms:
Ag
Inf o
Future Info: βquintile
Concurrent Info: βquintile
Pquintile :
1
2
3
4
5
1
2
3
−17
−3
2
7
13
−1
7
5
(11)

(12)

(10)

(12)

(3) Renegotiation:
Pr renegotiation: 1{reneghjt }
Pquintile :
1
2
3
4
.01
.013
.016∗
.018
(.01)

(.01)

(.009)

(.011)

(18)

(6)

(5)

(5)

5
−71†

(8)

(13)

4
−1

5
−30†

(5)

(7)

Inf o
Upon renegotiation: βquintile,
1{reneg

hjt }

5
.023∗∗

1
−14

2
4

3
1

4
−13

5
−76†

(.009)

(15)

(14)

(19)

(17)

(18)

Authors’ calculations from PriceGuide data, 2009-2014. N = 32, 453 member-brand-months. Includes 508 members.
Standard errors clustered at hospital-brand level shown in parentheses. Superscript (†) indicates significant difference
from zero at the 1% level; (**) at the 5% level; (*) at the 10% level.

top-quintile treatment effect for high-quantity hospital-brands is more than triple the effect
for low-quantity hospital-brands in the preferred specification.
The fact that quantity matters suggests that costs of attention, analysis, or action act as
frictions that sustain price variation. That more savings are not realized, even when large
quantities are at stake, suggests that further frictions independent of information, such as
strong physician brand preferences, could be important as well. As shown in Appendix D, we
see similar patterns when we consider different sets of fixed effects and time trends, when we
modify the regression sample to focus on only the twelve months pre- and post-information,
when we limit the sample to hospitals only, and when we estimate effects within similar sets
of hospitals. The results are also similar when we identify treatment effects based only on the
information shock of database “join” as part of the expanded analysis discussed in Section
6. All told, these results imply price convergence: removing time trends and applying our
treatment effect estimates to the pre-join price distribution decreases the standard deviation
of price by 3.7 percent among low-quantity hospital-brands and by 6.4 percent among highquantity hospital-brands.
5.2.2

New brands: agency and asymmetric information mechanisms

The β Inf o estimates thus far have provided a treatment effect of access to the benchmarking information, subsuming both the agency and asymmetric information mechanisms that
market participants put forth, as outlined in our Section 3. To separate these theories, we
20

leverage the fact that almost all hospitals negotiate their first contract with a new brand by
the first or second month after its introduction, but the resulting purchase order data will
not begin to show up in the benchmarking database until month three or four. By month
six, there are enough observations in the database for a hospital to develop a useful estimate
of its place in the price distribution for that brand. We use this to estimate a regression in
the spirit of Figure 2 that allows for heterogeneous treatment effects by price quintile and by
these two information states. We estimate βkAg by interacting the price quintile k treatment
effect with an indicator for all hospital-months after the hospital joins and logs in to the
benchmarking database 1{postjoin } ; and we estimate a “clean” βkInf o by including a further
ht
interaction with an indicator that is equal to one upon a hospital’s first login more than six
months after the introduction of that brand 1{(t−tminj )>6} .
The estimates in Panel (2) of Table 2 suggest that the asymmetric information effect
explains a substantial portion of the effect of information on prices. To the extent that
one remains concerned about endogenous timing of join, recall from Section 4 that any
associated bias will be captured in β Ag , but not β Inf o . Thus, our most robust finding is
that of a statistically and economically significant β Inf o , concentrated among those paying
the highest prices before obtaining information, and consistent with the use of concurrent
information in bargaining. These results are most consistent with the theory of asymmetric
information in bargaining based on Rubinstein (1985).
One implication of this result is that asymmetric information may be among the effects driving the heterogeneity found in bargaining parameter estimates in studies using full
information Nash Equilibrium of Nash Bargaining models. It suggests that these information and incentive issues should be kept in mind when thinking about the factors driving
bargaining outcomes, including as potential sources of changes to bargaining parameters in
counterfactuals with negotiated prices.
5.2.3

Price changes with “sticky” contracts

All of the price coefficient estimates reported thus far can be described as capturing the
combined effect of information on the probability that price negotiation occurs and on prices
arrived at during each price negotiation. We consider this to be the treatment effect of
interest for policy, as it estimates the overall value of access to benchmarking information
for decreasing the total spend of hospitals on medical inputs over time, taking into account
the stickiness of prices in real-world hospital-supplier contracting. However, in the main
estimation sample, renegotiations take place in 9 percent of observations (member-brandmonths with any transactions), and prices decrease on average by $25 at each renegotiation,
meaning that we would expect small price changes to occur if information led to larger price
21

decreases at each renegotiation or if information increased the likelihood of renegotiation.
We consider these two effects separately by flagging hospital-brand-month observations
in which renegotiation is observed 1{reneghjt } .27 We then estimate the effect of information on
the rate of renegotiation using the usual price quintiles specification, but with the indicator
for renegotiation as the dependent variable. The effect of information on price, conditional
on renegotiation, is obtained from the same regression, run only on the subset of data where
the renegotiation indicator equals one.
The results in Panel (3) of Table 2 show the effect of information on the likelihood of
renegotiation is only statistically significant (at the 5% level) in the top quintile of price,
where information increases the probability of renegotiation by 2.3 percentage points, or
about one quarter the baseline probability of renegotiation. Point estimates in other quintiles
are positive but smaller and not significant at conventional levels. To the extent this is not
simply a statistical coincidence, it could be due to a slight increase in efforts to get to the
negotiating table or change in the frequency with which renegotiation results in zero price
change among those with information.
By contrast, the effect of information on price conditional on renegotiation is about -$75,
nearly three times the -$27 effect on price paid. Thus, the impact of transparency in the
form of benchmarking information is substantially affected by renegotiation frictions.

6

Generalizing the Results – All Important Products

While the above results are useful for investigating mechanisms via which savings are achieved
for an important product category, a natural question arises: what happens to the remaining
98 percent of hospital spending? To investigate this question, we extend our analyses to 52
other product categories that are important in terms of high spending or transaction counts.
We organize product categories based on the likely importance of physician preferences in
determining their usage. Class 1 is “commodities”: relatively inexpensive products that
are unlikely to be chosen primarily by physicians; e.g., surgical gloves. Class 3 is “physician preference items”: high-tech medical devices, mainly coronary and orthopedic products
that are the primary implanted device in their corresponding surgical procedures; e.g., coronary stents. Class 2 is intermediate: other medical/surgical products used during invasive
27

We sort transactions for each hospital-brand by month and group observations with the same price
together within month. We then flag each hospital-brand-month as including a renegotiation event if we
observe that prices change and that the price change “sticks” for two cumulative months after the renegotiation event (or until the final observed purchase for that member-brand). The results are qualitatively
similar (though larger in magnitude) using a less conservative method that flags all months in which average
prices change. Of course, with transactions data, we cannot observe if a renegotiation took place and price
remained the same, but the baseline level of these events is differenced out in our estimation strategy.

22

procedures, but explicitly excluding PPIs.28 See Appendix A.3 for sample details.
In this expanded set of analyses, we estimate equation (1) and its variants within each
product category, using join timing to identify treatment effects of information. Appendix E
reports estimated average treatment effects and treatment effects by price and quantity for
each product category, including several different fixed effect specifications, and for the full
sample as well as a restricted sample focusing on products purchased in at least 100 hospitals
on average in each year (where price quintile estimates have larger statistical power). Here,
we summarize the key insights using the full sample. Figure 4 plots the average treatment
effect (left panel) and high-price, high-quantity treatment effect (right panel) for each of the
52 product categories, normalized by mean price to facilitate comparisons across groups,
and organized by treatment effect and product class. The table below the Figure shows
spending-weighted averages of the estimated treatment effects across all product categories
within each class, in dollars and percentages.
We observe several general patterns similar to those from stents. In panel (a), we see
that the average treatment effects are negative for the majority of product categories, but
relatively small and rarely statistically significant. In panel (b), we see that among hospitalbrands in the top quartile of quantity and quintile of price at the time of joining, the treatment effects are larger in magnitude, almost all negative, and sometimes statistically significant, particularly for PPIs. The primary takeaway across all of these top categories is
that high-price hospital-brands within PPIs experience 3.4 percent savings (3.9 percent if
high-quantity as well) after obtaining access to benchmarking data; savings are limited for
other hospitals and products.
The final two columns in the table at the bottom of Figure 4 show the mean and standard
deviation of expected annual savings across hospitals, averaged over product categories for
each class. The results reinforce that, on average, hospitals can expect modest savings of
$1,869 on PPIs, but there is a large amount of heterogeneity across hospitals. A standard
deviation improvement takes expected savings to $7,361 per hospital-product category-year.
The favorable parts of the savings distributions for commodities and other surgical supplies
offer substantial opportunities as well, with annual category savings of over two thousand
dollars one standard deviation from the mean.
28

Our typology overlaps substantially with the Food and Drug Administration’s classification system.
Class I devices, such as gloves, are deemed to be low risk and are therefore subject to the least regulatory
controls. Class II devices, such as catheters, are higher risk devices with greater regulatory controls to
provide reasonable assurance of the devices’ safety and effectiveness. Class III devices, such as replacement
heart valves and coronary stents, are the highest-risk devices and must typically be approved by FDA before
they are marketed (United States Food and Drug Administration 2015). For product categories that did not
obviously fit into one of our classes, we relied on the FDA class directly.

23

0.10
Other Med/Surg

-0.10

-0.05

0.00

0.05

0.10
0.05
0.00
-0.05
-0.10

Commodities

PPIs

Commodities

(a) ATE

(1) Commodities

T Ehighp
%

$

%

T Ehighp ,highq
$
%

Expected Savings
µ($/h-yr)
σ($/h − yr)

0.17

0.002

-0.39

-0.013

-0.58

-0.016**

63

2,828

(0.19)

(0.004)

(0.85)

(0.014)

(0.56)

(0.008)

(306)

(1,028)

1,974

-1.87

-0.003

-8.40

-0.018

-8.89**

-0.006

-254

(2.21)

(0.002)

(10.69)

(0.018)

(3.92)

(0.005)

(428)

(279)

-38.13

-0.005†

-162.79

-0.034**

-205.28†

-0.039†

-1,869

5,492

(23.26)

(0.002)

(158.78)

(0.017)

(74.88)

(0.005)

(1,281)

(893)

(2) Other Med/Surg
(3) PPIs

PPIs

(b) High Price and Quantity TE

AT E
$

Other Med/Surg

(1)

(2)

(3)

Authors’ calculations from PriceGuide data, 2009-2014. Nhjt = 516, 582; Nhjt = 1, 344, 515; Nhjt = 703, 544.
(1)

(2)

(3)

Nh = 748; Nh = 701; Nh = 601. Reported specifications include hospital-brand and brand-year fixed
effects; alternative fixed effects shown in Appendix. Standard errors in category-specific regressions clustered at
hospital-brand level. Superscript (†) indicates significant difference from zero at the 1% level; (**) at the 5%
level; (*) at the 10% level.

Figure 4: Treatment Effect Estimates for Important Product Categories

7

Conclusion

This paper conducts the first empirical study of the impact of transparency on price negotiations in business-to-business markets. Our empirical context is hospital supply purchasing,
an area where there has been keen interest in information as a way to decrease hospital
supply costs. Using new data on all purchase orders issued by over fifteen percent of US hospitals from 2009-14 and difference-in-differences research designs, we find that hospitals that
gain access to benchmarking information see subsequent savings on the brands for which
they were previously paying relatively high prices. These estimates provide evidence on
the potential economic impacts of the rise in benchmarking data services marketed towards
buyers in business-to-business markets. They also suggest that information is a potentially
important driver of heterogeneity in negotiated prices, with implications for the growing

24

structural empirical literature in bargaining.
Our tests of the mechanisms behind these information effects imply that the value of
information is attenuated by the costs of putting the information to use. The evidence
suggests that there are costs consistent with time-constrained negotiators (gains are focused
in high-quantity items where the most money is at stake) and also stickiness of businessto-business contracts (long term contracts may not be renegotiated for some time). The
latter friction is a fundamental feature of many business-to-business markets. However, the
time and effort cost of accessing and/or using information could be reduced as technology
improves. As both information and analytics are increasingly important in the modern
economy, this suggests a path for future research.
We examined two potential theories for how benchmarking information might be used in
a business-to-business setting – asymmetric information about seller bargaining parameters
and buyer-side negotiator agency. We found robust evidence for the asymmetric information
theory, but noisy evidence for agency. We see modeling frictions in the use of information
and the potential for information to affect within-firm agency frictions in negotiation as two
especially interesting areas for future theory development.
While our results suggest that intermediaries who increase transparency may indeed lower
the prices hospitals pay for a wide variety of medical supplies, our detailed analysis of mechanisms focuses on coronary stents. Variation across product markets in terms of supply side
competition, complexity of contracts (for example, nonlinearities or multi-product bundling),
and the particular mechanisms through which information affects prices thus represents rich
opportunities for future empirical analysis of information in business-to-business bargaining.
Such work would require expanding the empirical toolkit to analyze complex contracts when
the contract terms themselves may not be observed.
Finally, while this paper takes a small step towards understanding the implications of
information in business-to-business markets, more work is necessary to evaluate what we
would expect as benchmarking information diffuses into wider use or in policy proposals
for greater transparency in medical device markets. For example, a more structural model,
combined with variation in market structure and information penetration, could explore the
potential roles of supply side phenomena such as obfuscation or collusion.

References
Albek, S., Mollgaard, P., and Overgaard, P. (1996). Law-assisted collusion? the transparency
principle in the danish competition act. European Competition Law Review.
Ausubel, L., Cramton, P., and Deneckere, R. (2002). Bargaining with incomplete infor25

mation. In Aumann, R. and Hart, S., editors, Handbook of Game Theory, volume 3,
chapter 50, pages 1897–1945. Amsterdam: Elsevier Science.
Backus, M., Blake, T., and Tadelis, S. (2015). Cheap talk, round numbers, and the economics
of negotiation. NBER Working Paper No. 21285.
Bandiera, O., Prat, A., and Valletti, T. (2009). Active and passive waste in government
spending: Evidence from a policy experiment. American Economic Review, 99(4):1278–
1308.
Binmore, K., Rubinstein, A., and Wolinsky, A. (1986). The nash bargaining solution in
economic modelling. The RAND Journal of Economics, 17(2):176–188.
Bronnenberg, B., Dube, J.-P., Gentzkow, M., and Shapiro, J. (2015). Do pharmacists buy
bayer? informed shoppers and the brand premium. Quarterly Journal of Economics,
130(4):1669–1726.
Calsyn, M. and Emanuel, E. J. (2014). Controlling costs by expanding the medicare acute
care episode demonstration. JAMA Intern Med, 174(9):1438–1439.
Card, D., Mas, A., Moretti, E., and Saez, E. (2012). Inequality at work: the effect of peer
salaries on job satisfaction. American Economic Review, 102(6):2981–3003.
Collard-Wexler, A., Gowrisankaran, G., and Lee, R. S. (2017). Nash-in-nash bargaining: A
microfoundation for applied work. forthcoming in Journal of Political Economy.
Cooper, Z., Craig, S., Gaynor, M., and Van Reenen, J. (2015). The price ain’t right? hospital
prices and health spending on the privately insured. NBER Working Paper 21815.
Cramton, P. (1992). Strategic delay in bargaining with two-sided uncertainty. Review of
Economic Studies, 59:205–225.
Crawford, G. and Yurukoglu, A. (2012). The welfare effects of bundling in multichannel
television. American Economic Review, 102(2).
Cutler, D. and Dafny, L. (2011). Designing transparency systems for medical care prices.
The New England Journal of Medicine, 364:894–895.
Draganksa, M., Klapper, D., and Villas-Boas, S. B. (2009). A larger slice or a larger pie? an
empirical investigation of bargaining power in the distribution channel. Marketing Science.

26

Duggan, M. and Morton, F. S. (2006). The distortionary effects of government procurement:
Evidence from medicaid prescription drug purchasing. Quarterly Journal of Economics,
121:1–31.
Ellison, G. and Ellison, S. (2009). Search, obfuscation, and price elasticities on the internet.
Econometrica, 77(2):427–452.
Gowrisankaran, G., Nevo, A., and Town, R. (2015). Mergers when prices are negotiated:
Evidence from the hospital industry. The American Economic Review, 105(1):172–203.
Grennan, M. (2013). Price discrimination and bargaining: Empirical evidence from medical
devices. American Economic Review, 103(1):145–177.
Grennan, M. (2014). Bargaining ability and competitive advantage: Empirical evidence from
medical devices. Management Science, 60(12):3011–3025.
Hendricks, K., Sorensen, A., and Wiseman, T. (2012). Observational learning and demand
for search goods. American Economic Journal: Microeconomics, 4(1):1–31.
Ho, K. and Lee, R. S. (2017). Insurer competition in health care markets. Econometrica,
85(2):379–417.
Holmstrom, B. (1982). Moral hazard in teams. The Bell Journal of Economics, 13(2):324–
340.
Horn, H. and Wolinsky, A. (1988). Bilateral monopolies and incentives for merger. RAND
Journal of Economics, 19:408–419.
James, J. (2012). Health policy brief: Pay-for-performance. Health Affairs.
Jin, G. and Leslie, P. (2003). The effect of information of product quality: Evidence from
restaurant hygiene grade cards. Quarterly Journal of Economics, 118(2):409–451.
Kaplan, G. and Menzio, G. (2015). The morphology of price dispersion. International
Economic Review, 56(4).
Larsen, B. (2014). The efficiency of real-world bargaining: Evidence from wholesale usedauto auctions. NBER Working Paper No. 20431.
Lazear, E. P. and Oyer, P. (2012). The handbook of organizational economics, chapter
Personnel economics. Princeton University Press.

27

Lewis, M. and Pflum, K. (2015). Diagnosing hospital system bargaining power in managed
care networks. American Economic Journal: Economic Policy, 7(1):243–74.
Maeda, J. L. K., Raetzman, S. O., and Friedman, B. S. (2012). What hospital inpatient
services contributed the most to the 2001-2006 growth in the cos per case? Health Services
Research, 478:1814–1835.
McConnell, K. J., Lindrooth, R. C., Wholey, D. R., Maddox, T. M., and Bloom, N. (2013).
Management practices and the quality of care in cardiac units. JAMA Internal Medicine,
173(8):684–692.
Pauly, M. V. and Burns, L. R. (2008). Price transparency for medical devices. Health Affairs,
27:1544–1553.
Rubinstein, A. (1982). Perfect equilibrium in a bargaining model. Econometrica, 50(1):97–
110.
Rubinstein, A. (1985). A bargaining model with incomplete information about time preferences. Econometrica, 53(5):1151–1172.
Schneller, E. S. (2009). The value of group purchasing - 2009: Meeting the need for strategic
savings. Health Care Sector Advances, Inc.
Scholten, P. A. and Smith, S. (2002). Price dispersion then and now: Evidence from retail
and e-tail markets. The Economics of the Internet and E-commerce, 11:63–88.
Scott Morton, F., Silva-Rosso, J., and Zettelmeyer, F. (2011). What matters in a price
negotiation: Evidence from the u.s. auto retailing industry. Quantitative Marketing and
Economics, 9(4):365–402.
Sorensen, A. (2000). Equilibrium price dispersion in retail markets for prescription drugs.
Journal of Political Economy, 108(4).
United States Food and Drug Administration (2015).
https://www.fda.gov/aboutfda/transparency/basics/ucm194438.htm.

About

fda.

Waldman, P., Armstrong, D., and Freedberg, S. P. (2013). Deaths linked to cardiac stents
rise as overuse seen. Bloomberg Business.
Zettelmeyer, F., Scott Morton, F., and Silva-Risso, J. (2006). How the internet lowers prices:
Evidence from matched survey and automobile transaction data. Journal of Marketing
Research, XLIII:168–181.
28

ELECTRONIC APPENDICES – NOT FOR PRINT PUBLICATION

A

Data Appendix

The raw transactions data contain 82.5 million observations for 2,111 members across 3,375
product categories and 1.9 million SKUs. Our main analyses focus on coronary stents; our
expanded analysis includes 52 other important product categories. For stents, we assign
product IDs to each branded product by examining each manufacturer’s catalog and searching for brand and model names within the free-text item description field in the transaction
database. The procedure for assigning brand IDs in the expanded sample is detailed in
Appendix A.3 below.
Table A1 presents details for our main analysis sample of facilities purchasing coronary
stents. The top panel summarizes facilities purchasing coronary stents: the average sample facility submitted transactions in 41 months, spending $3.4 million per month on 1,143
product categories. The bottom panel examines stent purchasing patterns by type: the
average sample facility spent $80,000 on 59 stents per month. 82 percent of stents purchased were drug-eluting, as opposed to the older, bare metal technology. Stents comprised
approximately 2 percent of overall monthly spending.
Table A1: Summary Statistics of Stent Purchase Orders

Months of Data
Product Categories
Total Spend/Month ($m)
% Hospital & Health System
Stent Spend/Month ($k)
Stent Qty/Month
Stent Brands/Month
Stent Mfrs/Month

All Stents
[N=508]
Mean
SD
41.4
21.4
1143.1
313.4
3.4
3.2
0.97
0.17
80.4
73.8
58.7
52.7
3.8
1.4
2.1
0.7

Drug-Eluting
[N=508]
Mean
SD
41.4
21.4
1143.1
313.4
3.4
3.2
0.97
0.17
73.1
69.2
48.4
46.1
2.3
0.9
1.9
0.7

Bare Metal
[N= 504]
Mean
SD
41.6
21.4
1147.2
308.2
3.4
3.2
0.97
0.18
7.4
7.0
10.4
9.8
1.5
0.7
1.4
0.6

Authors’ calculations from PriceGuide data.

Table A2 shows each statistic separately by hospital bed count; larger hospitals generally submitted more months’ data and, as logic would indicate, purchased more stents per
month for a greater total monthly expenditure. Hospitals with ≥ 500 beds spent more than
double the amount that the smallest hospitals did on stents per month. The vast majority
of transactions in our data are for drug-eluting (as opposed to bare metal) stents; in the
remainder of our description of the data and in our results, we focus on drug-eluting stents.
29

Table A2: Summary Statistics – Stent Hospitals Only

Bed
Size
0-99

Members
52

100-199

102

200-299

117

300-399

83

400-499

47

500+

107

Months of
Data
31.4
(19.4)
40.0
(20.3)
43.4
(22.0)
41.0
(20.7)
41.4
(21.3)
45.9
(22.0)

Monthly
Exp. ($ k)
59.0
(56.6)
45.5
(43.3)
55.6
(45.9)
73.5
(46.9)
128.9
(92.1)
135.2
(94.2)

Monthly
Quantity
45.0
(44.4)
33.5
(31.5)
40.7
(33.5)
53.6
(33.1)
93.5
(65.5)
97.7
(65.6)

% DES
82.0
(10.8)
81.6
(12.1)
77.4
(14.3)
79.7
(11.6)
79.6
(12.2)
81.1
(9.5)

Authors’ calculations from PriceGuide data.

The heterogeneity in prices observed in our sample is not well-explained by hospital characteristics that might seem a priori to be important for negotiation. For example, we observe
no clear relationship between hospital size and stent prices. See the left panel of Figure A1,
in which we display a box plot of drug-eluting stent prices for each category of bed count.29
Mean prices are, if anything, increasing in bed count, though the differences are not statistically significant. Part of this (lack of) relationship could be due to the heterogeneity in
purchasing behavior across hospitals with similar bed counts – e.g., small cardiac specialty
hospitals may purchase stents in greater quantities than similarly-sized acute care hospitals.
In the right panel of Figure A1, we also show box plots of stent prices for each decile of
monthly stent purchasing volume. Here, we do see a relationship between “size” and price
– the price distribution for hospitals with the smallest purchasing volumes is spread slightly
upward relative to that of the hospitals with the largest volumes, so that low-volume hospitals’ prices have larger means and variances than high-volume hospitals. For drug-eluting
stents, 10th decile hospitals’ prices are 7 percent lower than those obtained by 1st decile
hospitals. These differences are economically and statistically significant; however, the price
distributions for the high-volume and low-volume hospitals overlap substantially, so that
there is a great deal of unexplained hospital price heterogeneity conditional on purchasing
volume.
29

“Prices” are hospital fixed effects obtained from a regression of price on hospital and brand-month fixed
effects.

30

Figure A1: Distribution of Prices Across Hospitals
(b) By Stent Volume Decile
2,400
Hospital Price Fixed Effects
1,800
2,000
2,200
1,600

1,600

Hospital Price Fixed Effects
1,800
2,000
2,200

2,400

(a) By Bed Count

0−99

100−199

200−299

300−399

400−499

500+

1

2

3

Bed Size

4

5

6

7

8

9

10

Purchase Volume (Decile)

excludes outside values

excludes outside values

Drug-Eluting Stent Prices by Size Category (Regression Results)
β 1{h∈ decile x} =
100 − 200 − 300 − 400 −
0 − 99
500+
1
2
3
4
5
6
7
8
9
10
199
299
399
499
1,785 1,801 1,852 1,778 1,805 1,829
1,916 1,864 1,830 1,832 1,766 1,784 1,801 1,807 1,787 1,774
(38) (27) (30) (25) (32) (22)
(54) (40) (44) (36) (26) (31) (29) (25) (25) (32)
β 1{h∈ bed size x} =

Authors’ calculations from PriceGuide data. Estimated mean hospital fixed effects within bed size categories and decile of monthly
purchase volume. Hospital fixed effects obtained from regression of price on hospital and brand-month fixed effects, pre-join data
only. Mean estimates from regression of fixed effects on indicators for size. Standard errors from nonparametric bootstrap of entire
procedure, resampling at hospital level.

A.1

Representativeness of the Benchmarking Database Sample

The facilities in the purchase order data voluntarily joined a subscription service that allows
them to benchmark their own prices and quantities to those of other members in the database
and thus may not be a random sample of US hospitals. In particular, subscription is costly,
so we expect hospitals with greater concerns about supply costs to be overrepresented in the
database – for example, in a survey of database members, “cost reduction on PPIs” and “cost
reduction on commodities” were the first and second (and nearly tied) most commonly cited
reasons for joining. This is in accord with our own conversations with purchasing managers
who cite a broad array of reasons and product areas as motivations for benchmarking. Here,
we discuss representativeness of sample facilities.
The left panel of Figure A2 compares the distribution of sample hospitals across US census
regions to American Hospital Association (AHA) member hospitals with cardiac catheterization labs. The Figure also compares our sample to that in the Millennium Research Group’s
TM
(MRG) Markettrack survey of catheter labs. The MRG survey is explicitly intended to

31

provide an accurate picture of market shares and prices by US region. The Figure shows
that, relative to both comparison samples, the west region is overrepresented in the benchmarking database sample, while the south is underrepresented. The average sample hospital
is also larger than the average US hospital with cardiac catheterization capabilities – the
right panel of Figure A2 shows that the sample contains disproportionately fewer hospitals
in the < 200 beds range and disproportionately more hospitals in the ≥ 500 beds range,
relative to AHA hospitals that would purchase stents. We do not have access to bed size
for the MRG sample, but we do find that the member facilities in our estimation sample
purchased in significantly higher volumes than MRG sample hospitals (60 vs. 33 stents per
month).
Figure A2: Distribution of Benchmarking Database vs. Comparison Hospitals
(b) By Bed Size

0

.1

.1

Percent

Percent
.2

.2

.3

.4

.3

(a) Across Census Regions

Northeast

South

West

0

Midwest

Census Region
Database Sample
MRG Sample

0-99

100-199

200-299

300-399

400-499

500+

Bed Size

AHA Comparison Sample
Database Sample

AHA Comparison Sample

Database sample computations from PriceGuide data, 2009-2014. AHA sample computations from American
Hospital Association Annual Survey of Hospitals, 2012; hospitals with catheterization labs defined as those listed
as having in-hospital adult or pediatric interventional or diagnostic catheterization services. MRG sample
computations from Millennium Research Group survey of catheter labs, January 2010-June 2013.

For January 2010 through June 2013, we also have access to stent price data from the
MRG survey. This allows us to further check the representativeness of the sample of hospitals
joining the price benchmarking database. Figure A3 provides further details on the full
distribution of prices across hospitals in the two samples of 143 pre-join database sample
hospitals vs. 107 MRG hospitals. The prices paid in the two samples are statistically
close to one another, with the average prices paid (controlling for brand-time trends) in
the MRG sample slightly higher (mean $1,666, s.d. $149) than those paid by hospitals
in the estimation sample (mean $1,631, s.d. $120) during the period before they joined
the benchmarking service. These pre-join hospitals do have a slightly larger upper tail of
high prices, with an 80th percentile of $1,743 versus $1,730 in the MRG sample, but this
32

difference is not statistically significant. The representation of larger facilities with slightly
better negotiation outcomes ex ante in our sample may be due to small hospitals’ limited
ability to afford access to the database, though we would expect a countervailing effect to
come from large hospitals’ greater ability to purchase custom benchmarking services from
consulting firms.

0

.001

Density
.002

.003

.004

Figure A3: Pre-Join Distribution of Prices Across Hospitals: Comparison to
MRG Sample

1200

1400

1600

1800

2000

2200

Price
Pre-join

Pre-join p̄h (within brand-month)
MRG p̄h (within brand-month)

mean
1631
1666

sd
120
149

MRG

cv= σµ
0.07
0.09

20th
%ile
1539
1563

50th
%ile
1607
1651

80th
%ile
1743
1730

NH
143
107

Authors’ calculations from PriceGuide data and MRG survey. Sample restricted to Jan. 2010-Jun. 2013 when
MRG data available. Hospital average prices with brand-month trends removed.

Despite potential selection into our sample, the estimation strategy we employ in this
paper is internally valid in that it exploits the existence of pre/post data and staggered join
dates within the sample of joiners (and uses no non-joiners) to estimate the effect of access
to benchmarking information. These estimates are of direct interest, capturing the benefit of
benchmarking for facilities that seek out such services. We also examine the external validity
of our results, using the MRG sample to extrapolate our estimates to the population of US
hospitals.
A.2

Information Flags

In order to construct each member’s information set upon joining the database and later
upon new brands’ entry, we linked the transactions data with several additional datasets
33

relating each individual login ID with associated members and login activity. The first of
these is a “clickstream” dataset containing timestamped observations of unique IDs’ login
activity, to the minute.30 The second is a membership “hierarchy” file linking individual
database members with parent accounts for those cases where members are part of a set of
health care organizations purchasing membership jointly. The third file associates each login
ID with the given individual’s direct-linked member organization and broader access level –
i.e., the individual with ID X may work with member 1 but have access to the data for all
members 1, 2, and 3 under the same parent organization. For individuals with higher-level
access, data for all associated members is automatically reported to them when they log in to
the database. Accordingly, when we observed a click for a particular login ID, we associated
that click with all linked member organizations for which that login had access.
We used the above-described datasets to determine each date of login for each member.
The goal of this exercise was to determine when benchmarking data on a given brand would
enter each member’s information set. For non-entering stent brands and all product categories in the expanded analyses, this is the date of the first observed login for each member.
For entering stent brands, this is the date of the first observed login for each member after
six months post-entry. This is to account for the lag between transactions occurring for new
brands and transactions being submitted by member facilities, loaded into the database,
and viewed by members logging in. The left panel of Figure A4 displays the steady increase
over time in the count of members for which transactions for the average entering brand
are observed, and demonstrates the lag with which members’ transactions become available
in the database for benchmarking purposes.31 In any given month in the year following
new brand entry, there are on average 56 more members we observe having transactions
for new brands than there are members whose transactions data are actually loaded into
the database. We also observe transactions data for members that have not yet joined the
benchmarking database – in the year following brand entry, 9 percent of members observed
in the average month are pre-join. To see this more concretely, the right panel of Figure A4
displays the trend in the number of hospitals purchasing the average new brand, overall and
for pre-join hospitals in particular. For each new brand, we observe 10-15 hospitals in the
pre-join state within a short window after brand entry, and the time period for our study
contains many meaningful brand introductions. This is precisely what allows us to separately
identify effects of joining the database per se, versus actually having access to information
30

Each login ID corresponds to a unique individual’s account within a member. For example, a given
database member may have had login accounts for a number of different purchasing managers, administrators,
and department clinicians.
31
There may be an additional lag before joining hospitals become informed if they do not frequently log
in to the database.

34

on a particular brand, on prices. In Figure 2 in the main text, we note the timing of entry
of seven new drug-eluting stent brands between 2010 and 2014 (of the thirteen brands sold
during this time period overall).
Figure A4: Transactions Observed After New Brand Entry
(a) Cumulative Members Purchasing

0
5
10
15
Pre-Join Members with Transactions (Mean)

0

0

Members with Prior Transactions (Mean)
50
100
150
200

Sample Members with Transactions (Mean)
50
100
150
200

(b) Members Purchasing, by Join Status

0

3

6
Months after Product Entry
All

9

12

Available for Benchmarking

0

3

6
Months after Product Entry
All

9

12

Pre-Join

Authors’ calculations from PriceGuide data.

We use the linked login and transactions data to calculate each member-brand’s position
in the pre-information price and quantity distributions. All calculations are specific to the
first informed login for the given member-brand, as defined above. Following the approach
used in the database to aggregate data across all members’ transactions and present summary
statistics to members logging in at a point in time, we calculate percentiles of the price
distribution using all members’ most recent transactions for the same brand, in the past year,
that would have been loaded into the database prior to the login. We calculate percentiles
of the quantity distribution using all members’ total quantity purchased per month for the
same brand in the past year. Across all specifications, we consistently include only those
observations that can be used to estimate the richest specification with interactions based on
point in the price and quantity distributions – this requires that we observe pre-information
data for the given member-brand.
This estimation sample for drug-eluting stents includes 395,271 transactions for 508 members and thirteen brands in 72 months between January 2009 and December 2014. Seven
of the included drug-eluting stent brands entered the market during this time horizon. We
collapse the transaction-level data to perform all analyses at the member-brand-month level
(with mean price as the dependent variable). We do this in order to avoid overweighting
member-brands that tend to have multiple transactions per month. The regression sample
35

used in our main analyses focused on drug-eluting coronary stents contains 32,453 memberbrand-month observations.
A.3

Other Important Products

For our work in Section 6, we generated analysis files for a large number of additional product
categories, defined by their UMDNS codes. We restricted to the top 50 categories by spending
or number of transactions, yielding 80 categories total. From these, we excluded categories
that were too broad (e.g., “food item”).32 Next, creating the final analysis file required
two key steps for each product category: (1) rationalizing the multiple units of measure in
which different transactions’ quantities were reported, in order to analyze price for a common
quantity across transactions; and (2) generating brand IDs, in order to appropriately control
for brand-specific price trends.
Regarding the first step, although many medical and surgical product categories are sold
by the unit (a single coronary stent, e.g.), others are sold in pairs, boxes, cases, etc. The
transactions data indicates this distinction in the “unit of measure” field, and further notes
how many subunits are in each unit of measure using a “conversion factor” field. In order
to perform our analyses on the cleanest and most internally-consistent transactions data
possible, we transformed all transactions into price per single unit and quantity of single
units purchased. We also excluded UMDNS codes with inconsistent or missing quantity
data.33
Regarding the second step, the absence of a brand ID in the database creates a problem
of sparsity, in which many SKUs are purchased by only a small number of hospitals, or
in only a small number of months. The method we employed to identify brands within
the coronary stents data involved examining manufacturer catalogs, finding likely brand
names, searching for similar strings within the item description field, and validating SKUs
for those brands against the catalog numbers. This was infeasible in the expanded analysis
for several reasons: the average category has 30 manufacturers and more than 2,000 SKUs;
many manufacturers’ websites were found to be difficult to navigate, particularly once we
extended the analysis beyond high-dollar physician preference items; and the item description
field was often uninformative as to brand. Hence, we used an algorithmic approach to assign
brand IDs for the other product categories.
32

We did this based on “reasonableness” of the observed price variation – categories for which the coefficient of variation in price exceeded 10 were excluded – and selected categories by hand that seemed
excessively broad based on their UMDNS names (e.g., “office supplies”). The list of product categories
excluded by hand is 8889, 99936, 88885, 88884, 88883, 88695, 88539, 88311, 88073, and 16101.
33
Specifically, we excluded UMDNS codes for which the conversion factor (e.g., ten units per box) was
missing more than 1/3 of the time, or for which the modal unit of measure (e.g., “box” vs. “case”) accounted
for less than 50 percent of the data.

36

The algorithm proceeded as follows: within each manufacturer, for each k = 0, ..., K,
where K is the maximum SKU length for the manufacturer under consideration, we generated
a candidate brand ID as the left-most k digits of each SKU. We then regressed price on
dummies for each unique candidate brand ID, interacted with each hospital ID. We recorded
the resulting R2 for each k. The goal of this exercise was to identify brands that generate price
variation in the data: looking within a given hospital, price variation proxies for contract
variation. The R2 is always increasing in k, so the algorithm is meant to choose k opt that
maximizes R2 while keeping the number of identified “brands” relatively manageable. Table
A3 below compares the algorithmic approach to the time-intensive hand-coding approach
for coronary DES stents and for one manufacturer of surgical staplers whose catalog was
available online. The first three rows show the number of brands implied by unique SKUs,
vs. the hand-coding of manufacturer catalogs, vs. the algorithm. We also show the R2
of a regression of price on hospital-brand dummies. The remaining rows show the detailed
brand count and R2 for each SKU digit count k. For the 52 products in our expanded
analysis, we generally found that R2 would climb steeply, then level off after a few SKU
digits. For example, within stent manufacturer 1, R2 increases from 0.42 at one SKU digit
to 0.6 at three SKU digits, but only increases to 0.65 thereafter. Similarly, within linear
surgical staplers, R2 climbs from 0.61 to 0.95 as we move from one to three digits, eventually
reaching a maximum of 0.97. These patterns are consistent with our intuition that the first
few SKU digits would indicate a particular product line, while the last few SKU digits would
indicate finer (and likely unpriced) distinctions such as color or size.
The machine learning literature has many methods for explicitly penalizing excessive
complexity in classification and other modeling exercises. We chose k opt = min{k|R2 (k) >
95%∗R2 (K)}; that is, we erred on the side of allowing for more sparsity and less classification
error. For stents, this implies about ten times as many algorithmically-identified “brands”
than our hand-coding would indicate; for staplers, the algorithm identifies 47 products while
hand-coding indicates 53. Across all product category-manufacturer combinations in Table
A3, the algorithmic brands explain as much price variation as the hand-coded brands, and
mitigates the sparsity problem significantly. For stents (staplers), the number of algorithmic
brands is 88 percent (49 percent) smaller than the number of unique SKUs.
The goal of our expanded analyses is to determine whether the patterns documented for
stents are similar to those we observe for other important purchase categories. To that end,
we employed the same regression specifications as in the stents analyses: (1) We estimate
the average treatment effect of joining the database, for which we find no significant result in
stents. (2) We estimate the average treatment effect of joining the database among all highprice hospital-brands. (3) We estimate the average treatment effect of joining the database
37

Table A3: Performance of Brand-Assignment Algorithm

|J| R2
261 .65
5 .66
47 .62

|J| R2
510 .87
5 .82
54 .84

|J| R2
47 .6
1 .54
23 .58

|J|
350
2
11

R2
.73
.69
.69

Staplers [Nm = 1]
Surgical
Surgical
Linear
|J| R2
|J| R2
40 .97
53 .99
29 .99
24 .96
20 .95
27 .95

1 .42
2 .44
5
.6
5
.6
13 .6
29 .61
47 .62
137 .63
261 .65

1
2
5
8
14
54
112
271
510

1
2
2
8
12
23
46
47
47

4
6
8
9
11
23
43
91
129

.69
.69
.69
.69
.69
.69
.69
.7
.71

8
20
31
40
51
52
53
53
53

Mfg 1

SKU
Hand-coded
Algorithm
k
k
k
k
k
k
k
k
k

=1
=2
=3
=4
=5
=6
=7
=8
=9

Stents [Nm = 4]
Mfg 2
Mfg 3

.42
.73
.82
.82
.83
.84
.85
.86
.87

.54
.54
.54
.56
.56
.58
.6
.6
.6

Mfg 4

.84
.95
.98
.99
.99
.99
.99
.99
.99

7
15
27
31
38
40
40
40
40

.61
.7
.95
.95
.97
.97
.97
.97
.97

specifically among high-price, high-quantity hospital-brands. For the latter two analyses, we
find economically and statistically large effects in stents. We estimate treatment effects of
join only: due to the lack of precise brand data across all product categories, we do not use
brand entry as an additional information shock.
A.3.1

Estimation Sample for Other Important Products

Table A4 shows the effect of each sampling restriction described above on the composition
of facilities in our data. The first column summarizes the full set of 2,110 facilities in our
data, the second shows the set of facilities purchasing the 52 product categories of interest,
the third removes facilities missing conversion factor data or purchasing in non-standard
units of measure, and the fourth removes facilities missing “brand” data and/or login data.
The fifth column summarizes the final regression sample of facilities for which we were able
to flag hospital-brands’ positions in the pre-join price and quantity distribution. At each
restriction, we tend to remove small facilities and non-hospitals. The final regression sample
contains 775 facilities, 73 percent of which were hospitals or health systems, spending $1.8
million per month on 774 product categories.34
34

One might expect “Restriction 1” to remove only a small number of facilities, as all health care facilities
would be expected to purchase commodity products. The removal of a large number of facilities in that
cut is due to our reliance on the UMDNS code to identify product categories – if some transactions in a
facility’s materials management database were recorded in such a way that UMDNS codes could not readily
be assigned upon database upload, then it will likely not appear in our analytic sample.

38

Table A4: Summary Statistics from Purchase Order Database

Months of Data
Product Categories
Total Spend/Month ($m)
% Hospital & Health System

Full Sample

Restriction 1

Restriction 2

Restriction 3

[N=2,110]
SD
Mean
31.2
21.2
462.1
502.7
1.1
2.7
0.48
0.50

[N= 1,605]
Mean
SD
34.5
21.1
605.5
496.2
1.5
3.1
0.61
0.49

[N=1,491]
Mean
SD
35.0
21.2
649.3
487.8
1.6
3.1
0.65
0.48

[N= 1,388]
Mean
SD
36.7
20.9
670.1
488.3
1.6
2.6
0.67
0.47

Regression
Sample
[N= 775]
Mean
SD
41.4
21.4
774.0
487.9
1.8
2.7
0.73
0.44

Authors’ calculations from PriceGuide data, 2009-2014.

Figure A5 below compares the distribution of the expanded sample of database members
to the general acute care hospitals in the AHA survey data. The patterns presented above
for stent purchasers are largely present here as well: database members in our sample are
underrepresented in the south and somewhat larger than the average US general acute care
hospital.

Figure A5: Distribution of Benchmarking Database vs. Comparison Hospitals
– All Facilities Purchasing “Important” Products
(b) By Bed Size

Percent
0

0

.1

.2

Percent
.2

.4

.3

.4

.6

(a) Across Census Regions

Midwest

Northeast

South

West

0-99

100-199

200-299

Census Region
Extended Sample

300-399

400-499

500+

Bed Size

AHA Comparison Sample

Extended Sample

AHA Comparison Sample

Database sample computations from PriceGuide data, 2009-2014. AHA sample computations from American
Hospital Association Annual Survey of Hospitals, 2012; includes all general acute care hospitals.

The hospital-brand-month level regression sample data are summarized for each product
category in Table A5. The Table also shows aggregates at the product class level.35 All
35

As discussed in Section 6, Class 1 is “commodities”: relatively inexpensive products that are unlikely
to be chosen primarily by physicians; e.g., surgical gloves. Class 3 is “physician preference items”: high-tech
medical devices, mainly coronary and orthopedic products that are the primary implanted device in their
corresponding surgical procedures; e.g., coronary stents. Class 2 is intermediate: other medical/surgical
products used during invasive procedures, but explicitly excluding PPIs. Note that each row’s data is within
the set of hospitals with nonzero purchase in that category or class; i.e., average spending on bandages is
within 481 hospitals whose bandage transactions we observe, whereas average spending on all commodities

39

together, top commodities account for 2 percent of hospital spend, vs. 21 percent for top
PPIs, and 13 percent for other medical/surgical products. This is consistent with the large
discrepancies in their pricing: the average unit price of a commodity is $74, vs. $2,032
for PPIs. Interestingly, we see similar degrees of price dispersion for commodities as we do
for other medical/surgical products and PPIs – coefficients of variation across hospitals are
0.195, 0.166, and 0.188, respectively – hinting that physician preference alone cannot account
for observed dispersion. Finally, note that the drug-eluting stent sample in Table A5 differs
from the sample used in the main analyses in the draft because of the focus on join timing
for identification of information effects: hospital-brands such that the brand enters after the
hospital joins the database have no pre-information data and thus fall out of the analysis.
However, average monthly spend and quantity for this subset of stent-purchasing hospitals
is similar to our main stent sample.

B

Mapping of Bargaining Setting into Models of Asymmetric Information and Agency

Here we elaborate on the concise theory sections of the main text.
B.1

Asymmetric Information about Supplier Bargaining Parameters

We follow Rubinstein (1985) to model uncertainty of hospital buyers about the bargaining
parameter of a given supplier. The model departs from the complete information model
in Rubinstein (1982) in that the supplier is either of weak type with discount factor δwS or
strong type with discount factor δsS (1 > δsS > δwS > 0). The supplier knows his own type,
but the buyer has only a subjective prior ωw of the probability that the supplier is the weak
type.
The equilibrium split of this surplus depends on both the type of the supplier and the
prior of the buyer as follows: Rubinstein (1985) shows that there exists a cutoff prior ω ∗ such
that if the buyer is sufficiently pessimistic about the seller being the weak type ωw < ω ∗ ,
then the buyer simply offers what she would offer the strong type in a complete information
will include 267 hospitals whose bandage transactions we do not observe. As noted previously, the fact that
we do not observe all facilities purchasing every commodity product is due to our reliance on the UMDNS
code to identify product categories – if some transactions in a facility’s materials management database were
recorded in such a way that UMDNS codes could not readily be assigned upon database upload, then it will
likely not appear in our analytic sample.

40

Table A5: Summary of important product categories
ID

Name

Bandages Elastic
Dressings
Gloves Surgical
Drapes Surgical
Needles Injection Hypodermic
Containers Specimen
Drill Bits
Commodities
10688 Catheters Vascular Angiography
10894 Clip Appliers
11502 Forceps Electrosurgical
11910 Grafts Bone
11925 Guide Wires
12830 Orthopedic Cement
13050 Plates Bone
13909 Sutures Synthetic Nonabsorbable Polypropylene
13910 Sutures Natural Nonabsorbable Silk
14085 Tubes Tracheal
16071 Lenses Intraocular Posterior Chamber
16078 Nails Bone
16104 Wires Bone
16655 Catheters Cardiac Ablation
17184 Catheters Vascular Angioplasty Balloon
17471 Sutures Synthetic Absorbable Polyglactin
17600 Bone Matrix Implants
17846 Catheters Vascular Guiding
18609 Catheters Cardiac Mapping/Ablation
20317 Staplers Surgical
20318 Staplers Surgical Linear
20453 Stent/Grafts Vascular Aortic
22538 Suture Anchors
22908 Sutures Synthetic Nonabsorbable Nylon Monofilament
34196 Screws Bone Spinal
Other Med/Surg
12324 Lenses Intraocular
12913 Pacemakers Cardiac Implantable
15766 Orthopedic Internal Fixation Systems Spinal
15870 Prostheses Cardiac Valve Biological
16040 Stents Ureteral
16084 Prostheses Joint Hip Acetabular Component
16095 Prostheses Joint Hip Femoral Component
16097 Prostheses Joint Knee Femoral Component
16098 Prostheses Joint Knee Tibial Component
16111 Prostheses Mammary Internal
16921 Prostheses Joint Shoulder Humeral Component
17165 Allografts
17241 Stimulators Electrical Spinal Cord Analgesic
18253 Grafts Skin Biological
18504 Defrib/Pacemakers Implantable
20376 Defrib/Pacemakers Implantable Resynchronization
20383 Stents Vascular Coronary Drug-Eluting
20422 Stents Vascular Coronary Balloon-Expandable
22543 Occluders Vascular Intravascular Embolization Coil
923150 Orthopedic Fixation Systems Implantable Spine
PPIs
10279
11315
11883
12368
12745
13655
923840

Class
1
1
1
1
1
1
1
1
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
3
3
3
3
3
3
3
3
3
3
3
3
3
3
3
3
3
3
3
3
3

Spendhy
$
%

Njht

Nh

0.0
11,237
23,216
481
0.2
44,105
42,514
581
0.6
107,187
51,660
579
0.2
47,462
76,910
565
0.1
22,351
66,170
618
0.2
43,895
28,761
496
0.5
91,421
227,351 573
1.9
277,910
516,582 748
0.1
38,249
46,764
420
0.5
118,993
26,179
499
0.4
108,463
10,689
302
1.3
377,912
34,324
471
1.1
192,401
189,814 592
0.5
110,897
21,954
466
1.4
300,071
198,059 570
0.2
42,126
98,186
572
0.1
19,211
54,640
502
0.2
34,726
34,323
525
0.1
76,046
15,621
268
0.6
133,181
51,900
482
0.1
22,144
41,367
535
0.4
187,729
17,711
256
1.1
276,092
139,972 449
0.4
69,078
78,022
605
0.5
93,743
28,302
475
0.6
105,814
71,039
430
0.6
208,145
10,742
208
0.6
140,430
19,993
400
0.4
110,985
21,776
423
1.0
303,258
11,376
290
0.5
95,811
31,637
526
0.1
15,805
85,860
596
0.5
296,353
4,265
67
13.2 1,981,568 1,344,515 701
0.1
44,309
11,372
279
1.7
543,311
29,907
392
0.9
338,861
62,248
392
1.0
463,734
13,737
249
0.1
30,037
29,097
480
0.8
247,393
61,747
457
1.3
375,090
97,347
467
1.5
405,992
61,277
461
1.3
364,878
110,185 469
0.6
166,975
37,651
373
0.4
118,044
21,559
394
0.6
157,176
27,301
483
0.8
310,908
5,693
284
0.4
135,230
6,857
342
2.0
851,354
7,212
280
2.3 1,007,055
5,331
264
2.9 1,132,582
15,529
336
0.3
142,779
46,854
334
0.4
112,271
17,407
304
1.5
476,814
35,243
362
20.9 4,314,551 703,554 601

41

Nj

Qhy

phjt

81
3,176
3
151
10,492
10
49
48,532
2
171
7,235
7
61
100,657
0
88
49,321
3
1,192
610
162
1,793 166,520
74
144
982
27
18
629
118
113
137
1,770
290
136
2,638
859
1,528
82
85
306
341
3,205
411
724
300
3,950
15
73
4,532
4
102
4,428
7
184
495
161
457
96
1,424
376
214
110
85
165
1,020
641
1,202
291
51
14,241
9
266
137
751
380
1,169
157
134
173
1,418
80
421
355
47
635
150
130
54
5,581
217
223
319
179
3,425
6
442
545
695
8,858 29,572
415
121
301
365
126
107
4,316
1,256
566
628
37
301
5,699
80
218
137
621
200
1,294
998
236
1,568
553
197
2,474
1,304
307
1,259
223
211
815
273
52
2,424
608
94
1,638
19
23
15,249
65
201
2,916
180
51
16,415
109
45
21,199
13
606
1,623
200
157
720
319
179
769
975
148
3,235
8,080 2,298
2,032

CV (ph|jt )
0.226
0.238
0.158
0.191
0.156
0.333
0.166
0.195
0.126
0.170
0.115
0.124
0.158
0.199
0.158
0.140
0.262
0.217
0.092
0.154
0.189
0.127
0.131
0.587
0.179
0.177
0.123
0.216
0.245
0.050
0.155
0.181
0.198
0.166
0.138
0.136
0.237
0.131
0.117
0.242
0.244
0.189
0.201
0.111
0.185
0.155
0.104
0.087
0.125
0.122
0.080
0.110
0.101
0.177
0.188

game of Rubinstein (1982):
pAI (ωw < ω ∗ ) := c + δsS

1 − δB
V,
1 − δ B δsS

(2)

and both seller types accept this offer. However, if the buyer is more optimistic about the
probability that the seller is the weak type (ωw ≥ ω ∗ ), then the buyer offers:
2

pAI
w (ωw

∗

≥ ω ) := c +

δwS

1 − δ B (1 − ωw ) − δ B ωw
V,
1 − δ B 2 (1 − ωw ) − δ B δwS ωw

(3)

which the weak seller type accepts. The strong seller type will reject this offer, and counteroffer with a price that would make a weak seller no better off than pAI
w , but that the
strong seller strictly prefers:
2

∗
pAI
s (ωw ≥ ω ) := c +

1 − δ B (1 − ωw ) − δ B ωw
V,
1 − δ B 2 (1 − ωw ) − δ B δwS ωw

(4)

which the buyer accepts.
This equilibrium has direct implications for what we would expect to happen to prices
in a move from this type of asymmetric information to complete information. First, note
CI
∗
CI
∗
AI
AI
∗
AI
(pCI
that pCI
w ) is the
s = p (ωw < ω ) > ps (ωw ≥ ω ) > pw (ωw ≥ ω ) > pw (where ps
equilibrium price for the strong (weak) supplier type with complete information). Thus the
weak type seller is strictly better off with asymmetric information. The strong type seller is
weakly worse off (strictly whenever the buyer’s prior is sufficiently optimistic). A sufficiently
pessimistic buyer is also weakly worse off without information. For more optimistic buyers,
whether information would make them better off ex-ante depends on parameter values.
In our context we are interested in when a buyer might benefit from benchmarking
information that reveals the seller’s type, and what would happen to price in such a case.
For simplicity, we assume that this information fully reveals a seller’s type, though the
qualitative results can be extended to a signal extraction problem where the information
moves the buyer’s prior in the direction of the truth. The intuition for how this unfolds in
practice is a scenario where a manufacturer sales representative says “This is the best price
I can offer. Corporate won’t let me go any lower.” Benchmarking information allows the
hospital negotiator to perform the due diligence of checking the prices at other hospitals in
order to verify or refute this statement.
Prediction 1 (Direct Information Effect on High Prices) If information is costless,
pessimistic buyers will always become informed. This information will cause a propor42

CI
tion of the highest prices pCI
s to fall to pw for those cases where the supplier was in
fact the weak type. Thus exposure to benchmarking information should lead to some
of the highest prices falling.

Prediction 2 (Direct Information Effect on High Prices with High Quantity) If information is costly to obtain (in the sense that searching and analyzing the data takes
time that could be used on other productive activity), a pessimistic buyer will become
CI
informed whenever the expected benefit ωw (pCI
s −pw )q exceeds the cost of information.
CI
This information will cause a proportion of the highest prices pCI
s to fall to pw for those
cases where the supplier was in fact the weak type. Thus exposure to benchmarking
information should lead to some of the highest prices falling, among those brands with
the highest quantity used.
Prediction 2b (Indirect Information/Competition Effect on All Prices) With imperfect substitute products, under reasonable assumptions on how the negotiation for
one brand affects the disagreement payoff of other brand negotiations, a fall in price
of substitute brand j will decrease the surplus up for negotiation for other brands −j,
leading to a decrease in the prices of other brands −j, all else equal.36 Thus exposure
to benchmarking information that leads to a fall in a high price for j should also lead
to a fall in any price for other brands −j, and the size of this fall will be increasing to
the extent the brands are good substitutes for j.
B.2

Negotiator Agency

The other candidate mechanism via which we propose benchmarking information could be
valuable to buyers would be through providing aggregate information to help the buying
firm solve a moral hazard problem with its purchasing agent. Here we provide a specific
model of information in the bargaining context that generates predictions in our setting.
Modifying Holmstrom (1982) to our context, let price ph at hospital h be as in the full
information Rubinstein bargaining game. However, instead of the hospital negotiator’s bargaining parameter being exogenous, the price will be a function of the hospital agent’s choice
of discount factor δhB and the discount factor of the supplier, which takes value δwS h with
probability ωw and δsS h with probability 1 − ωw . As before, the discount factor of the strong
supplier type is greater than that of the weak type (1 > δsS > δwS > 0). h is a random term
36

This will be the case in any model where disagreement payoffs are a function of the prices agreed to
with other manufacturers, which has been the case in the empirical bargaining literature thus far and much
of the negotiation with externalities theory. It would not be the case in a model such as the Core, where
disagreements are based on the primitives of willingness-to-pay and costs.

43

distributed uniform on [0, 1]. Importantly, the realization of h is independent across hospital
buyers, but whether the seller is weak or strong is common to all buyers. The realizations
of both of these random variables are observable to the negotiating agents, but not to the
principals who manage them.
A moral hazard problem arises in this setting because bargaining effort is costly and
provides the agent disutility v(δhB ). The agent is compensated by some contract based on the
price m(ph ). The agent is risk averse in money, so the optimal solution to the agency problem
involves risk sharing between the principal and the agent. Holmstrom (1982) shows that if
agents face some common parameter which is uncertain from the principals’ perspectives,
then relative performance evaluation compared to some aggregate sufficient statistic can be
used to write a better contract with each agent. The intuition in our real-world setting is
one where with the benchmarking data, hospital administrators can make their negotiators’
performance reviews contingent on the prices they negotiate relative to other hospitals for
the same brand. This motivates the following Predictions:
Prediction 3 (Monitoring Effect on Prices) If buyer negotiators are imperfect agents
of the buying firm, then benchmarking information (observing the distribution of price
realizations across hospitals {ph }H
h=1 ) allows the principal to estimate whether the seller
is the weak or strong type, and thus reduce the risk to which the agent is exposed and
write a contract which induces more bargaining effort and a lower price than in the
case where only ph is observed.37
Prediction 4 (Monitoring Effect on Prices with High Quantity) If buyer negotiators
are imperfect agents of the buying firm, but it is costly for hospital managers to
search and analyze the data in a way that allows them to write better contracts, then
managers will use benchmarking information (observing the distribution of price realizations across hospitals {ph }H
h=1 ) to write a contract which induces more bargaining
effort by the agent and a lower price than in the case where only ph is observed if
(ph (m) − ph (m({ph }H
h=1 )))qh exceeds the cost of information use.

C

Details on the Contracting Environment

In this Appendix, we provide some additional background on how medical devices are used
and purchased, and we provide additional evidence regarding the validity of our assumptions
37

The model as written has a strong prediction that this effect will be independent of price. However,
in general the prediction of how the price distribution would move with information depends on where in
the model the current heterogeneity is coming from. For example, if the heterogeneity were due to different
levels of risk aversion among negotiators, then benchmarking information would tend to decrease the highest
prices more than the lowest.

44

and potential mechanisms.
C.1

Stent Usage and Purchasing

The main product category we analyze is coronary stents; coronary stents are small metal
tubes placed into narrowed coronary arteries to widen them and allow blood flow to the
heart.38 In the US, hospitals spend more than two billion dollars annually on stents used in
over 700,000 procedures.39
For stents, as for other physician preference technologies, usage is driven by physicians
choosing which brand to use to treat a given patient, while prices are determined in negotiation between a hospital administrator and a representative of the brand’s manufacturer.40
There is no “search” in the conventional sense, as a given brand can only be purchased
directly from its manufacturer. The manufacturer holds inventory on-site at the hospital,
and the purchase is made when the physician pulls the product off the shelf and implants it
into the patient.
Stent contracts typically specify a linear price for the contract duration, often a year. In
the short run, hospitals are reimbursed a fixed amount by private or public insurers based
on the services they provide, and so device prices come directly from the hospital’s bottom
line. In our conversations with industry participants, the purchasing practices via which
these contracts are negotiated vary widely across organizations. Some hospitals have large
materials management or purchasing departments with agents who specialize in negotiations.
Sometimes a large business unit, such as a catheter lab in the case of stents, will coordinate its
own purchasing separately from the rest of the hospital. Even absent access to benchmarking
information, hospitals vary in access to information on the prices other hospitals pay via
GPOs, hospital system membership, or informal networks of peers.
C.2

Compensation of Purchasing Agents

In this Appendix, we use survey and interview data to explore the agency hypothesis. First,
we have obtained access to management practices survey data for a large sample of hospital
38

The original technology, the bare metal stent (BMS), was approved in the early 1990s; in the early
2000s, the drug-eluting stent (DES) was introduced as an improvement over the older technology with lower
risk of restenosis, a condition that may arise when scar tissue builds up around the stent and restricts blood
flow yet again.
39
700,000 estimate from Waldman et al. (2013), referencing stent procedures in Medicare enrollee population. Two billion dollar figure based on authors’ calculations using Boston Scientific’s reported US revenue
in 2012 (BSX 10-K 2012) and Boston Scientific’s 2012 market share in purchase order data.
40
Hospitals typically rely on the services of group purchasing organizations (GPOs) to negotiate contracts
for many products, but GPO prices are used as a starting point for direct hospital-manufacturer negotiations
for physician preference items and capital equipment (Schneller 2009).

45

cardiac units from McConnell et al. (2013). Second, we have conducted interviews with three
different types of hospitals regarding their purchasing practices, contracting with purchasers,
and the interaction of these with using benchmarking information.
McConnell et al. (2013) developed a survey instrument, adapted from “lean manufacturing” surveys, to measure management practices in the cardiac inpatient setting. The survey
included open-ended questions on standardization, performance monitoring, setting targets,
and incentivizing employees and managers. Many of these questions shed light on how staff
in cardiac units are tracked and rewarded. Those that are most relevant for the current
setting are the following (in each case, we summarize the “best case scenario”):
• Technology Adoption Score 5: “There is a systematic approach in the adoption of
all new technologies, including a review of best evidence on costs and effectiveness;
unit may participate in learning collaborative to accelerate information gathering.”
• Performance Review “Performance is continually reviewed, based on the indicators
tracked; all aspects are followed up to ensure continuous improvement; results are
communicated to all staff.”
• Target Stretch: “Goals are genuinely demanding for all parts of the organization
and developed in consultation with senior staff (eg, to adjust external benchmarks
appropriately).”
• Rewarding High Performers: “There is an evaluation system for the awarding of
performance related rewards, including personal financial rewards and shared group/team
rewards.”
• Removing Poor Performers: “We work hard to identify weaknesses and improve
or remove poor performers.”
Each survey answer was scored on a scale of 1 to 5, with 5 corresponding to the “best”
answer as described above. Cardiac units were heterogeneous in their responses to these
questions, suggesting that the ex ante potential for our “moral hazard” mechanism would
be limited to a small number of hospitals in our data. The raw scores are summarized
in Table A6. First, they suggest that only 33 percent of units received a 4 or 5 on the
technology adoption question – while not touching on incentives explicitly, this question
characterizes the extent to which cost-effective input use is an objective of the unit. Second,
more than half of units received a 4 or 5 on the performance review question. Together, these
findings imply that only a small subset of cardiac units might both prioritize cost-effective
purchasing and review performance on that metric. Finally, the percent of respondents
46

scoring a 4 or 5 on the target stretch (i.e., external benchmarks), rewarding high performers,
and removing poor performers questions ranged from 20-27 percent. In our view, this paints a
relatively pessimistic picture of the potential role of performance pay based on benchmarking
to mitigate moral hazard in our setting.
Table A6: Proportion of answers to five practice-related questions in %

1-worst

2

3

4

5-best

Technology adoption
Performance review
Target stretch

8
1
8

15
12
28

44
33
37

26
40
23

8
14
4

Rewarding high performers
Removing poor performers

20
9

19
30

40
36

16
21

4
3

Raw interview score tabulations shared by K. J. McConnell; summary data
reported in McConnell et al. (2013).

We also interviewed several representatives of hospital purchasing departments. Each interviewee worked within the central purchasing unit of a hospital or hospital system and was
asked about use of external benchmarking data in employee compensation. One interviewee
worked within a large regional hospital system, one within a large urban academic medical
center, and one within a small community hospital. Our interview with the representative
of the large regional hospital chain indicated that the central purchasing manager regularly
makes individual business units aware of opportunities for savings based on external benchmarking, and that annual performance evaluation involves discussion of the prior year’s
accomplishments, including savings on medical supplies. Staff are also eligible to receive
small bonuses (around $300) for particularly strong performance, akin to employee-of-themonth recognition. Our interview with the representative of the academic medical center
described performance pay for purchasing staff in a similarly holistic way: each contract
manager is evaluated periodically based on general performance on his/her overall portfolio
of contracts, with dimensions including timely execution of contracts, management of contracts, and “savings they drive.” In each of these interviews with representatives of large
purchasers, we learned that benchmarking data provide information on savings achieved
by contract managers and that annual performance is evaluated in part based on savings,
but there is no formal or specific link between compensation and performance relative to
metrics from benchmarking resources. The interview with the small community hospital
indicated that pricing information was primarily obtained from the hospital’s GPO and a
small regional purchasing collaborative; that hospital was in the process of transitioning to
a subscription benchmarking service, but did not mention employee performance evaluation
47

as a goal of that subscription.
In sum, our understanding is that benchmarking can be part of a purchasing agent’s
overall performance evaluation, consistent with the theoretical benefit of benchmarking to
resolve moral hazard problems. However, both large-sample surveys of cardiac units and our
in-depth interviews of purchasing units indicate that reliance on benchmarking to evaluate
purchasing employees is heterogeneous and informal, consistent with our finding that asymmetric information can account for the overall effect of transparency on price realizations.
C.3

Evidence Regarding Linear Price Assumption

It is important for our analysis that the prices we observe are comparable across observations
in the sense that there are not important contract dimensions that we do not observe (e.g.,
bundling, exclusivity, or market share based contracting). Our conversations with industry
participants indicate that stents tend to have simple linear price contracts, so we assume
that transactions data capture real prices. Here, we examine these assumptions in the data.
C.3.1

Extent of “exclusivity” and correlations with prices

In panels (a) and (c) of Figure A6, we show histograms of total unique manufacturers and
stent products (brands) purchased over each quarter by each hospital in the sample. The
vast majority of hospitals purchase multiple brands from multiple manufacturers, rather than
purchasing a single most-preferred brand for the whole facility. Panels (b) and (d) show these
histograms for only hospitals above the 25th percentile in total stent volume, and show even
less evidence of “exclusivity” – fewer than 3 percent of hospital-quarters involve a single
brand and fewer than 7 percent involve a single manufacturer. The fact that the majority of
the already small amount of observed “exclusivity” occurs at hospitals with lower utilization
is consistent with the anecdotal evidence that exclusivity does not play a systematic role
in stent contracting – with true linear price contracts, “exclusive” purchasing patterns are
more likely to be observed among hospitals with low utilization due to random variation and
costly contracting.
As a further check, we look at the pricing consequences of the observed sole sourcing in
the usage data. For the minority of hospitals that do happen to use only a single brand
or manufacturer in a given quarter, we create an indicators for 1{|Jht |=1} and 1{|Mht |=1}
and regress price on each indicator and brand-month fixed effects θjt . The only negative
and statistically significant result is a $15.90 lower price associated with manufacturer sole
sourcing when hospital fixed effects are included. This is consistent with a small price
savings from “standardization,” holding the hospital fixed. However, the result goes away

48

Figure A6: Histograms – Number of Unique Brands/Manufacturers per Hospital-Quarter
(b) Brands (excluding smallest hospitals)

Fraction of Hospital-Quarters
.05
.1
.15
0

0

Fraction of Hospital-Quarters
.05
.1
.15

.2

.2

(a) Brands

1

2

3
4
5
6
7
8
9
10
Number of Unique Products (per Hospital-Quarter)

11

1

2

3
4
5
6
7
8
9
10
Number of Unique Products (per Hospital-Quarter)

(d) Manufacturers (excluding smallest hospitals)
.6
Fraction of Hospital-Quarters
.2
.4
0

0

Fraction of Hospital-Quarters
.2
.4

.6

(c) Manufacturers

1
2
3
4
Number of Unique Manufacturers (per Hospital-Quarter)

1
2
3
4
Number of Unique Manufacturers (per Hospital-Quarter)

Regressions of price on indicators for exclusivity:
Specification
β Excl
Excl
phjt = β
1{|Jht |=1} + θjt + hjt
25.3†
Excl
13.2
phjt = β
1{|Jht |=1} + θjt + θh + hjt
-2.9
phjt = β Excl 1{|Jht |=1} + θjt + θhj + hjt
8.6
phjt = β Excl 1{|Mht |=1} + θjt + hjt
−15.9∗∗
phjt = β Excl 1{|Mht |=1} + θjt + θh + hjt
-4.2
phjt = β Excl 1{|Mht |=1} +θjt +θhj +hjt

(s.e.)
(9.0)
(9.5)
(8.0)
(9.4)
(6.5)
(6.8)

Authors’ calculations from PriceGuide data, 2009-2014. N = 32, 223. Standard errors
clustered at hospital level, Nh = 507 in first two specifications and hospital-brand level
Nhj = 2, 227 in brand-hospital fixed effects specification. Superscript (†) indicates
significant difference from zero at the 1% level; (**) at the 5% level; (*) at the 10% level.

49

11

when including hospital-brand fixed effects, so the $16 result appears to be either spurious or
driven by composition effects. We conclude that the small amount of sole sourcing observed
is most likely due to other factors besides contracting concerns.
Finally, we check for any evidence of near-exclusivity in the form of market share based
contracts (which we are told are commonly used for many medical products, but not stents).
Figure A7 plots the cumulative density of observations by brand market share at the hospitalquarter level. We do not observe the bunching that we would expect if contracts commonly
specified market share thresholds in either the full sample (panel (a)) or restricting to the
most used brand at each hospital (panel (b)). We also rerun the “exclusivity” price regressions using cases where market shares exceed 90 percent, i.e. 1{sjht >0.90} , and find no
economically or statistically meaningful relationship with prices.
Figure A7: Cumulative distributions by market share
(b) Most Used Brands Only
1
Cumulative Fraction of Hospital-Quarters
.2
.4
.6
.8
0

0

Cumulative Fraction of Hospital-Quarters
.2
.4
.6
.8

1

(a) All

0

.2

.4
.6
.8
Product Share (Product-Hospital-Quarter)

1

0

.2
.4
.6
.8
Share of Most Used Product (Hospital-Quarter)

Regressions of price on indicators for exclusivity (share-based contracts):
Specification
(s.e.)
β Excl
Excl
12.2
(11.5)
phjt = β
1{|Jht |=1} + θjt + hjt
-9.4
(10.7)
phjt = β Excl 1{|Jht |=1} + θjt + θh + hjt
-2.9
(8.0)
phjt = β Excl 1{|Jht |=1} + θjt + θhj + hjt
18.3
(13.5)
phjt = β Excl 1{|Mht |=1} + θjt + hjt
-7.5
(9.9)
phjt = β Excl 1{|Mht |=1} + θjt + θh + hjt
-4.2
(6.8)
phjt = β Excl 1{|Mht |=1} +θjt +θhj +hjt
Authors’ calculations from PriceGuide data, 2009-2014. N = 32, 223. Standard errors
clustered at hospital level, Nh = 507 in first two specifications and hospital-brand level
Nhj = 2, 227 in brand-hospital fixed effects specification. Superscript (†) indicates
significant difference from zero at the 1% level; (**) at the 5% level; (*) at the 10% level.

50

1

C.3.2

Standard offers and multipliers/bundling

Many real-world bargaining settings have “list prices” as a starting point for negotiations.
Sometimes these prices are in practice paid by almost no one, and so less relevant to the
bargaining problem. Sometimes they are paid by a large mass of smaller customers. They
may also act as a starting point for a negotiation of a single “multiplier” that would modify
the list prices across a variety of products sold by the supplier to the buyer. Our understanding from talking to both buyers and suppliers in the coronary stent market is that
these practices are not prevalent. Here we examine the data to verify this understanding
and better understand the nature of price setting.
Figure A8: Histograms of prices across hospitals for each brand in January 2012

Jan 2012: DES2

0

0

.05

Proportion of hospitals
.05
.1

Proportion of hospitals
.1
.15

.2

.15

Jan 2012: DES1

1400

1500

1600
1700
price paid

1800

1900

1400

1600

1800

2000

price paid

Jan 2012: DES4

0

0

.05

.05

Proportion of hospitals
.1
.15

Proportion of hospitals
.1
.15

.2

.2

Jan 2012: DES3

1400

1500

1600
price paid

1700

1800

1400

1600

1800
price paid

2000

2200

Figure A8 plots the price distributions across hospitals for each of four DES sold to at
least 100 hospitals in January 2012. While the contracted prices do aggregate at the “round”
$50 increments, they do so in a way that appears to approximate single-peaked distributions
that are smooth in the sense of no mass suggesting an obvious focal price standing out from
the rest. In particular, they do not show evidence of a list price at the top paid by a large
51

subset of customers. These figures are representative of the price distributions for DES across
hospitals in other time periods.
Table A7: Price Co-movement at the Manufacturer-Hospital Level
1{∆p6=0} (DES)

(1)

1{∆p6=0} (BMS)

0.165†
(0.0186)

(2)

0.0569†
(0.0202)

1{∆p6=0} (Guiding Cath)
1{∆p6=0} (Guide Wires)
R2

(3)

0.00630
(0.0167)
0.033

0.004

0.000

∆p (DES)

(1)

(2)

(3)

∆p (BMS)

0.0552†
(0.0166)

∆p (Guiding Cath)

-0.000177
(0.00611)

∆p (Guide Wires)
R2

-0.000987
(0.00108)
0.005

0.000

0.000

N = 4, 874 manufacturer-hospital-month observations. Standard errors in
parentheses, clustered by hospital. Nh = 434. Superscript (†) indicates significant
difference from zero at the 1% level; (**) at the 5% level; (*) at the 10% level.

Table A7 explores the extent to which prices move together for products sold by the
same manufacturer to the same hospital. We flag price changes (using the same algorithm
for identifying price changes for our renegotiation analysis) for DES, BMS, Guiding Catheters
(CVG), and Guide Wires (GW) – all of these product categories are used together in interventional cardiology procedures and sold by the same manufacturers, and potentially even
sold via the same sales force.41 We then merge the four data sets at the manufacturerhospital-month level, keeping the most purchased brand for each manufacturer-hospital pair
to ensure at most one observation in a category. The top panel of the table then regresses the
flag for DES price change on the flag for a price change in each of the three other categories
(e.g. 1{∆pdes
= β0 + β1 1{∆pbms
+ ). The interpretation of the coefficient β1 is then the
mht 6=0}
mht 6=0}
percentage of hospital-manufacturer-months in which price changes for the other cardiology
device category are accompanied by price changes in DES, and R2 is then the percentage of
price co-movement overall – in the case of perfect co-movement, β1 = 1 and R2 = 1. The
41

Guiding Catheters and Guide Wires are used in catheter-based interventional procedures outside of
the coronary and even vascular settings, and so used by physicians outside of interventional cardiology.
Depending on the hospital and manufacturer, these could be sold via separate channels.

52

results indicate that DES prices change 16.5 percent of the times BMS prices change and
5.7 percent of the times catheter prices change, but rarely with guide wires. R2 are also
an order of magnitude smaller for other product categories than for BMS, indicating DES
prices often change when other category prices do not.
The bottom panel of Table A7 shows the output of similar regressions but using the
bms
actual magnitudes of price changes (e.g. ∆pdes
mht = β0 + β1 ∆pmht + ) to understand the direction and magnitude of co-movements. Here the only statistically significant result is that a 1
dollar increase in BMS price is correlated with a 0.06 dollar increase in DES price (inflating
by the top panel coefficient to condition on co-movement raises this to 0.055/0.165 = 0.33
dollars). Our interpretation of these results is that both the degree and magnitude of price
co-movements are small. This seems inconsistent with a model of a multiplier on list prices
negotiated across many product categories, where we would expect large degrees of positive
correlation in the incidence and magnitude of price changes. It is also inconsistent with most
models of bundled pricing. The moderate correlation in DES and BMS price change magnitudes conditional on co-movement would be consistent with models of correlated preference
and/or bargaining parameters at the hospital-manufacturer level for these two categories.

D

Stent Analyses – Detail and Robustness

D.1

Stent Analyses in Text – Detail and Alternative Controls

The differences in differences estimate of the average treatment effect of access to information
is small, statistically and economically, at -$3 (s.e. 3). Here, we also use an event study
specification that includes indicators for each month relative to the hospital’s “info” date:
Phjt =

+12
X

β Inf o,mo ∗ 1{mo=t−tinf ohj } + θhj + θt + γj ∗ (t − tminj ) + εhjt

mo=−12

Figure A9 shows results for these estimated differences between treated and untreated
prices. The plot shows evidence of a slight decline in prices prior to accessing information,
though the pre-trends in price in the six months leading up to the timing of information
are essentially zero.42 After the hospital accesses the benchmarking information, there is a
steady downward trend in the coefficients. The downward trend in the post-period may be
42

It should be noted that there are fewer “pre-info” observations available 6-12 months prior to accessing
information because of the presence of entering brands and because some hospitals do not submit retrospective data until a few months after joining the database. Accordingly, the earlier relative month effects are
less precisely estimated.

53

due to price stickiness – it may take newly-informed hospitals some time to arrive at the
bargaining table.
In general, estimates for each relative month effect are insignificant and there is not
strong evidence of a trend break. Moreover, estimated patterns are similar across the different
specifications of controls, though standard errors are large in the richest specification (Version
3).43
Figures A10 and A11 show the same information as in Figure 3 in the main text, but
allowing for alternative specifications of fixed effects. As with the overall average treatment
effects, the estimates are significantly smaller when we control for hospital-by-brand (rather
than hospital and brand) fixed effects. However, we see the same qualitative pattern regardless of controls: the treatment effects are statistically zero in all but the top quintile of the
pre-information price distribution, the previously high-priced hospital-brands achieve significant price decreases in the presence of benchmarking information, and these price decreases
manifest somewhat slowly after the initial information shock.
The following three Figures show how the specifications in Table 2, each of which explores
the mechanisms underlying the core results for drug-eluting stents, vary with the included
controls. Figure A12 shows how the distribution of treatment effects as a function of preinformation price vary by whether the hospital-brand involved high or low purchase quantities
pre-information. Figure A13 explores whether our treatment effects can be attributed to the
agency vs. asymmetric information hypotheses. Finally, Figure A14 shows the effects of
information on renegotiation per se, as well as the effects of information on price decreases
conditional on renegotiation taking place.

43

It was not possible to estimate the monthly event studies with hospital-brand and brand-month fixed
effects. However, the quarterly event study with hospital-brand and brand-month fixed effects is essentially
identical to the quarterly event study with hospital-brand and brand-specific linear trends.

54

55

19

(14)

14

(32)

(14)

16

(35)

(14)

(14)

22

-11
15

-12
17

(28)

22
(26)

19

(10)

22∗∗

19∗

(11)

(11)

-9
20∗

(11)

-10
20∗

100
(23)

14

(9)

16∗

(9)

-8
17∗

(20)

7

(8)

7

(7)

-7
3

(17)

7

(8)

5

(6)

-6
−1

-10

0

5

(14)

3

(7)

1

(5)

-5
−5

(11)

5

(6)

9

(5)

-4
3

(9)

2

(6)

8

(4)

-3
0

(6)

1

(5)

4

(3)

-2
−1

(3)

0

(5)

6

(3)

-1
3

10

(3)

(4)

(4)

(5)

(5)

(6)

(6)

(7)

(3)

(6)

(4)

−6

(4)

−4

(6)

(7)

(7)

(7)

(8)

(9)

(8)

−21∗∗

(7)

(8)

(9)

(9)

−23† −18∗

(7)

(9)

(12)

(15)

(18)

(19)

(22)

(25)

(28)

(30)

(33)

−10 −11 −15 −17 −19 −23 −19 −22 −23 −22

(5)

−13† −17† −18† −21† −27† −27† −25† −24† −24†

(3)

1
2
3
4
5
6
7
8
9
10
11
12
−8† −10† −14† −16† −20† −21† −22† −24† −22† −20† −22† −21†

Month relative to info date (β Inf o,mo =)

Month Relative to Treatment Date

-5

Figure A9: Event Studies of Treatment Effect of Access to Benchmarking Information

Authors’ calculations from PriceGuide data, 2009-2014. N = 23, 016 member-brand-months. Includes 507 members, twelve months pre- and post-join only. Version 1 includes hospital,
brand, and month fixed effects, plus linear brand-specific time trends. Version 2 includes hospital and brand-month fixed effects. Version 3 includes hospital-brand and month fixed effects,
plus linear brand-specific time trends. Figure shows Version 3 results. Standard errors clustered at hospital (Versions 1 and 2) or hospital-brand (Version 3) level shown in parentheses.
Superscript (†) indicates significant difference from zero at the 1% level; (**) at the 5% level; (*) at the 10% level.

3

2

1

Version

Treatment Effect, $

75
50
25
0
-25
-50
-75
-100

25
0
-25

Treatment Effect, $

-50

1

2

3

4

5

Quintile of Pre-Join Price
Version
1

Inf o
Pre-info price quintiles (βquintile
=)
1
2
3
4
9
17†

4
−2

5
−55†

(6)

(6)

(6)

(6)

(9)

2

−1

11

4

−7

−63†

(7)

(7)

(7)

(8)

(10)

3

−7

6

6

1

−27†

(5)

(5)

(5)

(5)

(7)

4

−10

1

2

−3

−34†

(6)

(6)

(6)

(6)

(8)

Authors’ calculations from PriceGuide data, 2009-2014. N = 32, 453
member-brand-months. Includes 508 members. Version 1 includes hospital, brand, and
month fixed effects, plus linear brand-specific time trends. Version 2 includes hospital and
brand-month fixed effects. Version 3 includes hospital-brand and month fixed effects, plus
linear brand-specific time trends. Version 4 includes hospital-brand and brand-month fixed
effects. Figure shows Version 3 results. Standard errors clustered at hospital (Versions 1
and 2) or hospital-brand (Versions 3 and 4) level shown in parentheses. Superscript (†)
indicates significant difference from zero at the 1% level; (**) at the 5% level; (*) at the
10% level.

Figure A10: Treatment Effect Estimates Throughout the Price Distribution

56

57

-11

-10

-9

-8

-7

-6

-10

-5

-5

(24)

(22)

(18)

(27)

(36)

(30)

−8

−18 −36 −27 −40 −34 −26

(34)

(10)

(16)

−4

(10)

−14 −29†

(12)

(13)

−8

(17)

(17)

(18)

(15)

(22)

(19)

(24)

−6

−17 −15 −10 −11

(22)

(16)

(25)

(19)

(20)

0

5

-4

-3

(12)

−6

(9)

−22∗∗

(8)

(10)

−4

(6)

−5

(7)

−9

−15∗
(8)

(7)

(7)

−14∗∗

-2

(4)

−4

(7)

−6

(6)

−8

-1

2

3

4

10

5

6

7

8

9

10

11

12

(8)

(9)

(9)

(11)

(12)

(10)

(13)

(13)

(11)

(13)

(13)

(9)

(9)

(10)

(11)

(13)

(11)

(13)

(14)

(5)

(9)

(11)

(14)

(17)

(20)

(21)

(24)

(27)

−16† −28† −43† −50† −56† −62† −65† −82† −76†

(7)

(29)

−75∗∗

(12)

(13)

(32)

(35)

−93† −96†

(13)

−26† −43† −54† −65† −70† −80† −80† −89† −83† −75† −104† −102†

(7)

−23† −40† −52† −61† −64† −74† −77† −88† −83† −78† −104† −104†

1

Month relative to join date (β5Join,mo =)

Month Relative to Treatment Date

−24 −33 −20 −24 −14 −14 −21∗ −31† −27† −22†

-12

75
50

Figure A11: Event Studies of Treatment Effect of Access to Benchmarking Information, Top Quintile of Price Only

Authors’ calculations from PriceGuide data, 2009-2014. N = 23, 016 member-brand-months. Includes 507 members, twelve months pre- and post-join only. Version 1 includes hospital,
brand, and month fixed effects, plus linear brand-specific time trends. Version 2 includes hospital and brand-month fixed effects. Version 3 includes hospital-brand and month fixed effects,
plus linear brand-specific time trends. Figure shows Version 3 results. Standard errors clustered at hospital (Versions 1 and 2) or hospital-brand (Version 3) level shown in parentheses.
Superscript (†) indicates significant difference from zero at the 1% level; (**) at the 5% level; (*) at the 10% level.

3

2

1

Version

Treatment Effect, $

25
0
-175 -150 -125 -100 -75 -50 -25

25
-25
-100

-75

-50

Treatment Effect, $

0

25
0
-25
-50

Treatment Effect, $

-75
-100

1

2

3

4

5

1

2

Quintile of Pre-Join Price

(a) Low Quantity
Version

3

4

5

Quintile of Pre-Join Price

(b) High Quantity

Inf o
Pre-info price quintiles (βquintile,low
q =)

4
1

5
−51†

Pre-info price quintiles
Inf o
Inf o
(βquintile,low
q + βquintile,highq =)
1
2
3
4
5
3
13
−4
−10
−73†

1

1
5

2
19†

3
16∗∗

(7)

(6)

(7)

(7)

(9)

(10)

(9)

(9)

(10)

(15)

2

−1

12

11

−4

−60†

0

7

−12

−14

−79†

(8)

(8)

(8)

(8)

(11)

(11)

(10)

(10)

(11)

(16)

3

−4

9

9

5

−17∗∗

−11

0

0

−9

−71†

(6)

(6)

(6)

(6)

(7)

(9)

(8)

(7)

(8)

(13)

4

−9

4

6

1

−23†

−12

−4

−5

−12

−78†

(7)

(7)

(7)

(7)

(8)

(9)

(8)

(8)

(9)

(13)

Authors’ calculations from PriceGuide data, 2009-2014. N = 32, 453 member-brand-months. Includes 508 members.
Version 1 includes hospital, brand, and month fixed effects, plus linear brand-specific time trends. Version 2 includes
hospital and brand-month fixed effects. Version 3 includes hospital-brand and month fixed effects, plus linear
brand-specific time trends. Version 4 includes hospital-brand and brand-month fixed effects. Figure shows Version 3
results. Standard errors clustered at hospital (Versions 1 and 2) or hospital-brand (Versions 3 and 4) level shown in
parentheses. Superscript (†) indicates significant difference from zero at the 1% level; (**) at the 5% level; (*) at the 10%
level.

Figure A12: Treatment Effect Estimates Across the Price and Quantity Distributions

58

50
25
0

Treatment Effect, $

-50

-25

50
25
0

Treatment Effect, $

-25
-50

1

2

3

4

5

1

2

Quintile of Pre-Join Price

(a) Agency
Version
1

3

4

5

Quintile of Pre-Join Price

(b) Asymmetric Info

Pre-info price quintiles
1
2
3
8
14
−9

Agency
(βquintile

4
−21∗

=)
5
−60†

Inf o
Pre-info price quintiles (βquintile
=)
1
2
3
4
5
∗∗
†
3
12
8
15
−33†

(12)

(11)

(10)

(12)

(21)

(6)

(5)

(5)

(7)

(7)

2

19

31∗∗

1

−11

−53∗∗

−8

−2

4

−2

−46†

(13)

(12)

(11)

(14)

(22)

(9)

(8)

(8)

(10)

(10)

3

−17

−3

2

7

13

−1

7

5

−1

−30†

(11)

(12)

(10)

(12)

(18)

(6)

(5)

(5)

(5)

(7)

−3

16

16

18

25

−15∗

−11

−11

−15∗∗

−47†

(12)

(12)

(11)

(12)

(19)

(8)

(7)

(7)

(7)

(9)

4

Authors’ calculations from PriceGuide data, 2009-2014. N = 32, 453 member-brand-months. Includes 508 members.
Version 1 includes hospital, brand, and month fixed effects, plus linear brand-specific time trends. Version 2 includes
hospital and brand-month fixed effects. Version 3 includes hospital-brand and month fixed effects, plus linear
brand-specific time trends. Version 4 includes hospital-brand and brand-month fixed effects. Figure shows Version 3
results. Standard errors clustered at hospital (Versions 1 and 2) or hospital-brand (Versions 3 and 4) level shown in
parentheses. Superscript (†) indicates significant difference from zero at the 1% level; (**) at the 5% level; (*) at the 10%
level.

Figure A13: Treatment Effect Estimates Across the Price Distribution, Separating
Agency and Asymmetric Information Mechanisms

59

2

3

4

5

.05
.04
.03
.02
.01
0
-.01

Treatment Effect, Renegotiation Dummy

50
25
0
-25
-50
-75

Treatment Effect, $

-100
-125

1

1

2

Quintile of Pre-Join Price

(a) Conditional on Renegotiation
Version

3

4

5

Quintile of Pre-Join Price

Inf o
(βquintile

(b)

Inf o
Pre-join price quintiles (βquintile
=)
1
2
3
4
5
∗∗
∗
.008
.002
.018
.018
.034†

1

Pre-join price quintiles
1
2
3
−7
13
11
(12)

(12)

(14)

(14)

(19)

(.008)

(.009)

(.008)

(.01)

(.008)

2

−11

5

1

−25

−111†

.017∗

.01

.023∗∗

.025∗∗

.04†

(16)

(15)

(17)

(17)

(23)

(.009)

(.01)

(.009)

(.011)

(.009)

3

−14

4

1

−13

−76†

.01

.013

.016∗

.018

.023∗∗

(15)

(14)

(19)

(17)

(18)

(.01)

(.01)

(.009)

(.011)

(.009)

−8

4

−3

−11

−80†

.022∗∗

.022∗

.024∗∗

.029∗∗

.032†

(19)

(19)

(22)

(20)

(22)

(.011)

(.012)

(.01)

(.012)

(.011)

4

4
−22

=)

1{reneghjt }

5
−91†

Authors’ calculations from PriceGuide data, 2009-2014. N = 6, 510 member-brand-months in regressions conditional on
renegotiation. N = 32, 453 member-brand-months in renegotiation dummies regression. Includes 508 members. Version 1
includes hospital, brand, and month fixed effects, plus linear brand-specific time trends. Version 2 includes hospital and
brand-month fixed effects. Version 3 includes hospital-brand and month fixed effects, plus linear brand-specific time
trends. Version 4 includes hospital-brand and brand-month fixed effects. Figure shows Version 3 results. Standard errors
clustered at hospital (Versions 1 and 2) or hospital-brand (Versions 3 and 4) level shown in parentheses. Superscript (†)
indicates significant difference from zero at the 1% level; (**) at the 5% level; (*) at the 10% level.

Figure A14:
Renegotiation

Treatment Effects Conditional on Renegotiation and on Occurrence of

60

D.2

Robustness

50
25
Treatment Effect, $
-50
-25
0
-75
-100

-100

-75

Treatment Effect, $
-50
-25
0

25

50

The following Figures show the results of our richest regression specification, allowing for
different treatment effects for different parts of the price and quantity distributions, for specifications that (1) focus only on the twelve months before and after information (Figure A15);
(2) limit the sample to those facilities registered with the database as “hospitals” as opposed
to “health systems” or other facility types (Figure A16); and (3) examine heterogeneity in
results as a function of hospital type (Table A8). Results are qualitatively and quantitatively
similar in specifications (1) and (2).

1

2

3
Quintile of Pre-Join Price

4

5

1

2

(a) Low Quantity
Version

3
Quintile of Pre-Join Price

4

5

(b) High Quantity

Inf o
Pre-info price quintiles (βquintile,low
q =)

5
−30†

Pre-info price quintiles
Inf o
Inf o
(βquintile,low
q + βquintile,highq =)
1
2
3
4
5
−11
7
7
1
−54†

1

1
−7

2
15∗∗

3
14∗∗

4
8

(7)

(6)

(6)

(7)

(9)

(9)

(8)

(7)

(8)

(16)

2

−13

9

6

3

−38†

−16

0

−2

−3

−61†

(8)

(8)

(7)

(8)

(9)

(10)

(8)

(8)

(9)

(16)

3

−7

10∗

9∗

14∗∗

−11∗

−7

2

5

1

−60†

(6)

(5)

(5)

(6)

(6)

(8)

(7)

(6)

(7)

(15)

4

−11∗

7

5

11∗

−16∗∗

−10

−1

1

−2

−66†

(7)

(6)

(6)

(6)

(7)

(8)

(8)

(6)

(7)

(15)

Authors’ calculations from PriceGuide data, 2009-2014. N = 23, 016 member-brand-months. Includes 507 members.
Version 1 includes hospital, brand, and month fixed effects, plus linear brand-specific time trends. Version 2 includes
hospital and brand-month fixed effects. Version 3 includes hospital-brand and month fixed effects, plus linear
brand-specific time trends. Version 4 includes hospital-brand and brand-month fixed effects. Figure shows Version 3
results. Standard errors clustered at hospital (Versions 1 and 2) or hospital-brand (Versions 3 and 4) level shown in
parentheses. Superscript (†) indicates significant difference from zero at the 1% level; (**) at the 5% level; (*) at the 10%
level.

Figure A15: Treatment Effect Estimates Across the Price and Quantity Distributions –
Twelve Months Pre/Post

To further explore convergence within hospitals of differing “types”, we also estimate

61

25
-125

-100

Treatment Effect, $
-75
-50
-25

0

25
0
Treatment Effect, $
-75
-50
-25
-100
-125

1

2

3
Quintile of Pre-Join Price

4

5

1

2

(a) Low Quantity
Version
1
2

3
Quintile of Pre-Join Price

4

5

(b) High Quantity

Inf o
Pre-info price quintiles (βquintile,low
q =)

4
−2

5
−53†

Pre-info price quintiles
Inf o
Inf o
(βquintile,low
q + βquintile,highq =)
1
2
3
4
5
−1
8
−10
−7
−80†

1
8

2
21†

3
15∗∗

(7)

(6)

(7)

(8)

(11)

(10)

(10)

(10)

(12)

(18)

2

13

11

−5

−64†

−5

2

−18

−13

−84†

(8)

(8)

(8)

(9)

(12)

(11)

(10)

(11)

(12)

(18)

3

0

12∗∗

9

6

−20∗∗

−11

−2

−3

−7

−72†

(6)

(5)

(7)

(7)

(8)

(9)

(8)

(8)

(9)

(16)

4

−3

7

7

2

−26†

−12

−5

−7

−10

−77†

(7)

(6)

(8)

(7)

(9)

(9)

(9)

(9)

(9)

(16)

Authors’ calculations from PriceGuide data, 2009-2014. N = 27, 698 member-brand-months. Includes 436 members.
Version 1 includes hospital, brand, and month fixed effects, plus linear brand-specific time trends. Version 2 includes
hospital and brand-month fixed effects. Version 3 includes hospital-brand and month fixed effects, plus linear
brand-specific time trends. Version 4 includes hospital-brand and brand-month fixed effects. Figure shows Version 3
results. Standard errors clustered at hospital (Versions 1 and 2) or hospital-brand (Versions 3 and 4) level shown in
parentheses. Superscript (†) indicates significant difference from zero at the 1% level; (**) at the 5% level; (*) at the 10%
level.

Figure A16: Treatment Effect Estimates Across the Price and Quantity Distributions –
Hospitals Only

62

our richest specification within hospital size bins, within regions, and within size-region.44
We find several patterns of interest, now reported in Table A8.45 In the second panel of
Table A8, we see suggestive evidence that treatment effects vary across regions. Focusing on
the high-price and high-quantity hospital-brands, the treatment effects are smallest in the
northeast and south (-$42 and -$43, respectively), largest in the west (-$104), and similar to
our baseline, pooled-region estimates (-$71) in the midwest (-$70); none of these estimates is
statistically significantly different from the pooled-region estimate at the 5% level. For highprice and relatively low-quantity hospital-brands, only the treatment effect for the western
region is statistically significant. In the third panel of Table A8, we show that the distribution of treatment effect estimates in price and quantity space differs by hospital size. The
treatment effect estimates for small- and medium-sized hospitals (1-199 and 200-399 beds,
respectively) are statistically significant and of similar magnitude to our baseline estimate
(-$17) for high-price, relatively low-quantity hospital-brands: the treatment effects estimates
are -$27 and -$24, respectively. The treatment effect estimates for medium-sized and large
hospitals (400+ beds) are large and statistically significant for high-price, relatively highquantity hospital-brands: the treatment effects estimates are -$90 and -$68, respectively.
This pattern is driven by the fact that large hospitals tend to purchase brands in large quantities and small hospitals tend to purchase brands in low quantities. In unreported results,
we see no clear evidence that the overall distribution of treatment effects varies with hospital
size; the treatment effect for all hospital-brands that were high-price pre-join is largest (-$31)
among medium-sized hospitals, compared to (-$23) for both small and large hospitals.
These within-type results are noisier than our baseline pooled results, as expected, but
largely confirm our finding of large treatment effects of information among hospital-brands
where there is room for improvement and a great deal of spending at stake, at least within
the limited set of hospital characteristics we have. Furthermore, the final panel of Table
A8 reports estimates that mirror our full-sample regressions in the first panel, but using knearest neighbors matching. The results are nearly identical to our baseline estimates. Thus,
price convergence pertains across all hospital-brands and within sets of similar hospitals.

44

The results split by size crossed with region are noisy, but largely confirm the marginal interactions
with size and region separately.
45
Note that, for the sake of comparison with the baseline results, the flags for high- vs. low-quantity
hospital-brands and high- vs. low-price hospital-brands are relative to the full sample, not the sample for
the relevant hospital type.

63

Table A8: Exploring the Results by Hospital Type
(1) Baseline Estimates – Treatment Effect Variation with Quantity Purchased:
Inf o
Inf o
High quantity βquintile,high
Low quantity βquintile,low
q
q
pquintile
1
2
3
4
5
1
2
3
4
−4
9
9
5
−17∗∗
−11
0
0
−9
(6)

(6)

(6)

(6)

(2) Treatment Effect Variation by Region:
Inf o
Low quantity βquintile,low
q
pquintile
1
2
3
4
Midwest
−7
18∗
−4
6
Northeast
South
West

(9)

(10)

−14

10

(24)

7

(7)

5
−12

400+

(8)

(7)

(8)

Inf o
High quantity βquintile,high
q
1
2
3
4
−24∗
21∗
−1
−25

(13)

5
−70∗∗

(12)

(13)

(13)

(14)

(12)

(10)

(21)

(30)

†

42

24∗∗

−9

−11

9

20

−14

−42

(23)

(14)

(11)

(11)

(27)

(23)

(14)

(14)

(31)

9

−1

6

11

16∗

−5

−6

9

−43†

(13)

(7)

(8)

(10)

(16)

(9)

(13)

(12)

(14)

(11)

−4

−2

9

0

−42†

−61∗∗

−4

5

1

−104†

(13)

(10)

(13)

(14)

(14)

(29)

(7)

(10)

(19)

(26)

(3) Treatment Effect Variation by Bed Count:
Inf o
Low quantity βquintile,low
q
pquintile
1
2
3
4
5
0-199
−16
5
7
−10
−27∗
200-399

(9)

5
−71†

Inf o
High quantity βquintile,high
q
1
2
3
4
−19
13∗
−23
−16

5
29

(11)

(7)

(12)

(12)

(14)

(22)

(7)

(18)

(23)

(18)

−4

−2

0

−8

−24∗

3

−5

−19

19

−90†

(7)

(11)

(9)

(9)

(13)

(10)

(12)

(18)

(14)

(26)

2

†

26

19∗

24

†

−3

−14

4

12

−13

−68†

(16)

(9)

(10)

(9)

(9)

(13)

(11)

(8)

(10)

(15)

(4) Matching by p, q, Region, Bed Count:
Inf o
Low quantity βquintile,low
q
pquintile
1
2
3
4
−10
8
23∗∗
17∗∗
(11)

(7)

(9)

(7)

5
−19
(12)

Inf o
High quantity βquintile,high
q
1
2
3
4
−16
−25
8
−2

(17)

(22)

(10)

(9)

5
−74†
(9)

Authors’ calculations from PriceGuide data, 2009-2014. (1): Full sample N = 32, 453 member-brand-months; 508
members. (2): NM idwest = 7, 540; NN ortheast = 5, 944; NSouth = 10, 451; NW est = 8, 518. (3): N0−199 = 6, 991;
N200−399 = 12, 884; N400+ = 12, 578. (4) based on k-Nearest Neighbors matching algorithm. Each treated hospital-brand
hj matched to five similar hospitals k 6= h based on region and bed count, as well as price and quantity for brand j in the
three months prior to hj treatment. Nmatch = 25, 961. Standard errors clustered at hospital-brand level shown in
parentheses. Superscript (†) indicates significant difference from zero at the 1% level; (**) at the 5% level; (*) at the 10%
level.

D.3

Externalities in Bargaining

As noted briefly in the main text, and more explicitly in Prediction 2B in the theory appendix, a full analysis of the information we examine should take into account the potential
externality that information relevant for one supplier imposes on negotiations with other
suppliers. For example, consider the delegated agent model in Collard-Wexler et al. (2017)
(which would apply to our context since transfers are not lump sum). In such a model,
information about supplier A’s bargaining parameter would enter all other suppliers’ negoti-

64

ations via its expected impact on supplier A’s price, which enters the elasticity and marginal
contribution terms in all other suppliers’ negotiations.
While our empirical approach does incorporate these types of externalities, it is difficult
to disentangle them. When a hospital joins the database, all brands receive information
shocks, so any externalities between brands are captured in the treatment effect (β Join ). In
cases of new brand entry, these are shocks to single brands, so in principle this provides an
opportunity to identify externalities. The challenge is that new brand entry occurs sometime
after join, so the simple effect of the new brand information on other brands (β OtherInf o ) is
akin to choosing a random point some time after join to remeasure the effect – like picking
the post month in the event study that corresponds with the new brand information date.
To address this, we focus on the instances where the hospital is a high-price, high-quantity
case when information is revealed about the entering brand. These are the instances where
the information shock is strongest, and we difference them versus the rest of the sample for
that same brand to isolate the externality effect on other brands in the same hospital-month
(β Externality ). The point estimates in Table A9 suggest externalities roughly half the size of
the point estimates for the focal entering brands, but the estimates are noisy, and none are
statistically different from zero at standard confidence levels.
Table A9: Externalities: Effect of New Brand Information on Other Brands
Version of Controls
β Join
β OtherInf o
β Externality

[1]
-32†

[2]
-32†

[3]
-9

[4]
-9

(10)

(10)

(8)

(8)

19†

23†

-4

2

(8)

(8)

(8)

(9)

-15

-17

-23

-25

(19)

(19)

(18)

(19)

Hospital+Brand FEs

Y

Y

N

N

Hospital×Brand FEs

N

N

Y

Y

Linear Brand Trends

Y

N

Y

N

Brand×Month FEs

N

Y

N

Y

Authors’ calculations from PriceGuide data, 2009-2014. N = 11, 975 member-brand-months. Includes 508 members.
Standard errors clustered at hospital level shown in parentheses. Superscript (†) indicates significant difference from zero
at the 1% level; (**) at the 5% level; (*) at the 10% level.

65

E

Expanded Analyses – Detail

The estimates of our main difference-in-differences regression of price on join timing for
each “important” product category are shown in Table A10. In the results in Section 6 in
the main text, we summarize these results across product category within each physician
preference class. In the detailed results here, the left panel shows the results for the full
sample described in Appendix A.3. The right panel shows the results for a restricted sample
of brands with “significant” market presence (defined as those brands purchased by at least
100 hospitals per year on average), where we can be more confident that our price quintile
estimates have reasonable statistical power. In each case, the regression coefficient has been
normalized by the mean unit price of the product category to facilitate comparisons across
products with dramatically different prices.

66

67

Name

1
1
1
1
1
1
1
1
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
3
3
3
3
3
3
3
3
3
3
3
3
3
3
3
3
3
3
3
3
3

Class
1
-0.010
-0.021
-0.016
-0.024
-0.020**
0.011
-0.011
-0.013
-0.013
-0.008
-0.001
-0.000
-0.001
-0.017
-0.017**
-0.017
-0.022
-0.046†
0.005
-0.024
-0.031
-0.017**
-0.030†
-0.110
-0.007
-0.004
-0.003
-0.034
-0.002
0.001
-0.008
-0.068**
-0.061*
-0.018
-0.009*
-0.028**
-0.034**
-0.015
-0.020*
-0.086†
-0.065†
-0.056†
-0.079†
-0.014
0.000
-0.033
-0.007
0.003
-0.042†
-0.017
-0.019
-0.040†
0.002
-0.056†
-0.034**

5
-0.018
-0.022*
-0.009
0.001
-0.028
-0.045**
-0.012
-0.016**
-0.078**
-0.043**
-0.001
0.000
0.005
-0.005
-0.026**
0.008
-0.047
-0.011
0.003
-0.015
-0.040
-0.032**
-0.035†
0.214
-0.027**
0.003
0.004
0.007
0.056
-0.004
-0.001
-0.047
-0.016
-0.006
-0.008
-0.028
-0.041*
0.003
-0.015
-0.102†
-0.049**
-0.058†
-0.048**
-0.016
-0.028
-0.024
-0.027*
0.011
-0.028
-0.026
-0.075†
-0.031**
0.018
-0.047†
-0.039†

-0.014
0.002
0.025†
-0.001
-0.110*
0.007*
0.021**
0.008
0.003
-0.001
-0.008** -0.005 -0.014**
0.000
-0.011
-0.013
-0.019
-0.009
0.035**
-0.000
0.000
0.011**
0.007
0.003
0.008**
0.050
-0.046
0.040
0.100** 0.102**
0.011*
0.022**
0.019†
0.004
0.017*
0.007
-0.002
0.010
0.022
0.007
-0.001
0.000
0.005
0.001
0.012
0.008*
0.040**
0.013
-0.006
0.015*
-0.000*
-0.002
0.006**
0.004
-0.000
-0.000
-0.012
0.000†
0.000†
0.000†
0.003
-0.002
0.013
0.009
-0.003
-0.002
0.004
0.004
0.030*
-0.037*
0.002
0.005
0.019**
0.018†
0.006
0.011*
-0.012† 0.025**
0.009
0.021†
0.010
0.002
0.013*
0.012
0.044
0.002
0.009
0.060**
0.016
-0.022
0.008** 0.028** 0.014**
0.009†
0.012**
0.010
0.002
0.029†
0.012
0.033†
0.021*
0.038
0.023
0.026**
0.013
0.000
-0.001
-0.001
-0.005
0.006
-0.006**
0.002
0.008**
0.003
-0.007
0.033
-0.004
-0.045
0.047
0.152*
-0.007
0.028
-0.048†
-0.001
-0.021*
0.006
0.009
0.021*
0.002
-0.005
-0.002
0.029
0.001
-0.053** 0.023*
-0.001
-0.045*
0.021
0.010
0.027
0.001
0.019**
0.001
-0.008
0.030**
-0.003
-0.017
-0.011
0.002
0.002
-0.001
0.007
0.009
0.009
-0.001
-0.011
0.047
0.077
-0.026 -0.040**
-0.064** -0.014
-0.068
-0.003 -0.117**
-0.005
0.002
-0.000
0.002
-0.002
0.002
0.105**
0.000†
0.002**
0.001†
0.009*
0.038†
0.012*
-0.004
0.012
-0.021
-0.011
0.016
-0.042* -0.063**
-0.006
-0.003
0.020
0.006
-0.016
0.003
0.003
0.002
0.004
0.017*
-0.012
0.044†
0.004
0.014
-0.040**
0.003
0.056†
-0.003
-0.017
-0.003
-0.002
0.052†
0.015**
-0.008
-0.027
-0.009
0.019*
0.000
-0.011
-0.013
0.004
0.030†
0.005
0.014**
-0.004
-0.027 -0.046** -0.045
-0.007
0.004
0.049
0.115
0.105
0.144*
0.008
-0.002
-0.014 -0.014** -0.001
0.021**
-0.011* -0.025** -0.046**
0.001
-0.017
-0.019*
0.009
0.038**
-0.037
-0.031
-0.012
-0.009
0.009
0.002
-0.038**
-0.014† -0.013** -0.019** -0.008
-0.011
-0.005
-0.018
0.006
0.014
0.009
0.010
0.032†
-0.032
0.019*
0.017
-0.037
-0.010
0.055
0.039
0.014
-0.010†
0.013
0.010
0.001
-0.013

1

|Hj | ≥ 100 Sample
ATE

TE by Price Quintile
2
3
4

T Ehighp ,highq

Unrestricted Sample
TE by Price Quintile
2
3
4

-0.011
0.007
-0.019
0.002
-0.038**
0.000
0.021**
-0.001
0.020*
-0.024
-0.005
-0.018
0.028
0.008
-0.028
0.007
0.004
0.024**
0.009
0.015**
-0.000
0.014**
0.005
-0.000
0.004
0.018
0.082
0.004
0.003
0.005
0.004
0.019†
0.008*
-0.000
0.004
0.002
0.017
0.009
0.006
-0.008
0.004
0.025**
0.001
0.001
0.007
0.008** 0.035**
0.006
-0.001
0.012*
-0.000
-0.002
0.004**
0.003
0.001
-0.001
-0.008
0.004
-0.005
0.001
0.004
0.007
0.004
0.008*
0.001
-0.004
-0.007
0.001
0.019†
-0.011
-0.003
0.004
0.008
-0.001
-0.010
-0.000
-0.019
0.033*
0.009
0.001
0.009
0.007
0.029
0.009
0.028
0.005
0.015**
0.023†
0.008
0.011
0.008*
0.009
0.011*
0.012**
0.007
0.009
0.002
0.024†
0.017†
0.027†
0.013
0.053**
0.017*
0.027†
0.013
0.000
0.011
-0.003
0.008
0.002
-0.005**
0.003
0.007*
0.004
-0.009**
-0.025
-0.056
-0.008
-0.016
0.041
-0.011** -0.007 -0.027** -0.007
-0.002
0.004
0.010
0.016**
0.003
-0.002
0.005
0.042*
0.016
-0.035*
0.009
0.001
-0.030
0.018
0.015
0.032
0.001
-0.005
-0.049
0.015
0.020*
-0.000
-0.005
-0.004
0.014
-0.001
-0.000
0.005
0.005
0.009
0.000
-0.004
0.046**
0.061
-0.003
-0.019
-0.034*
0.004
-0.037
-0.001
-0.083†
-0.003
0.003
0.001
0.003
-0.002
0.001
0.051**
0.012
0.010*
0.012*
0.009*
0.035†
0.012**
-0.003
0.009
-0.017*
0.003
-0.004
-0.012 -0.050**
-0.002
0.008
0.008
0.004
-0.015*
-0.000
0.005
-0.007
0.008*
0.008
-0.006
0.044†
0.009
-0.013
-0.025†
0.004
0.047†
0.020†
-0.002 -0.024**
0.003
0.045†
0.014**
0.006
-0.012
-0.002
0.041†
0.017**
0.006
-0.020**
0.003
0.025†
0.005
0.016**
-0.002
-0.001
0.001
-0.002
0.003
-0.009
0.008
0.043*
0.069*
0.028
-0.010
-0.006
-0.008
-0.017† -0.012** 0.016**
-0.008* -0.016** -0.020
0.000
-0.016
-0.013*
0.011
0.014*
-0.018 -0.038**
-0.002
0.013
0.010
0.006
-0.021
-0.013† -0.013** -0.018** -0.008
-0.011
-0.010* -0.025**
0.002
0.009
0.005
0.004
0.008
-0.003
0.015*
-0.002
-0.013**
0.007
0.016*
-0.014* -0.023**
-0.005†
0.015
0.007
-0.002
-0.015

ATE

-0.033
0.001
-0.009
-0.082**
-0.026†
-0.007
-0.006
-0.022
-0.017
-0.013
-0.001**
0.000
-0.002
-0.016
-0.034*
0.010
-0.021
-0.086**
-0.002
-0.028
-0.001
0.001
-0.032†
0.002
0.012
0.003
-0.023
-0.032
-0.032*
0.004
-0.014
-0.073†
-0.145*
-0.024
0.000
-0.031**
-0.013
-0.047
-0.022
-0.123†
-0.070†
-0.074†
-0.062†
-0.012
-0.035
-0.164
-0.005
0.006
-0.051†
-0.011
-0.023*
-0.043†
0.002
-0.194†
-0.053

5
-0.046
0.005
-0.006
0.007
-0.000
-0.310†
-0.019
-0.053†
-0.092**
-0.055**
-0.001*
0.000
0.004
-0.023
-0.076*
0.026
-0.075*
-0.056
0.003
-0.018
0.023
-0.006
-0.047†
0.037
-0.003
0.009
-0.055
0.043
0.004
-0.002
-0.007
-0.004
-0.231**
-0.037†
-0.000
-0.036
0.026
-0.025
-0.036
-0.197†
-0.078*
-0.107**
0.010
-0.020
-0.107
-0.690
-0.026
0.017
-0.065*
-0.007
-0.079†
-0.034*
0.005
-0.298†
-0.081†

T Ehighp ,highq

Authors’ calculations from PriceGuide data, 2009-2014. Specifications include hospital-brand and brand-year fixed effects; alternative fixed effects in Table A11. Standard errors clustered at hospital-brand level. Superscript (†)
indicates significant difference from zero at the 1% level; (**) at the 5% level; (*) at the 10% level.

10279
11315
11883
12368
12745
13655
923840

Bandages Elastic
Dressings
Gloves Surgical
Drapes Surgical
Needles Injection Hypodermic
Containers Specimen
Drill Bits
Commodities
Catheters Vascular Angiography
10688
10894
Clip Appliers
11502
Forceps Electrosurgical
11910
Grafts Bone
11925
Guide Wires
12830
Orthopedic Cement
13050
Plates Bone
13909
Sutures Synthetic Nonabsorbable Polypropylene
13910
Sutures Natural Nonabsorbable Silk
14085
Tubes Tracheal
16071
Lenses Intraocular Posterior Chamber
16078
Nails Bone
16104
Wires Bone
16655
Catheters Cardiac Ablation
17184
Catheters Vascular Angioplasty Balloon
17471
Sutures Synthetic Absorbable Polyglactin
17600
Bone Matrix Implants
17846
Catheters Vascular Guiding
18609
Catheters Cardiac Mapping/Ablation
20317
Staplers Surgical
20318
Staplers Surgical Linear
20453
Stent/Grafts Vascular Aortic
22538
Suture Anchors
22908 Sutures Synthetic Nonabsorbable Nylon Monofilament
34196
Screws Bone Spinal
Other Med/Surg
Lenses Intraocular
12324
12913
Pacemakers Cardiac Implantable
15766
Orthopedic Internal Fixation Systems Spinal
15870
Prostheses Cardiac Valve Biological
16040
Stents Ureteral
16084
Prostheses Joint Hip Acetabular Component
16095
Prostheses Joint Hip Femoral Component
16097
Prostheses Joint Knee Femoral Component
16098
Prostheses Joint Knee Tibial Component
16111
Prostheses Mammary Internal
16921
Prostheses Joint Shoulder Humeral Component
17165
Allografts
17241
Stimulators Electrical Spinal Cord Analgesic
18253
Grafts Skin Biological
18504
Defrib/Pacemakers Implantable
20376
Defrib/Pacemakers Implantable Resynchronization
20383
Stents Vascular Coronary Drug-Eluting
20422
Stents Vascular Coronary Balloon-Expandable
22543
Occluders Vascular Intravascular Embolization Coil
923150
Orthopedic Fixation Systems Implantable Spine
PPIs

ID

Table A10: Treatment Effects for Important Product Categories, with hj and jY FE

The columns in Table A10 are presented as follows: within each sample, the first column
shows the average treatment effect; the second through sixth columns show the treatment
effect by price quintile; and the seventh column shows the treatment effect for hospitalbrands in the top quintile of the pre-join price distribution and in the top quartile of the
pre-join quantity distribution. Each panel of rows shows results for each individual product
category, as well as a spend-weighted average for each product class.
While there is quite a bit of variation in results for this large number of product categories
and different specifications, several patterns emerge. The average treatment effects are, as
with stents, small and not statistically significant. The treatment effects for hospital-brands
in the bottom quintiles of the pre-join price distribution hover near zero, some positive, some
negative; in contrast, the treatment effects for the top quintile of the price distribution are
generally negative and, particularly for PPIs, often statistically significant. The treatment
effects are often, though not universally, larger in magnitude for high-price, high-quantity
hospital-brands. Thus, as we found with drug-eluting stents, these results demonstrate that
the largest savings are achieved by hospitals and for PPI brands with the highest prices and
quantities prior to the hospital joining the database. The treatment effects are often larger
in magnitude for the restricted sample of brands purchased by an average of 100 or more
hospitals; those brands may have received additional attention from hospitals searching the
benchmarking database.
Table A10 reported the results of our preferred specification, with controls for hospitalbrand and brand-year fixed effects. This choice of specification is intended to accommodate
trends in technology prices across a wide variety of product categories, some of which are
purchased frequently and some infrequently. Table A11 below compares summary results
with alternative fixed effects: hospital and brand fixed effects vs. hospital-brand fixed effects,
and brand-specific linear trends vs. brand-year fixed effects vs. brand-month fixed effects.
In each case, we show spend-weighted average treatment effects within each product class,
for the unrestricted and restricted samples.
The results indicate that inclusion of hospital-brand fixed effects has an important effect
on the estimates – in the first panel, which includes hospital and brand and month fixed
effects, as well as brand-specific linear trends, the standard errors are quite large, capturing
the fact that many product categories in the expanded analysis are more heterogeneous than
drug-eluting stents and estimates can be sensitive to compositional changes. Within the set
of results with hospital-brand fixed effects, the results with different controls for time trends
are qualitatively similar: for example, among PPIs, the high-price, high-quantity hospitalbrand results range from -0.025 to -0.039 in the unrestricted sample, and from -0.073 to
-0.081 in the restricted sample. Similarly, the unrestricted sample treatment effects for high68

Table A11: Treatment Effects with Alternative Fixed Effects
|Hj | ≥ 100 Sample

Unrestricted Sample
ATE
$

T Ehighp
%

$

%

T Ehighp ,highq
$
%

ATE
$

T Ehighp
%

$

%

T Ehighp ,highq
$
%

θh + θj + θt + γj (t − tminj )
Commodities
Other Med/Surg
PPIs

-0.09
(0.23)
0.93
(2.63)
37.07
(27.82)

-0.007
-7.81
(0.014) (1479.15)
-0.002
-31.25
(0.002) (9202.55)
-0.001
-318.56
(0.002) (8028.78)

-0.118
(8.596)
-0.055
(5.462)
-0.058
(10.867)

3.41
(335.13)
-70.06
(1536.21)
-472.00
(3347.51)

-0.013
(2.276)
-0.130
(1.900)
-0.073
(4.009)

0.37∗
(0.21)
-2.78
(3.08)
-29.39
(35.23)

0.004
-1.75
(0.007) (2.92)
-0.002
-24.47
(0.003) (23.16)
-0.005 -226.80
(0.004) (222.27)

-0.060
-3.13†
(0.066) (0.81)
-0.051
-42.94†
(0.038) (11.52)
-0.071 -485.62†
(0.047) (106.53)

-0.069†
(0.019)
-0.075†
(0.015)
-0.108†
(0.018)

0.24
(0.19)
0.13
(2.23)
31.51
(21.64)

0.001
(0.004)
-0.000
(0.002)
0.002
(0.002)

-0.28
(0.76)
-6.34
(11.13)
-111.42
(122.74)

-0.010
(0.014)
-0.015
(0.017)
-0.027
(0.017)

-0.33
(0.60)
-0.13
(5.45)
-92.63
(58.78)

-0.009
(0.011)
-0.002
(0.006)
-0.025†
(0.005)

0.50∗∗
(0.21)
-3.33
(2.91)
-27.98
(31.92)

0.010
(0.006)
-0.002
(0.003)
-0.003
(0.003)

-0.08
-0.015
(0.72) (0.035)
-11.07
-0.020
(20.39) (0.029)
-186.83 -0.047
(198.01) (0.043)

-0.49
(0.83)
-25.14†
(9.14)
-276.09†
(89.31)

-0.038†
(0.011)
-0.033†
(0.012)
-0.073†
(0.017)

0.16
(0.19)
-1.70
(2.23)
-37.36∗
(22.12)

-0.001
(0.004)
-0.003
(0.002)
-0.005†
(0.002)

-0.33
(0.80)
-7.30
(11.60)
-155.15
(154.81)

-0.012
(0.013)
-0.016
(0.017)
-0.032∗∗
(0.016)

-0.45
(0.61)
-2.61
(5.17)
-182.09†
(63.95)

-0.011
(0.010)
-0.004
(0.006)
-0.035†
(0.005)

0.42∗∗
(0.20)
-5.57∗
(2.98)
-76.52∗∗
(30.35)

0.007
(0.006)
-0.005∗
(0.003)
-0.009†
(0.003)

-0.15
-0.018
(0.73) (0.035)
-12.99
-0.023
(21.74) (0.030)
-220.78 -0.053
(199.61) (0.043)

-0.58
(0.82)
-27.32†
(9.91)
-334.89†
(91.09)

-0.041†
(0.011)
-0.035†
(0.012)
-0.081†
(0.016)

0.17
(0.19)
-1.87
(2.24)
-37.99
(23.17)

0.002
(0.004)
-0.003
(0.002)
-0.005†
(0.002)

-0.39
(0.85)
-8.39
(10.59)
-163.37
(160.35)

-0.013
(0.014)
-0.018
(0.017)
-0.034∗∗
(0.017)

-0.58
(0.56)
-8.93∗∗
(3.87)
-205.71†
(75.03)

-0.016∗∗
(0.008)
-0.006
(0.005)
-0.039†
(0.005)

0.39∗
(0.20)
-5.46∗
(3.04)
-77.79†
(29.99)

0.007
(0.006)
-0.005
(0.003)
-0.009†
(0.003)

-0.24
-0.022
(0.74) (0.037)
-13.46
-0.024
(21.92) (0.030)
-224.46 -0.053
(205.97) (0.043)

-0.72
(0.76)
-28.09†
(9.99)
-342.55†
(90.22)

-0.054†
(0.017)
-0.038†
(0.012)
-0.081†
(0.016)

0.04
(0.23)
-1.42
(3.05)
46.53
(31.57)

-0.003
(0.011)
-0.003
(0.003)
0.000
(0.002)

-2.32
(3.81)
-31.91
(20.77)
-321.84
(208.37)

-0.060
(0.060)
-0.062∗
(0.037)
-0.080∗∗
(0.035)

-3.92†
(0.76)
-46.54†
(8.27)
-561.45†
(97.56)

-0.061
(0.041)
-0.081†
(0.016)
-0.095†
(0.008)

0.39∗
(0.22)
-2.53
(3.39)
-28.65
(38.77)

0.004
(0.007)
-0.003
(0.004)
-0.006
(0.004)

-1.77
-0.063
-3.17†
(2.92) (0.068) (0.79)
-24.14
-0.051
-46.64
(23.90) (0.038) (61.96)
-214.38 -0.071 -466.67†
(229.67) (0.048) (104.20)

-0.080†
(0.022)
-0.083†
(0.020)
-0.105†
(0.018)

0.28
(0.20)
-1.34
(2.57)
29.76
(28.85)

0.002
(0.003)
-0.002
(0.003)
0.002
(0.002)

-0.28
(0.75)
-8.54
(15.59)
-131.99
(146.83)

-0.013
(0.016)
-0.019
(0.022)
-0.031
(0.021)

-0.69
(0.67)
-11.78
(8.07)
-169.53∗
(102.18)

-0.018∗∗
(0.007)
-0.013
(0.011)
-0.035†
(0.007)

0.49∗∗
(0.21)
-3.66
(3.05)
-29.71
(35.67)

0.009
-0.14
-0.019
(0.006) (0.74) (0.038)
-0.003
-11.29
-0.021
(0.003) (20.66) (0.028)
-0.003 -184.27 -0.046
(0.004) (196.38) (0.043)

θhj + θt + γj (t − tminj )
Commodities
Other Med/Surg
PPIs
θh + θjy
Commodities
Other Med/Surg
PPIs
θhj + θjy
Commodities
Other Med/Surg
PPIs
θh + θjm
Commodities
Other Med/Surg
PPIs
θhj + θjm
Commodities
Other Med/Surg
PPIs

(1)

(2)

(3)

(1)

(2)

-0.69
(0.80)
-29.29∗∗
(12.85)
-284.62†
(93.69)

-0.052†
(0.017)
-0.042∗∗
(0.018)
-0.073†
(0.017)

(3)

Authors’ calculations from PriceGuide data, 2009-2014. Nhjt = 516, 582; Nhjt = 1, 344, 515; Nhjt = 703, 544. Nh = 748; Nh = 701; Nh = 601.
Fixed effects for each panel indicated in first column. Standard errors in category-specific regressions clustered at hospital-brand level. Superscript
(†) indicates significant difference from zero at the 1% level; (**) at the 5% level; (*) at the 10% level.

price, high-quantity hospital-brands range from -0.009 to -0.018 for commodities and from
-0.002 to -0.013 for other medical/surgical products. Given the stability of the estimates,
in the main text, we focus on the intermediate specification with brand-year fixed effects,
which tend to have smaller standard errors due to the sparsity of monthly data for some
brands in the expanded analysis.

69

F

Usage Pattern Changes and Demand

Stents and certain other expensive medical technologies are “physician preference items”
where physician demand is based on strong preferences and is relatively insensitive to price
– Grennan (2013) estimates own-elasticities centered around -0.32 for bare metal stents
and -0.52 for drug-eluting stents. In general, however, the price benchmarking information
treatment could influence quantities as well. Here, we perform a set of analyses to provide
a check of this hypothesis and also provide proof of concept for how this analysis might be
incorporated in the case of products where demand is more sensitive to price.
There are two primary ways in which quantities might adjust to benchmarking price
information and subsequent renegotiations: (1) In a context where contracts specify quantities or market shares in addition to price, renegotiations to obtain better prices might also
involve large quantity or share commitments—this effect was tested and ruled out in our
analysis in Appendix C. (2) In a context where quantity is responsive to price, negotiation
of better prices would lead to increased usage in the brands with the largest relative price
decreases. We analyze this second case here.
We run the regression specifications allowing for heterogeneous treatment effects of information depending on pre-join prices and quantities, but here with quantity qhjt as the
dependent variable (results are qualitatively similar and so unreported for market shares and
log transformations):
Inf o
Qhjt = βquintile
∗ 1{posthjt } ∗ 1{quintilehj,pre }

+θhj + θt + γj ∗ (t − tminj ) + εhjt
Inf o
where βquintile
estimates the treatment effect, by price quintile. The results are shown in
Table A12.
If quantity were responsive to price (with downward sloping demand), then we would
expect quantity/share increases in exactly the areas we see relative price decreases. Because
information leads to decreases in prices for brands in the high-price, high-quantity part of
the pre-information distribution, we should expect potential quantity increases for those
brands and decreases for other brands (whose prices haven’t changed, but have become
higher relative to the brands with price decreases). This is not the case in Table A12,
where some specifications indicate that quantities may be changing slightly post join, but
no specification shows that these changes vary significantly (economically or statistically) as
one moves across the pre-join price distribution.

70

Version
θh + θj + θt + γj ∗ (t − tminj )
θh + θjt
θhj + θt + γj ∗ (t − tminj )
θhj + θjt

Inf o
Pre-info price quintiles (βquintile
=)
1
2
3
4
5
0.2
1.4
1.3
0.7
2.4∗∗

(1.5)

(1.9)

(1.7)

(1.7)

(1.1)

−0.1

2.0

1.6

1.0

2.9∗∗

(1.6)

(2.0)

(1.9)

(1.8)

(1.3)

3.2†

2.7

3.8†

2.9∗∗

3.0†

(1.3)

(1.7)

(1.3)

(1.3)

(1.1)

4.0†

3.9∗

5.2†

4.2†

5.0†

(1.5)

(2.0)

(1.5)

(1.5)

(1.3)

Authors’ calculations from PriceGuide data, 2009-2014. N = 32, 453
member-brand-months. Includes 508 members. Version 1 includes hospital, brand, and
month fixed effects, plus linear brand-specific time trends. Version 2 includes hospital and
brand-month fixed effects. Version 3 includes hospital-brand and month fixed effects, plus
linear brand-specific time trends. Version 4 includes hospital-brand and brand-month fixed
effects. Figure shows Version 3 results. Standard errors clustered at hospital (Versions 1
and 2) or hospital-brand (Versions 3 and 4) level shown in parentheses. Superscript (†)
indicates significant difference from zero at the 1% level; (**) at the 5% level; (*) at the
10% level.

Table A12: Treatment Effect on Quantity Estimates Across the Price Distribution

F.1

Censoring

The data used in this study is based on purchase orders issued by hospitals, so the data
are “censored” in the sense that we only observe a price when a transaction takes place for
a given brand-hospital-month. In our final analyses, we investigate whether this censoring
could be a potential source of bias – e.g., if is correlated with the pricing process in a way
that affects the interpretation of our results.
There are three distinct cases of these censored (qhjt = 0, phjt = .) observations: (1)
brands the hospital never contracts with; (2) brands a hospital contracts with at some point,
but not the full time the brand is available; (3) brands that are currently contracted with,
but not purchased in a given month due to sampling variation.
Cases (1) and (2) relate to the issue of whether hospitals contract with the “full support”
of manufacturers, which is analyzed in Appendix C as a part of our analysis of potential
standardization and share-based contracts. There, we document that almost half of hospitals
contract for the “full support” set of manufacturers/brands (among the set of larger hospitals
where sampling variation is less likely a problem). Of course, one cannot observe prices
for the censored cases, so there is no way to compare prices for censored vs. uncensored
observations. However, we can test for patterns in prices across hospitals that contract more
vs. less with a given manufacturer. There we find no economically or statistically significant
evidence that prices vary when hospitals contract exclusively with or devote more of their
market share to a manufacturer (or brand).This holds in specifications across hospitals and
within hospitals (and hospital-brand pairs). That we find no relationship on this margin we
71

can observe provides us some comfort regarding the margin we cannot.
Our quantity analyses thus far provide suggestive evidence on cases (2) and (3): if quantity were responsive to price (with downward sloping demand), then we would expect quantity/share increases in exactly the areas we see relative price decreases. This was not the
case in Table A12. However, we find it instructive to dig deeper on points (2) and (3) by
examining censoring explicitly: we examine the reduced form association between each hospital’s position in the pre-join price and quantity distributions and the degree of censoring
before and after join. That is, for each hospital-brand for which we were able to determine
relative pre-join price and quantity position, we generated a panel of all months in which that
hospital and brand existed in the database, with a dummy indicating whether we observed
nonzero purchase for that hospital-brand.
The results are shown in Table A13. First, we note that, although the quintiles of the price
distribution are mutually exclusive, this analysis only includes hospital-brands that were
observed pre-join – thus, we generally observe fewer nonzero purchases (negative coefficients)
for all hospital-brands in the post-join period as hospitals switch to newly entering brands.
Second, the largest reduced form effects are in the middle of the pre-join price distribution:
data are not differentially censored post-join for brands that were found to have relatively
high prices. To put these numbers in perspective, consider the largest coefficient: -0.15 for
the middle quintile hospital-brands in the preferred specification. Post-join, hospital-brands
in the middle of the pre-join price distribution were 15 percentage points more likely to
be censored; overall, observations for that quintile have nonzero purchase 49 percent of the
time, and full discontinuation of all usage of those brands in the post-join period would
decrease the nonzero purchase rate to 18 percent. That is, full discontinuation would more
than double the censoring rate we observe. More to the point, we do not read too much
into the average rate of censoring/discontinuation these results reveal, but rather focus on
the fact that high-priced hospital-brands exhibit slower censoring post-join than mid-range
hospital-brands.

72

Version
θh + θj + θt + γj ∗ (t − tminj )

Inf o
Pre-info price quintiles (βquintile
=)
1
2
3
−0.06
−0.01
−0.11†

4
−0.11†

5
−0.07∗

(0.04)

(0.04)

(0.03)

(0.04)

(0.04)

θh + θjt

−0.07∗

−0.00

−0.07∗∗

−0.12†

−0.04

(0.04)

(0.04)

(0.03)

(0.03)

(0.04)

θhj + θt + γj ∗ (t − tminj )

−0.03

0.01

−0.15†

−0.10†

−0.03

(0.04)

(0.03)

(0.03)

(0.03)

(0.04)

θhj + θjt

−0.04

0.00

−0.10†

−0.10†

0.00

(0.03)

(0.03)

(0.03)

(0.03)

(0.03)

Authors’ calculations from PriceGuide data, 2009-2014. N = 30, 183 member-brand-months. Identification focuses on
timing of join; sample contains 331 members. Version 1 includes hospital, brand, and month fixed effects, plus linear
brand-specific time trends. Version 2 includes hospital and brand-month fixed effects. Version 3 includes hospital-brand
and month fixed effects, plus linear brand-specific time trends. Version 4 includes hospital-brand and brand-month fixed
effects. Figure shows Version 3 results. Standard errors clustered at hospital (Versions 1 and 2) or hospital-brand
(Versions 3 and 4) level shown in parentheses. Superscript (†) indicates significant difference from zero at the 1% level;
(**) at the 5% level; (*) at the 10% level.

Table A13: Reduced Form Effect of Join on Censoring

73

