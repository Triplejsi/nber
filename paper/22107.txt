NBER WORKING PAPER SERIES

THE EFFECT OF PERFORMANCE-BASED INCENTIVES ON EDUCATIONAL ACHIEVEMENT:
EVIDENCE FROM A RANDOMIZED EXPERIMENT
Steven D. Levitt
John A. List
Sally Sadoff
Working Paper 22107
http://www.nber.org/papers/w22107

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
March 2016

We gratefully acknowledge the leadership and support of our Bloom Township School District
partners Glen Giannetti, Lynn Manning, Lenell Navarre, Ron Ray, Gloria Spires, Susan
Woodyatt, Matt Osterholt and Andrew Schmidt. Brian Jacob contributed insightful comments
that helped improve the study. Trevor Gallen, Sean Golden, Natalie Hall, David Herberich,
Mikhail Levin, Jeff Picel, Mattie Toma, Jeannine van Reeken, and Yana Peysakhovich provided
truly outstanding research assistance. The project was made possible by the generous financial
support of the Kenneth and Anne Griffin Foundation. The views expressed herein are those of the
authors and do not necessarily reflect the views of the National Bureau of Economic Research.
NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.
© 2016 by Steven D. Levitt, John A. List, and Sally Sadoff. All rights reserved. Short sections of
text, not to exceed two paragraphs, may be quoted without explicit permission provided that full
credit, including © notice, is given to the source.

The Effect of Performance-Based Incentives on Educational Achievement: Evidence from
a Randomized Experiment
Steven D. Levitt, John A. List, and Sally Sadoff
NBER Working Paper No. 22107
March 2016
JEL No. C93,I24,I25
ABSTRACT
We test the effect of performance-based incentives on educational achievement in a lowperforming school district using a randomized field experiment. High school freshmen were
provided monthly financial incentives for meeting an achievement standard based on multiple
measures of performance including attendance, behavior, grades and standardized test scores.
Within the design, we compare the effectiveness of varying the recipient of the reward (students
or parents) and the incentive structure (fixed rate or lottery). While the overall effects of the
incentives are modest, the program has a large and significant impact among students on the
threshold of meeting the achievement standard. These students continue to outperform their
control group peers a year after the financial incentives end. However, the program effects fade in
longer term follow up, highlighting the importance of longer term tracking of incentive programs.

Steven D. Levitt
Department of Economics
University of Chicago
1126 East 59th Street
Chicago, IL 60637
and NBER
slevitt@midway.uchicago.edu
John A. List
Department of Economics
University of Chicago
1126 East 59th
Chicago, IL 60637
and NBER
jlist@uchicago.edu

Sally Sadoff
Rady School of Management
Wells Fargo Hall, Room 4W121
9500 Gilman Drive #0553
La Jolla, CA 92093-0553
ssadoff@ucsd.edu

The Effect of Performance-Based Incentives on Educational
Achievement: Evidence from a Randomized Experiment∗
Steven D. Levitt, John A. List and Sally Sadoff
March, 2016

Abstract
We test the effect of performance-based incentives on educational achievement
in a low-performing school district using a randomized field experiment. High
school freshmen were provided monthly financial incentives for meeting an achievement standard based on multiple measures of performance including attendance,
behavior, grades and standardized test scores. Within the design, we compare the
effectiveness of varying the recipient of the reward (students or parents) and the
incentive structure (fixed rate or lottery). While the overall effects of the incentives
are modest, the program has a large and significant impact among students on the
threshold of meeting the achievement standard. These students continue to outperform their control group peers a year after the financial incentives end. However,
the program effects fade in longer term follow up, highlighting the importance of
longer term tracking of incentive programs.

Graduating from high school has become increasingly important in the past 25
years as wage differentials between high school graduates and dropouts have widened
(e.g., Autor, Katz and Kearney, 2008). Despite the large and increasing returns, approximately one-fifth of students fail to graduate (Murnane, 2013). Dropout rates are particularly high among low-income and minority students who are 10 to 15 percentage
∗

We gratefully acknowledge the leadership and support of our Bloom Township School District partners Glen Giannetti, Lynn Manning, Lenell Navarre, Ron Ray, Gloria Spires, Susan Woodyatt, Matt
Osterholt and Andrew Schmidt. Brian Jacob contributed insightful comments that helped improve the
study. Trevor Gallen, Sean Golden, Natalie Hall, David Herberich, Mikhail Levin, Jeff Picel, Mattie
Toma, Jeannine van Reeken, and Yana Peysakhovich provided truly outstanding research assistance.
The project was made possible by the generous financial support of the Kenneth and Anne Griffin Foundation.

1

points less likely to graduate than their white and more affluent peers (NCES, 2015).
In low-income urban school districts, graduation rates are often even lower. Chicago
Public Schools, for example, graduate only 54% of entering freshman by age 19 (Allensworth, 2005).
In contrast to many other facets of life, direct financial incentives for students are
not a standard component of the American educational system. Recent studies suggest
that freshman year performance may be critical for high school success (Allensworth
and Easton, 2005; Neild, Stoner-Eby and Frustenberg, 2008; Roderick et al., 2014).
However, the wage gains associated with earning a diploma accrue years in the future,
and may lack salience for students just beginning high school.1 Offering nearer term
incentives can potentially motivate greater investment and thus increase graduation
rates.
In this paper, we describe the results of a randomized field experiment that introduces financial incentives for meeting an achievement standard based on multiple
measures of performance including attendance, behavior, grades and standardized test
scores. The incentives had an expected value of $50 per month over the course of 8
months – or, $400 over the school year.2 The program was carried out among high
school freshmen in Chicago Heights, IL, a suburb thirty miles south of Chicago. Like
larger urban school districts, Chicago Heights high schools are made up largely of lowincome and minority students who struggle with low achievement and high dropout
rates.
There has been an explosion of academic interest in incentive based education programs in recent years.3 Our program is closest in design to a series of randomized ex1

Related research finds evidence that high discount rates among adolescents can partially explain
high school dropout behavior (Oreopoulos, 2007; Cadena and Keys, 2015).
2
Previous programs have offered incentives ranging from .07 − 5% of per capita GDP with a median
value of about 1% of per capita GDP. Our program’s incentives of $50 per month over the course of 8
months ($400 per year) are equivalent to about 0.8% of average US household income and represent a
higher fraction of household income among our primarily low-income participants.
3
Previous programs have offered incentives based on enrollment and attendance, such as Progresa/Oportunidades in Mexico (Behrman, Sengupta, and Todd, 2005; Schultz, 2004) and similar con-

2

periments conducted concurrently to ours by Roland Fryer. Fryer (2010, 2011) tests incentives for grade performance among ninth graders in Chicago; attendance, behavior
and homework among sixth, seventh and eighth graders in the District of Columbia;
interim assessment test performance among fourth and seventh graders in New York
City; and reading books among second graders in Dallas. These programs all used
monthly (or near monthly) piece rate rewards given to students. He finds that incentives for reading books (Dallas) have the largest effects, followed by incentives for attendance, behavior and homework (Washington D.C.). The test-based incentives (New
York City) and grade-based incentives (Chicago) have little or no effect on achievement
outcomes.
We expand on previous incentive interventions in two important ways. First, our
research design is motivated by a theoretical framework in which student performance
depends on both student and parent effort. Building on insights from behavioral economics, this model highlights the possibility that both the reward recipient within the
family (student or parent) and the incentive structure (fixed rate or lottery) may influence the effectiveness of rewards. We then test these variants within a single design in
order to compare their effectiveness.
Previous interventions have examined program features such as varying the performance measures or offering incentives with and without academic services (e.g., Fryer,
ditional cash transfer programs in Columbia (Barrera-Osorio, Bertrand, Linden and Perez-Calle, 2008),
the U.S. (Dee, 2011) and the UK (Dearden et al., 2009). Related programs have offered incentives for
post-secondary application or enrollment in the U.S. (Rodriguez-Planas, 2012; Carrell and Sacerdote,
2013). Others have conditioned incentives on test performance, such as those using high school exit
and achievement exams in Israel (Angrist and Lavy, 2009) and Texas (Jackson, 2010); standardized tests
for elementary/middle school aged students in India (Berry, 2015), Kenya (Kremer, Miguel and Thornton, 2009) and Coshocton, Ohio (Bettinger, 2012); as well as assessment tests in India (Hirshleifer, 2015),
Houston (Fryer, 2012) and the Chicago area (Levitt et al., forthcoming; List, Livingston and Neckermann, 2012). There have also been programs that like ours that reward overall school performance,
including a program for middle school students in Nepal (Sharma, 2010), high school students in the
UK (Burgess, Metcalfe and Sadoff, 2015); and college students in Canada (Angrist, Lang and Oreopoulos, 2009; Angrist, Oreopoulos and Williams, 2014), the Netherlands (Leuven, Oosterbeek, and van der
Klaauw, 2010), Italy (De Paola, Scoppa and Nistico, 2012) and several U.S. cities (Barrow et al., 2014;
Barrow and Rouse, 2013); as well as merit aid programs for high school students in the U.S. (Dynarski,
2002) and voucher programs for elementary school students in Columbia (Angrist et al., 2002; Angrist,
Bettinger and Kremer, 2006).

3

2011; Angrist, Lang and Oreopoulos, 2009; Carrell and Sacerdote, 2013). Others have
tested incentives of different size (Leuven, Oosterbeek, and van der Klaauw, 2010; De
Paola, Scoppa and Nistico, 2012; Barrow et al., 2014; Barrow and Rouse, 2013). But,
despite the now large literature on incentives in education, few studies have explored
the role of incentive design.4
Second, we follow students after the program ends to test whether improving effort
and achievement freshman year affects overall performance in high school. If the program improves human capital (e.g., knowledge, study habits, motivation, etc.) there
may be positive post-treatment effects. If however, offering students financial incentives crowds out intrinsic motivation, once the extrinsic rewards are removed student
performance may suffer (see e.g., Kohn, 1999 for further discussion).
To address this question, most incentive interventions continue to track students
after the program ends. Several studies have found positive post-treatment effects,
particularly among the subgroup of students who experience the largest impacts during treatment (Kremer, Miguel and Thornton, 2009; Angrist and Lavy, 2009; Angrist,
Lavy and Oreopoulos, 2009; Leuven, Oosterbeek and van der Klaauw, 2010; De Paola,
Scoppa and Nistico, 2012).5 However these studies tend to stop at intermediate outcomes occurring one to two years post-treatment.6 We conduct a longer term follow
4

As far as we know, Berry (2015) is the only previous study to vary the reward recipient (student
or parent) and was conducted among a very different population: young children (first, second and
third graders) in India. In studies conducted subsequently to ours, List, Livingston and Neckermann
(2012) offer incentives to students, parents and teachers in various combinations; Fryer (2012) offers
incentives simultaneously to students, parents and teachers but does not vary the recipient. To our
knowledge, ours is the only study to compare the relative effectiveness of two incentive structures (fixed
rate and lottery). In a similar vein, Volpp et al. (2008) compare a lottery incentive program to a deposit
contract program for weight loss. In education, related work conducted subsequently to ours varies
the timing, framing and types of rewards (e.g., Levitt et al., forthcoming; Burgess, Metcalfe and Sadoff,
2015; Hirshleifer, 2015).
5
There is little evidence from this work that incentives lead to crowding out, though there are examples of negative effects in particular subgroups (Leuven, Oosterbeek and van der Klaauw, 2010;
Rogriguez-Planas, 2012). More commonly, there is little or no overall impact of incentives after the
program ends (Fryer, 2011; Levitt et al., forthcoming; Barrow and Rouse, 2013; Angrist, Oreopoulos and
Williams, 2014).
6
A notable exception is Rodriguez-Planas (2012), who conducts a five-year follow up of an intervention that combines mentoring, educational services and incentives throughout high school. She finds
that female students benefit in the short, medium and long run on measures of education and employ-

4

up, tracking students for up to five years in order to measure the program’s impact on
high school achievement and graduation.
We find that while the overall impact of the incentives are modest, the program has
large and significant effects among students we predict to be at the threshold for meeting the achievement standard. These students continue to outperform their control
group peers in the year after the program ends. Our intermediate results suggest that
repeated, near-term incentives on multiple performance measures can lead to gains
in human capital that have lasting returns. However, these effects decline in longer
term follow up, highlighting the challenge of program fadeout in affecting longer term
outcomes.
We estimate overall program effects (on the achievement standard) between 4 − 6
percentage points, or a 15−22% increase. The results are largely driven by students predicted to be on the threshold of meeting the performance standards at baseline. Among
these students, we estimate treatment effects between 10 − 11 percentage points, which
represent increases of 34−40% over their control group peers. Threshold students who
receive incentives are more likely to be on track to graduate (as measured by grades)
by 14 − 15 percentage points in year 1 of the program and 11 − 12 percentage points in
year 2 after the intervention ends. These effects remain positive but are smaller and not
statistically significant in years 3 and 4, yielding no impact on high school graduation
rates.
Turning to our examination of incentive design, we do not find a significant differential impact of offering rewards to parents compared to students. We find suggestive
evidence that potential differences between these treatments may have been diluted
by the perception that the parent incentives were intended for students. We also do
not find an impact of varying the reward structure, either fixed rate or lottery. There is
ment; male students show little positive impact and some negative effects on risky behaviors. At an
estimated $26,000 per participant, the cost of the program is 65 times higher than the $400 incentive we
offer.

5

suggestive evidence that the the two novel features of our design – parent rewards and
the lottery structure – are most effective in combination, highlighting the importance
of testing multiple features of the incentive design within a single experiment.
The remainder of the paper is organized as follows. Section 2 presents the motivating framework driving our incentive design. Section 3 describes the experimental
design and provides details on program implementation. Section 4 presents results
and Section 5 concludes.

2

M OTIVATING F RAMEWORK

We develop a simple framework for education investment and production in a family.
We then consider the impact of offering monthly incentives for meeting a performance
standard. As we discuss in more detail below, our model predicts that the largest treatment effects will occur among students whose baseline achievement is on the threshold
of the standard for success. These are students for whom a small increase in effort has
a large impact on the probability that they meet the achievement standard and receive
the incentive.
We then turn to our first incentive design feature: varying the recipient of the incentive – either the student or the parent.7 We build on Becker’s seminal model of the family, the Rotten Kid Theorem (1974, 1991) which demonstrates that parents can induce
children’s investment in schooling through parental transfers. A key insight of this
model is that if transfers are unconstrained, external incentives provided to the child
will be equivalent to external incentives provided to the parent. This occurs because
the parent adjusts her internal transfers so that the child receives the same amount regardless of the reward recipient. That is, incentives given to the parent increase internal
transfers while incentives given to the student crowd out internal transfers.
Our framework explores two features of this model. First, we allow the parent to
7

For clarity, we refer to the student as male and the parent as female.

6

affect the student’s actions and outcomes not only through transfers but also through
her own effort. Second, we examine the case in which incentive equivalence fails to
hold because transfers are constrained. This can occur when parental transfers are
small, as is likely among our low income participants. In such cases, outcomes may
vary depending on the incentive recipient. Student incentives will have greater impact
when marginal student effort is relatively more effective in the education production
function. Parent incentives will have a greater impact when marginal parent effort is
relatively more effective. Importantly, parent effort operates through two channels: it
affects student achievement directly, and it also affects the student’s choice of effort.
Thus the impact of parent incentives will depend on whether parent effort is a complement or a substitute for student effort in the production function.8
Finally, we consider our second incentive design feature: varying the structure of
the incentive – either a fixed rate or a lottery of equivalent expected value. Here again
we examine the case where the standard equivalence fails. For risk neutral participants, a fixed rate incentive is equivalent to a lottery incentive with the same expected
value. However, a long line of studies beginning with Kahneman and Tversky (1979)
argue that individuals tend to overestimate or overweight small probabilities. If this
occurs in the domain of educational incentives, lottery incentives will outperform fixed
rate incentives.
2.1

F RAMEWORK

More formally, we consider a household with a student s and a parent p. A student’s
human capital ht in a given period depends on student effort est , parent effort ept and
8

De Fraja, Oliveira and Zanchi (2010) develop a model of parent, student and school effort that does
not include parental transfers. Using survey measures of effort, they find evidence that parent and
student effort are complements.

7

human capital at the beginning of the period ht−1

ht = h(est , ept , ht−1 )

where human capital at the beginning of the first period h0 is given.9 We assume human capital is weakly increasing and weakly concave in student effort, parent effort
and baseline human capital. We also assume effort and baseline human capital are
additively separable. However, student effort and parent effort may be either substitutes or complements in the production of human capital. As we discuss below, parent
incentives can potentially take advantage of such complementarities if they exist.
We cannot observe human capital, but instead observe student achievement At
which is a noisy measure of human capital

At = Â(ht ) + ε

where we assume ε is an i.i.d. error term with distribution ψ which has mean 0, variance σ 2 and a single maximum at its mean.
In a given period, a student is considered successful if his achievement meets a
given standard Ā (hereafter t = 1 unless otherwise noted). The probability π of success
is
π = π(A(h(es , ep , h0 ))) = 1 − Ψ(Ā − Â(h(es , ep , h0 )))

(1)

where Ψ is the cumulative distribution function for ψ, the distribution of the error term
9

We assume all functions are smooth on their domains of definition.

8

in achievement.10
The student and parent each receive a reward from success rs and rp respectively.11
A parent can also offer the student a bonus b for success.12 The student’s and parent’s
respective value of success are
Vs = r s + b

(2a)

Vp = r p − b

(2b)

where Vs , Vp ≥ 0 and we normalize rewards if a student is not successful to zero. We
assume an individual’s return from achievement is weakly increasing in his or her own
reward. We also assume that the student cannot make transfers to the parent and that
the parent can only give positive bonuses - that is, she cannot expropriate rewards from
the student or give negative transfers.13
Each family member maximizes his or her expected return from achievement net of
effort costs. We assume that the student and the parent are both risk neutral and that
effort costs are strictly increasing and strictly convex.
The student chooses effort es to maximize his expected return from achievement
10

In more detail,
π = π(A(h(es , ep , h0 )))
= P (A > Ā)
= P (Â + ε > Ā)
= P (ε > Ā − Â)
= 1 − P (ε ≤ Ā − Â)
= 1 − Ψ(Ā − Â(h(es , ep , h0 )))

Where P (A > Ā) is the probability that achievement A is greater than the achievement standard Ā.
11
The reward can be thought of as an individual’s present discounted value of the returns to student
achievement in the current period.
12
We assume the parent has full information and that the parent can fully commit to the contract,
which we argue holds in our context of repeated monthly rewards for parents and children living in the
same household. See, for example, Bergstrom (1989), Chami (1998) and Berry (2015) for discussion of
cases in which commitment fails to hold.
13
We discuss the implications of this constraint below. Weinberg (2001) develops a model that allows
for negative parental transfers.

9

πVs minus costs cs taking parent effort ep and the bonus b as given

max π(es , ep , h0 )Vs − cs (es )
es

The first order condition with respect to student effort es is
∂π
∂cs
Vs −
=0
∂es
∂es

(3a)

for a given parent effort ep and bonus b. Optimal student effort e∗s solves equation (3a)
above. The parent chooses effort ep and the bonus b to maximize her expected return
from achievement πVp , taking the student’s best response function e∗s (ep , Vs ) as given
max π(e∗s (ep , Vs ), ep , h0 )Vp − cp (ep )
ep ,b

subject to
b≥0
The first order condition with respect to parent effort ep is



∂π ∂e∗s
∂π
∂cp
+
=0
Vp −
∂es ∂ep ∂ep
∂ep

(3b)

The first order condition with respect to the bonus b is
∂π ∂e∗s
Vp − π ≤ 0
∂es ∂Vs

(3c)

Optimal parent effort e∗p and the optimal bonus b∗ solve the simultaneous equations (3b)
and (3c) above.14 The optimal probability of success is π ∗ = π(e∗s , e∗p , h0 ).15
We consider an incentive policy that increases either baseline student rewards rs0
14

We consider households who are at an interior solution at baseline. Below, we consider corner
solutions under incentives.
15
See Appendix B for more detail.

10

or baseline parent rewards rp0 by giving the recipient i an additional reward ∆ri if the
student is successful, i ∈ {s, p}. The treatment effect is
i

0

Z

ri0 +∆ri

π −π =
ri0

dπ ∗
dπ ∗
dri ≈
dri
dri

∆ri

(4)

ri0

where π i is optimal probability of success under incentives given to recipient i, π 0 is
the optimal probability at baseline and

dπ ∗
∆ri
dri

is the change in the probability under

incentives.
Below, we describe the predictions of our framework. We focus on the intution for
the results with the proofs provided in Appendix B.
2.2

E FFECTS

OF I NCENTIVES

Prediction 1: Incentives will increase achievement and human capital, with the largest treatment effects among students on the threshold of meeting the performance standard at baseline.
The treatment effect will be maximized among students for whom exerting additional effort has the highest marginal return, in terms of the probability of meeting the
achievement standard and receiving the reward. Because we set a single standard, the
highest marginal return occurs among students who are on the threshold of passing before rewards are introduced. These are students for whom a relatively small increase
in their effort and achievement can lead to a relatively large change in their probability
of success. For example, a student who is passing all but one of his classes can move
from failure to success by improving a single grade.
In contrast, students who are far below the achievement standard are unable or
unwilling to exert the high levels of additional effort required to meaningfully increase
their probability of receiving the reward. At the other end of the distribution, students
who are already meeting the achievement standard in the absence of rewards need to
exert little additional effort to ensure success.16
16

Students whose baseline achievement is above or far below the standard may still exert some addi-

11

By equation (4), the treatment effect is increasing in the size of the incentive ∆ri .
We assume the program rewards are sufficiently large to motivate greater effort from
students but sufficiently small such that threshold students are those whose baseline
expected achievement in the absence of incentives is near-below the achievement standard. That is, we expect our distribution to contain threshold students as well as
below-threshold and above-threshold students.17

Prediction 2: If parents are resource constrained, parent incentives will be more (less) effective
relative to student incentives when parent and student effort are complements (substitutes).
As discussed above, parent and student incentives will be equivalent if transfers
are unconstrained – i.e., the optimal bonus under incentives is an interior solution.
Suppose for example that the parent transfers $100 to the student at baseline and then
50% of any external incentive she receives. If the policymaker offers a $50 incentive to
the parent, the student will receive $100 + $25 = $125. If instead the policymaker
offers a $50 incentive to the student, the parent will reduce her transfer from $100
to $75 so that the student equivalently receives $75 + $50 = $125. Like the student,
the parent receives the same amount (here an additional $25) under both incentive
schemes. Because the value of success is equivalent across incentive schemes so too
will be optimal effort and achievement. Here, full crowding out occurs and so varying
the recipient of the incentive does not affect the outcome.
However, this requires that the parent can sufficiently reduce the bonus under student incentives without violating the constraint against negative transfers. Now consider a second case in which as before the parent transfers 50% of any external incentive she receives but only transfers $10 at baseline. Under parent incentives of $50
the student will receive $10 + $25 = $35. Under student incentives, the parent would
tional effort due to the random error term in the achievement function A = Â(ei , h0 ) + .
17
Note that if participants could only choose the marginal unit of effort (rather than the optimal level of
effort) the baseline expected achievement of threshold students would be exactly equal to the achievement standard rather than near-below it.

12

like to reduce her transfer from $10 to −$15 so that the student equivalently receives
−$15 + $50 = $35. However if parents are constrained against imposing negative
transfers then the parent will reduce her transfer to $0 (i.e., a corner solution) and the
student will receive $0 + $50 = $50. Here, the student will receive $15 more (and the
parent $15 less) under student incentives compared to under parent incentives. In this
case, full crowding out does not hold and thus outcomes may vary depending on the
incentive recipient.
More generally, in cases where baseline parental transfers are small relative to the
external rewards, the crowding out constraint may be binding and thus the effects of
student and parent incentives may not be equivalent.18 We argue that this is likely to
be the case among low income families in which baseline transfers tend to be relatively
small.19 When transfers are constrained, parents will experience larger rewards under
parent incentives than under student incentives (and vice versa - students will experience larger rewards under student incentives than under parent incentives). In such
cases, the effect of parent incentives will be greater than the effect of student incentives
if the following equation holds (see Appendix B for derivation):



∂π ∂e∗p
∂π ∂e∗s
∂π ∂e∗s
+
>
∂es ∂ep
∂ep ∂Vp
∂es ∂Vs

(5)

which is evaluated at the (constrained) optimum. The right hand side of the inequality
is the marginal impact of increasing the returns experienced by students; the left hand
side is the marginal impact of increasing the returns experienced by parents.
18

Note that if students could make transfers to parents or parents could expropriate rewards from students, then student and parent incentives would always be equivalent – i.e, the behavior of the household would be unitary.
19
For further discussion of the theoretical relationship between family income and transfers, see for
example, Becker (1981, 1991), Cox (1987), Weinberg (2001). A large body of literature demonstrates a
positive relationship between parental income and transfers to adult children (e.g., Cox and Rank ,1992;
Rosenzweig and Wolpin, 1993; Altonji, Hayashi and Kotlikoff, 1996). More recent studies document a
similar relationship for investments and transfers in childhood including overall childhood expenditures (Lino and Carlson, 2009), investments in childhood learning activities (Kaushal, Magnuson and
Waldfogel, 2011) and pocket money provided to children (Barnet-Verzat and Wolff, 2002).

13

The right-hand side is increasing in the effect of student returns on student effort
∂e∗s
∂Vs

and the effect of student effort on the probability of success

∂π
.
∂es

That is, student in-

centives will be relatively more effective the more responsive are students to incentives
and the greater the marginal impact on achievement of increased student effort.
The left-hand side is increasing in the effect of parent returns on parent effort
and the effect of parent effort on achievement

∂π ∂e∗s
∂es ∂ep

∂e∗p
∂Vp

∂π
+ ∂e
. Whereas student effort only
p

affects achievement directly, parent effort affects achievement through two channels:
∂π
∂ep

the direct effect on achievement
effect on student effort

and the indirect effect on achievement through its

∂π ∂e∗s
.
∂es ∂ep

To examine the effect of parent effort on student effort, we differentiate the first
order condition for student effort (equation (3a)) with respect to parent effort ep (evaluated the optimum). Solving for

∂e∗s
∂ep

gives
2

∂ π
V
∂e∗s
∂es ∂ep s
=
2
2
∂ep
−( ∂∂eπ2 Vs − ∂∂ec2s )
s

s

The denominator of the right hand side of the equation is positive by the second order
condition for a maximum.20 Student returns Vs are non-negative by assumption. Thus
the sign of the right hand side will be determined by the sign of the cross-partial derivative

∂2π
.
∂es ∂ep

∂2π
∂es ∂ep
∂e∗s
∂ep

When parent and student effort are substitutes in the production function

< 0, the student will reduce his own effort in response to increased parent effort

< 0. When student and parent effort are complements

parent effort will also increase student effort

∂e∗s
∂ep

∂2π
∂es ∂ep

> 0, an increase in

> 0, which will in turn increase the

effectiveness of parent incentives relative to student incentives. Thus, the relative effectiveness of parent incentives is increasing in complementarities in the production
function.
More broadly, parent incentives will be relatively more effective the more respon20

See Appendix B equation (7a).

14

sive are parents to incentives and the greater the marginal impact on achievement of
increased parent effort – either directly, or through its impact on (complementary) student effort. Offering incentives directly to parents potentially increases parent engagement and taps into complementarities in the production function if they exist. On the
other hand, if the key to increasing achievement is motivating greater effort from students themselves, then offering incentives directly to students may be more effective.

Prediction 3: Lottery rewards will outperform fixed rewards of equivalent expected value if
individuals overvalue low probability events in this domain.
We compare a fixed rate reward rF to a lottery reward rL that either the student or
parent receives with a low probability p where rL =

rF
p

. That is, the expected value of

the rewards are equivalent under the two incentive structures
prL = p

rF
= rF
p

Thus, if participants value the lottery reward at its expected value, the lottery and
fixed rate incentives will be equivalent. However, as discussed above, participants
may overvalue or overestimate the likelihood of low probability events. That is, the recipient’s valuation of the reward may be greater than the expected value. Achievement
and human capital are weakly increasing in the valuation of the reward (Prediction 1).
Thus, if individuals overvalue (relative to expected value) low probability events in the
domain of educational incentives, then lottery incentives will outperform fixed rate incentives.21
21
We are considering a framework in which participants are risk neutral. If participants are risk averse,
we would expect fixed rate incentives to be relatively more effective. Conversely, participants may be
risk loving in the domain of financial rewards (Gruber, 2001; Guryan and Kearney, 2008) in which case
we would expect lottery incentives to be relatively more effective.

15

3

E XPERIMENTAL DESIGN AND PROGRAM DETAILS

Our experimental design consists of four treatment groups and a control group. In
all four treatment groups, financial incentives were offered to participants each month
from October to May. In order to qualify for the monthly reward, a student had to meet
a monthly achievement standard for attendance, behavior, grades and test scores. The
school leadership determined the standard based on what they considered to be the
minimum requirements necessary to successfully complete ninth grade.
The monthly achievement standard was: no more than one unexcused absence in
the month, no all day suspensions in the month, and letter grades of C or higher in all
classes on the last day of the month.22 In February and May, the achievement standard
additionally included either scoring at grade level or improving upon one’s fall score
on a standardized school reading assessment taken in January and April respectively.
Each month was independent so that students who did not qualify for a reward in one
month could qualify for a reward the following month and vice versa.23
The treatment groups cross the reward recipient treatment (parent or student) with
the incentive structure treatment (fixed rate or lottery), yielding four groups: Student
Fixed, Student Lottery, Parent Fixed and Parent Lottery. In the parent treatments, parents received the incentives; in the student treatments, students received the incentives.
In the fixed rate treatments, students who met the monthly achievement standards
qualified for a $50 reward. In the lottery treatments, students who met the monthly
22
We define an absence as excused if it is a school excused absence, which requires documentation
(e.g., a doctor’s note) or it is excused by a parent phone call to the school. Otherwise, the student’s
absence is considered unexcused. We consider a student as having more than one unexcused absence
if in the month he is absent for more than a full day or absent for more than a total of 350 minutes of
class (which is equivalent to a full day of classes). All day suspensions can either be full day in school
suspensions or full day out of school suspensions. In school suspensions that are not full day (e.g.,
detention) do not count towards the suspension standard. In January and May, we measured grades
using semester report card grades. In the other months, we used grades entered by teachers into an
online database.
23
However, because grades are cumulative for the year (or the semester in semester-long courses),
qualification in a given month does depend on performance in previous months (absence and suspension records are reset each month).

16

achievement standards qualified for a lottery in which they had about a 10% probability of winning $500. The lotteries were organized as follows: each month ten names
(out of about 100) were chosen randomly. If a student whose name was chosen had
met the monthly achievement standard, he (or his parent) received $500. If a student
whose name was chosen had not met the monthly achievement standards, he received
nothing.
This structure preserves an expected value for meeting the achievement standard
of about $50 per student per month across treatment groups. If a student met the
achievement standard every month, he (or his parent) received an expected value of
$400 over the course of the 8-month program.
We implemented the randomized field experiment beginning in September 2008
in the Bloom Township School District in Chicago Heights, Illinois. Bloom Township
is made up of two high schools: Bloom High School and Bloom Trail High School
(referred to hereafter as Bloom and Trail respectively).24 The district struggles with low
achievement and high dropout rates: 80% of eleventh grades fail to meet the Illinois
state standards, fewer than half the freshmen students eventually graduate, and less
than a third meet the achievement standard set forth by the school.25 As shown in
Table 1, about three-fourths of the students are African-American or Hispanic, a similar
proportion are low-income (as measured by eligibility for free or reduced lunch), and
almost 40% have a single guardian.26
We offered the program to every freshman in Bloom Township and all but 25 students (2.5%) agreed to participate. We randomized students at the individual level into
24

While both of the high schools in Bloom Township are located in Chicago Heights, they also serve
students from surrounding areas, including: Ford Heights, Lynwood, Sauk Village, South Chicago
Heights and Steger. We refer to the entire district as either Bloom Township or Chicago Heights.
25
For state standards, see Illinois District Report Card (2008). Achievement standard calculations are
based on school district data. The Chicago Heights Promise Working Group provided the estimates of
graduation rates.
26
We measure single guardian status by whether a student has one guardian listed in his school registration file. Students with more than one guardian may still live in single parent homes, as the second
guardian is not necessarily a parent or may not live in the same household as the child. Similarly, students may live in two parent homes but have only one guardian listed in their registration file.

17

the four treatment groups and one control group, blocking on school (Bloom or Trail),
gender, race/ethnicity and baseline (eighth grade) test score when available.27 Thus,
at each school about 80% of freshmen were in a treatment group and about 20% were
in the control group.28
Table 1 presents the student means for demographics and baseline achievement by
treatment group. There are no statistically significant differences between the control
and treatment groups on the blocked characteristics (school, gender, race/ethnicity
and baseline test score). We are also well balanced on the additional demographic
characteristics including eligibility for free or reduced priced lunch, single guardian
status, English as a Second Language (ESL) status and eligibility for an Individualized Education Plan (IEP); as well as, baseline achievement measures taken before the
program announcement six weeks into school, which include baseline grade point average (GPA) and baseline grades, absences and suspensions (measured by whether
students met the relevant achievement standard in the first month of school).29 The
one exception is highly significant differences across groups for the number of honors
class assignments (honors status was not available at the time of randomization).30 The
percentage of honors students in the treatment groups is about twice the percentage in
the control group, a difference that is statistically significant at the p < 0.01 level. As
shown below, the results are robust to including honors classes along with our other
covariates.
27
The only exception to individual level randomization is that we randomized siblings into the same
treatment group. Eighth grade test scores were only available for about half the students at the time of
randomization.
28
Our initial randomization included every student in Bloom Township as of mid-September. We
conducted a second randomization in January to include 26 students who entered Bloom Township
after our initial randomization.
29
An Individualized Education Plan (IEP) is a written plan for students eligible for special education
services. GPA is an average of a student’s grades in each of her classes with a minimum of 0 and a
maximum of 4. Students with a C average have a GPA of 2.
30
Honors class assignments measure a student’s honors class assignments in English and math. These
assignments occurred at the beginning of the year before the program began and are based on the student’s performance in eighth grade (students are assigned to either regular or honors classes in English
and math).

18

We announced the “Chicago Heights Miracle” program the third week in September, approximately six weeks after school had begun. Students’ performance as of the
program announcement serves as their baseline achievement. We held informational
meetings for each of the treatment groups at the students’ schools. In the fixed rate
groups, we offered reward recipients $20 in cash to attend the informational meeting.
In the lottery groups, we randomly chose 10 names (out of about 100) to receive a cash
reward of $200. Participants had to attend the meeting to receive the reward. These
rewards were designed to demonstrate the program incentives and encourage attendance. Families who did not attend the meeting received the informational materials
by mail. We did not distribute materials to families in the control group. However, not
surprisingly, control group participants did learn about the program from their peers
(over 90% of control group students report that they have heard about the program).
Each month during the school year, we held “Miracle Rewards Day” meetings for
each of the treatment groups.31 While we notified participants of their achievement
status prior to the meeting, both participants who had met the achievement standard
and those who had not met the achievement standard were encouraged to attend. We
advertised meetings through mailings and phone calls. And, we incentivized attendance by offering free food and a raffle for ten $40 gift cards (participants did not need
to meet the achievement standard to qualify for the raffle).
At the meetings for the fixed rate treatment, we paid qualifying participants $50 in
cash. At the meetings for the lottery treatment, we held a public lottery in which we
randomly chose 10 lottery winners (out of about 100) in each group.32 Lottery winners
who had met the monthly achievement standards received $500 in cash (or their parent
31

We held separate meetings for Bloom participants and Trail participants. We also held separate
meetings for the fixed rate and lottery groups. We pooled the student and parent groups into the same
meeting. We therefore held four meetings each month: Bloom fixed rate (students and parents), Bloom
lottery (students and parents), Trail fixed rate (students and parents) and Trail lottery (students and
parents).
32
Lottery winners were chosen by pulling 10 bingo balls from a tumbler. We assigned each participant
an anonymous number that corresponded to one of the numbered bingo balls.

19

did). Lottery winners who had not met the monthly achievement standards received
nothing. We also presented winners with an oversized check and gave them a ride
home in a Hummer limousine. These features aimed to increase the excitement around
the lottery and celebrate the success of students who met the achievement standard.
Similarly, qualifying students in all treatment groups received a wristband that read “I
met the standards.”
At the meetings we handed out reminder notices for the next meeting that described the monthly achievement standard and incentives. We also distributed report
cards describing students’ performance on each of the standards, which we discussed
individually with students and parents. We addressed questions they had about their
performance, offered guidance on how students could improve and encouraged them
to meet the achievement standard in the coming month. Participants who did not attend the meeting received meeting notices and report cards by mail. If they qualified
for a reward, we sent them a check for their reward. We also notified students who
had been chosen in the lottery but did not qualify for a reward due to a failure to meet
the achievement standard.
In addition to monthly meetings and mailings, we made monthly phone calls to
participants to discuss their performance and encourage them to meet the achievement
standard.33 We also worked with an administrator at each school that acted as the inschool liaison for the program, addressing student questions and concerns about the
program and facilitating school services, such as after school tutoring for participants.
We term as “cheerleading” the combined efforts of the monthly meetings, mailings,
phone calls and in-school administration. We designed these activities to make the rewards of the program salient, provide participants with feedback on their performance
and encourage a culture of success. Thus, the effect of our incentives includes both the
financial rewards and these non-financial features.
33

The phone calls focused effort on students whose grades were on the threshold of either meeting or
missing the achievement standard.

20

We also administered surveys to participants in the fall before the treatments were
implemented, at the end of the first semester (in mid-December), at the end of the year
(in mid-May) and in the fall of sophomore year (October) after the program ended.

4

R ESULTS

4.1

E FFECT

OF INCENTIVES ON ACHIEVEMENT

To examine the effect of incentives, we begin by pooling the four incentive treatments.
As discussed in Section 2, we predict that incentives will increase achievement, particularly among those students who are near-below the achievement threshold at baseline
(Prediction 1). These are the students for whom exerting additional effort is likely to
determine whether or not they receive the reward. In contrast, we expect small (or
zero) treatment effects among students whose baseline achievement is above or far
below the standard.
Figure 1 plots the relationship between predicted grade point average (GPA) and
the probability of meeting the achievement standard for both the control group and the
pooled treatment group.34 The vertical line represents the performance standard – i.e.,
the GPA at which 50% of students are expected to meet the grades standard.35 We use
the grade performance of the prior freshman cohort (in the year before the program
began) to estimate the achievement standard GPA, as well as the coefficients to predict end of the year GPA from baseline grade performance and student demographics.
We then apply these coefficients to our experimental cohort using their baseline grade
performance in the first six weeks of school before the program began.36
Among students whose predicted GPA is above or far below the standard, the treat34

The figure plots the proportion of students meeting the monthly achievement standard for twenty
quantiles of predicted GPA. The s-curve for each group was fitted using LOWESS.
35
The estimated performance standard GPA is 2.96.
36
We did not have the relevant data from the prior year cohort to include absences and suspensions
in the prediction. As discussed below, the grades standard largely determined whether a student met
the overall achievement standard.

21

ment and control groups are identical. However, a gap emerges among students nearbelow the standard. Here, treated students are more likely to meet the achievement
standard compared to control group peers with equivalent baseline performance. Figure 2 plots the treatment-control difference in the proportion of students meeting the
achievement standard by predicted GPA.37 The treatment-control difference is maximized near-below the standard and declines both above and far below the standard.
Our main regression results are reported in Table 2, which present OLS estimates
of the effects of incentives on meeting the monthly achievement standard, pooling the
four treatments. Each month of the program serves as an observation with standard
errors clustered by student. Estimates for the whole sample and threshold subgroups
(threshold, below threshold and above threshold) are presented first absent any controls and then including the covariates presented in Table 1.38
The first two columns of Table 2 present estimates for the full sample. Achievement
in the control group is low with only a quarter of students meeting the achievement
standard. The incentives have a modest positive impact, increasing performance by 4−
6 percentage points, significant at the p < 0.05 level. These effects represent increases
of 15 − 22% above the control group mean.
Columns (3) and (4) present results for threshold students. Notably, threshold students’ performance in the control group is very similar to the population average.
However, the impact of incentives on threshold students is about twice as large as the
effects estimated for the full sample. Incentives improve achievement by an estimated
10 − 11 percentage points, significant at the p < 0.01 level. This represents an increase
of 34 − 40% above their control group peers. Treatment effects among below threshold
37

The figure plots the difference between the proportion of students meeting the monthly achievement
standards in treatment and control for ten quantiles of predicted GPA. The treatment effect line was
fitted using LOWESS. Dashed lines indicate 95% confidence intervals. As in Figure 1, the vertical line
represents the grade performance standard.
38
We define threshold students as those whose predicted GPA is between -0.75 and 0.25 grade points
of the estimated performance standard. Appendix A Figures 1 and 2 present results by month for
the whole sample and for threshold students. All results discussed below are robust to using probit
estimates (available upon request).

22

students are positive but small and not significant. There is no impact of incentives
among above threshold students who are already meeting the achievement standard
at high rates in the control group.
As we predicted, the treatment effects are concentrated among threshold students.
In the following results therefore we focus on threshold students in order to understand the impact of incentives among students who were the most responsive to them.
4.2

E FFECT

OF INCENTIVE DESIGN

We now turn to examining the effects of varying the incentive design. As discussed
in Section 2, we predict that there may be differential effects of offering incentives to
parents rather than students. In particular, parent incentives may be relatively more
effective if they tap into complementarities of parent and student engagement in education (Prediction 2). We also varied the incentive structure in order to test whether
recipients were more responsive to lottery rewards than to fixed rate rewards of equivalent expected value (Prediction 3).
In Table 3, we estimate the treatment effects for each of our four treatment arms –
Student Fixed, Student Lottery, Parent Fixed and Parent Lottery – among all students
(columns 1-2) and among threshold students (columns 3-4). As in Table 2, each month
of the program serves as an observation with standard errors clustered by student
(odd numbered columns contain no covariates; even numbered columns contain the
covariates discussed above).
The estimated effects range from 3-8 percentage points in the full sample and generally are not statistically significant. As in Table 2, the estimated effects among threshold
students are about twice as large, ranging from from 6-16 percentage points. The Parent Lottery group which combines our two novel design features – parent rewards and
the lottery structure – has the largest estimated effects (p < 0.01). However, the effects
are not statistically distinguishable across the various treatment arms.

23

As discussed in Section 2, parent and student incentives can only differ if net parental
transfers under the two treatments differ. While we are not able to measure net transfers, our survey evidence suggests that many students received the full reward in both
the student and parent treatments. Over 60% of students in the parent incentive treatment mistakenly believed that they were the reward recipient (in the student incentive
treatment only 4% of students mistakenly believed that the parent was the reward recipient).39 This suggests that in the parent treatment, many parents transferred the full
reward to their children. Indeed, the researchers frequently witnessed parents handing
the cash incentive to students immediately after receiving it. If parental behavior leads
to equivalent transfers in both treatments, this will dampen any differential effects of
varying the reward recipient.
4.3

H ETEROGENEOUS

EFFECTS AND GAMING

Table 4 reports estimated treatment effects for the demographic subgroups we blocked
on in our randomization: gender, race/ethnicity and baseline test score. We find no
significant differences across subgroups. However, there is suggestive evidence that
treatment effects are strongest among males, black students and those scoring below
the median on the baseline test. These findings are particularly interesting in light of
previous studies that tend to find larger impacts for women (Angrist and Lavy, 2009;
Angrist, Lang and Oreopoulos, 2009; Rodriguez-Planas, 2012) and high achieving students (De Paola, Scoppa and Nistico, 2012; Leuven, Oosterbeek and van der Klaauw,
2010). The difference may be attributable to the fact that we provided nearer term
rewards compared to earlier programs. The finding that boys are more responsive
is consistent with studies demonstrating that boys are more sensitive to shorter term
rewards than girls, which may be due in part to gender differences in time preferences (e.g., Bettinger and Slonim, 2007; Castillo et al., 2011; Levitt et al., forthcoming).
39

Percentages are based on pooled responses from the winter and spring surveys, which both had a
60% response rate among treated students.

24

Similarly, there is evidence that short-run discounting is more common among lower
achieving students (Benjamin, Brown and Shapiro, 2013).
In Table 5, we examine treatment effects on each of the performance measures used
to determine the achievement standard: grades, absences, suspensions, and test scores.
Whether a student met the achievement standard was largely determined by whether
he met the grades standard. Fewer than a third of students in control meet the grades
standard and, in only 3% of cases did a student meet the grades standard but fail to
meet the achievement standard. Therefore, we examine treatment effects on non-grade
performance measures both unconditionally and conditional on a student meeting the
grades standard (columns 3 and 6).40 We find a large, positive and significant impact
on grades in both the full sample and among threshold students. The incentives do not
have a significant impact on any of the other performance measures except for a small
negative impact on threshold students meeting the attendance standard. This effect
disappears among students who are meeting the grades standard.
Finally, we address the concern that the structure of the achievement standard
could induce behaviors we broadly refer to as “gaming.” We examine two potential
forms of gaming that could be induced by the grades standard requiring students to
earn at least a C grade in all of their classes. First, a student could reduce the number
of classes he takes. Second, he could crowd his grades around the C standard – e.g.,
bring a D grade up to a C in one class by letting a B grade fall to a C in another class.
If this is the case, treated students would have a higher percentage of C grades and a
lower percentage of all other grades compared to control. In Table 6, we report the effect of treatment on the number of classes a student takes as well as the distribution of
his letter grades measured by the percentage of A grades, B grades, C grades, D grades
and E grades (where E is a failing grade).
40

As in previous tables, each month of the program serves as an observation with standard errors
clustered by student. As discussed in Section 3, test scores were only included in the achievement
standard in February and May.

25

Among threshold students, the incentives significantly decrease the percentage of D
grades which was the aim of the program. However this does not come at the expense
of above-C grades with the percentage of A grades actually increasing. The results in
the full sample are similar though not statistically significant. We also find no evidence
that treated students decrease the number of classes they take in order to more easily
satisfy the achievement standard.
4.4

M EDIUM AND LONG

TERM EFFECTS OF INCENTIVES

Our treatment group received repeated short-term incentives to meet an achievement
standard based on multiple performance measures. If human capital accumulation
requires this kind of broad-based sustained effort, then students who are responsive
to the incentives may increase their longer term achievement (Prediction 1). That is,
students who receive incentives in their freshman year will carry forward the skills acquired during treatment and outperform their control group peers after the incentives
have ended.41
To explore whether these effects persist and in particular whether we could improve high school graduation rates, we follow students for up to five years through
the end of high school (allowing an additional year to graduate). In Table 7 Panel A,
we measure the impact of treatment (in Year 1) on the probability of meeting the on
track grade standard in Year 1, Year 2, Year 3 and Year 4.42 In Panels B and C, we
measure treatment effects on 4-year and 5-year high school graduation for all students
randomized to treatment (Panel B) and conditional on Year 4 enrollment (Panel C).43
As in previous tables, we present results for both the full sample and the threshold
41

As discussed above, these effects will be attenuated if offering students performance-based incentives crowds out intrinsic motivation.
42
The dependent variable is whether semester grades meet the grades standard. Semester 1 and
Semester 2 grades determine whether students earn the necessary credits to graduate. Each semester
serves as an observation and standard errors are clustered at the student level.
43
We separately estimate the effect of treatment on attrition in Appendix Table A.1 and find no evidence of differential attrition across groups.

26

subsample, with and without covariates.
In line with the main results from Table 2, the incentives significantly improve
grades in Year 1 by 7 − 8 percentage points in the full sample (p < 0.05) and 14 − 15
percentage points among threshold students (p < 0.01). In Year 2, the effects persist
for threshold students, yielding intermediate impacts of approximately 12 percentage
points. However in longer term follow up in Years 3 and 4, the effects fade out. Among
threshold students, the effects remain positive but are about half the size and never statistically significant. Similarly, we find no impact of treatment on our measures of high
school graduation.

5

C ONCLUSION

This study reports the results of a performance-based incentive program tested using
a randomized field experiment. Within the program we test variations of the incentive
design, allowing us to compare their effectiveness. We also perform a long term follow
up of the program in order to track persistence and program fade out. We find that the
program is particularly effective among students for whom the achievement standard
is most relevant – i.e., students just below the performance measure at baseline. These
students continue to outperform their control group peers in the second year after the
incentives end. Based on our short run and intermediate follow up, we would project
that the incentives would significantly improve graduation rates at an approximate
cost of $1,200 per additional graduate.44 However, the program effects fade in years 3
and 4 yielding no impact on high school graduation rates.
These results highlight two key challenges for both performance-based incentives
and educational interventions more generally. First, programs need to be tailored to
44

Calculations are based on Year 1 and Year 2 estimated treatment effects among threshold students
and baseline rates in the control group of 0.29 in Year 1 and 0.248 in Year 2. Estimated costs range from
$1,189 to $1,255. For the full population, estimated costs per additional graduate range from $1,816 to
$2,493 with baseline rates in control of 0.294 in Year 1 and 0.225 in Year 2.

27

students’ abilities and needs, which is difficult given the broad distribution of students
in most settings (Cullen et al., 2013). Second, while our intervention and previous ones
like it have demonstrated near term impacts of incentives, we still have a limited understanding of how to effect longer term behavioral change (see Gneezy, Meier and
Biel, 2011 for further discussion). In this vein, we believe interventions aimed at building human capital in ways that allow for individualization hold the greatest promise.

R EFERENCES
Allensworth, Elaine. 2005. “Graduation and Dropout Trends in Chicago: A Look at
Cohorts of Students from 1991 through 2004.” The Consortium on Chicago School
Research.
Allensworth, Elaine and John Q. Easton. 2005. “The On-Track Indicator as a Predictor
of High School Graduation.” The Consortium on Chicago School Research.
Altonji, Joseph G., Fumio Hayashi, and Laurence Kotlikoff. 1996. “The Effects of Income and Wealth on Time and Money Transfers between Parents and Children.”
NBER Working No. 5522.
Angrist, Joshua D., Eric Bettinger, Erik Bloom, Elizabeth King and Michael Kremer.
2002. “Vouchers for Private Schooling in Columbia: Evidence from a Randomized
Natural Experiment.” American Economic Review, 92(5): 1535-1558.
Angrist, Joshua D., Eric Bettinger, and Michael Kremer. 2006. “Long-Term Educational Consequences of Secondary School Vouchers: Evidence from Administrative
Records in Columbia.” American Economic Review, 96(3): 847-862.
Angrist, Joshua D., Daniel Lang and Philip Oreopoulos. 2009. “Incentives and Services
for College Achievement: Evidence from a Randomized Trial.” American Economic
Journal: Applied Economics, 1(1): 136-63.
Angrist, Johua D., and Victor Lavy. 2009. “The Effect of High-Stakes High School
Achievement Awards: Evidence from a Group-Randomized Trial.” American Economic Review, 99(4): 1384-1414.
Angrist, Joshua, Philip Oreopoulos, and Tyler Williams. 2014. “When Opportunity
Knocks, Who Answers? New Evidence on College Achievement Awards.” Journal
of Human Resources 49(3): 572-610.
Autor, David H., Lawrence F. Katz and Melissa S. Kearney. 2008. “Trends in U.S. Wage
Inequality: Revising the Revisionists.” Review of Economics and Statistics, 90(2): 300323.
28

Barnet-Verzat, Christine, and Franois-Charles Wolff. 2002. “Motives for Pocket Money
Allowance and Family Incentives.” Journal of Economic Psychology 23(3): 339-366.
Barrera-Osorio, Felipe, Marianne Bertrand, Leigh L. Linden and Francisco Perex-Calle.
2008. “Conditional Cash Transfers in Education: Design Features, Peer and Sibling
Effects: Evidence from a Randomized Experiment in Columbia.” NBER Working
Paper No. 13890.
Barrow, Lisa, Lashawn Richburg-Hayes, Cecilia Elena Rouse, and Thomas Brock. 2014.
“Paying for Performance: The Education Impacts of a Community College Scholarship Program for Low-income Adults.” Journal of Labor Economics, 32(3): 563-599.
Barrow, Lisa, and Cecilia Elena Rouse. 2013. “Financial Incentives and Educational
Investment: the Impact of Performance-Based Scholarships on Student Time Use.”
NBER Working Paper No. 19351.
Behrman, Jere, Piyali Sengupta and Petra Todd. 2005. “Progressing through Progresa:
An Impact Assessment of a School Subsidy Experiment in Rural Mexico.” Economic
Development and Cultural Change, 54: 237-275.
Becker, Gary. 1974. ”A Theory of Social Interactions.” Journal of Political Economy, 82(6):
1063-1093.
Becker, Gary. 1981 (Enl. ed. 1991). A Treatise on the Family. Cambridge, MA: Harvard
University Press.
Benjamin, Daniel J., Sebastian A. Brown, and Jesse M. Shapiro. 2013. “‘Who is ?behavioral’? Cognitive ability and anomalous preferences.” Journal of the European Economic Association, 11(6): 1231-1255.
Bergstrom, Theodore C. 1989. “A Fresh Look at the Rotten Kid Theorem – and Other
Household Mysteries.” Journal of Political Economy, 97: 1138-59.
Berry, James. 2015. “Child Control in Education Decisions: An Evaluation of Targeted
Incentives to Learn in India.” Journal of Human Resources, 50(4): 1051-1080.
Bettinger, Eric P. 2012.“Paying to learn: The effect of financial incentives on elementary
school test scores.” Review of Economics and Statistics, 94(3): 686-698.
Bettinger, Eric and Robert Slonim. 2007. “Patience in Children: Evidence from Experimental Economics.” Journal of Public Economics, 91(1-2): 343-363.
Burgess, Simon, Robert Metcalfe and Sally Sadoff. 2015. “Using behaviour incentives
to improve performance on high stakes tests: Evidence from a field experiment.”
Working Paper.
Cadena, Brian C., and Benjamin J. Keys. 2015. “Human Capital and the Lifetime Costs
of Impatience.” American Economic Journal: Economic Policy, 7(3): 126-53.

29

Carrell, Scott E. and Bruce Sacerdote. 2013. “Late Interventions Matter Too: The Case
of College Coaching New Hampshire.” NBER Working Paper 19031.
Castillo, Marco, Paul J. Ferraro, Jeffrey L. Jordan, and Ragan Petrie. 2011. “The today
and tomorrow of kids: Time preferences and educational outcomes of children.”
Journal of Public Economics, 95(11): 1377-1385.
Chami, Ralph. 1998. “Private Income Transfers and Market Incentives.” Economica
65(260): 557-580.
Cox, Donald. 1987. “Motives for Private Income Transfers,” Journal of Political Economy,
95: 508-546.
Cox, Donald, and Mark R. Rank. 1992. “Inter-vivos Transfers and Intergenerational
Exchange.” The Review of Economics and Statistics, 305-314.
Cullen, Julie Berry, Steven D. Levitt, Erin Robertson, and Sally Sadoff. 2013. “What Can
Be Done To Improve Struggling High Schools?” The Journal of Economic Perspectives,
27(2): 133-52.
De Fraja, Gianni, Tania Oliveira, and Luisa Zanchi. ”Must try harder: Evaluating the
role of effort in educational attainment.” The Review of Economics and Statistics, 92(3):
577-597.
De Paola, Maria, Vincenzo Scoppa, and Rosanna Nistic. 2012. “Monetary Incentives
and Student Achievement in a Depressed Labor Market: Results from a Randomized
Experiment.” Journal of Human Capital, 6(1): 56-85.
Dearden, Lorraine, Carl Emmerson, Christine Frayne, and Costas Meghir. 2009. “Conditional cash transfers and school dropout rates.” Journal of Human Resources 44(4):
827-857.
Dee, Thomas S. 2011. ”Conditional Cash Penalties in Education: Evidence from the
Learnfare Experiment.” Economics of Education Review, 30(5): 924-937.
Dynarski, Mark and Philip Gleason. 2002. “How Can We Help? What We Have
Learned from Recent Federal Dropout Prevention Evaluations.” Journal of Education
for Students Placed at Risk, 7(1): 43-69.
Dynarski, Susan. 2002. “The Behavioral and Distributional Implications for Aid for
College.” American Economic Review, 92(2): 279-285.
Fryer, Roland G. 2010. “Financial Incentives and Student Achievement: Evidence from
Randomized Trials.” NBER Working Paper 15898.
Fryer, Roland G. 2011. “Financial Incentives and Student Achievement: Evidence from
Randomized Trials.” The Quarterly Journal of Economics, 126(4): 1755-1798.
Fryer, Roland G. 2012. “Aligning Student, Parent and Teacher Incentives: Evidence
from Houston Public Schools.” NBER Working Paper 17752.
30

Gneezy, Uri, Stephan Meier, and Pedro Rey-Biel. 2011. “When and Why incentives
(Don’t) Work to Modify Behavior.” The Journal of Economic Perspectives 25(4): 191-209.
Gruber, Jonathan. 2001. Risky Behavior Among Youth: An Economic Analysis. Chicago:
University of Chicago Press.
Guryan, Jonathan and Melissa S. Kearney. 2008. “Gambling at Lucky Stores: Evidence
from State Lottery Sales.” American Economic Review, 98(1): 458-73.
Heckman, James J. and Paul A. LaFontaine. 2007. “The American High School Graduation Rate: Trends and Levels.” The Review of Economics and Statistics, 92(2): 244-262.
Hirshleifer, Sarojini. 2015. “Incentives for Effort or Outputs? A Field Experiment to
Improve Student Performance.” Working Paper.
Illinois District Report Card. 2008. “Bloom Twp HSD 206 Chicago Heights, Illinois,”
Illinois State Board of Education.
Jackson, C. Kirabo. 2010. “A Little Now for a Lot Later: A Look at a Texas Advanced
Placement Incentive Program.” Journal of Human Resources, 45(3): 591-639.
Kaushal, Neeraj, Katherine Magnuson, and Jane Waldfogel. 2011. How is Family Income
Related to Investments in Childrens Learning? Russell Sage Foundation.
Kahneman, Daniel and Amos Tversky. 1979. “Prospect Theory: An Analysis of Decision Under Risk.” Econometrica, 47(2): 263-292.
Kohn, Alfie. 1999. Punished by Rewards: The Trouble with Gold Stars, Incentive Plans, A’s,
Praise, and Other Bribes. Boston: Houghton Mifflin.
Kremer, Michael, Edward Miguel and Rebecca Thornton. 2009. “Incentives to Learn.”
The Review of Economics and Statistics, 91(3): 437-456.
Levitt, Steven D., John A. List, Susanne Neckermann and Sally Sadoff. “The Behavioralist Goes to School: Leveraging Behavioral Economics to Improve Educational
Performance.” Forthcoming, American Economic Journal: Economic Policy.
Lino, Mark and Andrea Carlson. 2009. “Expenditures on Children by Families, 2008
(Miscellaneous Publication No. 1528-2008). Washington, DC: US Department of
Agriculture,” Center for Nutrition Policy and Promotion.
List, John A., Jeffrey A. Livingston and Susanne Neckermann. 2012. “Harnessing Complementarities in the Education Production Function.” Working Paper.
Murnane, Richard J. “U.S. High School Graduation Rates: Patterns and Explanations.”
Journal of Economic Literature, 5(2): 370-422.
National Center Education Statistics. 2015. “Public high school 4-year adjusted cohort graduation rate (ACGR), by race/ethnicity and selected demographics for the
United States, the 50 states, and the District of Columbia: School year 2012-13.”
31

Leuven, Edwin, Hessel Oosterbeek and Bas van der Klaauw. 2010. “The Effect of Financial Rewards on Students’ Achievement: Evidence from a Randomized Experiment.”
Journal of the European Economic Association, 8(6): 1243-1256.
Oreopoulos, Philip. 2007. “Do dropouts drop out too soon? Wealth, health and happiness from compulsory schooling.” Journal of Public Economics, 91(11):2213-2229.
Neild, Ruth Curran, Stoner-Eby, Scott and Frank Furstenberg. 2008.
”Connecting Entrance and Departure:
The Transition to Ninth Grade
and High School Dropout.” Education and Urban Society. Available at
http://eus.sagepub.com/content/early/2008/04/10/0013124508316438.
Roderick, Melissa, Thomas Kelley-Kemple, David W. Johnson, and Nicole O. Beechum.
2014. ”Preventable failure: Improvements in long-term outcomes when high schools
focused on the ninth grade year.” Chicago, IL: Consortium on Chicago School Research..
Rosenzweig, Mark R., and Kenneth I. Wolpin. 1993. “Intergenerational Support and the
Life-Cycle Incomes of Young Men and their Parents: Human Capital Investments,
Coresidence, and Intergenerational Financial Transfers.” Journal of Labor Economics,
84-112.
Schultz, T. Paul. 2004. “School Subsidies for the Poor: Evaluating the Mexican Progresa
Poverty Program.” Journal of Development Economics, 74(1): 199-250.
Sharma, Dhiraj. 2010. “The Impact of Financial Incentives on Academic Achievement
and Household Behavior: Evidence from a Randomized Trial.” Manuscript.
Volpp, Kevin G, Leslie K. John, Andrea B. Troxel, Laurie Norton, Jennifer Fassbender
and George Loewenstein. 2008. “Financial Incentive-Based Approached for Weight
Loss: A Randomized Trial.” Journal of the American Medical Association, 300(22): 26312637.
Weinberg, Bruce A. 2001. “An Incentive Model of the Effect of Parental Income on
Children.” Journal of Political Economy, 109(2): 266-280.

32

0

Proportion Meeting Achievement Standards
.25
.5
.75
1

Figure 1: Effect of Predicted GPA on Achievement

0

1

2
Predicted GPA
Control

3

4

Treated

Note: The figure plots the proportion of students meeting the monthly grades standards for each of the
twenty quantiles of predicted GPA. GPA was predicted from baseline demographic and achievement
information, using coefficients estimated from the previous cohort of Freshmen. The fitted line was
fitted using LOWESS. The vertical line indicates the achievement standard.

33

Treatment-Control Difference in Achievement Standard
-.1
0
.1
.2

Figure 2: Effect of Predicted GPA on Treatment Effects

0

1

2
Predicted GPA

3

4

Note: The figure plots the difference between the proportion of students meeting the monthly grades
standards in treatment and control for each of the ten quantiles of predicted GPA. GPA was predicted
from baseline demographic and achievement information, using coefficients estimated from the previous cohort of Freshmen. The fitted line was fitted using LOWESS. Dashed lines indicate 95% confidence
intervals. The vertical line indicates the achievement standard.

34

Table 1: Baseline Characteristics: Summary Statistics By Treatment Group

Control
193

Pooled
Treated
802

Student
Fixed
198

Parent
Fixed
199

Student
Lottery
202

Parent
Lottery
203

175

750

186

185

189

190

Bloom High School

0.469
(0.038)

0.483
(0.018)

0.495
(0.037)

0.497
(0.037)

0.466
(0.036)

0.474
(0.036)

Female

0.451
(0.038)

0.481
(0.018)

0.500
(0.037)

0.459
(0.037)

0.439
(0.036)

0.526
(0.036)

African-American

0.583
(0.037)

0.593
(0.018)

0.608
(0.036)

0.573
(0.036)

0.566
(0.036)

0.626
(0.035)

Hispanic

0.206
(0.031)

0.188
(0.014)

0.188
(0.029)

0.205
(0.030)

0.180
(0.028)

0.179
(0.028)

White

0.149
(0.027)

0.143
(0.013)

0.129
(0.025)

0.135
(0.025)

0.169
(0.027)

0.137
(0.025)

Free/Reduced Lunch

0.811
(0.030)

0.793
(0.015)

0.812
(0.029)

0.800
(0.029)

0.810
(0.029)

0.753
(0.031)

Single Guardian

0.406
(0.037)

0.345
(0.017)

0.360
(0.035)

0.286∗∗
(0.033)

0.349
(0.035)

0.384
(0.035)

English as a Second Language (ESL)

0.291
(0.034)

0.300
(0.017)

0.274
(0.033)

0.281
(0.033)

0.317
(0.034)

0.326
(0.034)

Individualized Education Plan (IEP)

0.217
(0.031)

0.184
(0.014)

0.199
(0.029)

0.178
(0.028)

0.196
(0.029)

0.163
(0.027)

Baseline Grades

0.368
(0.037)

0.352
(0.018)

0.358
(0.036)

0.311
(0.035)

0.402
(0.036)

0.335
(0.035)

Baseline Absences

0.865
(0.027)

0.871
(0.013)

0.868
(0.026)

0.898
(0.023)

0.856
(0.026)

0.863
(0.025)

Baseline Suspensions

0.883
(0.025)

0.889
(0.012)

0.885
(0.024)

0.892
(0.023)

0.917
(0.020)

0.863
(0.025)

Honors Class Assignments

0.131
(0.429)

0.284∗∗∗
(0.623)

0.237∗
(0.577)

0.324∗∗∗
(0.653)

0.280∗∗∗
(0.628)

0.295∗∗∗
(0.632)

Baseline Grade Point Average (GPA)

2.396
(1.039)

2.462
(0.966)

2.375
(1.009)

2.485
(0.967)

2.593∗
(0.933)

2.392
(0.947)

Baseline Test: Composite

−0.074
(0.902)

−0.008
(1.033)

−0.030
(1.014)

0.005
(1.000)

−0.002
(1.116)

−0.005
(1.005)

N (Assigned)
N (In Study at Leat One Month)

Note: The table reports sample means for each treatment group. Standard deviations are in parentheses.Baseline grades, absences and suspensions report the proportion of students meeting the
monthly standard. Baseline test scores are standardized to have mean zero and standard deviation one. Asterisks indicate a difference of means (compared to the control group) significant at
*0.1, **0.05, ***0.001 levels.

35

Table 2: Effect of Incentives on Achievement

All Students
(1)
(2)

Threshold Students
(3)
(4)

Below Threshold
(5)
(6)

Above Threshold
(7)
(8)

.251

.261

.034

.738

Control Mean
Treated
Covariates
Observations
Students

0.058**
(0.029)

0.040**
(0.020)

0.111**
(0.043)

0.102***
(0.038)

0.020
(0.016)

0.023
(0.017)

0.013
(0.044)

-0.002
(0.042)

No

Yes

No

Yes

No

Yes

No

Yes

7056
925

7056
925

2659
338

2659
338

2838
369

2838
369

1330
167

1330
167

Note: The table reports OLS estimates of treatment effects for the pooled treatment group.
Threshold students have expected baseline achievement within -0.75 to 0.25 grade points
of the achievement standard. The dependent variable is meeting the monthly achievement standards. Standard errors clustered by student are reported in parentheses. Odd
numbered columns contain no covariates. Even numbered columns include covariates for
school, gender, race/ethnicity, free/reduced lunch status, single guardian status, English
as a Second Language (ESL) status, Independent Education Plan (IEP) status, honors class
assignments, baseline GPA, and baseline grades, absences, suspensions, and test score.
Asterisks indicate significance at *0.1, **0.05, ***0.001 levels.

36

Table 3: Effects of Incentive Design on Achievement

All Students
(1)
(2)

Threshold Students
(3)
(4)

.251

.261

Control Mean
Student Fixed

0.044
(0.037)

0.046*
(0.025)

0.148**
(0.058)

0.105**
(0.053)

Student Lottery

0.055
(0.037)

0.033
(0.024)

0.058
(0.052)

0.075
(0.047)

Parent Fixed

0.074*
(0.038)

0.028
(0.025)

0.087
(0.054)

0.093*
(0.047)

Parent Lottery

0.059
(0.037)

0.053**
(0.025)

0.158***
(0.057)

0.137***
(0.049)

No

Yes

No

Yes

7056
925

7056
925

2659
338

2659
338

Covariates
Observations
Students

Note: The table reports OLS estimates of treatment effects for each treatment
arm. Threshold students have expected baseline achievement within -0.75 to 0.25
grade points of the achievement standard. The dependent variable is meeting the
monthly achievement standards. Standard errors clustered by student are reported
in parentheses. Columns (1) and (3) contain no covariates. Columns (2) and (4)
include covariates for school, gender, race/ethnicity, free/reduced lunch status,
single guardian status, English as a Second Language (ESL) status, Independent
Education Plan (IEP) status, honors class assignments, baseline GPA, and baseline
grades, absences, suspensions, and test score. Asterisks indicate significance at
*0.1, **0.05, ***0.001 levels.

37

Table 4: The Effect of Incentives on Achievement Within Demographic Subgroups

All
Students
0.040∗∗
(0.020)

Male
0.053∗∗
(0.024)

Gender
Female
0.027
(0.032)

Controls

Yes

Yes

Yes

Yes

Yes

Yes

Yes

Yes

Observations
Students

7056
925

3663
485

3393
440

1033
133

1373
177

4142
547

3622
462

2713
351

Treated

p-value
0.503

White
−0.060
(0.057)

Race
Hispanic Black
0.075∗
0.055∗∗
(0.041)
(0.024)

p-value
0.126

Baseline Score
Above Median Below Median
0.030
0.062∗∗
(0.028)
(0.031)

38

Note: The table reports OLS estimates of treatment effects for the pooled treatment arm within subgroups. The dependent
variable is meeting the monthly achievement standards. Standard errors clustered by student are reported in parentheses. All
columns include covariates for school, gender, race/ethnicity, free/reduced lunch status, single guardian status, English as a
Second Language (ESL) status, Independent Education Plan (IEP) status, honors class assignments, baseline GPA, and baseline
grades, absences, suspensions, and test score. The p-value reports the results of a test for equality (chow test) over the coefficients
in the given subgroup. Asterisks indicate significance at *0.1, **0.05, ***0.001 levels.

p-value
0.434

Table 5: Effect of Incentives on Grades, Attendance, Behavior and Test Scores

All Students

Grades

Control
Mean

(1)

(2)

0.300

0.063∗

0.049∗∗

(0.033)
7056
925

(0.021)
7056
925

Threshold Students
(3)

Control
Mean

(4)

(5)

0.317

0.124∗∗∗

0.117∗∗∗

(0.047)
2659
338

(0.041)
2659
338

(6)

Attendance

0.873

0.001
(0.016)
7056
925

−0.014
(0.013)
7056
925

0.003
(0.012)
2484
509

0.942

−0.034∗∗
(0.015)
2659
338

−0.043∗∗
(0.017)
2659
338

−0.004
(0.022)
1113
255

Suspensions

0.753

0.026
(0.025)
7056
925

0.014
(0.020)
7056
925

−0.011
(0.014)
2484
509

0.822

0.016
(0.035)
2659
338

0.024
(0.032)
2659
338

0.001
(0.021)
1113
255

Test Scores

0.630

−0.001
(0.035)
1495
781

−0.021
(0.036)
1495
781

0.067
(0.065)
533
324

0.602

0.013
(0.060)
588
299

0.001
(0.058)
588
299

0.113
(0.088)
220
146

No

Yes

Yes

No

Yes

Yes

No

No

Yes

No

No

Yes

Covariates
Conditional
on Grades

Note: The table reports OLS estimates of treatment effects for the pooled treatment group. Students were incentivized during Year 1 of the program. Threshold students have expected baseline achievement within -0.75 to 0.25
grade points of the achievement standard. The dependent variable is reported for each row. Meet Grades Standard is based on first semester and second semester grades in the indicated year. Standard errors are reported in
parentheses. Sample Sizes and Number of Clusters are reported below the standard errors. Columns (1), (2), (4)
and (5) only includes students enrolled in the program schools in the indicated year. Columns (3) and (6) include
attrited students who are assigned a zero for the indicated outcome. Columns (2), (3), (5), and (6) include covariates
for school, gender, race/ethnicity, free/reduced lunch status, single guardian status, English as a Second Language
(ESL) status, Independent Education Plan (IEP) status, honors class assignments, baseline GPA, and baseline grades,
absences, suspensions, and test score. Asterisks indicate signifcance at *0.1, **0.05, ***0.001 levels.

39

Table 6: Gaming of Incentives

All Students
(1)
(2)
No. of Classes

Threshold Students
(3)
(4)

0.001
(0.042)

-0.022
(0.026)

0.019
(0.072)

-0.036
(0.047)

A grades

0.017
(0.019)

0.007
(0.013)

0.044**
(0.019)

0.042**
(0.018)

B grades

-0.012
(0.016)

-0.017
(0.013)

-0.022
(0.023)

-0.019
(0.022)

C grades

0.014
(0.012)

0.009
(0.011)

0.011
(0.018)

0.006
(0.017)

D grades

-0.015
(0.011)

-0.013
(0.009)

-0.032**
(0.016)

-0.034**
(0.014)

E grades

-0.004
(0.020)

0.013
(0.012)

-0.002
(0.016)

0.003
(0.015)

No

Yes

No

Yes

7056
925

7056
925

2659
338

2659
338

Letter Grades

Covariates
Observations
Students

Note: The table reports OLS estimates of treatment effects for the pooled treatment group.
Threshold students have expected baseline achievement within -0.75 to 0.25 grade points
of the achievement standard. The dependent variable is reported for each row. Letter
grades are the percentage of A, B, C, D and E (failing) grades. Standard errors are reported
in parentheses. Columns (1) and (3) contain no covariates. Columns (2) and (4) include
covariates for school, gender, race/ethnicity, free/reduced lunch status, single guardian
status, English as a Second Language (ESL) status, Independent Education Plan (IEP) status, honors class assignments, baseline GPA, and baseline grades, absences, suspensions,
and test score. Asterisks indicate significance at *0.1, **0.05, ***0.001 levels.

40

Table 7: Long Term Effects of Incentives

All Students
(1)
(2)

Threshold Students
(3)
(4)

Panel A: Meet on Track Grade Standard
Year 1

0.083**
(0.036)
1766
904

0.065**
(0.026)
1766
904

0.147***
(0.055)
661
333

0.144***
(0.053)
661
333

Year 2

0.063*
(0.038)
1513
782

0.043
(0.035)
1513
782

0.120**
(0.061)
589
300

0.116*
(0.059)
589
300

Year 3

-0.003
(0.042)
1270
641

-0.013
(0.038)
1270
641

0.050
(0.063)
528
265

0.067
(0.060)
528
265

Year 4

0.017
(0.047)
1125
565

-0.003
(0.045)
1125
565

0.055
(0.072)
496
249

0.029
(0.071)
496
249

Panel B: High School Graduation
Graduated within 4 Years

-0.006
(0.040)
995

-0.037
(0.035)
995

-0.038
(0.064)
339

-0.034
(0.064)
339

Graduated within 5 Years

0.003
(0.040)
995

-0.028
(0.035)
995

-0.035
(0.064)
339

-0.027
(0.064)
339

Panel C: High School Graduation, Conditional on Year 4 Enrollment
Graduated within 4 Years

-0.010
(0.030)
567

-0.021
(0.029)
567

0.011
(0.036)
250

-0.004
(0.036)
250

Graduated within 5 Years

0.003
(0.029)
567

-0.005
(0.028)
567

0.016
(0.034)
250

0.005
(0.035)
250

No

Yes

No

Yes

Covariates

Note: The table reports OLS estimates of treatment effects for the pooled treatment group.
Students were incentivized during Year 1 of the program. Threshold students have expected baseline achievement within -0.75 to 0.25 grade points of the achievement standard.
The dependent variable is reported for each row. Meet on Track Grade Standard is based on
first semester and second semester grades in the indicated year. Standard errors (clustered
by student in Panel A) are reported in parentheses. Sample Sizes and Number of Students are reported below the standard errors. Columns (1) and (3) contain no covariates.
Columns (2) and (4) include covariates for school, gender, race/ethnicity, free/reduced
lunch status, single guardian status, English as a Second Language (ESL) status, Indepen41
dent Education Plan (IEP) status, honors class assignments, baseline GPA, and baseline
grades, absences, suspensions, and test score. Asterisks indicate significance at *0.1, **0.05,
***0.001 levels.

A

A PPENDIX F IGURES AND TABLES

42

.2

.3

.4

.5

.6

.7

.8

.9

1

Treatment Effects on Achievement by Month: All Students

.1

Proportion Meeting Achievement Standards

Figure 1

Baseline

Oct

Nov

Dec

Jan
Month

Control

Feb

Mar

Apr

May

Treated

Note: The figure plots the proportion of students meeting the monthly achievement standards in treatment and control for each month of the program. For consistency across months, we exclude the test
score standard that was only used in February and May. Dashed lines indicate 95% confidence intervals.

43

.1

.2

.3

.4

.5

.6

.7

.8

.9

1

Treatment Effects on Achievement by Month: Threshold Students

0

Proportion Meeting Achievement Standards

Figure 2

Baseline

Oct

Nov

Dec

Jan
Month

Control

Feb

Mar

Apr

May

Treated

Note: The figure plots the proportion of threshold students meeting the monthly achievement standards
in treatment and control for each month of the program. For consistency across months, we exclude
the test score standard that was only used in February and May. Dashed lines indicate 95% confidence
intervals.

44

Table A.1: Attrition

All Students
(1)
(2)

Threshold Students
(3)
(4)

Completed Year 1

0.028
(0.027)

-0.001
(0.021)

0.038
(0.025)

0.037
(0.025)

Completed Year 2

0.023
(0.035)

-0.013
(0.031)

-0.025
(0.050)

-0.036
(0.050)

Completed Year 3

0.028
(0.038)

-0.005
(0.035)

0.005
(0.058)

-0.003
(0.059)

Completed Year 4

0.004
(0.040)

-0.028
(0.035)

-0.053
(0.062)

-0.039
(0.062)

Covariates

No

Yes

No

Yes

Students

995

995

339

339

Note: The table reports OLS estimates of treatment effects for the pooled treatment group.
Threshold students have expected baseline achievement within -0.75 to 0.25 grade points
of the achievement standard. The dependent variable is reported for each row. Standard
errors are reported in parentheses. Columns (1) and (3) contain no covariates. Columns
(2) and (4) include covariates for school, gender, race/ethnicity, free/reduced lunch status,
single guardian status, English as a Second Language (ESL) status, Independent Education
Plan (IEP) status, honors class assignments, baseline GPA, and baseline grades, absences,
suspensions, and test score. Asterisks indicate significance at *0.1, **0.05, ***0.001 levels.

45

B

F RAMEWORK IN MORE DETAIL

Optimal human capital, optimal achievement and optimal probability of success.
Optimal human capital is
h∗ = h(e∗s , e∗p , h0 )

(6a)

A∗ = A(h∗ ) = A(h(e∗s , e∗p , h0 )) = A(e∗s , e∗p , h0 )

(6b)

Optimal achievement is

Optimal probability of success is
π ∗ = π(A∗ ) = π(A(h∗ )) = π(A(h(e∗s , e∗p , h0 ))) = π(e∗s , e∗p , h0 )

(6c)

where baseline human capital h0 is given and the following equations hold for optimal
student effort e∗s , optimal parent effort e∗p , the student’s optimal value of success Vs∗ , the
parent’s optimal value of success Vp∗ and the optimal bonus b∗ :
e∗s = es (e∗p , Vs∗ )

(6d)

e∗p = ep (Vp∗ )

(6e)

Vs∗ = Vs (b∗ ) = rs + b∗

(6f)

Vp∗ = Vp (b∗ ) = rp − b∗

(6g)

b∗ = b(rp , rs )

(6h)

Second order conditions for a maximum We assume the following second order conditions for a maximum hold at the optimum:
46

∂ 2π
∂ 2 cs
V
−
<0
s
∂e2s
∂e2s

(7a)

which follows from differentiating the first order condition for student effort (3a) with
respect to student effort es (evaluated at the optimal bonus b∗ and optimal parent effort
e∗p ).



2

∂ 2 π ∂e∗s
∂ 2 π ∂e∗s
∂π ∂ 2 e∗s ∂ 2 π
∂ 2 cp
+
2
+
+
V
−
<0
p
∂e2s ∂ep
∂es ∂ep ∂ep ∂es ∂e2p
∂e2p
∂e2p

(7b)

which follows from differentiating the first order condition for parent effort (3b) with
respect to parent effort ep . And,



2

∂ 2 π ∂e∗s
∂π ∂ 2 e∗s
∂π ∂e∗s
+
V
−
2
<0
p
∂e2s ∂Vs
∂Vs ∂Vs2
∂es ∂Vs

(7c)

which follows from differentiating the first order condition for the bonus (3c) with
respect to the optimal bonus b∗ .

Proof of Prediction 1 Incentives will increase achievement and human capital, with the
largest treatment effects among students on the threshold of meeting the performance standard
at baseline.
. We will first show that human capital, achievement and the probability of success are
weakly increasing in rewards,

dπ ∗ dA∗ dh∗
,
,
dri dri dri

≥ 0, where π ∗ , A∗ and h∗ are respectively

optimal probability of success, optimal achievement and optimal human capital, i ∈
{s, p}.
The effect of a change in student rewards on the optimal probability of success
π ∗ = π(e∗s , e∗p , h0 ) is, differentiating π ∗ with respect to rs (evaluated at the optimum)
dπ ∗
∂π ∂e∗s ∂Vs (b∗ )
=
+
drs
∂es ∂Vs ∂rs




∂π ∂e∗s
∂π ∂e∗p ∂Vp (b∗ )
+
∂es ∂ep ∂ep ∂Vp ∂rs

47

(8a)

which follows from equations (6c)-(6h). Similarly, the effect of a change in parent rewards is, differentiating π ∗ with respect to rp (evaluated at the optimum)
dπ ∗
∂π ∂e∗s ∂Vs (b∗ )
=
+
drp
∂es ∂Vs ∂rp




∂π ∂e∗s
∂π ∂e∗p ∂Vp (b∗ )
+
∂es ∂ep ∂ep ∂Vp ∂rp

(8b)

which also follows from equations (6c)-(6h).
The right-hand sides of equations (8a) and (8b) are non-negative by lemmas 1 6 and the assumption that an individual’s value of success is increasing in her own
reward. Thus, the optimal probability of success is weakly increasing in rewards,
dπ ∗ dπ ∗
,
drs drp

≥ 0.

Further,

dπ ∗
drs

dπ
dA∗
dA A∗ drs

=

dπ
dA A∗

from above.

dπ ∗
drp

and

=

dπ
dA∗
dA A∗ drp

by equations (6b)-(6h).

dπ ∗ dπ ∗
,
drs drp

≥0

≥ 0 by the assumption that the probability of success is weakly in-

creasing in achievement. Thus, optimal achievement is weakly increasing in rewards,
dA∗ dA∗
,
drs drp

≥ 0.
dA∗
drs

Similarly,
(6h).

dA∗ dA∗
,
drs drp

=

dA
dh∗
dh h∗ drs

and

dA∗
drp

=

dA
dh h∗

≥ 0 from above.

dA
dh∗
dh h∗ drp

by equations (6a)-(6b) and (6d)-

≥ 0 by the assumption that achievement is

weakly increasing in human capital. Thus, optimal human capital is weakly increasing
in rewards,

dh∗ dh∗
,
drs drp

≥ 0.

We will next show that the treatment effect is maximized for students whose optimal expected achievement Âi under incentives given to recipient i ∈ {s, p} equals the
achievement standard Ā. And, that such students are those whose baseline achievement is near-below the achievement standard. The treatment effect is
i

0

Z

ri0 +∆ri

π −π =
ri0

dπ ∗
dri =
dri

Z

ri0 +∆ri

ri0

dπ ∗ dA
dri =
dA dri

Z

A(ri0 +∆ri )

A(ri0 )

dπ ∗
dπ ∗
dA ≈
dA
dA

∆A
A0

where the first equality follows from equation (4); the second equality follows from
equations (6b)-(6h); and, the third equality follows from u-substitution under the assumption that effort and baseline human capital are additively separable and therefore
48

dA
dri

is independent of baseline achievement A0 . To find the achievement level where

the treatment effect is maximized, we differentiate the treatment effect with respect to
baseline achievement
∂
∂
(π i − π 0 ) ≈
0
∂A
∂A0



dπ ∗
dA


∆A = ψ 0 (Ā − Âi )∆A
A0

where the final equality follows from equation (1). Setting the above equal to zero
gives
ψ 0 (Ā − Âi )∆A = 0
∆A is weakly positive under incentives (prediction 1). Thus, the maximum occurs
where ψ 0 (Ā − Âi ) = 0. ψ 0 (u) = 0 at the mean of ψ, which is 0. This occurs where
Ā − Âi = 0, or Âi = Ā. Thus, the treatment effect is maximized for students whose
optimal expected achievement under incentives Âi equals the achievement standard
Ā.
Achievement and the probability of success are weakly increasing in the reward
(prediction 1). Thus, students whose optimal achievement under incentives equals the
achievement standard will have weakly lower achievement at baseline A0 ≤ Âi = Ā.
Note that if participants could only choose the marginal unit of effort (rather than the
optimal level of effort) the baseline expected achievement of threshold students would
exactly equal the achievement standard.

Prediction 2 - Derivation of equation (5)

49

. The difference in the effect of parent and student incentives is (from equation 4)
p



s

π −π ≈
=


dπ ∗ dπ ∗
−
∆r
drp
drs
!
!

 ∗
∗
∗
∗
∗
∂e
∂π ∂es
∂π
∂π ∂es
∂Vs (b ) ∂Vs (b )
p
+
−
−
∆r
∂es ∂ep ∂ep ∂Vp ∂es ∂Vs
∂rs
∂rp

(9)

evaluated at the optimum where ∆r = ∆rs = ∆rp . The final equation follows from
substituting the right-hand sides of equations (8a) and (8b) for
and substituting

(b∗ )

∂Vp
∂rp

=1−

∂Vs (b∗ )
∂rp

and

(b∗ )

∂Vp
∂rs

=1−

∂Vs (b∗ )
∂rs

dπ ∗
drs

and

dπ ∗
drp

respectively;

(Remark 1).

For interior solutions of the optimal bonus b∗ , there will be no difference between
parent and student incentives, π p − π s = 0 (lemma 8). When parents are resource
constrained, the optimal bonus under student incentives will be a corner solution
(lemma 9). In such cases, π p − π s > 0 iff the following holds, evaluated at the (constrained) optimum:



∂π ∂e∗s
∂π ∂e∗p
∂π ∂e∗s
+
>
∂es ∂ep ∂ep ∂Vp
∂es ∂Vs

which follows from equation (9),

∂Vs (b∗ )
∂rs

−

∂Vs (b∗ )
∂rp

> 0 if the optimal bonus is a corner

solution under student incentives (lemma 9) and the assumption that ∆r > 0.
Lemma 1

∂π
∂es

≥ 0 at the optimum.

Proof. At the optimum,

∂π
∂es

1 ∂cs
Vs ∂es

=

by equation (3a). The right hand side is non-

negative by the assumptions that effort costs are strictly increasing and Vs ≥ 0. Thus,
∂π
. ∂e
≥ 0 at the optimum.
s

Lemma 2

∂π ∂e∗s
∂es ∂ep

+

∂π
∂ep



Proof. At the optimum,

≥ 0 at the optimum.
∂π ∂e∗s
∂es ∂ep

+

∂π
∂ep



=

1 ∂cp
Vp ∂ep

by equation (3b). The right hand side

is non-negative by the assumptions that effort costs are strictly increasing and Vp ≥ 0.

∂π ∂e∗s
∂π
Thus, ∂e
+
≥ 0 at the optimum.
∂ep
s ∂ep
Lemma 3

∂e∗s
∂Vs

≥ 0 at the optimum.
50

Proof. Differentiating the first order condition for student effort (3a) with respect to
the student’s value of success Vs (evaluated at the optimum) and rearranging gives
∂π

∂e∗s
∂es
=
2
∂Vs
−( ∂∂eπ2 Vs −
s

∂ 2 cs
)
∂e2s

The right-hand side numerator is non-negative by lemma 1. The denominator is positive by the second order condition for a maximum (7a). Thus,

Lemma 4

∂e∗p
∂Vp

∂e∗s
∂Vs

≥ 0 at the optimum.

≥ 0 at the optimum.

Proof. Differentiating the first order condition for parent effort (3b) with respect to the
parent’s value of success Vp (evaluated at the optimum) and rearranging gives
∂e∗p
=
∂Vp
−

∂2π
∂e2s


∂e∗s 2
∂ep

+

∂π
∂π ∂e∗s
+ ∂e
∂es ∂ep
p
∂ 2 π ∂e∗s
∂π ∂ 2 e∗s
2 ∂es ∂ep ∂ep + ∂es ∂e2
p

+

∂2π
∂e2p



Vp −

∂ 2 cp
∂e2p

The right-hand side numerator is non-negative by lemma 2. The denominator is positive by the second order condition for a maximum (7b). Thus,

Lemma 5

∂Vp (b∗ )
∂rs

∂e∗p
∂Vp

≥ 0 at the optimum.

≥ 0 at the optimum.

Proof. Differentiating the parent’s value of success (2b) with respect to student rewards
rs evaluated at the optimum gives
∂Vp (b∗ )
∂
∂b∗
=
(rp − b∗ ) = −
>0
∂rs
∂rs
∂rs
where the final inequality follows from lemma 7
Lemma 6

∂Vs (b∗ )
∂rp

≥ 0 at the optimum.

51

Proof. Differentiating the student’s value of success (2a) with respect to parent rewards
rp evaluated at the optimum gives
∂Vs (b∗ )
∂
∂b∗
=
(rs + b∗ ) =
≥0
∂rp
∂rp
∂rp
where the final inequality follows from lemma 7
Lemma 7 The optimal bonus is weakly increasing in parent rewards and weakly decreasing in
student rewards, with 0 ≤

∂b∗
∂rp

≤ 1, −1 ≤

∂b∗
∂rs

≤ 0 and

∂b∗
∂rs

=

∂b∗
∂rp

− 1 at the optimum.

Proof. Differentiating the first order condition for the bonus (3c) with respect to parent
rewards rp (evaluated at the optimum) and rearranging gives
∂b∗
=
∂rp
−

∂2π
∂e2s

∂π ∂e∗s
∂es ∂Vs

∂e∗s 2
∂π ∂ 2 e∗s
+
Vp
2
∂Vs
∂Vs ∂Vs

∗

∂π ∂es
− 2 ∂e
s ∂Vs

(10a)



The right-hand side numerator is non-negative by lemmas 1 and 3. The denominator
is positive by the second order condition for a maximum (7c). Thus,

∂b∗
∂rp

≥ 0.

Differentiating the parent’s value of success (2b) with respect to parent rewards rp
(evaluated at the optimum) gives
∂Vp (b∗ )
∂
∂b∗
=
(rp − b∗ ) = 1 −
≥0
∂rp
∂rp
∂rp
where the final inequality follows from the assumption that an individual’s value of
success is increasing in her own reward. Thus,

∂b∗
∂rp

≤ 1.

Similarly, differentiating the first order condition for the bonus (equation (3c)) with
respect to student rewards rs (evaluated at the optimum) and rearranging gives

∂e∗s 2
∂π ∂e∗s
∂π ∂ 2 e∗s
+
V
−
p
2
∂Vs
∂Vs ∂Vs
∂es ∂Vs



∂ 2 π ∂e∗s 2
∂π ∂ 2 e∗s
∂π ∂e∗s
+ ∂Vs ∂V 2 Vp − 2 ∂e
∂e2s ∂Vs
∂V
s
s
s

∂2π
∂e2s

∂b∗
=
∂rs
−
∗

=

∂b
−1
∂rp
52

(10b)

where the final equality follows from equation (10a). From above, 0 ≤
−1 ≤

∂b∗
∂rs

∂b∗
∂rp

≤ 1, so

≤ 0.

Lemma 8 For interior solutions of the optimal bonus b∗ , there will be no difference between
parent and student incentives, π p − π s = 0.
Proof. We will show that for interior solutions of b∗ ,

∂Vs (b∗ )
∂rs

−

∂Vs (b∗ )
∂rp

= 0 on the right-

hand side of equation (9) and therefore π p − π s = 0.
∂
∂
Vs (b∗ ) ∂Vs (b∗ )
−
=
(rs + b∗ ) −
(rs + b∗ )
∂rs
∂rp
∂rs
∂rp
∗
∗
∂b
∂b
=1+
−
∂rs ∂rp
=0
where the final equality follows from substituting

∂b∗
∂rs

=

∂b∗
∂rp

− 1 (lemma 7).
0

Lemma 9 For corner solutions of the optimal bonus under student incentives b∗ ,
∂Vs (b∗ )
∂rp

∂Vs (b∗ )
∂rs

−

>0

Proof.
∂Vs (b∗ ) ∂Vs (b∗ )
∂
∂
0
0
−
=
(rs + b∗ ) −
(rs + b∗ )
∂rs
∂rp
∂rs
∂rp
∗0
∗0
∂b
∂b
−
=1+
∂rs
∂rp
∗
∂b
∂b∗
>1+
−
∂rs ∂rp
>0
where the first inequality follows from

∂b∗ 0
∂rs

>

∂b∗
∂rs

(remark 3); and

∂b∗ 0
∂rp

=

∂b∗
∂rp

because

bonuses are not constrained under parent rewards (remark 2). The final inequality
follows from substituting
Remark 1

∂Vp
∂rp

=1−

∂Vs
∂rp

∂b∗
∂rs

and

=
∂Vp
∂rs

∂b∗
∂rp

− 1 (lemma 7).

=1−

∂Vs
.
∂rs

53

Proof. Differentiating the parent’s value of success (2b) with respect to student rewards
rs gives
∂Vp
∂
∂b
∂b 
∂
∂Vs
=
(rp − b) = −
=1− 1+
=1−
(rs + b) = 1 −
∂rs
∂rs
∂rs
∂rs
∂rs
∂rs
Differentiating the parent’s value of success (2b) with respect to parent rewards rp gives
∂Vp
∂
∂b
∂
∂Vs
=
(rp − b) = 1 −
=1−
(rs + b) = 1 −
∂rp
∂rp
∂rp
∂rp
∂rp

Remark 2 When parents are resource constrained, the optimal bonus under student incentives
will be a corner solution. The optimal bonus under parent incentives will always be an interior
solution.
Proof. The optimal bonus bi under incentives given to recipient i ∈ {s, p} must satisfy
the non-negativity (crowding out) constraint on bonuses
0

Z

ri0 +∆ri

0 ≤ bi = b +
ri0

∂b∗
∂b∗
∂ri ≈ b0 +
∂ri
∂ri

where b0 is the optimal bonus at baseline and

∂b∗
∆ri
∂ri

∆ri

(11)

ri0

is the change in the bonus under

incentives given to recipient i ∈ {s, p}. That is, in response to incentives parents cannot
reduce the bonus by more than they transfer at baseline. From lemma 7, transfers
increase under parent incentives

∂b∗
∂rp

≥ 0 and thus the constraint will always hold;

under student incentives, however, transfers decrease

∂b∗
∂rs

≤ 0 and thus the crowding

out constraint may bind. This is more likely to occur when the external incentive ∆rs
is large relative to baseline transfers b0 . Because −1 ≤

∂b∗
∂rs

≤ 0, if the baseline bonus is

greater than the incentive b0 ≥ ∆rs , the constraint will not be binding. In such cases,
the optimal bonus b∗s is negative and so the constrained bonus will be a corner solution
b0s = 0 .
54

Remark 3 For corner solutions of the optimal bonus under students incentives,
where

∂b∗ 0
∆rs
∂rs

∂b∗ 0
∂rs

>

∂b∗
∂rs

is the constrained change in the bonus under student incentives.

Proof. If the optimal bonus under student incentives is negative bs < 0, then the constrained bonus under student incentives will be a corner solution b0s = 0. Hence
b0s > bs
∂b∗
∂b∗ 0
0
∆rs > b +
∆rs
b +
∂rs
∂rs
∂b∗ 0 ∂b∗
>
∂rs
∂rs
0

where the second equation follows from equation (11).

55

