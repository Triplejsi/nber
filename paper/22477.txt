NBER WORKING PAPER SERIES

ANALYST PROMOTIONS WITHIN CREDIT RATING AGENCIES:
ACCURACY OR BIAS?
Darren J. Kisgen
Matthew Osborn
Jonathan Reuter
Working Paper 22477
http://www.nber.org/papers/w22477

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
August 2016, Revised August 2017

We thank Ramin Baghai (discussant), Nicole Boyson, Thomas Chemmanur, Jesse Cornaggia
(discussant), Matti Keloharju, Jeffrey Pontiff, Vikram Nanda (discussant), Philip Strahan, brown
bag participants at Boston College and Harvard, seminar participants at Rice University,
University of Kansas, and University of Virginia, and conference participants at The Economics
of Credit Rating Agencies, Credit Ratings and Information Intermediaries Conference (2015),
Colorado Finance Summit (2015), Northeastern University Finance Conference (2016), and
University of Connecticut Risk Management Conference (2016) for helpful questions and
comments. Before collecting data on analyst career paths from LinkedIn.com, we submitted a
proposal to Boston College's Institutional Review Board (IRB). We were granted an exemption
from Boston College IRB review in accordance with 45 CFR 46.101 (b) 4. Our IRB Protocol
Number is 16.192.01e. The views expressed in this article are solely those of the authors, who are
responsible for the content, and do not necessarily represent the views of our employers. Any
remaining errors are our own. The views expressed herein are those of the authors and do not
necessarily reflect the views of the National Bureau of Economic Research.
NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.
© 2016 by Darren J. Kisgen, Matthew Osborn, and Jonathan Reuter. All rights reserved. Short
sections of text, not to exceed two paragraphs, may be quoted without explicit permission
provided that full credit, including © notice, is given to the source.

Analyst Promotions within Credit Rating Agencies: Accuracy or Bias?
Darren J. Kisgen, Matthew Osborn, and Jonathan Reuter
NBER Working Paper No. 22477
August 2016, Revised August 2017
JEL No. G14,G24,G28
ABSTRACT
We examine whether credit rating agencies reward accurate or biased analysts. Using data
collected from Moody’s corporate debt credit reports, we find that Moody’s is more likely to
promote analysts who are accurate, but less likely to promote analysts who downgrade frequently.
Combined, analysts who are accurate but not overly negative are approximately twice as likely to
get promoted. Further, analysts whose rating changes are more informative to the market are
more likely to get promoted, unless their ratings changes cause large negative market reactions.
Moody’s balances a desire for accuracy with a desire to cater to its corporate clients.

Darren J. Kisgen
Boston College
Fulton Hall, Finance Department
140 Commonwealth Av.
Chestnut Hill, MA 02467
Kisgen@bc.edu
Matthew Osborn
3409 Wilson Blvd, Unit 611
Arlington, VA 22201
m.g.osborn@gmail.com

Jonathan Reuter
Carroll School of Management
Boston College
224B Fulton Hall
140 Commonwealth Avenue
Chestnut Hill, MA 02467
and NBER
reuterj@bc.edu

I. Introduction
While credit ratings play an important role in bond markets and institutional investing,
their objectivity has been under scrutiny for years.1 Corporate bond ratings provide a summary
assessment of a firm’s credit quality that can be used by investors and regulators to assess risk.
However, the structure of the industry provides the potential for conflicts of interest, not least
because issuers of bonds typically pay rating agencies for the ratings on their bonds. While much
research has focused on the quality of corporate and mortgage backed security ratings (e.g., Ashcraft, Goldsmith-Pinkham, and Vickery (2010); Becker and Milbourn (2011); Griffin and Tang
(2012)), as yet little research has focused on the employees of credit rating agencies.2 In this paper, we infer Moody’s preference for accurate versus biased ratings from the internal labor market outcomes of its analysts. Specifically, we combine data on analyst promotions and departures
between 2002 and 2011 with analyst-level measures of ratings accuracy and bias and then explore how our measures correlate with subsequent career outcomes. Doing so allows us to shed
new light on the objective function of a major credit rating agency.
We collect data on Moody’s analysts names and ranks from over 40,000 “announcement”
and “ratings action” reports on corporate debt. We focus on analysts who rate corporate bonds
for two reasons. First, with over $8.5 trillion in outstanding U.S. corporate debt, this market
segment is important to investors and regulators.3 Second, and most importantly, corporate bond
ratings are the setting in which we might expect to find the strongest preference for accuracy
from credit ratings agencies, because the incentive to reward accurate ratings are arguably
1

See, for example, Cornaggia, Cornaggia, and Xia (2016) and Behr, Kisgen, and Taillard (2016).
One notable exception is Fracassi, Petry and Tate (2016). In their paper, they identify credit rating analyst fixed effects and find that these effects are important for bond yields and corporate policy. We focus
instead on linking rating characteristics to analyst promotions and departures.
3
At the end of 2016, SIFMA valued outstanding corporate debt at $8.5 trillion, outstanding mortgage related debt at $8.9 trillion, and outstanding treasury debt at $13.9 trillion.
2

2

stronger for corporate bonds than for mortgage backed securities (e.g., Frenkel (2015)). Our final
sample includes 177 Moody’s analysts covering 1,843 firms. The lowest of the five analyst ranks
is Analyst and the highest is Managing Director. We observe 102 promotions (increases in analyst rank between years t-1 and t) across 786 analyst years. Because we recognize that not all departures reflect forced exits, we collect data from LinkedIn.com on the career paths of the 75 analysts who stop authoring corporate credit reports during our sample period. We find 14 rotations
into other divisions of Moody’s and 16 employer changes that plausibly reflect external promotions, leaving us with 45 departures that plausibly reflect an unfavorable assessment of the analyst’s ratings by Moody’s.
To determine the role that accuracy plays in the 102 promotions and 45 departures, we
construct three distinct measures of accurate ratings, each with its own advantages and disadvantages. Using three measures increases the likelihood of detecting any underlying preference
of Moody’s for accurate ratings. To increase precision and reduce measurement error, our preferred specifications combine the (binary) accuracy measures into an “Accuracy Index.”
Our first measure of accuracy, “Stock Accurate,” is based on the idea that more informative rating initiations and revisions should generate larger stock price reactions. We find that analysts whose rating initiations and revisions are associated with above-median stock price reactions in year t-1 (relative to those of other Moody’s analysts, excluding earnings announcements,
and adjusting for stock-level idiosyncratic volatility) are significantly more likely to be promoted
and significantly less likely to depart in year t. While this finding is consistent with Moody’s
valuing accuracy, we recognize that Stock Accurate may also proxy for an analyst’s external
reputation, which may not perfectly correlate with accuracy. Our second measure of accuracy is
based on whether the Moody’s analyst is a ratings “leader” relative to his counterpart at S&P.

3

Specifically, if Moody’s and S&P disagree on the rating for firm j in year t-1, and S&P subsequently moves its rating toward Moody’s rating (thereby validating the initial Moody’s rating),
we classify the Moody’s analyst’s rating as “leading.” We classify an analyst as “Rating Accurate” when he has more leading ratings than the median Moody’s analyst of the same rank in the
same calendar year. We find that Rating Accurate analysts are also significantly more likely to
experience positive career outcomes at Moody’s. Our third measure of accuracy focuses on
changes in bond yields. We identify an analyst as “Yield Accurate” if, when her rating for firm j
differs from S&P’s rating, firm j’s bond yields move in the direction implied by the Moody’s
rating more often than not (e.g., if the Moody’s rating was more negative than S&P’s rating, the
yield subsequently increases). While the point estimates on Yield Accurate are economically
significant, they are not statistically significant at conventional levels, perhaps because we are
only able to calculate Yield Accurate for 55% of our analyst-year observations.4
When we combine the accuracy measures into an “Accuracy Index,” we find that a one
standard deviation increase in accuracy increases the probability of positive career outcomes between 35% and 66%, with the largest effects in the sample of analyst-years for which we can include Yield Accurate in the index. All of the differences are statistically significant at the 1%
level. To the best of our knowledge, this is the first paper to show that Moody’s rewards analysts
who generate accurate corporate bond ratings.
Next, we examine whether promotions and departures are related to measures that might
plausibly be associated with negative analyst bias (i.e., pessimism) or positive analyst bias (i.e.,
optimism).5 We measure the overall pessimism or optimism of analysts in two ways. First, we

4

The missing observations primarily reflect missing bond yield data in TRACE. See Section IV.A.
When we observe that Moody’s rating for firm j is higher than S&P’s rating, the difference could reflect
a strategic decision by the Moody’s analyst to inflate the rating or a genuine belief that the S&P rating is
5

4

evaluate the frequency that each analyst downgrades or upgrades relative to the S&P rating on a
firm. Consider a firm that has a BBB rating from Moody’s and an equivalent rating from S&P.
We view a Moody’s analyst to be more negative if the analyst downgrades the rating to BBBbut S&P does not lower its rating (defining this as a “relative downgrade”). Using S&P as a
benchmark implicitly controls for changing firm fundamentals, reducing concerns about analyst
selection bias. Using changes in ratings instead of levels of ratings also reduces concerns about a
Moody’s fixed effect or industry-analyst fixed effect. We define an analyst to have a negative
(positive) bias when he has more relative downgrades (upgrades) in a year than the median analyst, conditional on having at least one downgrade (upgrade). We find that analysts with negative
bias in year t-1 are approximately 30% less likely to experience positive career outcomes in year
t. We do not find any significant effects for analysts that we classify as upgraders.
Our second approach to identifying analyst bias relies on the rating prediction model of
Baghai, Servaes, and Tamayo (2014), which allows us to predict the rating for firm j in year t
based on its fundamentals. We then compare each analyst’s actual rating to the corresponding
model predicted rating. We classify an analyst as having a negative bias if more of his ratings fall
below the model predicted rating than above (the control group exhibits either no bias or positive
bias). We find that analysts classified as “Model Predicted Pessimists” are approximately 35%
less likely to experience positive career outcomes. We also find that analysts classified as “Model Predicted Optimists” are more likely experience positive career outcomes, but this finding is
only statistically significant at conventional levels in univariate specifications.
When we combine the two binary measures of negative bias into a “Pessimist Index,” we
too low. Because we cannot distinguish between these situations, we refer to positive bias relative to either S&P or a predictive ratings model as optimism and negative bias relative to either S&P or a predictive ratings model as pessimism. To the extent that conservative analysts prefer to issue lower ratings,
pessimism is indistinguishable from conservatism.

5

find that a one standard deviation increase in this index implies that more pessimistic analysts are
approximately 30% less likely to experience a positive career. This finding is statistically significant at the 1% level. In contrast, an “Optimist Index” based on upgrades and model predicted
optimism is neither economically nor statistically significant. We conclude that analysts who exhibit a negative bias are less likely to experience positive career outcomes at Moody’s.
To determine the relative weights that Moody’s places on accuracy versus pessimism, we
include both indices in the same specification. We find that a one standard deviation in the Accuracy Index increases the likelihood of positive career outcomes by approximately 60%, while a
one standard deviation increase in the Pessimist Index decreases the likelihood of positive career
outcomes by approximately 30%.6 The patterns are quantitatively similar and remain statistically
significant when we exclude career outcomes during the financial crisis (2008 and 2009), and
when we limit the sample to the three junior-most analyst ranks.7
To shed additional light on Moody’s preference for accuracy, we ask whether downgrades that generate large negative announcement returns are rewarded or punished by Moody’s.
Downgrades with a large negative announcement return indicate that the market has received
significant new information from the analyst report, either due to the information content of the
report itself or the overall reputation of the analyst. In either case, these downgrades arguably
help identify the most accurate analysts in our sample.8 At the same time, because downgrades

6

When we extend the specification to include the Optimist Index, the odds ratios on this third index are
both economically and statistically indistinguishable from one. See Appendix Table A-3.
7
As we highlight in Section III, all of the credit reports in our sample are signed by both a junior and a
senior analyst. Estimating our main specification on the subsample of junior analysts minimizes concerns
about the same rating appearing simultaneously in the accuracy and pessimist indices of two Moody’s
analysts.
8
Large equity returns around a downgrade might also indicate the analyst was slow to respond to negative news. However, since the market reacts significantly to the downgrade, this does not represent a situation in which the rating was slower than the market, which is a typical complaint against rating agencies.

6

highlighting significant problems with a firm’s creditworthiness are the most likely to harm relations with issuers, Moody’s may choose not to reward this outcome. We find that analysts who
generate in year t-1 an abnormal equity return in the bottom quartile of the abnormal equity returns within our sample (after excluding downgrades that coincide with earnings announcements
and adjusting for stock-level idiosyncratic volatility) are between 36% and 53% less likely to experience a positive career outcome in year t. However, we continue to find that accurate analysts
are significantly more likely to experience positive career outcomes. Consequently, while
Moody’s appears to value accurate ratings, it also appears to fault analysts whose downgrades
trigger a large negative equity return, essentially treating these downgrades as another form of
pessimism.
In our final set of tests, we shift our focus to firm coverage decisions within Moody’s.
We find that firms that are downgraded by a Moody’s analyst in year t-1 are approximately 50%
more likely to receive a new analyst in year t. This is true even when we exclude firms that require a new analyst because their former analyst departs from Moody’s in year t. This finding
complements our earlier findings that Moody’s discourages pessimist ratings.9
Overall, our findings are consistent with Moody’s valuing accuracy, but also wanting its
analysts to avoid being overly pessimistic. These are precisely the patterns that we would expect
to find if Moody’s were incentivizing analysts to balance the conflicting preferences of investors
and issuers. Our findings are broadly consistent with the findings of Hong and Kubik (2003),
who relate movements of equity analysts between brokerage houses to the accuracy and bias of
their earnings forecasts, using data between 1983 and 2000. The main difference—beyond the
Rather, a significant market reaction indicates that the rating was informative, and informing the market
should correlate to an objective for ratings accuracy.
9
While we find that Moody’s is more likely to reassigns pessimistic analysts, we do not find (in unreported regressions) any evidence that the new analysts assigned less pessimistic ratings the following year.

7

different types of analysts and time periods—is that Hong and Kubik (2003) emphasize the effect
of external promotions on analyst behavior whereas we emphasize the effect of internal promotions and (less favorable) departures.
Endogeneity is frequently a concern in papers identifying empirical relationships outside
a laboratory setting. In our case, the most likely concern would be that analysts are not randomly
assigned to firms. For example, if lower quality analysts are assigned to lower quality firms, we
might identify a relationship between downgrades and career outcomes that neglects the omitted
variable of analyst quality. We attempt to address this concern in several ways. First, three of our
five main measures match Moody’s analysts’ ratings to S&P’s ratings for the same firm (i.e.,
“Rating Accurate,” “Yield Accurate,” and “Downgrader”). For example, when we identify an
analyst as downgrading more frequently, we focus only on cases where Moody’s downgrades
and S&P does not. If lower quality analysts are assigned to lower quality firms, any impact on
downgrade frequency should cancel out, since lower quality analysts would be assigned to lower
quality firms at both Moody’s and S&P. Further, we primarily study changes in ratings. While
different quality analysts might be selected for different qualities of firms, it is less likely that
different quality analysts would be selected for firms whose ratings are about to change. And finally, two of our measures are based on changes in market prices (i.e., “Stock Accurate” and
“Yield Accurate”). If certain analysts are assigned to low quality firms, the low quality should be
reflected in market prices at the time of assignment, rather than in subsequent price changes.

8

II. Hypothesis Development and Related Literature
We test two broad hypotheses in this paper regarding the incentive systems within rating
agencies. The first hypothesis is that rating agencies internalize the preferences of institutional
investors (and government agencies) for accuracy, leading them to reward analysts whose ratings
are more accurate. Rating agencies are primarily information providers and rely on their reputations for providing accurate information to drive their business.10 If the desire for accuracy is
paramount to rating agencies, they will reward analysts who provide more accurate ratings on a
timely basis. Furthermore, a rating agency that places too little weight on accuracy may eventually lose its Nationally Recognized Statistical Ratings Organization (NRSRO) status, resulting in
dramatically lower expected revenues. Indeed, beginning in September 2007, the Securities and
Exchange Commission (SEC) began conducting annual audits of NRSROs to determine whether
each NRSRO adhered to its stated rating criteria.11
The null hypothesis is that ratings agencies do not value accuracy due to a lack of significant competition in the rating industry plus a payment model in which issuers pay for ratings.
Regulations in the rating industry simultaneously increase barriers to entry and provide a guaranteed client base since many regulations for institutional bond investment depend on ratings.
These regulations might lead rating agencies to place little weight on analyst accuracy in promotion and firing decisions. Kisgen and Strahan (2010) find that regulations based on ratings affect
10

Bouvard and Levy (2013) and Frenkel (2015) both model rating agency profits as a function of accuracy. Bouvard and Levy argue that profitability is eventually decreasing in an agency’s reputation for accuracy, because perfectly accurate ratings reduce revenues from lower-quality issuers. They also argue that
when issuers are allowed to receive ratings from multiple agencies, competition between agencies weakens the return to developing a reputation for accuracy. Frenkel (2015) argues that biased ratings are more
likely to arise when there are a small number of issuers that receive (and pay for) ratings on a large number of issues. The implication is that ratings for corporate bonds should be more accurate than ratings for
mortgage backed securities, even within the same agency.
11
We explore the impact of SEC audits on Moody’s revealed preferences for accuracy versus bias in Section IV.E.

9

a firm’s cost of capital; this implies that firms have a material reason to care about their credit
rating absent any information content of those ratings. Cornaggia and Cornaggia (2013) show
that ratings agencies that are paid directly by investors (rather than by issuers) provide ratings
that are timelier with regard to default likelihoods. Institutional investors that want to engage in
regulatory arbitrage may also place less weight on accurate ratings if bond yields do not fully
reflect the published ratings (e.g., Opp, Opp, and Harris (2013)).
The second hypothesis is that ratings agencies internalize the preferences of issuers for
optimistic ratings, leading them to reward analysts whose ratings are more optimistic and to punish analysts whose ratings are more pessimistic. To attract new business (and increase revenue),
rating agencies might forgo accuracy and offer positively biased ratings to attract clients. Institutional investors seeking higher yielding bonds than they would otherwise have access to due to
regulations may also push for inflated ratings. Some contend that optimist ratings on mortgage
backed securities contributed to the recent financial crisis (e.g., Griffin and Tang (2012)). With
respect to corporate bonds, Behr, Kisgen, and Taillard (2016) find that entrenchment due to ratings regulations enacted in 1975 led to ratings inflation. Bongaerts, Cremers, and Goetzmann
(2006) find that firms shop for ratings, especially when they have split ratings from Moody’s and
S&P around the investment grade threshold. Fracassi, Petry and Tate (2016) examine analyst bias and determine that some analysts’ ratings are systematically optimistic or pessimistic. They
show that this bias affects corporate decision making, which is consistent with the evidence in
Kisgen (2006). Kedia, Rajgopal, and Zhou (2014, 2017) present evidence that Moody’s awards
differentially higher ratings to firms from which it was likely to earn more revenues after it became a publicly traded firm, or that were held in the portfolios of its two largest post-IPO shareholders (Berkshire Hathaway and Davis Selected Advisors). None of these studies, however, use

10

the career outcomes of analysts to infer the preferences of credit rating agencies, which is our
primary contribution.
To test these hypotheses, we focus on promotions and departures. A promotion is an unambiguously positive outcome for an analyst. A departure is likely to be a negative outcome, except when the analyst is leaving to take a higher-paying, more prestigious job. For example, Cornaggia, Cornaggia, and Xia (2016) find that some analysts leave their rating agency to work for
banks for which they previously issued a favorable rating. It is important to note, however, that
this possibility does not jeopardize the interpretation of our results. Regarding pessimism, if optimistic analysts are systematically recruited away from Moody’s, we should find that optimism
leads to departures and pessimism does not. We find the opposite to be true. Regarding accuracy,
we find accurate analysts are more likely to be promoted and non-accurate analysts are more
likely to depart. It is unclear why non-accurate analysts would be differentially recruited away
from Moody’s. Indeed, Kempf (2017) finds that analysts issuing more accurate ratings for nonagency securitized finance deals are more likely to leave for an investment bank. However, to
account for departures that are positive career outcomes, we collect data on career outcomes
from LinkedIn (described below). To more cleanly infer Moody’s preferences for accuracy and
bias from career outcomes, we exclude the small number of external promotions from our tests.
III. Data
We analyze hand-collected data on Moody’s analyst coverage, ratings, promotions and
departures. Our data come from over 40,000 “announcement” and “rating action” reports published on Moody’s website between 2002 and 2011. Each report is linked to a firm and typically
includes the names and current titles of two credit rating analysts (e.g., “John Smith, Senior Ana-

11

lyst”).12 Aggregating this analyst information across all firms allows us to infer the timing of
promotions within Moody’s and departures from Moody’s. Our review of all Moody’s reports
linked to Compustat firms during the sample period yields 342 unique analysts. From this initial
list, we limit our sample to analysts with at least one year of tenure at Moody’s and at least five
analyst reports, where the analyst-rank spell begins in 2001 or later.13 We further limit our sample to analyst-years with at least one firm-level credit rating. It consists of 177 unique analysts
covering 1,843 firms across 799 analyst-years and 9,557 firm-years.
We assume that an analyst is promoted in the year of the first report in which the analyst
lists a new title. We identify 102 promotions. We do not find any instances of analyst demotions
(i.e., where an analyst assumes a lower rank subsequent to obtaining a higher rank). To identify
departures from Moody’s, we begin by identifying 75 analysts whose names appear on multiple
corporate credit reports in year t-1, but on zero corporate credit reports in year t. We then attempt
to collect data on these 75 analysts’ career paths from LinkedIn.com. Of the 54 analysts with
LinkedIn accounts, we find that 16 leave Moody’s for arguably more prestigious jobs (e.g.,
Blackstone Group, Goldman Sachs, or Merrill Lynch), 24 leave Moody’s for comparable or less
prestigious jobs (e.g., journalist, analyst at a foreign bank, analyst at A.M. Best, consultant at
S&P), and 14 rotate to another division within Moody’s. The remaining 21 analysts appear on
neither LinkedIn nor Moody’s website, leading us to conclude that they also represent departures

12

We assume an analyst covers a firm if he signed at least one of the last two analyst reports specific to
the firm. We deem a report specific to the firm, as opposed to a broader industry comment, if the report is
linked to fewer than four firms. An analyst’s coverage status expires when a new analyst begins covering
the firm, when two years pass without the analyst writing a report that references the firm, or when the
firm leaves the Compustat database.
13
Moody’s began publishing analyst reports on their website in 2000. Because we cannot determine the
history of analyst-rank spells in effect at the start of the sample, we include only analyst-rank spells that
begin in 2001 or later in our sample for analysis. This allows us to condition promotions and departures
on time in rank. Our empirical analysis is based on credit reports issued between 2002 and 2011.

12

to comparable or less prestigious firms. In the end, we classify 45 departures as “external demotions” and 14 rotations as neither a promotion nor a departure. Three of the 16 “external promotions” occur in the same calendar year as an internal promotion. Because our focus is on
Moody’s preferences for accuracy and bias, we retain these analyst-year observations as internal
promotions, and we exclude the remaining 13 “external promotions” from the measure of departures our tests, reducing the number of analyst-year observations from 799 to 786.
We supplement our hand-collected data with firm- and event-level information from other standard sources. We obtain Moody’s credit ratings data from Moody’s Default Risk Service
database.14 We then match each firm to Compustat, where we obtain firm-level financial information and the corresponding S&P ratings for each firm. We compare Moody’s rating for each
firm to S&P’s rating by converting both rating scales to a numeric index, ranging from 1 (Ca/CC
or lower) to 20 (Aaa/AAA). For this index, ratings of 11 (Baa3/BBB-) and above are considered
investment-grade, whereas ratings of 10 (Ba1/BB+) and below are considered speculative-grade.
We use daily stock return data from CRSP, and a Fama-French three factor model estimated over
the prior three years of returns, to calculate three-day abnormal stock returns around the dates of
ratings actions by analysts in the sample. We also use the daily stock return data to measure
stock-level volatility. We use RavenPack to identify the dates of corporate earnings announcements. Finally, we use the FINRA Trade Reporting and Compliance Engine (TRACE) to measure firm-level changes in bond yields between year t-1 and year t. Since analysts cover multiple
firms simultaneously, we aggregate all firm- and event-level data to the analyst-year level for our
main empirical analysis as described in the next section.
To understand how Moody’s coverage varies across analyst ranks, Table 1 reports ana14

We use Moody’s long term issuer rating. If unavailable, we use the Moody’s Corporate Family rating.

13

lyst-level summary statistics by rank. The five ranks are Analyst, Senior Analyst, Senior Credit
Officer, Senior Vice President, and Managing Director. The average Moody’s analyst rates 14.7
firms representing $161 billion in aggregate firm assets. However, the number and average size
of firms covered increases significantly with rank. The average Analyst covers 7.4 firms with an
average firm size of $11.6 billion in assets, while the average Managing Director covers 28.5
firms with an average firm size of $24.7 billion in assets. Aggregate firm assets covered increases from $34 billion for Analysts to $387 billion for Managing Directors. These statistics reveal
that analysts assume significantly broader firm coverage responsibility as they move up the ranks
within Moody’s. The average (and median) rating is consistently above the investment-grade
cutoff, but also increases slightly with analyst rank. The fact that the average difference in ratings between Moody’s and S&P is negative confirms existing evidence that ratings issued by
Moody’s are slightly lower, on average, than those issued by S&P (e.g., Jewell and Livingston
(1999) and Bongaerts, Cremers, and Goetzmann (2012)).
Moody’s corporate credit reports are signed by two analysts. Table 2 presents firm-level
summary statistics on analyst coverage for our 9,557 firm-year observations. It reveals that larger
and more highly rated firms are disproportionately assigned to Moody’s more senior analysts.
For instance, a Managing Director is the senior most rank assigned to 81.4% of firms rated A or
higher, but only 55.5% of firms rated B or lower. Likewise, a Senior Vice President or higher is
the junior most rank for 27.2% of firms rated A or higher, but only 14.2% of firms rated B or
lower. Similar patterns hold for larger versus smaller firms. In other words, Moody’s tends to
assign senior analysts to cover potentially valuable relationships with larger, less risky firms
(e.g., blue chips) while its junior analysts are assigned to smaller, riskier firms (e.g., junk issuers). More generally, Appendix Table A-1 reveals that the number of covered firms and level of

14

covered assets increase with both analyst rank and years in rank, motivating us to estimate specifications that include analyst rank-by-years in rank fixed effects.15
The average number of analysts covering each firm is consistently greater than two because we are focusing on the number of distinct analysts who cover firm j during calendar year t
and there is some firm-level turnover in analyst coverage within each calendar year. The fact that
the average number of analysts is slightly higher among lower rated firms (2.4 versus 2.2) implies that analyst turnover rates are also slightly higher among these firms. The fact that each report is signed by both a junior and a senior analyst motivates us to estimate versions of our main
specifications on the subsample of junior analysts.
Table 3 summarizes the frequency of Moody’s analyst promotions and departures. As we
describe above, we classify analyst i as having been promoted in year t if the analyst’s title
changes, for example, from Analyst to Senior Analyst during year t. We classify analyst i as having departed from Moody’s in year t if we directly observe the departure on LinkedIn, or if the
analyst signs one or more credit reports in year t-1, does not sign any credit reports in year t or
later, does not rotate to another division within Moody’s, and does not appear on LinkedIn.
Across the full sample, we observe promotion and departures in 13.0% and 6.6% of analystyears, respectively. Of the 177 unique analysts in the sample, 45.2% receive at least one promotion and 25.4% depart from Moody’s during the sample period.
The rate of both promotion and departures is highest in the two most junior positions, at
16.7% and 6.9% for an Analyst, and at 18.3% and 7.0% rate for a Senior Analyst. In addition,
when we sort by the number of years in position across all levels (Panel A), we find that the likelihood of promotion is highest in the fourth and fifth years at 24.2% and 14.0% compared to
15

We consider the possible link between accuracy, bias, and the level of covered assets in Section IV.D.

15

8.8% and 8.3% in the first and second years. Including analyst rank-by-years in rank fixed effects allows us to capture baseline differences in promotion and departure probabilities across
analyst ranks and years in rank. Although we do not observe any discernable time-series patterns
with respect to either promotions or departures when we sort the data by calendar year (Panel B),
we also estimate specifications that include calendar year fixed effects.
IV. Results
A. Measures of accuracy and bias
Our goal is to determine how ratings accuracy and bias influence the internal labor market outcomes of Moody’s analysts. Evaluating these relations empirically requires us to distinguish accurate ratings from inaccurate ratings and positive bias from negative bias. However,
studying Moody’s analysts’ ratings in isolation can raise potential measurement issues. For instance, an analyst’s propensity to downgrade or upgrade firms may simply reflect relative performance of the firms and industries that the analyst covers. To address these types of concerns,
we tend to compare Moody’s analyst ratings to corresponding ratings from S&P.
We construct three measures of Moody’s analyst accuracy. The first is based on stock returns surrounding Moody’s rating initiations and revisions (“Stock Accurate”), the second is
based on the direction of S&P rating revisions (“Rating Accurate”), and the third is based on
changes in firm-level bond yields (“Yield Accurate”). For the stock return-based measure, we
classify an analyst’s rating as being accurate if the rated company’s stock reacts significantly to
Moody’s ratings decision, based on a three factor abnormal return over a three day window
around the rating announcement (excluding any rating announcements that coincide with earn-

16

ings announcements).16 For each rating event, we calculate an accuracy “score” based on the corresponding abnormal return that accounts for the direction of the ratings changes. Specifically,
we use the absolute value of the abnormal return for new ratings, the negative of the abnormal
return for downgraded ratings, and the unadjusted abnormal return for upgraded ratings. We consider a higher score to reflect a more accurate ratings decision. Next, we aggregate the accuracy
measure to a firm-year level by taking the maximum accuracy score within each firm-year. For
example, if the Moody’s analyst downgrades a firm twice within the same year, we use the
downgrade with the highest return impact. We aggregate to analyst-year level by taking the median accuracy score across firms the analyst covered in that year. Finally, we set the “Stock Accurate” dummy variable equal to one for the half of analyst-year observations that have accuracy
scores above the median for analysts within the full sample.
To construct “Rating Accurate,” we focus on situations in which Moody’s and S&P publish different ratings for firm j in year t. In these cases, when the S&P analyst’s next rating
change reduces or eliminates this difference in ratings (i.e., when the S&P analyst follows the
lead of the Moody’s analyst), we classify the Moody’s analyst’s rating of firm j in year t as being
“leading”. We classify a Moody’s analyst as “Accurate” using this measure when his percentage
of “leading” ratings (as a percentage of firm assets) is greater than the median of all analysts in
the sample (approximately 15% or more of the analyst’s rated firm assets in year t). We set the
accuracy dummy variable equal to zero if S&P’s ratings do not converge toward Moody’s ratings, or if S&P’s and Moody’s ratings differ for less than 15% (the median) of the analyst’s rated
firm assets. Based on this measure, 313 of the 786 analyst-year observations involve a “Rating

16

While this filter is intended to reduce the likelihood that abnormal returns are contaminated by the release of other value-relevant news, the impact of “Stock Accurate” on career outcomes is quantitatively
similar to that estimated in earlier versions of the paper, which lacked this filter.

17

Accurate” analyst.
Our final measure of accuracy is based on changes in firm-level bond yields. We again
focus on situations where the Moody’s analyst assigns a higher or lower rating to firm j than the
S&P analyst. For each such rating, we then ask whether the firm’s bond yield moves in the direction implied by the Moody’s rating (e.g., the yield moves down in year t when the Moody’s rating is lower than the S&P rating in year t-1). We classify an analyst as “Yield Accurate” when
the number of successful predictions is larger than the number of unsuccessful predictions. We
calculate this measure for every analyst-year in which we can calculate the change in bond yields
for at least one covered firm. However, because we are only able to calculate changes in bond
yields in TRACE for a subset of covered firms, we are only able to calculate the “Yield Accurate” dummy variable for 436 of the 786 analyst-years within our sample.17
To increase precision and reduce measurement error, we also combine the (binary) accuracy measures into an “Accuracy Index.” The Accuracy Index used throughout much of the paper sums the “Stock Accurate” and “Rating Accurate” dummy variables. It has a mean of 0.892
and a standard deviation of 0.742. It is also highly persistent. Consider analysts for whom the
Accuracy Index in year t-1 equals zero. In year t, the Accuracy Index equals zero for 54.0%, one
for 35.2%, and two for 10.9%. For analysts for whom the Accuracy Index in year t-1 years two,
the corresponding percentages are 8.4%, 46.1%, and 45.5%. We also consider an expanded Accuracy Index that includes “Yield Accurate” (and therefore ranges between zero and three).
Among the 436 analyst-years for which this index is defined, the mean is 1.686 and the standard
deviation is 0.868.
When calculating the “Yield Accurate” measure, we restrict our sample to bonds in TRACE that are not
putable, convertible, payable-in-kind, do not have a subsidiary guarantee, and have a non-missing maturity date and a fixed coupon. Annual yield spread changes are computed from trades that fall in the December month of adjacent years.
17

18

To construct our first measures of negative and positive analyst bias, we consider the frequency with which each analyst downgrades or upgrades relative to the S&P rating on a firm.
Consider a firm that has a BBB rating from S&P and a (comparable) Baa2 rating from Moody’s.
If the Moody’s analyst lowers her rating below Baa2 in year t and the S&P analyst does not lower her rating in year t, we classify the Moody’s rating change as a downgrade. Focusing on
downgrades relative to S&P effectively controls for firm-level and industry-level shocks. If the
analyst downgrades ratings on at least 15% of the rated firm assets, we set the “Downgrader”
dummy variable equal to one for that analyst in year t. Similarly, if the analyst upgrades ratings
on at least 15% of rated firm assets in year t without corresponding upgrades by S&P, we set the
“Upgrader” dummy variable equal to one in year t. (The 15% cutoff was chosen so that approximately half of analysts who downgrade at least one firm are classified as downgraders and approximately half of analysts who upgrade at least one firm are classified as upgraders.) Based on
this approach, 316 of the 786 analyst-year observations involve downgraders and 319 involve
upgraders. Note that although a given analyst can be classified as both an “Upgrader” and a
“Downgrader” in the same calendar year, this is rarely the case.
Our second measures of negative and positive analyst bias are based on the ratings prediction model of Baghai, Servaes, and Tamayo (2014), which allows us to predict the rating for
firm j in year t based on its fundamentals. We then compare each analyst’s actual rating to the
corresponding model predicted rating. We classify an analyst as a “Model Predicted Pessimist” if
more of his ratings fall below the model predicted rating than above (the control group exhibits
either no bias or positive bias). This occurs in 201 (25.6%) of the 786 analyst years. Similarly,
we classify an analyst as a “Model Predicted Optimist” if more of his ratings fall above the model predicted rating than below. This occurs in 272 (34.6%) of the 786 analyst years. (The remain-

19

ing 313 (39.8%) observations are classified as neither model predicted pessimists or optimists.)
We construct a “Pessimist Index” by summing our “Downgrader” and “Model Predicted Pessimist” dummy variables, and we construct an analogous “Optimist Index.” The “Pessimist Index”
has a mean 0.469 and a standard deviation of 0.694, while the “Optimist Index” has a mean of
0.474 and a standard deviation of 0.674. We find that both indices are highly persistent. For example, for analysts with a Pessimist Index value in year t-1 of zero, in year t, the index equals
zero for 62.0%, one for 30.7%, and two for 7.3%. For analysts with a Pessimist Index value in
year t-1 of two, the corresponding percentages are 14.3%, 46.7%, and 39.0%. Our evidence of
persistence with respect to pessimism and optimism is consistent with Fracassi, Petry and Tate’s
(2016) findings of analyst fixed effects.
B. Does accuracy influence analyst career paths?
We explore the effect of analyst accuracy on promotions and departures in Figure 1 and
Table 4. Figure 1 plots the fraction of analysts who are promoted or depart from Moody’s in year
t for the three different values of the Accuracy Index in year t-1. (We exclude the 13 departures
that we classify as external promotions.) As the index increases from zero to two, the probability
of promotion increases monotonically from 10.6% to 16.9% while the probability of departure
decreases monotonically from 9.1% to 2.2%. These patterns suggest that Moody’s rewards analysts who generate accurate corporate bond ratings.
In Table 4, we report odds ratios from ordered logit regressions that classify promotions
as positive outcomes and departures as negative outcomes. The independent variables of interest
are the Accuracy Index and its components: the Stock Accurate, Rating Accurate, and Yield Accurate dummy variables. Panel A focuses on the full sample of analyst-year observations while
Panel B focuses on the subsample for which we can calculate Yield Accurate. For each accuracy

20

measure, we report both a univariate specification and a multivariate specification that includes a
full set of calendar year and analyst rank-by-years in rank fixed effects.
Panel A reveals that the Stock Accurate and Rating Accurate dummy variables both predict positive career outcomes regardless of whether we focus on the univariate or the multivariate
specification. Analysts classified as Stock Accurate are between 62% and 66% more likely to
experience a positive career outcome the following year (significant at the 1-percent level), while
analysts classified as Rating Accurate are between 38% and 47% more likely to do so (significant at the 10-percent level and below). The Accuracy Index, which sums the Stock Accurate
and Rating Accurate dummy variables, also successfully predicts positive career outcomes.
Our findings are qualitatively similar in Panel B, where we extend the Accuracy Index to
include the Yield Accurate dummy variable. The estimated odds ratios on the Stock Accurate
and Rating Accurate dummy variables are slightly higher than in Panel A, and the significance
levels are slightly lower. The odds ratios on Yield Accurate are economically significant, suggesting that Yield Accurate analysts are between 38% and 56% more likely to experience a positive career outcome, but neither estimate is statistically significant at conventional levels. We
conclude from Table 4 that Moody’s internal labor market rewards analysts who issue more accurate corporate bond ratings. To the best of our knowledge, this is the first paper to demonstrate
that Moody’s values accurate corporate bond rating.
C. Does bias influence analyst career paths?
In this section, we focus on analyst-level measures of negative and positive. Figures 2
and 3 present univariate patterns for the Pessimist Index and Optimist Index, respectively. Figure
2 reveals that higher levels of pessimism in year t-1 are associated with lower probabilities of
promotion and higher probabilities of departure in year t. Figure 3 reveals the highest probability

21

of promotion and the lowest probability of departure when the Optimist Index equals two, but
essentially no differences between these career outcomes when the index equals zero or one.
Panel A of Table 5 estimates ordered logits for the Pessimist Index and its components.
Downgraders and Model Predicted Pessimists are both less likely to experience positive career
outcomes in year t than their peers. The odds ratios on the components range between 0.620 and
0.707 (significant at the 10-percent level and below), while the odds ratios on the Pessimist Index range between 0.701 and 0.724 (significant at the 5-percent level and below). The implication is that Moody’s internal labor market appears to punish analysts that downgrade relative to
S&P or that issue ratings below those implied by our predicted ratings model.
Panel B estimates similar specifications for the Optimist Index and its components. The
odds ratios on the Upgrader dummy variable are close to one (1.045 and 1.059) and statistically
insignificant. Comparing the odds ratios in Panels A and B suggests that Moody’s internal labor
market punishes downgraders more than it rewards upgraders. The odds ratios on the Model Predicted Optimist dummy variable are economically larger, ranging from 1.404 in the univariate
specification to 1.309 in the multivariate specification. However, we can only reject the hypothesis that the odds ratio equals one in the univariate specification, and only at the 10-percent level.
Again, comparing Panels A and B, the implication appears to be that Moody’s punishes model
predicted pessimism more than it rewards model predicted optimism. The odds ratios on the Optimist Index vary between 1.137 and 1.182, but are statistically indistinguishable from one. We
conclude from Table 5 that Moody’s internal labor market punishes pessimistic analysts more
than it rewards optimistic analysts.18

18

Although investment-grade issuers have an obvious preference for remaining investment grade, we do
not find that Moody’s punishes analysts any more severely for downgrading firms from investment grade
to speculative grade. When we include a dummy variable indicating whether analyst i downgraded one or

22

D. Does Moody’s value accuracy, bias, or both?
We begin investigating in Table 6 whether Moody’s values accuracy, the absence of pessimism, or both. Panel A reports the fraction of analyst observations that depart from Moody’s in
year t for different values of the accuracy and pessimism indices in year t-1. For each value of
the Accuracy Index, higher values of the Pessimist Index are associated with higher departure
probabilities. Similar, for each value of the Pessimist Index, lower values of the Accuracy Index
are associated with higher departure probabilities. At the extremes, the probability of departure is
33.3% when the Accuracy Index equals zero and the Pessimist Index equals two and 0.0% when
the Accuracy Index equals two and the Pessimist Index equals one. Panel B, which instead reports the probability of promotion in year t, reinforces the possibility that Moody’s internal labor
market both rewards accuracy and punishes pessimism. In particular, the probability of promotion is 0.0% when the Accuracy Index equals zero and the Pessimist Index equals two and 36.1%
when the Accuracy Index equals two and the Pessimist Index equals one.
In Table 7, we estimate ordered logit regressions that include the Accuracy Index and the
Pessimist Index. We also estimate logit regressions where the dependent variable equals one
when the analyst is promoted in year t and zero otherwise (thereby treating analysts who remain
at Moody’s and are not promoted the same as analysts who depart from Moody’s).19 Panel A,
which focuses on the full sample of analyst-year observations, contains our main findings. The

more firms from investment grade to speculative grade in year t-1 to specifications [1] and [4] of Table 7
Panel A, we find (in unreported regressions) that the odds ratio on this dummy variable are similar to the
odds ratio on the Pessimist Index (between 0.723 and 0.784), but not statistically distinguish from one at
conventional levels in either specification (p-values of 0.485 and 0.635). Note, however, that because only 4.5% of analyst-years involve a downgrade from investment grade to speculative grade, we are forced
to define a downgrade from investment grade to speculative grade as an unconditional reductions in
Moody’s rating rather than as a reduction in Moody’s rating relative to S&P.
19
The number of analyst-year observations falls when we estimate logit regressions because we exclude
Managing Directors, for whom additional promotions are not possible.

23

probability of more favorable career outcomes increases significantly with our analyst-level Accuracy Index and decreases significantly with our analyst-level Pessimist Index. In the ordered
logits, all of the odds ratios are statistically distinguishable from one at the 1-percent level. In the
logits, the odds ratios on the Accuracy Index are closer to one. For example, in the multivariate
specifications, the odds ratio falls from 1.808 to 1.502 and statistically significance falls from the
1-percent level to the 5-percent level. These differences reflect the fact that less accurate analysts
are more likely to depart, highlighting the advantage of focusing on both promotions and (nonfavorable) departures.
The findings in Panel A are robust to alternative samples and specifications. In Panel B,
we exclude career outcomes for 2008 and 2009. Although our multivariate specifications already
include calendar year fixed effects, Panel B allows for the possibility that Moody’s revealed
preferences for accuracy and bias were skewed during the financial crisis. The odds ratios on
both indices are similar to those estimated over the full sample. In Panel C, we exclude Senior
Vice Presidents and Managing Directors. There are two reasons to consider the sample of junior
analysts. First, the fact that credit reports are signed by both junior and senior analysts implies
that a given rating is being used to measure the accuracy and bias of two different analysts. Focusing on the sample of junior analysts greatly reduces the extent to which this is true. Second, if
junior analysts have fewer managerial responsibilities, we might expect their promotions and departures to depend more strongly on the characteristics of their ratings. Alternatively, to increase
oversight of junior analysts, Moody’s might alternatively choose to hold senior analysts more
accountable for the content of each credit report. The net effect is that the odds ratios and significance levels in Panel C are similar to those in Panel A.
We include two additional robustness tests in the Appendix. In Appendix Table A-3, we

24

estimate specifications that include the Accuracy Index, Pessimist Index, and Optimist Index.
While the odds ratios and significance levels on the Accuracy Index and Pessimist Index are similar to those estimated in Table 7, none of the odds ratios on the Optimist Index (which range between 0.827 and 1.033) are statistically distinguishable from one at conventional levels. Finally,
in Appendix Table A-4, we replace the Optimist Index with the natural logarithm of rated assets
in year t-1. To the extent that this variable reflects Moody’s ongoing assessment on analyst ability, it is also likely to depend on the extent to which the analyst’s ratings are accurate or pessimist.20 Indeed, everything else equal, we find that analysts with more rated assets in year t-1 are
more likely to be promoted and less likely to depart in year t. For this reason, we prefer to exclude the measure from our main tests in Table 7. However, even controlling for the log of rated
assets, we continue to find that accurate ratings are rewarded and pessimistic ratings are punished. In the ordered logit specifications, the odds ratios on the Accuracy Index and Pessimist
Index are similar to those in Tables 7 and A-3 and consistently statistically significant from one
at the 1-percent level. In the logit specifications, the odds ratios on the Accuracy Index fall
slightly, but remain statistically significant at the 10-percent level and below. Overall, we conclude that Moody’s internal labor market punishes pessimism more than it rewards optimism.

20

While our focus has always been on analyst promotions and departures, we explored the possibility that
accurate analysts might gain covered firms and covered assets at the same time that pessimist analysts
lose them. We find a positive correlation (in unreported regressions) between the Accuracy Index and the
dollar value of covered assets, but it is economically modest and only statistically significant at the 10percent level. Moreover, there is essentially no correlation between the pessimist index and the dollar value of covered assets or between the levels of the accuracy and pessimist indices and changes in the number of covered firms. In other words, the impact of accuracy and bias on the level of covered assets appears to operate indirectly, through an increased probability of promotion and a decreased probability of
exit, rather than as an incremental reward within rank and years in rank.

25

E. Time-series variation in weights on accuracy and bias?
The SEC began conducting annual audits of NRSROs in September 2007. Its stated goal
was not to determine whether published ratings were accurate or biased relative to an absolute
standard but rather to determine whether published ratings accurately reflected each firm’s stated
methodology and criteria.21 In this section, we ask whether the weight that Moody’s placed on
accurate ratings was different in years with annual audits (2008-2011) than it was earlier (20022007). The prospect of annual audits may have prompted Moody’s to increase the weight placed
on accurate ratings in promotion and departure decisions. On the other hand, given the SEC’s
focus on internal consistency rather than absolute standards, the audits may have prompted
Moody’s either not to change the weight placed on accurate ratings or to decrease it. In Table 8,
we report versions of our main specifications in which we interact the Accuracy Index and Pessimism Index with Pre 2008 and Post 2007 dummy variables. (We also include either the Pre
2008 and Post 2007 dummy variables or the full set of calendar year fixed effects.) The odds ratio associated with the Accuracy Index falls significantly during the Post 2007 period. In ordered
logit specification [2], the odds ratio falls from 2.286 to 1.513. In logit specification [4], it falls
from 2.117 to 1.135. Both reductions are economically significant. The reduction in the logit
specification is also significant at the 10-percent level. In other words, we find suggestive evidence that Moody’s responded to the annual SEC audits by placing less weight on objective
measures of accuracy in its promotion decisions.
Of course, at around the same time as these new audits, the financial crises occurred,
which put rating agencies under further scrutiny. This additional scrutiny might arguably lead to

21

We thank Abe Losice, former SEC auditor, for describing the criteria used to evaluate NRSRO ratings.

26

a greater emphasis on accuracy by rating agencies; however, our evidence does not support this
argument.
F. Accuracy versus extreme equity market reactions to rating decisions
To shed additional light on the extent to which Moody’s values accuracy, we examine
whether the stock market announcement returns in the three days around a credit report in year t1 predict analyst promotions or departures in year t.22 On the one hand, analysts may be rewarded for reports that convey new information about default risk to market participants, even if that
information is negative. On the other hand, analysts may be punished for reports that significantly reduce the market capitalization of Moody’s clients. To distinguish between these two possibilities, we focus on the most negative announcement returns (after scaling by firm-level volatility and excluding three day windows that include firm earnings announcements).
The initial set of ordered logit and logit specifications in Table 9 replicate specifications
from Table 7. The new independent variable in the remaining specifications equals one if at least
one of the analyst’s announcement returns in year t-1 was in the bottom quartile of all announcement returns in our sample (-9.7% and below). We find strong evidence that low abnormal returns are associated with less favorable career outcomes, suggesting that Moody’s faults
those analysts whose downgrades most surprise the market. However, we also continue to find
that Moody’s rewards accuracy, with odds ratios that are even further above one. One interpretation of these patterns, in the spirit of Opp, Opp, and Harris’ (2013) political economy model of
rating agencies, is that Moody’s is catering to those issuers and investors with a preference for
gradual ratings adjustments.

22

Jorion, Liu, and Shi (2005) also focus on a three-day event window centered on the date of the rating
change. By including day t-1, we capture any announcement effect that might arise if the rating change
leaks one day early.

27

G. Does bias influence analyst reassignment?
In Table 10, we explore whether Moody’s is more likely to reassign analysts when firms
have negatively biased ratings. Analyst reassignment is a more common and less extreme outcome than analyst departure, providing us with an additional way to infer the level of Moody’s
aversion to pessimistic ratings. We evaluate analyst reassignment at the firm-year level. Our dependent variable is a binary variable indicating whether Moody’s replaces one or both of the analysts in year t who covered the firm in year t-1. To the extent that Moody’s seeks to discourage
pessimistic ratings, or that issuers respond to pessimistic ratings by lobbying Moody’s for new
analysts, we expect to observe analyst reassignment more often when Moody’s rating are more
pessimistic.
The independent variables in Table 10 are analogous to those used in Panel A of Table 5,
except that they are defined at the firm level. Downgrader equals one if Moody’s downgraded
firm j in year t-1 and S&P did not do the same, and zero otherwise. Model Predicted Pessimist
equals one if Moody’s rating for firm j in year t-1 was below that predicted by the Baghai,
Servaes, and Tamayo (2014) ratings model, and zero otherwise. We find that firms whose ratings
were downgraded in year t-1 are 52% more likely to receive a new analyst in year t (significant
at the 1-percent level), but do not find any effect for model predicted pessimism.23 When we
combine the two firm-level dummy variables into a Pessimist Index, we find that the odds ratio
is significantly greater than one (significant at the 1-percent level). This finding is robust to the
inclusion of industry-by-calendar year fixed effects, and to the exclusion of firms covered by analysts that depart Moody’s in year t. Overall, our findings in Table 10 complement our earlier
finding that downgraders are less likely to experience positive career outcomes at Moody’s.
23

In unreported regressions, we find that ratings are less likely to rebound in the year following a downgrade when a new analyst is assigned to the firm.

28

V. Conclusion
To shed new light on the behavior of credit rating agencies, we examine the career paths
of corporate credit rating analysts within Moody’s. Focusing on outcomes within Moody’s internal labor market provides us with a unique opportunity to infer Moody’s preferences for accuracy and bias. Focusing on corporate credit ratings provides us with a setting in which accuracy is
likely to be valued by institutional investors. Indeed, we find that accurate analysts are more likely to be promoted and less likely to depart. This finding holds for multiple measures of accuracy
and subsamples, and is strongest when we estimate specifications that consider the effect of accuracy on the likelihood of both positive and negative career outcomes. However, we also find
that analysts who downgrade more frequently, who assign ratings below those predicted by a ratings model, and whose downgrades are associated with large negative market reactions are significantly less likely to experience positive career outcomes within Moody’s. Furthermore, we
find that Moody’s is more likely to assign new analysts to firms with pessimistic ratings from
existing analysts. Because we find that Moody’s rewards accurate analysts but also punishes pessimistic analysts, we conclude that Moody’s internal labor market incentivizes analysts to consider the conflicting preferences of investors and issuers. While our findings that Moody’s values
accuracy are both novel and encouraging, the preference for upwardly biased ratings suggests
that there is still room for improvement.

29

References
Ashcraft, Adam, Paul Goldsmith-Pinkham, and James Vickery (2010). MBS ratings and the
mortgage credit boom. SSRN Working Paper #1615613.
Baghai, Ramin, Henri Servaes, and Ane Tamayo (2014). Have rating agencies become more
conservative? Journal of Finance 69(5), 1961-2005.
Behr, Patrick, Darren Kisgen, and Jerome Taillard (2016). Did government regulations lower
credit rating quality? Management Science, forthcoming.
Bongaerts, Dion, Martijn Cremers, and William Goetzmann (2012). Tiebreaker: Certification
and multiple credit ratings. Journal of Finance 67(1), 113-152.
Becker, Bo, and Todd Milbourn (2011). How did increased competition affect credit ratings?
Journal of Financial Economics 101, 493-514.
Bouvard, Matthieu, and Raphael Levy (2015). Two-sided reputation in certification markets.
Working paper.
Cornaggia, Jess, and Kimberly Cornaggia (2013). Estimating the costs of issuer-paid credit ratings. Review of Financial Studies 26(9), 2229-2269.
Cornaggia, Jess, Kimberly Cornaggia, and Han Xia (2016). Revolving doors on Wall Street.
Journal of Financial Economics 120(2), 400-419.
Fracassi, Cesare, Stefan Petry, and Geoffrey Tate (2016). Does rating analyst subjectivity affect
corporate debt pricing? Journal of Financial Economics 120 (3), 514-538.
Frenkel, Sivan (2015). Repeated interaction and rating inflation: A model of double reputation.
American Economic Journal: Microeconomics 7(1): 250-280.
Griffin, John, and Dragon Tang (2012). Did subjectivity play a role in CDO credit ratings? Journal of Finance 67(4): 1293-1328.
Hong, Harrison, and Jeffrey Kubik (2003). Analyzing the analysts: Career concerns and biased
earnings forecasts. Journal of Finance 58(1), 313-351.
Jewell, Jeff, and Miles Livingston (1999). A comparison of bond ratings from Moody’s, S&P,
and Fitch IBCA. Financial Markets, Institutions, and Instruments 8(4): 1-45.
Jorion, Philippe, Zhu Liu, and Charles Shi (2005). Informational effects of regulation FD: Evidence from rating agencies. Journal of Finance Economics 76(2), 309-330.
Kedia, Simi, Shivaram Rajgopal, and Xing Zhou (2014). Did going public impair Moody’s credit
ratings? Journal of Finance Economics 114(2), 293-315.

30

Kedia, Simi, Shivaram Rajgopal, and Xing Zhou (2017). Large shareholders and credit ratings.
Journal of Finance Economics 124(3), 632-653.
Kempf, Elisabeth (2017). The job rating game: The effects of revolving doors on analyst incentives. SSRN Working Paper #2893903.
Kisgen, Darren (2006). Credit ratings and capital structure. Journal of Finance 41(3), 10351072.
Kisgen, Darren, and Philip Strahan (2010). Do regulations based on credit ratings affect a firm’s
cost of capital? Review of Financial Studies 23(12), 4324-4347.
Opp, Christian, Marcus Opp, and Milton Harris (2013). Rating agencies in the face of regulation.
Journal of Financial Economics 108(1), 46-61.

31

Figure 1. Univariate Evidence on Influence of Accuracy on Career Outcomes
This Figure plots the fraction of analysts that promoted by Moody’s or departing from Moody’s in year t, for different values of the
“Accuracy Index.” We summarize the dummy variables underlying this index in Appendix Table A-2.
18.0%

16.9%

16.0%
14.0%
12.0%
10.0%

12.8%
10.6%
9.1%

8.0%
6.0%

4.9%

4.0%
2.2%
2.0%
0.0%
Accuracy Index = 0

Accuracy Index = 1
% Promotion

31

% Departure

Accuracy Index = 2

Figure 2. Univariate Evidence on Influence of Pessimism on Career Outcomes
This Figure plots the fraction of analysts that promoted by Moody’s or departing from Moody’s in year t, for different values of the
“Pessimist Index.” We summarize the dummy variables underlying this index in Appendix Table A-2.
18.0%
16.0%

14.6%
13.6%

14.0%
12.0%
10.0%

8.7%

8.0%
6.0%

5.9%

6.1%

4.7%

4.0%
2.0%
0.0%
Pessimist Index = 0

Pessimist Index = 1
% Promotion

32

% Departure

Pessimist Index = 2

Figure 3. Univariate Evidence on Influence of Optimism on Career Outcomes
This Figure plots the fraction of analysts that promoted by Moody’s or departing from Moody’s in year t, for different values of the
“Optimist Index.” We summarize the dummy variables underlying this index in Appendix Table A-2.
18.0%
15.8%

16.0%
14.0%
12.5%

12.3%
12.0%
10.0%
8.0%
6.0%

7.0%
6.0%

4.0%
2.2%
2.0%
0.0%
Optimist Index = 0

Optimist Index = 1
% Promotion

33

% Departure

Optimist Index = 2

Table 1
Analyst-Level Summary Statistics
This table summarizes how the number and types of firms that analysts cover varies with analyst rank. We report statistics for all analystyears and separately for each (beginning of year) rank within Moody's. "Analyst" is the junior most rank and "Managing Director" is the
senior most rank. The table reports means and medians for the number of firms covered with an issuer-level Moody's credit rating, the
average asset size of rated firms, the aggregate asset size of rated firms, as well as the average rating level and ratings notch difference from
S&P. Credit rating notch levels range from 1 (Ca or lower) to 20 (Aaa), where 10 is equivalent to a Moody's rating of Ba1.

Variable

All Levels

Analyst

N = 786

N = 144

Analyst Rank
Senior
Senior
Credit
Analyst
Officer
N = 229
N = 158

Senior
Vice
President
N = 170

Managing
Director
N = 85

Number Rated Firms

Mean
Median

14.7
8.0

7.4
7.0

9.2
9.0

9.9
8.0

25.8
13.0

28.5
7.0

Mean Firm Assets [Mill. $]

Mean
Median

$20,976
$8,190

$11,591
$3,086

$17,964
$6,804

$30,704
$10,232

$22,219
$9,302

$24,710
$13,549

Aggregate Rated Assets [Mill. $]

Mean
Median

$161,643
$64,611

$34,178
$17,538

$92,880
$52,492

$119,278
$78,910

$293,276
$159,836

$386,508
$231,683

Moody's Credit Rating

Mean
Median

9.2
8.0

8.7
8.0

8.9
8.0

10.1
9.0

8.9
8.0

9.8
9.0

Mean Difference from S&P

Mean
Median

-0.22
-0.20

-0.17
-0.20

-0.28
-0.29

-0.24
-0.20

-0.15
-0.13

-0.23
-0.13

Table 2
Issuer Characteristics and Analyst Ranks
This table reveals that larger and more highly rated firms tend to be covered by more senior analysts. The unit of observation is firm j in year t and the sample is
limited to rated issuers covered by Moody's analysts between 2002 and 2011. We report the fraction of firm-years where the "Senior Most Analyst" is a Managing
Director, Senior Vice President, or below. We also report the fraction of firm-years where the "Junior Most Analyst" is an Analyst, Senior Analyst, Senior Credit
Officer, or above. In each case, percentages sum to 100. Note that while the typical credit report is signed by two analysts, the average number of analysts is
consistently greater than two because we are focusing on the number of distinct analysts who covered firm j in calendar year t and there is some turnover in
analyst coverage within each calendar year.

Firm Credit Rating
All FirmYears
N = 9,557
Number of Analysts

B or
Baa
Lower
N = 3,081 N = 2,067

N = 716

A or
Higher
N = 523

Ba

Firm Asset Size Quartile
1st
2nd
3rd
4th
Quartile Quartile Quartile Quartile
N = 2,365 N = 2,364 N = 2,364 N = 2,364

2.4

2.4

2.4

2.2

2.2

2.3

2.4

2.4

2.4

Senior Most Analyst:
Managing Director
Senior Vice President
SCO or Lower

69.7%
27.5%
2.8%

55.5%
39.3%
5.2%

66.5%
31.6%
2.0%

88.3%
9.6%
2.1%

81.4%
16.9%
1.7%

49.6%
43.8%
6.6%

66.5%
31.3%
2.3%

77.9%
20.8%
1.2%

84.8%
14.2%
1.0%

Junior Most Analyst:
SVP or Higher
Senior Credit Officer
Senior Analyst
Analyst

18.5%
24.3%
39.1%
18.1%

14.2%
19.9%
42.0%
23.9%

17.4%
20.4%
43.0%
19.1%

20.5%
25.4%
42.7%
11.3%

27.2%
31.4%
29.5%
11.9%

12.3%
18.0%
39.7%
30.0%

15.3%
22.5%
41.8%
20.5%

18.5%
27.1%
41.5%
12.9%

27.8%
30.0%
33.4%
8.8%

Table 3
Frequency of Analyst Promotion and Departure
This table summarizes the frequency of promotions and departures for Moody's analysts. The column "% Promoted" reports the percentage of analyst-years with a promotion to a
higher rank. The column "% Depart" reports the percentage of analyst-years where the analyst departs from Moody's during the year (excluding the 13 observations where we
classify the departure as an external promotion). We report promotion and departure percentages for all analyst-years and separately for each (beginning of year) rank within
Moody's. "Analyst" is the junior most rank and "Managing Director" is the senior most rank. Panel A reports percentages by the number of years the analyst has remained in the
current rank. Panel B reports percentages by calendar year. The Total Analyst-Years row reports the average fraction of observations that are promoted or depart, either overall or
within rank. The Total Analysts row reports that fraction of analysts that are promoted at least once or depart, either overall or within rank. Of the 177 unique analysts in our
sample, 52 have held the rank of Analyst, 83 have held the rank of Senior Analyst, 57 have held the rank of Senior Credit Officer, 42 have held the rank of Senior Vice President,
and 24 have held the rank of Managing Director.

All Levels

Analyst

Senior Analyst

N = 786

N = 144

N = 229

Analyst%
Years Promoted

%
Depart

%
%
Promoted Depart

%
Promoted

%
Depart

Senior Credit
Officer
N = 158
%
Promoted

%
Depart

Senior
Vice President
N = 170

Managing
Director
N = 85

%
%
Promoted Depart

%
Depart

Panel A: Years in Rank
1 Year
2 Years
3 Years
4 Years
5+ Years

125
206
156
120
179

8.8%
8.3%
12.8%
24.2%
14.0%

4.0%
5.3%
7.1%
5.8%
6.1%

20.0%
2.2%
8.1%
27.6%
40.7%

0.0%
8.7%
8.1%
6.9%
3.7%

5.0%
10.1%
21.8%
43.2%
12.5%

10.0%
4.3%
9.1%
8.1%
6.3%

12.2%
20.5%
16.0%
11.1%
11.1%

6.1%
5.1%
8.0%
5.6%
3.7%

9.1%
3.1%
3.8%
13.0%
8.9%

0.0%
6.3%
3.8%
0.0%
5.4%

0.0%
0.0%
0.0%
7.7%
14.3%

25
41
54
63
85
102
111
112
96
97

8.0%
14.6%
14.8%
11.1%
10.6%
15.7%
13.5%
13.4%
16.7%
8.2%

8.0%
2.4%
11.1%
3.2%
3.5%
6.9%
7.2%
5.4%
4.2%
6.2%

0.0%
0.0%
28.6%
14.3%
12.5%
9.5%
18.5%
20.0%
35.3%
5.9%

0.0%
0.0%
14.3%
14.3%
6.3%
0.0%
7.4%
8.0%
0.0%
17.6%

0.0%
27.3%
21.4%
16.7%
10.3%
25.0%
18.8%
16.7%
19.2%
19.2%

14.3%
0.0%
14.3%
0.0%
6.9%
11.1%
9.4%
3.3%
11.5%
0.0%

25.0%
9.1%
13.3%
21.4%
23.1%
23.1%
15.8%
8.7%
14.3%
4.8%

12.5%
0.0%
20.0%
7.1%
0.0%
0.0%
5.3%
4.3%
4.8%
4.8%

0.0%
18.2%
9.1%
0.0%
5.9%
9.5%
4.5%
12.5%
9.1%
4.8%

0.0%
9.1%
0.0%
0.0%
0.0%
0.0%
4.5%
8.3%
0.0%
9.5%

0.0%
0.0%
0.0%
0.0%
0.0%
27.3%
9.1%
0.0%
0.0%
0.0%

Total AnalystYears

786

13.0%

5.7%

16.7%

6.9%

18.3%

7.0%

14.6%

5.7%

7.6%

3.5%

4.7%

Total Analysts

177

45.2%

25.4%

46.2%

19.2%

50.6%

19.3%

40.4%

15.8%

31.0%

14.3%

16.7%

Panel B: Calendar Year
2002
2003
2004
2005
2006
2007
2008
2009
2010
2011

Table 4
Does Accuracy Influence Career Paths?
This table reports odds ratios from ordered logistic regressions of analyst-level measures of accuracy on career outcomes. After dropping the 13 analyst-year
observations that we classify as external promotions, we code internal promotions as 1 and all other departures from Moody's as -1. Panel A focuses on the full
sample of analyst-year observations. Panel B focuses on the subsample of analyst-years observations for which we can calculate the Yield Accurate dummy
variable. In Panel A, the Accuracy Index is the sum of the Stock Accurate and Rating Accurate dummy variables. In Panel B, the Accuracy Index is the sum of
the Stock Accurate, Rating Accurate, and Yield Accurate dummy variables. All of the independent variables are defined in Section IV.A. The multivariate
specifications include calendar year fixed effects and analyst rank-by-years in rank fixed effects. We report the absolute values of Z-statistics below the odds
ratios. ***, **, and * denote statistical significance at the 1 percent, 5 percent, and 10 percent levels, respectively, based on heteroskedasticity-robust standard
errors that are clustered by analyst.

Panel A. Full Sample of Analyst-Years
Explanatory Variables
Accuracy Index [t-1]

[1]

[2]

1.474***
(3.075)

Stock Accurate [t-1]

N
Pseudo R-Squared

[5]

[6]

1.464***
(2.785)
1.621***
(2.632)

Rating Accurate [t-1]
Calendar Year FEs?
Analyst Rank * Years in Rank FEs?

Ordered Logit: Career Path [t]
[3]
[4]

1.662***
(2.655)
1.465**
(2.146)

1.384*
(1.695)

---

---

---

Yes
Yes

Yes
Yes

Yes
Yes

786
0.010

786
0.007

786
0.005

786
0.075

786
0.073

786
0.068

[6]

[7]

Panel B. Subsample of Analyst-Years with Yield Accuracy measure
Explanatory Variables
Accuracy Index [t-1]

[1]

[2]

[3]

1.667***
(3.004)

Stock Accurate [t-1]

2.137***
(2.826)

2.263***
(2.880)
1.573*
(1.828)

Yield Accurate [t-1]

N
Pseudo R-Squared

[8]

1.762***
(3.284)

Rating Accurate [t-1]

Calendar Year FEs?
Analyst Rank * Years in Rank FEs?

Ordered Logit: Career Path [t]
[4]
[5]

1.643*
(1.745)
1.383
(1.192)

1.568
(1.580)

---

---

---

---

Yes
Yes

Yes
Yes

Yes
Yes

Yes
Yes

436
0.024

436
0.017

436
0.006

436
0.003

436
0.127

436
0.119

436
0.108

436
0.107

Table 5
Does Bias Influence Career Paths?
This table reports odds ratios from ordered logistic regressions of analyst-level measures of negative and positive bias on career
outcomes. After dropping the 13 analyst-year observations that we classify as external promotions, we code internal promotions as
1 and all other departures from Moody's as -1. Panel A focuses on the Pessimist Index and its components, the Downgrader and
Model Predicted Pessimist dummy variables. Panel B focuses on the Optimist Index and its components, the Upgrader and Model
Predicted Optimist dummy variables. All of the independent variables are defined in Section IV.A. The multivariate specifications
include calendar year fixed effects and analyst rank-by-years in rank fixed effects. We report the absolute values of Z-statistics
below the odds ratios. ***, **, and * denote statistical significance at the 1 percent, 5 percent, and 10 percent levels, respectively,
based on heteroskedasticity-robust standard errors that are clustered by analyst.

Panel A. Pessimism
Explanatory Variables
Pessimist Index [t-1]

[1]

[2]

0.724***
(2.589)

Downgrader [t-1]

N
Pseudo R-Squared

[5]

[6]

0.701**
(2.488)
0.707*
(1.857)

Model Predicted Pessimist [t-1]
Calendar Year FEs?
Analyst Rank * Years in Rank FEs?

Ordered Logit: Career Path [t]
[3]
[4]

0.678*
(1.933)
0.644**
(2.179)

0.620**
(1.981)

---

---

---

Yes
Yes

Yes
Yes

Yes
Yes

786
0.007

786
0.004

786
0.005

786
0.073

786
0.070

786
0.070

[1]

[3]

[6]

[5]

Panel B. Optimist
Explanatory Variables
Optimist Index [t-1]

1.182
(1.490)

Upgrader [t-1]

1.137
(1.068)
1.059
(0.343)

Model Predicted Optimist [t-1]
Calendar Year FEs?
Analyst Rank * Years in Rank FEs?
N
Pseudo R-Squared

Ordered Logit: Career Path [t]
[2]
[4]

1.045
(0.241)
1.404*
(1.890)

1.309
(1.375)

---

---

---

Yes
Yes

Yes
Yes

Yes
Yes

786
0.002

786
0.000

786
0.003

786
0.067

786
0.066

786
0.067

Table 6
Accuracy, Pessimism, and Career Outcomes
Panel A reports the fraction of analyst-year observations that depart from Moody's in year t for different values of the Accuracy Index and Pessimist Index in
year t-1. It is based on the full sample of analyst-year observations. Panel B reports the fraction of analyst-year observations that a promoted by Moody's in
year t for different values of the Accuracy Index and Pessimist Index in year t-1. It excludes Managing Directors because they are not eligible for promotion.
In Panel A, more negative outcomes are shaded red. In Panel B, more positive outcomes are shaded darker blue.

Pessimist Index
2
1
0
ALL

Panel A. Departures
Accuracy Index
0
1
2
33.3%
8.9%
3.4%
10.1%
5.8%
2.5%
7.1%
3.1%
0.0%
9.1%

4.9%

2.2%

ALL
8.7%
5.9%
4.7%

Pessimist Index
2
1
0

5.7%

ALL

Panel B. Promotions
Accuracy Index
0
1
2
0.0%
5.0%
9.6%
12.9%
16.0%
16.9%
12.2%
15.6%
36.1%
11.9%

14.4%

18.9%

ALL

6.9%
15.5%
16.1%
14.6%

Table 7
Accuracy Versus Pessimism
This table reports odds ratios from ordered logistic regressions of analyst-level measures of accuracy and bias on career
outcomes. After dropping the 13 analyst-year observations that we classify as external promotions, we code internal
promotions as 1 and all other departures from Moody's as -1. It also reports odds ratios from logistic regressions of accuracy
and bias on internal promotions. Panel A focuses on the full sample of analyst-year observations. Panel B excludes career
outcomes for 2008 and 2009. Panel C excludes Senior Vice Presidents and Managing Directors. All specifications include
the Accuracy Index and the Pessimist Index, which are defined in Section IV.A. The multivariate specifications include
calendar year fixed effects and analyst rank-by-years in rank fixed effects. We report the absolute values of Z-statistics below
the odds ratios. ***, **, and * denote statistical significance at the 1 percent, 5 percent, and 10 percent levels, respectively,
based on heteroskedasticity-robust standard errors that are clustered by analyst.

Panel A. Full Sample
Explanatory Variables

Ordered Logit: Career Path [t]
[1]
[2]

Logit: Promoted [t]
[3]
[4]

Accuracy Index [t-1]

1.825***
(4.206)

1.808***
(3.883)

1.573***
(2.806)

1.502**
(2.183)

Pessimist Index [t-1]

0.569***
(4.050)

0.556***
(3.781)

0.608***
(2.826)

0.573***
(2.788)

---

Yes
Yes

---

Yes
Yes

786
0.028

786
0.091

701
0.021

701
0.130

Calendar Year FEs?
Analyst Rank * Years in Rank FEs?
N
Pseudo R-Squared

Panel B. Excludes career outcomes for 2008 and 2009
Explanatory Variables

Ordered Logit: Career Path [t]
[1]
[2]

Logit: Promoted [t]
[3]
[4]

Accuracy Index [t-1]

1.980***
(3.913)

1.919***
(3.533)

1.666***
(2.701)

1.567**
(2.068)

Pessimist Index [t-1]

0.568***
(3.336)

0.557***
(3.220)

0.613**
(2.436)

0.568**
(2.483)

563
0.032

563
0.090

499
0.024

480
0.122

N
Pseudo R-Squared

Panel C. Excludes Senior Vice Presidents (SVP) and Managing Directors (MD)
Explanatory Variables

Ordered Logit: Career Path [t]
[1]
[2]

Logit: Promoted [t]
[3]
[4]

Accuracy Index [t-1]

1.861***
(4.008)

1.849***
(3.764)

1.575***
(2.653)

1.508**
(2.112)

Pessimist Index [t-1]

0.578***
(3.511)

0.544***
(3.457)

0.671**
(2.171)

0.610**
(2.301)

531
0.031

531
0.085

531
0.020

531
0.124

N
Pseudo R-Squared

Table 8
Do Weights on Accuracy Versus Pessimism Change in Response to Annual SEC Audits?
This table extends the ordered logistic regressions and logistic regressions in Table 7 Panel A to interact the Accuracy Index
and Pessimist Index with pre-2008 and post-2007 dummy variables. We include but do not report the coefficients on the Pre
2008 dummy variable in specifications [1] and [3]. It also reports p-values from hypothesis tests that the odds ratios
estimated for an index in 2002-2007 are equal to the odds ratios estimated for the same index in 2008-2011. The multivariate
specifications include calendar year fixed effects and analyst rank-by-years in rank fixed effects. We report the absolute
values of Z-statistics below the odds ratios. ***, **, and * denote statistical significance at the 1 percent, 5 percent, and 10
percent levels, respectively, based on heteroskedasticity-robust standard errors that are clustered by analyst.

Explanatory Variables

Ordered Logit: Career Path [t]
[1]
[2]

Logit: Promoted [t]
[3]
[4]

Accuracy Index [t-1] * Pre 2008

2.235***
(3.840)

2.286***
(3.835)

2.173***
(2.998)

2.117**
(2.454)

Accuracy Index [t-1] * Post 2007

1.532**
(2.443)

1.513**
(2.361)

1.201
(0.936)

1.135
(0.554)

Pessimist Index [t-1] * Pre 2008

0.536***
(-3.160)

0.514***
(-3.172)

0.546**
(-2.413)

0.498**
(-2.382)

Pessimist Index [t-1] * Post 2007

0.575***
(-2.840)

0.575***
(-2.764)

0.633*
(-1.810)

0.628*
(-1.676)

Ho: Accuracy Pre = Accuracy Post
Ho: Pessimist Pre = Pessimist Post

0.139
0.798

0.116
0.698

0.052
0.682

0.091
0.566

Pre 2008 and Post 2007 FEs?
Calendar Year FEs?
Analyst Rank * Years in Rank FEs?

Yes
---

-Yes
Yes

Yes
---

-Yes
Yes

786
0.030

786
0.035

701
0.027

701
0.135

N
Pseudo R-Squared

Table 9
Career Outcomes and Extreme Announcement Returns
This table extends the ordered logistic regressions and logistic returns in Table 7 Panel A to include the Low Abnormal Return dummy
variable, which is defined in Section IV.F. The multivariate specifications include calendar year fixed effects and analyst rank-by-years
in rank fixed effects. We report the absolute values of Z-statistics below the odds ratios. ***, **, and * denote statistical significance at
the 1 percent, 5 percent, and 10 percent levels, respectively, based on heteroskedasticity-robust standard errors that are clustered by
analyst.

Explanatory Variables
Accuracy Index [t-1]
Pessimist Index [t-1]

Ordered Logit: Career Path [t]
[1]
[2]
[3]
1.825***
(4.206)
0.569***
(-4.050)

1.971***
(4.388)
0.585***
(-3.835)
0.640**
(-2.073)

1.971***
(4.104)
0.572***
(-3.581)
0.619**
(-1.964)

1.573***
(2.806)
0.608***
(-2.826)

1.725***
(3.205)
0.636***
(-2.585)
0.482**
(-2.230)

1.667***
(2.620)
0.601**
(-2.547)
0.464**
(-2.160)

---

---

Yes
Yes

---

---

Yes
Yes

786
0.028

786
0.031

786
0.095

701
0.021

701
0.030

701
0.137

Low Abnormal Return [t-1]
Calendar Year FEs?
Analyst Rank * Years in Rank FEs?
N
Pseudo R-Squared

Logit: Promoted [t]
[4]
[5]
[6]

Table 10
Does Ratings Bias Influence Analyst Reassignment?
This table reports odds ratios from logistic regressions that assess whether firms with negatively biased ratings are more
likely to be assigned a new Moody's analyst than other issuers. The unit of observation is firm-year. For each firm-year
covered by Moody's analysts in years t and t-1, the dependent variable equals one if one or more of the analysts
covering the firm in year t was not covering the firm in year t-1. The independent variables are analogous to those in
Panel A of Table 5, except that they are defined at the firm level. Downgrader equals one if Moody’s downgraded the
firm relative to S&P in year t-1, and zero otherwise. Model Predicted Pessimist equals one if the Moody's rating is
lower than that predicted by the rating prediction model of Ramin, Servaes, and Tamayo (2014). The Pessimist Index
equals the sum of the Downgrader and Model Predicted Pessimist dummy variables. Columns [4] and [6] include a
separate fixed effect for each of the 12 Fama French industries each calendar year. Columns [5] and [6] exclude firms
covered by analysts in year t-1 that depart Moody's in year t. We report the absolute values of Z-statistics below the
odds ratios. ***, **, and * denote statistical significance at the 1 percent, 5 percent, and 10 percent levels, respectively,
based on heteroskedasticity-robust standard errors that are clustered by firm.

Explanatory Variables
Pessimist Index [t-1]

[1]

Logit: New Analyst [t]
{ New Analyst Assigned to Firm = 1, Otherwise = 0 }
[2]
[3]
[4]
[5]

1.228***
(4.009)

Downgrader [t-1]

N
Pseudo R-Squared

1.204***
(3.027)

1.214***
(3.531)

1.233***
(2.894)

1.522***
(5.302)

Model Predicted Pessimist [t-1]
Industry-by-Calendar Year FEs?
Excluding Analyst Departures

[6]

1.041
(0.616)
---

---

---

Yes
--

-Yes

Yes
Yes

5,440
0.002

5,440
0.004

5,440
0.000

4,081
0.002

4,545
0.002

3,287
0.003

Appendix Table A-1
Number of Rated Firms and Level of Rated Firm Assets by Analyst Rank and Years in Rank
This table reports statistics by analyst rank and years in rank. Panel A reports the average number of covered firms and the fraction of observations for which we observe an inrease
in the number of covered firms. Panel B reports the mean total assets of covered firms and mean change in total assets of covered firms. Panel C reports the number of analysts in
each cell. The unexpectedly large number of covered firms for first-year Analysts is driven by 5 observations.

Panel A.

Analyst Rank
Analyst
Senior Analyst
Senior Credit Officer
Senior Vice President
Managing Director

1
16.6
8.5
13.0
24.1
33.0

Mean Number of Covered Firms
Years in Rank
2
3
4
6.1
9.3
8.4
25.0
30.2

7.5
10.1
9.8
29.8
35.3

7.6
10.0
9.0
29.4
33.4

5+

Fraction with Increase in Number of Covered Firms?
Years in Rank
1
2
3
4
5+

7.3
7.9
6.9
23.8
16.0

100.0%
50.0%
34.7%
69.7%
38.9%

65.2%
69.6%
33.3%
50.0%
55.0%

62.2%
49.1%
20.0%
30.8%
46.2%

31.0%
37.8%
38.9%
47.8%
23.1%

33.3%
27.1%
33.3%
26.8%
4.8%

Panel B.

Analyst Rank
Analyst
Senior Analyst
Senior Credit Officer
Senior Vice President
Managing Director

1
21.5
101.2
136.5
182.6
462.3

Mean Total Assets of Covered Firms
Years in Rank
2
3
4

5+

Mean Change in Total Assets of Covered Firms
Years in Rank
1
2
3
4
5+

27.3
84.5
136.6
232.5
388.8

39.2
97.8
112.1
294.8
407.0

37.6
79.6
77.9
383.4
504.4

37.4
106.2
98.4
357.4
229.9

10.2
33.7
50.1
53.0
122.7

2

Count
Years in Rank
3

4

5+

TOTAL

Panel C.

Analyst Rank
Analyst
Senior Analyst
Senior Credit Officer
Senior Vice President
Managing Director
TOTAL

1
5
20
49
33
18

46
69
39
32
20

37
55
25
26
13

29
37
18
23
13

27
48
27
56
21

144
229
158
170
85

125

206

156

120

179

786

19.0
27.6
8.8
70.8
55.4

6.7
15.6
15.4
37.1
52.5

6.9
-10.1
6.9
45.4
161.7

-2.9
6.3
14.7
34.2
-26.2

Appendix Table A-2
Measures of Accuracy and Bias
This table summarizes the frequency of Moody's analyst promotions and departures for our three measures of accuracy, two measures of negative bias, two measures
of positive bias, and measure of low abnormal equity returns. Across the columns, we report statistics for all analyst-years and separately for each (beginning of year)
rank within Moody's. "Analyst" is the junior most rank and "Managing Director" is the senior most rank. Panel A reports the percentage of analyst-years in which
analysts that we classify as accurate or biased are promoted; it excludes Managing Directors because they are not eligible for promotion. Panel B reports comparable
percentages for departures from Moody's; it includes Managing Directors but excludes the 13 analysts-year observations where we classify the departure as an external
promotion. We define the low abnormal equity return dummy variable in Section IV.F and the other dummy variables in Section IV.A.

Analyst Rank
All Levels
Variable

Analyst

Value

Senior
Analyst

Senior Credit
Senior
Officer
Vice President

Managing
Director

Panel A: Promotion [N = 701]
Stock Accurate [t-1]

Yes [N = 346]
No [N = 355]

16.8%
12.4%

15.4%
17.7%

22.6%
14.0%

18.6%
11.4%

9.4%
5.4%

-

Rating Accurate [t-1]

Yes [N = 278]
No [N = 423]

16.5%
13.2%

18.2%
15.7%

21.7%
15.9%

18.0%
12.4%

6.2%
8.6%

-

Yield Accurate [t-1]

Yes [N = 235]
No [N = 146]

16.6%
13.0%

18.2%
22.2%

21.3%
17.9%

15.8%
8.8%

10.4%
6.5%

-

Downgrader [t-1]

Yes [N = 275]
No [N = 426]

13.1%
15.5%

19.2%
15.2%

16.1%
19.9%

10.9%
16.5%

6.7%
8.4%

-

Model Predicted Pessimist [t-1]

Yes [N = 181]
No [N = 520]

9.4%
16.3%

20.8%
15.8%

11.9%
20.6%

8.2%
17.4%

2.0%
9.9%

-

Upgrader [t-1]

Yes [N = 277]
No [N = 424]

15.2%
14.2%

12.5%
19.3%

20.7%
16.8%

16.4%
13.6%

9.5%
6.3%

-

Model Predicted Optimist [t-1]

Yes [N = 240]
No [N = 461]

17.1%
13.2%

18.0%
16.0%

20.5%
17.2%

16.3%
13.8%

12.7%
4.7%

-

Low Abnormal Return [t-1]

Yes [N = 126]
No [N = 575]

9.5%
15.7%

13.6%
17.2%

6.3%
20.3%

9.1%
15.4%

10.0%
6.7%

-

Panel B: Departure [N = 786]
Stock Accurate [t-1]

Yes [N = 388]
No [N = 398]

3.6%
7.8%

4.6%
8.9%

3.5%
10.5%

2.9%
8.0%

3.1%
4.1%

4.8%
4.7%

Rating Accurate [t-1]

Yes [N = 313]
No [N = 473]

3.5%
7.2%

3.6%
9.0%

6.2%
7.6%

1.6%
8.2%

0.0%
5.7%

5.7%
4.0%

Yield Accurate [t-1]

Yes [N = 266]
No [N = 170]

3.8%
5.3%

0.0%
11.1%

7.9%
2.6%

1.8%
8.8%

1.5%
2.2%

3.2%
4.2%

Downgrader [t-1]

Yes [N = 316]
No [N = 470]

7.6%
4.5%

7.7%
6.5%

9.7%
5.1%

12.7%
1.9%

2.7%
4.2%

4.9%
4.5%

Model Predicted Pessimist [t-1]

Yes [N = 201]
No [N = 585]

6.5%
5.5%

4.2%
7.5%

10.2%
5.9%

8.2%
4.6%

2.0%
4.1%

5.0%
4.6%

Upgrader [t-1]

Yes [N = 319]
No [N = 467]

5.3%
6.0%

7.1%
6.8%

6.5%
7.3%

5.5%
5.8%

1.4%
5.2%

7.1%
2.3%

Model Predicted Optimist [t-1]

Yes [N = 272]
No [N = 514]

4.0%
6.6%

8.0%
6.4%

6.4%
7.3%

0.0%
8.3%

1.6%
4.7%

3.1%
5.7%

Low Abnormal Return [t-1]

Yes [N = 150]
No [N = 636]

3.3%
6.3%

0.0%
8.2%

9.4%
6.6%

0.0%
6.6%

4.0%
3.3%

0.0%
6.6%

Appendix Table A-3
Accuracy, Pessimism, and Optimism
This table reports ordered logit and logit specifications analogous to those estimated in Table 7, except that we now include
the Optimist Index. The absolute values of Z-statistics are reported below the coefficients, where ***, **, and * denote
statistical significance at the 1 percent, 5 percent, and 10 percent levels, respectively, based on heteroskedasticity-robust
standard errors that are clustered by analyst.

Panel A. Full Sample
Explanatory Variables

Ordered Logit: Career Path [t]
[1]
[2]

Logit: Promoted [t]
[3]
[4]

Accuracy Index [t-1]

1.850***
(4.100)

1.865***
(3.933)

1.565***
(2.656)

1.529**
(2.246)

Pessimist Index [t-1]

0.565***
(3.968)

0.549***
(3.812)

0.610***
(2.764)

0.569***
(2.827)

Optimist Index [t-1]

0.964
(0.316)

0.924
(0.631)

1.015
(0.106)

0.952
(0.320)

---

Yes
Yes

---

Yes
Yes

786
0.028

786
0.095

701
0.030

701
0.137

Calendar Year FEs?
Analyst Rank * Years in Rank FEs?
N
Pseudo R-Squared

Panel B. Excludes career outcomes for 2008 and 2009
Explanatory Variables

Ordered Logit: Career Path [t]
[1]
[2]

Logit: Promoted [t]
[3]
[4]

Accuracy Index [t-1]

2.017***
(3.856)

1.982***
(3.571)

1.646**
(2.479)

1.599**
(2.056)

Pessimist Index [t-1]

0.562***
(3.316)

0.549***
(3.278)

0.618**
(2.376)

0.562**
(2.532)

Optimist Index [t-1]

0.953
(0.326)

0.918
(0.525)

1.033
(0.179)

0.949
(0.255)

563
0.032

563
0.090

499
0.024

480
0.122

N
Pseudo R-Squared

Panel C. Excludes senior vice presidents (SVP) and managing directors
Explanatory Variables

Ordered Logit: Career Path [t]
[1]
[2]

Logit: Promoted [t]
[3]
[4]

Accuracy Index [t-1]

1.893***
(4.097)

1.958***
(4.079)

1.588***
(2.654)

1.609**
(2.407)

Pessimist Index [t-1]

0.572***
(3.473)

0.530***
(3.561)

0.668**
(2.169)

0.596**
(2.411)

Optimist Index [t-1]

0.944
(0.436)

0.836
(1.224)

0.972
(0.175)

0.827
(1.033)

531
0.032

531
0.086

531
0.020

531
0.127

N
Pseudo R-Squared

Appendix Table A-4
Accuracy Versus Bias Controlling for (Log) Level of Rated Assets
This table reports ordered logit and logit specifications analogous to those estimated in Table 7, except that we now control
for the natural logarithm of the level of rated assets in year t-1. The absolute values of Z-statistics are reported below the
coefficients, where ***, **, and * denote statistical significance at the 1 percent, 5 percent, and 10 percent levels,
respectively, based on heteroskedasticity-robust standard errors that are clustered by analyst.

Panel A. Full Sample
Explanatory Variables

Ordered Logit: Career Path [t]
[1]
[2]

Logit: Promoted [t]
[3]
[4]

Accuracy Index [t-1]

1.784***
(4.066)

1.721***
(3.519)

1.518**
(2.570)

1.409*
(1.797)

Pessimist Index [t-1]

0.552***
(4.161)

0.522***
(4.136)

0.590***
(2.977)

0.546***
(2.998)

1.088
(1.477)

1.220***
(2.761)

1.155*
(1.928)

1.351***
(2.809)

---

Yes
Yes

---

Yes
Yes

786
0.030

786
0.099

701
0.028

701
0.146

Log Rated Assets [t-1]
Calendar Year FEs?
Analyst Rank * Years in Rank FEs?
N
Pseudo R-Squared

Panel B. Excludes career outcomes for 2008 and 2009
Explanatory Variables

Ordered Logit: Career Path [t]
[1]
[2]

Logit: Promoted [t]
[3]
[4]

Accuracy Index [t-1]

1.940***
(3.843)

1.834***
(3.285)

1.608**
(2.526)

1.453*
(1.694)

Pessimist Index [t-1]

0.547***
(3.442)

0.506***
(3.640)

0.595***
(2.586)

0.537***
(2.733)

1.107
(1.454)

1.286***
(3.047)

1.179*
(1.772)

1.442***
(2.784)

563
0.035

563
0.102

499
0.032

480
0.145

Log Rated Assets [t-1]
N
Pseudo R-Squared

Panel C. Excludes senior vice presidents (SVP) and managing directors (MD)
Explanatory Variables

Ordered Logit: Career Path [t]
[1]
[2]

Logit: Promoted [t]
[3]
[4]

Accuracy Index [t-1]

1.785***
(3.721)

1.773***
(3.481)

1.490**
(2.291)

1.416*
(1.743)

Pessimist Index [t-1]

0.551***
(3.756)

0.512***
(3.781)

0.652**
(2.329)

0.581**
(2.498)

Log Rated Assets [t-1]

1.287***
(3.474)

1.311***
(3.044)

1.335***
(3.404)

1.382***
(2.887)

531
0.047

531
0.098

531
0.042

531
0.143

N
Pseudo R-Squared

