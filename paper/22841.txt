NBER WORKING PAPER SERIES

SHIFTING COLLEGE MAJORS IN RESPONSE TO ADVANCED PLACEMENT
EXAM SCORES
Christopher Avery
Oded Gurantz
Michael Hurwitz
Jonathan Smith
Working Paper 22841
http://www.nber.org/papers/w22841

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
November 2016

Christopher Avery receives funding from The College Board to support his work as Co-Principal
Investigator of a research collaboration between the College Board and the Center for Education
Policy Research at the Harvard Graduate School of Education. The contents of this paper
represent the views of the authors and not of their corresponding institutions, nor of the National
Bureau of Economic Research.
NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.
© 2016 by Christopher Avery, Oded Gurantz, Michael Hurwitz, and Jonathan Smith. All rights
reserved. Short sections of text, not to exceed two paragraphs, may be quoted without explicit
permission provided that full credit, including © notice, is given to the source.

Shifting College Majors in Response to Advanced Placement Exam Scores
Christopher Avery, Oded Gurantz, Michael Hurwitz, and Jonathan Smith
NBER Working Paper No. 22841
November 2016
JEL No. I2,I23,J24
ABSTRACT
Mapping continuous raw scores from millions of Advanced Placement examinations onto the 1 to
5 integer scoring scale, we apply a regression discontinuity design to understand how students’
choice of college major is impacted by receiving a higher integer score despite similar exam
performance to students who earned a lower integer score. Attaining higher scores increases the
probability that a student will major in that exam subject by approximately 5 percent (0.64
percentage points), with some individual exams demonstrating increases in major choice by as
much as 30 percent. These direct impacts of a higher score explain approximately 11 percent of
the unconditional 64 percent (5.7 percentage points) gap in the probability of majoring in the
same subject as the AP exam when attaining a 5 versus a 4. We estimate that a substantial
portion of the overall effect is driven by behavioral responses to the positive signal of receiving a
higher score.
Christopher Avery
Harvard Kennedy School of Government
79 JFK Street
Cambridge, MA 02138
and NBER
christopher_avery@hks.harvard.edu

Michael Hurwitz
College Board
1919 M Street NW
Suite 300
Washington, DC 20036
mhurwitz@collegeboard.org

Oded Gurantz
Stanford University
ogurantz@stanford.edu

Jonathan Smith
College Board
1919 M Street NW
Suite 300
Washington, DC 20036
jsmith@collegeboard.org

1. Introduction
A student’s choice of college major may have long-lasting implications, including on
future earnings. The average difference in lifetime earnings between the top-paying and lowestpaying majors is estimated to be several million dollars (Carnevale, Cheah, and Hanson, 2015),
and there is growing evidence that at least some portion of the connection between college major
and wages is causal (Hastings, Neilson, and Zimmerman, 2013; Kirkebøen, Leuven, and
Mogstad, forthcoming). Despite these seemingly strong labor market incentives, there remains a
mismatch between demand and supply of workers in some relatively lucrative fields. For
example, a 2012 Federal Government report estimates a ten-year shortfall of 1 million college
graduates with STEM (“Science, Technology, Engineering, and Mathematics”) majors.1 As
these findings suggest, some students may not be choosing their college majors optimally, either
because they lack adequate information on the relative benefits and challenges of majors in
specific fields, or because they enter college with inadequate academic preparation for a
preferred major (Betts, 1996; Oreopoulos and Dunn, 2013; R. Stinebrickner and Stinebrickner,
2012; Wiswall and Zafar, 2015a, 2015b).
In addition to the earnings potential associated with each field of study,2 the previous
literature emphasizes the importance of heterogeneous tastes and predilections on a student’s
choice of major. Morgan, Gelbgiser, and Weeden (2013) find in their analysis of Educational
Longitudinal Survey (ELS) data that specific occupational plans reported by students prior to
entering college yield much sharper predictions of their college majors than test scores and other
observable performance data. Similarly, Altonji, Arcidiacono, and Maurel (2015) suggest that a
combination of major-specific abilities and individual preferences drive the choice of major for
1

https://www.whitehouse.gov/sites/default/files/microsites/ostp/pcast-engage-to-excel-final_2-25-12.pdf
See for example, (Arcidiacono, Hotz, & Kang, 2012; Beffy, Fougère, & Maurel, 2011; Long, Goldhaber, &
Huntington-Klein, 2015; Shu, 2013; T. Stinebrickner & Stinebrickner, 2013; Wiswall & Zafar, 2015a; Zafar, 2011)
2

2

most students, while Wiswall and Zafar (2015a) estimate that 80% of the variation in majorspecific tastes remains unexplained by observable characteristics.
While this literature suggests that each student’s chosen field of study can be highly
personal and driven by factors in place before entering college, there is also a small body of
evidence that the choice of major is subject to external factors that can be shaped by policy. For
instance, peers (Ost, 2010), early exposure to a subject via required coursework (Fricke,
Grogger, and Steinmayr, 2015) and the final grade achieved by a student in an introductory
course (Goldin, 2015) can also have strong influence on a student’s subsequent course of study.
Several recent papers assess the effects of explicit financial incentives in directing students to
particular fields of study. Denning and Turley (2015) find that the “SMART” Program, which
provides US Department of Defense scholarships to college juniors and seniors pursuing STEM
majors, significantly increased the probability of completing college with a major in those fields,
though Evans (2015) finds no significant effects in Ohio. Similarly, Castleman, Long, and
Mabel (2015) find that the Florida State Access Grant (FSAG) program significantly increased
the probability of completing college with a STEM major even though FSAG funding was not
tied in any way to the choice of major.3
In this paper we focus on the role of Advanced Placement (AP) exam scores and their
signals, which reflect a nationally-recognized college-level curriculum taken by hundreds of
thousands of high school students each year, in encouraging students to choose a college major
in a subject of interest. In particular, to isolate the causal impact of different AP exam scores
among students with similar mastery of the content and skills of an AP course, we compare
students with very similar performance on the AP exam, but who receive different AP scores by
falling on either side of the cut score that separates an AP integer score of 5 from an AP integer
3

In related work, Stange (2011) finds that differential tuition policy can alter the demand for a particular degree.

3

score of 4, the cut score that separates an AP 4 from an AP 3, and so on. We investigate two
channels by which a higher reported AP exam score, among students with otherwise comparable
mastery of the course content and skills can increase the probability that the student complete a
college major in a field of study connected to that AP course. First, a higher AP score can
coincide with an increase in college credits (and/or preferential course placement), both towards
graduation requirements and towards completion of a particular major at a given college.
Second, students may have a behavioral response to a higher AP score, such that they perceive
themselves to have more ability in the field, or use the high score as a guidepost for choosing
initial courses or major.
As in our previous and related study, which finds a causal effect of AP exam scores on time
to degree completion (Smith, Hurwitz, and Avery, 2015), we apply a regression discontinuity
design to AP exam scores from millions of students who graduated high school between 2004
and 2009. Students and colleges only observe an integer exam score between 1 and 5 but we
rely on the underlying continuous scores that map to the integer score. These data allow us to
compare the majors of students who just barely attain a 3, for example, relative to those just shy
of the threshold who attain a 2. Isolating the impact of attaining a higher score by comparing
identical students distinguishes our paper from previous work, which establishes the strong
predictive component of AP scores and major (Mattern, Shaw, and Ewing, 2011). To be clear,
our analysis compares two essentially identical students who have both elected to take an AP, but
does not measure the effect of exposure to or quality of the AP curriculum on major choice.
Participating in AP courses may have strong and independent causal impacts on student major
(and other outcomes), but, in these analyses, we are not able to separate this effect from other
unobserved factors that might impact both AP exam performance and student major.

4

Similar to previous work in the area, we show a strong positive relationship between AP
integer scores and choice of college major. For example, students in our sample who attain a 5
on an AP exam – the highest possible score – are 5.7 percentage points (64 percent) more likely
to major in the same subject as the AP exam than students who attain a 4 on the exam. However,
when comparing students whose raw score barely received them a 5 compared to those who just
missed a score of 5, we find a 0.64 percentage points (5 percent) increase in majoring in the same
subject as the AP exam. This implies that approximately 11 percent of the increase in the
probability of majoring in the same subject as the AP exam can be explained not by differences
in students but rather, the direct impact of receiving a higher integer score. We also see causal
effects that are smaller in magnitude by attaining a 3 over a 2 and 4 over a 3. AP and its scoring
impacts millions of students each year across the entire nation and is delivered prior to the
beginning of college, which is unique among causal studies on major choice. Further, for
students with nearly identical performance on the AP Exam (adjacent scores on the continuous
scale) we find evidence that the effect of an increase in AP score on the choice of college major
is primarily driven by the behavioral effect of the positive signal communicated by the difference
in integer score.
Along with our above primary result, we also find several other results about how AP
scores influence a student’s choice of college major. First, our estimates do not detect any strong
heterogeneous effects, suggesting that the causal impacts on major choice hold across students
differing on gender and underrepresented minority status. Second, the strong impact of a 5 is
attentuated when students also receive additional high AP scores, implying that the power of a an
additional signal depends on how many other positive signals the student has received. Finally,
although students who attain higher AP scores on STEM exams are, on average,considerably

5

more likely to major in STEM (e.g. students scoring a 5 on a STEM AP exam are 42 percent
more likely than students scoring a 4 on a STEM AP exam), the impact of a higher AP integer
score among students with otherwise comparable AP exam performance shifts students across
STEM disciplines, which we discuss later in the paper. In other words, factors, many of which
are unobservable, such as quality of AP instruction, students’ mastery of the required content and
skills, or student interest and motivation in a subject, likely explain the strong positive
relationship between AP integer scores and the student’s likelihood of majoring in that AP
discipline, rather than the unique signalling effect of a higher integer score to a student who has
otherwise similar content and skill mastery to a student who received a lower integer score.
This paper is organized as follows.
program, scoring and literature.

Section 2 describes the Advanced Placement

Sections 3 and 4 describe our data and methodology,

respectively. Section 5 presents our main findings on the response to relatively higher AP
scores, along with the exploration of underlying mechanisms, including credit policies and
behavioral responses to positive signals. Section 6 investigates some of the broader impacts of
our findings, including heterogeneous effects, the impact of multiple signals, and changes in
STEM degree production. Section 7 concludes.
2. AP Background & Literature Review
The history of the Advanced Placement Program is rooted in the philosophies that collegelevel academic opportunities should be extended to high-achieving high school students and that
demonstration of proficiency in such coursework should exempt college students from re-taking
courses. (See Smith et al., for more details) Collaborating with high school teachers and college
professors, the AP program develops curricula that are reflective of the content typically taught
in introductory-level college courses and exams are constructed to certify whether students have

6

mastered the content and skills required for course exemption. Since its introduction in the
1950s, the AP program has extended its reach beyond college preparatory schools and wellfunded public schools, and currently, more than 9 out of 10 public school students in the United
States have access to at least one AP exam at their schools (Theokas & Saaris, 2013).4 In 2015,
high school students took nearly 4.5 million AP exams in 36 subjects. Exams take place over a
two-week period in May with only one administration per subject per year, and scores are
released several months later.5 The exact number of AP exams has varied over time, as some
exams were retired due to low participation rates and new exams were introduced as a result of
high student demand. This paper only considers the 19 most popular subject exams, with at least
100,000 exam takers between 2004 and 2009 (see Appendix Table 1 for details on all 34 exams).
AP scores are reported to students and colleges on a 1 through 5 scale, where 1 translates
into “no recommendation” and 5 translates into “extremely well-qualified”. The integer scores
are based on students’ raw scores, which reflect performance on multiple choice and freeresponse sections. Because the AP exams are criterion-based, cut scores are established based on
earning a pre-determined number of points that predict college-performance at varying levels and
not on relative performance. The exams are designed so students earning a score of 3 on one test
administration have an identical mastery of material as students earning a 3 on a separate
administration.6
In order to receive credit, course exemption and placement, students must submit AP
scores to the institutions at which they enroll. There exists enormous variation in how AP exam
scores are treated, both across postsecondary institutions and across exams within postsecondary
4

The College Board official statistics are slightly lower at around 60 percent. (See
http://apcentral.collegeboard.com/apc/public/program/index.html)
5
Approximately 0.3 percent of students retake an AP exam.
6
Continuous raw scores range from 0 to 180 points, though there is considerable variation in the scoring range and
maximum across exams.

7

institutions. Most students enrolling at four-year institutions attend colleges that award credits
toward graduation if students meet certain threshold minima- generally a 3 or 4 on the standard
1-5 scale. Along with receipt of college credit, the student is generally eligible to enroll
immediately in the sequent course. Colleges independently decide how many credits students
receive for meeting AP thresholds, the sequent courses for which they are eligible, and whether
scores exceeding the credit-granting thresholds are appropriate for the awarding of additional
credits and course exemptions.
2.1. AP Literature Review
Our paper contributes to a small, but expanding body of literature that separates out the
predictive effects of AP participation and performance from the causal effects of receiving
higher AP integer scores.

A substantial prior literature documents a positive relationship

between early college credit and choice of major (Dodd, Fitzpatrick, De Ayala, & Jennings,
2002; Keng & Dodd, 2008; Morgan & Klaric, 2007; Murphy & Dodd, 2009; Tai, Liu, Almarode,
& Fan, 2010).7 More recently, Mattern, Shaw, and Ewing (2011) find that students who take a
particular AP exam are much more likely to major in that subject: students who take AP
Computer Science are 4.5 times more likely to major in computer science than students who did
not take the AP course. These large estimates rest on a selection on observables identification
strategy.
Sources of randomization in the context of AP research are hard to come by, and many of
the most compelling studies examining the long and short term consequences of AP course and

7

There also exists a series of studies that demonstrate a strong positive correlation between AP participation, AP
exam scores and subsequent academic performance across a range of measures including college attendance
(Chajewski, Mattern, & Shaw, 2011) and success in subject performance (Patterson & Ewing, 2013), overall
performance (Mattern, Marini, & Shaw, 2013), and college completion (Dougherty, Mellor, & Jian, 2006; Hargrove,
Godin, & Dodd, 2008; Mattern et al., 2013; Morgan & Klaric, 2007). There is a similar line of research on dual
enrollment. For example, see Karp, Calcagno, Hughes, Jeong, and Bailey (2007).

8

exam taking have relied on a selection on observables research design (Evans, 2013; Long,
Conger, & Iatarola, 2012; Murphy & Dodd, 2009).8 Two notable exceptions are our own study
linking AP scores to college graduation outcomes (Smith, Hurwitz and Avery, forthcoming) and
Jackson (2010), who finds that the introduction of a program that paid teachers and students for
success on AP examinations increased SAT/ACT scores and college matriculation. Despite the
convincing case for causality, Jackson is unable to generalize about the relative contributions of
improved teaching, increased exposure to rigor and the direct effects of the fact that some
students may have earned higher AP scores as a result of this incentive program. In what follows,
we isolate the effect of higher AP scores and demonstrate its effects on choice of major.

3. Data and Descriptive Statistics
3.1.College Board Data
This paper uses student-level data from the 2004-09 graduating high school cohorts
collected from two main sources, College Board (CB) data on AP examinees and National
Student Clearinghouse (NSC) data. CB maintains a database of all students who take at least one
AP exam. This database contains not only the students’ AP exam scores on the 1-5 integer scale,
but their underlying continuous scores on most exams taken between 2004 and 2009. From these
two pieces of information, we identify the exact continuous scores that sharply form the
boundaries of the scaled scores.9 In addition to student performance on each AP exam, the CB
data also contain a host of student demographic information, such as a student’s gender,

8

There are currently some randomized AP evaluations underway, which will be very informative, but they are
limited in their scope of exams and populations (Long, Conger, & McGhee, 2014).
9
Data on raw scores are available only for exams taken during the 2003-04 school year or later. Therefore some AP
test takers, particularly in the 2004 and 2005 cohorts, will not have raw scores that can be mapped to their scaled
scores taken in sophomore or junior year of high school. The few exams without an accompanying raw score are
removed from our analyses,

9

race/ethnicity, and parental income.10 We also observe student SAT scores, if they take the
exam. We frequently divide our analyses into separate results for STEM and non-STEM AP
exams, which are listed in Appendix Table 1. AP exams used in this paper that are considered
STEM include Biology, Calculus, Chemistry, Environmental Sciences, Physics, and Statistics.
3.2.National Student Clearinghouse, CIP Codes, and IPEDS
CB data are then merged with the NSC data. As of 2015, over 3,600 postsecondary
institutions participate in NSC, which collects postsecondary enrollment information on more
than 98 percent of students enrolled in public and private colleges within the United States.11 In
this study, we track a student’s postsecondary trajectory including enrollment and degree
completion. We observe students college trajectories for six years after they graduate high school
for the 2004-2007 cohorts, five years for the 2008 cohort, and four years for the 2009 cohort.
The majors in the NSC data are provided only for graduating students, and we focus
exclusively on majors associated with a bachelor’s degree. NSC provides full six-digit
Classification of Instructional Program (CIP) code information,12 which we simplify by focusing
on the first two digits.13 Two-digit CIP codes translates into general fields such as biology,
history, or English.
In order to assess whether college majors are impacted by different AP scores for similar
exam performance, we match each AP subject to the closest two-digit CIP code, documented in
Appendix Table 2. In some cases the match is fairly exact; for example, students taking AP
10

Parental income is collected on the SAT registration forms, and so some AP test takers who did not participate in
the SAT will have missing demographic information. Even among SAT participants, some students fail to respond
to these questions.
11
Due to data privacy laws and potential complications with student matching, the actual NSC coverage may be a
bit lower than 98 percent rate (Dynarski, Hemelt, & Hyman, 2015).
12
The CIP codes are a taxonomic scheme created by the U.S. Department of Education to ensure a uniform system
of tracking across colleges.
13
CIP codes are not provided for the 2004 cohort and approximately one-third of institutions in other cohorts but are
instead in text form that we unify into CIP codes. Since there is the chance for classification error, we test the
sensitivity of the results by only using the students with a CIP code. Results hold and are in the appendix.

10

Biology are linked to the CIP code related to Biological Sciences. In other cases we are required
to group AP exams, as both Chemistry and Physics are most closely linked to the two digit CIP
code of Physical Sciences.14 In addition, we consider whether AP exams alter whether students
major in the broader field of STEM majors. We select all CIP codes where the first two digits
correspond to our STEM AP exams, namely 11, 14, 15, 26, 27, and 40. Although we do not
capture all STEM majors with this approach, we do capture most STEM degrees at four-year
universities.15
Finally, we append to our data several variables from the Integrated Postsecondary
Education Data System (IPEDS). These include the average standardized test scores (ACT and
SAT) of incoming students and whether the college is public or private.16
3.3. AP Credit Policies
We use AP credit policies from two sources: the Annual Survey of Colleges (ASC) and
data collected by the authors from college websites. Administered annually by the College Board
to nearly 4,000 colleges, the 2004 survey included information on the minimum credit-granting
scores by AP subject (only to be removed after 2005). We supplement these data, by

14

The only deviation from this approach that we adopt is a grouping of AP Calculus and Statistics with majors in
either math/statistics or engineering, primarily because relatively few students major in math and engineering is far
more prevalent among test takers in these subjects. Also, 4 percent of students double major. If one of the two
majors is related to the AP exam, students are counted as majoring in that subject. Results are not sensitive to
excluding double majors (see Appendix Table 5).
15
This is most problematic for students without CIP codes (but a textual description of major), of which we exclude
in robustness tests. Other commonly used STEM classification systems typically include a relatively small number
of CIP codes in the two-digit fields of 1 (Animal and Plant Sciences), 3 (Natural Resource Conservation), 29
(Military Technologies), 30 (Multi-disciplinary Studies), 41 (Science Technologies), and 51(Pharmaceutical
Sciences), along with a small number of other specific majors. As most majors in these broad two-digit disciplines
are not STEM-related, their inclusion was deemed incorrect. In alternate analyses not presented here, we show that
our STEM results in Table 9 are robust to using only schools that report six-digit STEM codes and using alternate
STEM classifications, such as U.S. Immigration and Enforcement lists of STEM programs that qualify foreigners
for expedited work visas.
16
To estimate average composite SAT scores, we add the 25th and 75th percentiles of the Math and Critical Reading
sections, as reported by IPEDS, and divide by 2. For colleges that only report ACT scores to IPEDS, we use an SAT
conversion table found at http://research.collegeboard.org/sites/default/files/publications/2012/7/researchnote-200940-act-sat-concordance-tables.pdf

11

constructing an enhanced “policy sample.” To accomplish this, we collected the more nuanced
AP credit and placement data directly from the websites of the 500 largest four-year institutions
in the country, as measured by full time equivalent students. This inclusion rule captures a wide
swath of postsecondary institutions: both selective and non-selective colleges, along with a
representative mix of public and private colleges, and represents approximately 82% of students
who take an AP exam. We create a binary “AP Credit” variable for each combination of AP
exam and threshold at each college. We code the AP Credit variable as a “1” for each examcollege-threshold combination if a college provides any beneficial advantage at that threshold,
including credit towards graduation, credit towards major, or placement into any advanced
course.17 For example, some colleges provide 4 units of credit for a scaled score of “at least a 3.”
In this example, the AP credit variable would be coded as “1” for an AP scaled score of 3 and
“0” for any other AP scaled score (2, 4, or 5). As another example, a college may provide 4
units of credit for a score of 3 and 8 units of credit for a score of 4 on a given AP exam. In this
example we would code the AP Credit variable as “1” for a scaled score of 3, “1” for a scaled
score of 4, and a “0” for a scaled score of 5. Appendix Table 1 provides summary statistics of
the credit policies across these 500 colleges.
We highlight several limitations in the use of the AP credit data that we collected for
these 500 colleges in the summer and fall of 2015. First, these policies reflect current practices
at these colleges, whereas our data applies to students who graduated from high school between
2004 and 2009. Even so, we find that at least 70% of colleges have identical minimum creditgranting policies from 2004 (derived from ASC data) and in 2015 (from our manual data
collection), and so we conduct sensitivity analyses on the subset of colleges and thresholds with
identical minimum credit-granting thresholds for AP credit in 2004 and 2015. (See section 5.3
17

Note that we use the word “credit” but in some instances it is only placement with no credit.

12

for results) Second, the coding of our binary AP credit variables does not account for a variety
of nuances in policies across colleges. For example, some colleges may place caps on AP credits
used towards college graduation, and/or provide conditional credit for scores on certain AP
exams based on a student’s choice of major.

For this reason, we intentionally adopt a

conservative approach through expansive coding rules in the creation of the AP Credit variables
– ensuring that imprecision in the coding of these variables will induce downward bias since
some fraction of students will not be receiving credit despite being coded as having done so in a
relevant AP credit variable. In the case of shifts in major that are driven by a behavioral response
to higher AP scores, these caveats about the coding of the AP credit variables should have no
impact on our estimates.

3.4.Descriptive Statistics
We present summary statistics of students in our analytic sample in Table 1. We find that
approximately 69 percent of the sample is white, 43 percent are male, and 50 percent had a
parent who attended at least some college. On average, students earned an 1176 on the SAT,
took almost 3 AP exams, and scored an average of 2.7 on the exams. As shown in Smith,
Hurwitz and Avery (2016), student demographics vary by AP exam.
Table 2 lists the probability that a student with a given AP score on an AP exam chooses
the college major most closely associated with that subject, and then more generally in any
STEM field.18 Consistent with previous research, there is a systematic increase in the probability
of choosing the most related college major for every field. Using AP Biology as one example,
the probability of majoring in biology monotonically increases with each integer score, such that

18

These probabilities look similar when conditioning on graduates. Our primary analyses does not condition on
graduating and so we only present these statistics on the entire sample of graduates and non-graduates.

13

students who receive a 5 are nearly five times as likely to major in the subject as students who
receive a 1. Similar patterns exist across all the exams, though the exact magnitude varies,
demonstrating the strong predictive power of AP scores in major choice. The second set of
columns show similar patterns on the likelihood of majoring in any STEM field, regardless of
whether it is directly tied to the particular AP subject. As the interests, abilities, and supportive
structures of students with a higher scaled score on a given AP exam are (presumably)
systematically different than those of students with a lower scaled score on that same test, the
values in Table 2 can be viewed as unrealistically large upper bounds on the causal effect of an
increase in scaled score on the choice of college major. In general the relationships between AP
integer scores and the probability of majoring in STEM are stronger for the STEM than for the
non-STEM exams. We still observe a strong correlation between integer scores in English
Language or World History and majoring in a STEM field, though we would not assume that the
curricular content in these courses has any particular impact on scientific knowledge.
Taking the previous table one step further, Table 3 reports the distribution of college
majors for students with scaled score of “3” or higher on each of 19 most popular AP exams,
indicating a conspicuous correlation between AP exam performance and choice of college
major.19 Typically, the most popular college major for students who score 3 or higher on a
particular AP exam is the major most closely associated with that exam. For example, students
with scaled score of 3 or higher in AP Biology were more than twice as likely to major in
Biology (18.9%) than in any of the other tabulated subjects.
The two previous tables demonstrate the predictive power of AP scores in determining
major for all students. The next section focuses in on students just around the integer thresholds

19

Students with scaled scores of “3” or higher on more than one AP exam are counted multiple times in this table.

14

so to compare students who are identical across all dimensions and to estimate the impact of
receiving higher AP scores, independent of differences in student attributes.

4. Methodology
In this section, we describe the methodology to estimate the effect of a marginal change
in AP exam scores on major choice. This notation and methodology is similar to that of Smith,
Hurwitz and Avery (forthcoming). Each student i on AP exam j receives a continuous score Cij.
This continuous score maps into the scaled score, Tij as follows20:



2

Tij  3
4



1 if Cij  t 2j
if t 2j  Cij  t 3j
if t 3j  Cij  t 4j
if t 4j  Cij  t 5j
5 if t 5j  Cij

n
where t j are the thresholds for each scaled score n on exam j. For each value of n  2,3,4,5 ,

we create two variables. The first is the forcing variable:

Dist ijn  C ij  t nj
which captures how far student i’s score on exam j is from threshold n. A Distijn  0 implies that
the student has a scaled scores of at least an n. This leads to the second variable for each value
of n, the dichotomous threshold variable:

1 if Dist ijn  0
Threshold ijn  
0 if Dist ijn  0

20

Technically, Tij, varies by year but for ease of exposition, we omit a year subscript.

15

After generating these variables, our basic empirical framework is shown by the standard
regression discontinuity equation presented in equation (1), where Xij is a vector of fixed effects
for the student’s year of high school graduation and the interaction of the AP exam subject and
year the exam is taken.
n
n
n
n
Outcome
ijn  0  1 Threshold
ijn  2 Distijn  3 Threshold
ijn  Distijn  X ij   ijn

(1)

We are primarily interested in the estimate of  1n , which is the coefficient on Thresholdijn that
represents the discontinuous effect of being above the AP scaled n threshold on the outcome of
interest. In practice, we separately estimate the effects of each scaled threshold.
The dependent variable in equation (1) is often an indicator variable for an outcome at
each threshold n, which is typically whether a student majors in the same subject or the same
field as the AP exam subject. In order to capture trends in the forcing variable that exist on either
side of the boundary, we fit a local linear regression with a triangular kernel. The triangular
kernel puts more weight on the observations closest to the threshold. In all regressions, we use a
bandwidth of 10, which is roughly equal to the optimal bandwidth suggested by Imbens and
Kalyanaram (2012).21
Researchers implementing regression discontinuity designs may confront challenges if
score manipulation or gaming takes place in the vicinity of thresholds. In this context, such
manipulation is essentially impossible, as grading standards and score thresholds vary from year
to year and are never reported to students. Still, as reported in Section 5.1, we perform empirical
tests to discount these threats, verifying that the density of raw scores is continuous in the
vicinity of the thresholds. We also run covariate balancing tests with similar specifications to
21

We test the sensitivity to bandwidth and kernel choices and find no measurable differences. These robustness
tests are presented in Appendix Table 4. We obtain the IK-estimated optimal bandwidth using software designed by
Calonico, Cattaneo, and Titiunik (2014).

16

equation (1), but using a covariate as the outcome, once again finding no indication of
manipulation of raw scores near scaled score thresholds.

5. Main Results
5.1.Testing the Assumptions of Regression Discontinuity
In Figure 1, we show the density of raw scores near each threshold. For each of the 19
exams in each of the years the exam is offered, the threshold is centered at zero, and then the raw
scores from the stacked exams are collapsed into one point bins. Continuous density in the
vicinity of each of the 1/2, 2/3, 3/4 and 4/5 thresholds is evident in this figure.22
Covariate balancing tests in Table 4 generally show balance across the thresholds. Among
the 52 separate covariate balancing tests shown in this table, 7 yield statistically significant (at
the 0.05 level) parameter estimates, and these 7 precisely estimated differences are extremely
small in magnitude.23
5.2.Main Regressions
Figure 2 presents our primary set of results on whether receiving higher AP exam scores
causes students to major in the same subject as the AP exam. There are clear, observable
differences in student major at the thresholds, particularly as students cross into AP scores of 4
22

The formal approach recommended by (McCrary, 2008) to test for continuous density around thresholds may not
be appropriate in light of the scoring rubric of most AP exams. Raw scores generally extend out to four decimal
places, but most raw scores are simply unattainable based on the combination of correct and incorrect responses.
Moreover, the distances between consecutive attainable raw scores appear to differ within AP exams, as does the
probability of achieving these raw scores based on combinations of points earned/deducted from the multiple choice
and free response sections. To illustrate, among students who took the 2008 administration of AP Biology and were
just on the cusp of 2/3 threshold, 18 had forcing variable values of -0.0435, followed by one student who had a
forcing variable value of exactly 0, twelve students with forcing variable values of 0.0008, and so on. As is also case
when the data are discrete (See Frandsen (2014)), this type of clustering, which is obviously not reflective of score
manipulation, presents a challenge to the traditional McCrary test.
23
The covariates are highly correlated with one another, which contributes to the number that are not balanced.
Running a seemingly unrelated regression to jointly test for balance shows similarly small imbalances on the 2/3 and
3/4 thresholds, though there is no evidence of imbalance on the 4/5 threshold, where we have our most prominent
results.

17

or 5. Table 5 provides regression estimates for the magnitude of these effects, with each
coefficient from a separate regression that represents the causal effect of receiving a higher AP
score on the corresponding threshold. Results in the first row show parameter estimates for the
full sample, with separate results in subsequent rows for the set of STEM and non-STEM exams.
Results for STEM and non-STEM exams are also shown graphically in Figure 3.
The first coefficient shows that receiving a score of 2 over a 1 on the sampled AP exams
does not shift students’ college majors into the AP exam field. This finding is unsurprising
because scores of 1 and 2 are both considered non-passing scores and colleges rarely offer credit
for either score (though, a 1 could be construed as an extremely negative signal and result in a
disincentive to major in the subject). Each successive integer jump above the 1/2 margin leads to
a larger boost in the probability that a student will choose a major in the same subject as the AP
exam. Across all sampled exams, jumps in the probability that the student major matches that
AP exam subject increases by approximately 0.2 pp (3.3 percent), 0.4 pp (4.7 percent), and 0.6
pp (5.2 percent) from receiving AP scores of 3, 4 and 5 respectively. Subject-by-subject results
are presented in Appendix Table 3 and demonstrate that there appears to be a distribution of
effects, with upper bound estimates in the range of two percentage points (and 30 percent). This
is more succinctly demonstrated in Figure 4, which plots the coefficient estimates of the 19
exams at each threshold. There is a clear pattern of positive results, particularly at the 4/5
threshold and in the non-STEM subjects.
When AP exams are separated into STEM and non-STEM exams, two different stories
emerge. Receiving a higher integer AP score on a STEM exam tends to yield a statistically
insignificant change in student major, except at the 4/5 threshold, where students are 0.5 pp (3.4
percent) more likely to major in the AP subject. By contrast, coefficients for non-STEM exams

18

are statistically significant at all margins other than the 1/2 threshold and are larger than the
STEM results.
In a set of robustness tests, we repeat the analysis reported in Table 5, while imposing some
changes in the underlying empirical specification. Appendix Table 4 reports the results of
analysis with different choices of bandwidth, kernel, the choice of controls and the number of
higher order expressions of the forcing variable (thereby altering the functional form). Appendix
Table 7 reports the results of analyses using different rules for inclusion and exclusion of
students from the sample, restricting analysis in turn to: students who graduated from high
school in the 2005-2007 cohorts so that all students are tracked for 6 years (Panel 1); students
who majored in a field where the CIP codes were provided by NSC and not hand coded by the
researchers (Panel 2); and students with a unique rather than a “double” major (Panel 3). All
results are similar to those reported in Table 5.

5.3. Mechanisms
Higher AP scores may alter college major through multiple mechanisms, which we explore
in two subsections.

First, we separately explore the contributions of endogenous college

enrollment and graduation; the former of which we rule out and the latter of which is only
marginally altered by a higher AP integer score among students with otherwise similar exam
performance. Second, we decompose the estimates into the mechanical effect of credit receipt
versus the behavioral response to a strong signal. We find strong support that the behavioral
responses to higher AP scores are the primary drivers of our estimates, though we cannot
discount the possibility that credit-granting policies are playing a small role in the shifting of
majors.

19

5.3.1. College Enrollment and Graduation
The first four columns of Table 6 indicate whether strategic college enrollment results from
the receipt of a higher AP score despite similar performance to students with a lower AP score.
The first two columns show little evidence of such trivial differences in student performance
shifting college choice, with small and often insignificant effects on school quality, as measured
by average SAT or Barron’s ranking.24 To further allay any concerns that our primary results are
being driven by shifts in college choice, we repeat the primary analyses from Table 5 in two
distinct ways. First, we re-fit our main models using only students taking AP exams in their
senior year (column 3), after college enrollment decisions have already been made, and we
continue to find positive and statistically significant results comparable to those shown in Table
5. We then re-fit our main models using college fixed-effects specification (column 4), and,
again, our results are unchanged from those shown in Table 5.
Finally, we test whether students with virtually similar exam performance, but different
integer scores, endogenously choose colleges that offer credit for the scores they attain. Column
5 of Table 6 tests whether students are more likely to enroll at a college that college offers
additional credit for a higher AP score. We find no statistical evidence to support this at the
integer score thresholds, other than a small negative coefficient on the 3/4 threshold which
paradoxically suggests that a student is less likely to attend a college if that college offers the
student additional credit for a score of 4 over a 3. Combined, the first five columns suggest that
there is no evidence that endogenous college enrollment is driving the main results.

24

We also test other measures of college quality, including each Barron’s ranking individually, college graduation
rates, and other potentially relevant measures, such as attending school out of state. We similarly find insignificant
results, which are available upon request. Our earlier paper (Smith et al., forthcoming) studies this possibility in
more detail and similarly finds no evidence that AP scores influence the choice of colleges by students.

20

As we only can identify a student’s choice of major for those students listed with a BA
degree in the NSC data, the results in Table 5 could conceivably reflect an effect of AP credit on
college graduation rather than on the choice of college major. Column 6 of Table 6 shows small
increases in six-year completion rates at the 2/3, 3/4 and 4/5 thresholds, which is consistent with
Smith, Hurwitz and Avery (forthcoming).25 However, when we condition on bachelor’s
completion (column 7), we find nearly identical point estimates to those shown in Table 5. This
provides reassuring evidence that we can isolate the effects of higher AP exam scores on shifting
college major from the documented effects on the production of more college majors.
5.3.2. Signal versus College Credit
With the mechanism(s) largely unexplained as of yet, we explore two alternatives: collegespecific credit policies that reduce major course requirements, which we label “mechanical,” or
the behavioral response to higher scores. The behavioral response may be a result of positive
affirmation of a student’s ability to succeed in a subject, but could be reaffirmed by other actors
driving the decision process, such as parents, counselors, or even the college itself.

An

alternative behavioral response may simply be that students use the high score as a guidepost to
in the course selection process, with no impact on self-confidence.
We exploit the rich variety in AP credit policies across postsecondary institutions and
compare students on the 4/5 thresholds (for example) who attend institutions where a score of 5
results in additional credit to similar students who attend institutions where no such credit is
offered. Note that students with higher scores at colleges that give credit for those scores may
benefit from the mechanical and behavioral impact of higher scores. Students only benefit from

25

We can only use 2004-2007 in these analyses. Using the full sample and four-year graduation rates, results are
consistent with Smith, Hurwitz, and Avery (forthcoming) - strong effects on the 2/3 and 3/4 thresholds, where
college credit is often at stake.

21

the behavioral impact of higher scores if their higher scores do not come with credit and thus, we
can compare the relative impacts across sets of institutions.
To separate the behavioral from the mechanical effects, we reproduce in column 1 of Table
7 our main results using only our “policy sample” of 500 largest colleges, for which we collected
detailed AP credit policy information. The results mimic those for the full sample in Table 5. The
second column then show results for the subsample of colleges that offer additional
credit/placement for scores above versus below a particular scaled score threshold, whereas
column 3 shows effects at colleges which do not offer credit/placement (henceforth referred to
credit for the sake of brevity). Thus, column 3 represents the pure behavioral effect, whereas the
estimated effects reported in Column 2 represent a combination of behavioral and mechanical
effects from receiving an increased AP integer score.
We find statistically significant increases in the probability of a matched college major due
to the pure behavioral effect at the 3/4 and 4/5 thresholds. The behavioral effect is slightly
smaller than the combined behavioral and mechanical effect at the 2/3 and 3/4 thresholds and
slightly larger than the combined effect at the 4/5 threshold. The evidence in Table 7 suggests a
strong behavioral effect from receiving higher AP integer scores, particularly at the 4/5 threshold
where the signal is strongest and changes in credit receipt are uncommon. However, we are
unable to rule out completely the possibility that the mechanical effect of receiving a higher AP
score plays a small role in influencing a student’s choice of college major.
Recall, the main results show no impact on major selection among students of similar exam
performance who receive an integer score of 2 rather than 1. This implies that the signaling
effect of a score of 1, as opposed to 2, does not cause students to shy away from majoring in the
AP subject. Since there is almost never credit on the line, the impact (or lack thereof) should be

22

considered behavioral and not mechanical. Given the strongest impact on the 4/5 margin and the
null impact on the 1/2 margin, students are responding to positive signals and not responding to
negative signals.
We further investigate the behavioral and mechanical effects of receiving higher AP integer
scores separately for STEM and Non-STEM AP exams. The middle set of columns in Table 7
report the results for STEM AP exams. We find a strong behavioral effect from receiving a score
of 5 over a 4 on STEM AP exams. We report the results for non-STEM AP exams on the right of
Table 7. In these specifications, we estimate that effects on college major that are of similar
magnitudes, regardless of whether or not the higher scaled AP score earns the student more
college credit. The consistent similarity between these two sets of estimates suggests that the
effect of an increased AP score on the choice of major is primarily behavioral in nature.26
5.3.3. Robustness Tests of the Behavioral Effect
As AP policies may have changed over time, we test the robustness of these results by
using only the set of colleges and subjects whereby the minimum credit granting AP exam score
as reported in ASC in 2004 matches the data we collected from the colleges’ websites in 2015.27
Using the approximately 70% of exams that agree perfectly between the sources, estimates are
largely unchanged and can be found in Appendix Table 6.
We next consider whether the behavioral effect is in fact students responding to higher
scores or rather, students responding to college-specific credit policies, even when students are
on the cusp of an AP integer margin where there is no difference in credit. As an example, a
college may give additional credit for a 3 (over a 2) and 5 (over a 4) in a subject but not a 4 (over
26

Subject-by-subject results are in Appendix Table 3, but are individually too imprecise to distinguish between these
two mechanisms. In general, we find positive effects irrespective of whether the college does or does not have an AP
policy at the threshold.
27
The ASC data contains only the minimum credit-granting thresholds and it is unclear whether colleges interpret
that to include instances of placement without credit, which is our approach in collecting data on the policy sample.

23

a 3). In this setting, does the student infer from the college-specific policy that scores of 3 and 4
represent the same level of preparation in that AP subject? If this scenario played out in the data,
we might expect null findings at these colleges for the impact of receiving higher AP scores.
Removing students attending these types of colleges from the analyses may expose even larger
behavioral responses among students attending colleges where the student is not primed to
interpret scores of 3 and 4 (for example) as representing identical ability.
To address this issue, we restrict attention to colleges that have uniform credit policies in
two senses. First, we look at the subsample of college-exam combinations for which the college
does not offer credit for any AP scaled score. Repeating the analysis from Table 5 for this
subsample provides a clean test of the behavioral effect described above. Not only is there no
mechanical effect from credit, but students cannot infer anything from lack of credit offered at
one score versus another.28 As shown in the first row of Table 8, the estimated effect of an
increase in AP score at the 3/4 and 4/5 thresholds is positive and of similar magnitude to our
estimated effects from earlier results. However, these coefficients are also imprecisely estimated
because of the relatively small subsample for college-exam pairs where there is no possibility of
AP credit.
Second, we repeat this analysis, for the subset of college-exam combinations where
students receive credit at each of the 3, 4, and 5 thresholds. Once again, as reported in Row 2 of
Table 8, the estimated effects of increased AP scaled score on choice of college major are
positive, generally large in magnitude, but still somewhat imprecisely estimated.
Finally, some colleges have a blanket policy on their credit policies across all subjects, for
example, by awarding credit for scoring a 3 on all exams with no additional credits offered at
higher integer scores. Assuming students are aware of the blanket policy, they may not infer
28

This is somewhat rare but the most common exams include AP Environmental Science and AP World History.

24

anything from the absence of credit increases on the other margins. Using only the subsample of
colleges that have these blanket policies, we find consistent evidence, as reported in Rows 3 and
4 of Table 8 with the main results. Combined, these analyses provide evidence supporting the
general accuracy of our earlier estimates in that students are responding to the positive signal,
and this behavioral response is not dampened from the unique college-specific credit policies
where they enroll.

6. Additional Results
In this section we examine three sets of additional results pertinent to our findings:
heterogeneous results across important demographic groups, how students respond to multiple
signals, and overall impacts on STEM degree attainment.
6.1 Heterogeneous Effects of AP Credit
In this subsection we investigate whether AP credits have heterogeneous effects by types of
student or college. On the student side, we are especially interested in the effects of AP credits
on subgroups, such as women, low-income families, and minority students traditionally
underrepresented in STEM fields (Turner & Bowen, 1999; Zafar, 2011). We report the results of
our analyses for each of these subgroups in the first eight rows of Table 9.

One immediate

challenge is that these subgroups of students are underrepresented in our AP samples (as
evidenced by the fairly small sample sizes for these groups), thereby limiting the precision of our
estimated effects for each of these subgroups. Subject to this caveat, we find only limited
evidence of differential responses for any subgroup of students, regardless of the threshold or
field, in the probability of majoring in the AP subject in response to a higher AP score.29

29

There is some evidence in Table 7 of larger estimated coefficients for “White” students than for other subgroups
of students. However, the estimated effects for Asian and other minority students (Black and Hispanic) are also

25

We consider separately the possibility of an interaction between SAT score and AP exam
score. Specifically, when we split the sample into three SAT score ranges, as reported in Rows 9
through 11 of Table 9, we find similar estimated effects of AP score on college major for each of
these subsamples. These results suggest that a change in AP scores has a similar effect on all
students, regardless of that student’s academic ability (as measured by SAT score).
On the college side, we split the sample by average SAT of all enrolled students at the
colleges and report the results in Rows 12 through 14 of Table 9. Once again, we find little
evidence of differential effects across the subsamples of colleges. These results suggest that the
effects of higher AP scores are not localized to certain types of colleges.
6.2 Multiple Signals
In this section, we address how students shift majors when they receive multiple signals
of ability. Students differ substantially in the number of AP exams taken and their performance
on these exams, and both of these factors likely influence the extent to which an additional score
of 5 (for example) alters student major. In the presence of many other positive signals through
high AP exam scores, we hypothesize that receiving an additional AP score of 5 (for example) is
less likely to shift a student’s major into the focal AP exam subject relative to the effect such a
signal might have on the student with no additional AP signals.
In Table 10, we present the results of a pooled regression in which the threshold dummy
variable in Equation 1 is interacted with student’s average performance on all other AP exams,
while including fixed effects that control for the exact combination of AP exams taken by the
student. We focus on the 4/5 margin because it is this threshold on which we find the largest

positive and the standard errors are sufficiently larger that it does not seem plausible to conclude that there are
differential effects across these groups. Similarly, the estimated effects at the 4/5 scaled score threshold appear to be
smaller for students from lowest-income families (less than $50,000 in family income) than for others, but this is not
the case at other score thresholds.

26

effects throughout the rest of the paper, and we only include the multiple exam takers in this
table. The first column of Table 10 demonstrates that the main effect of receiving a 5 over a 4 is
similar in magnitude for multiple-exam takers, compared to the entire sample of students.
Interacting the average of a student’s other AP exams with the 4/5 Threshold indicator,
we find that magnitude of the shift in college major into the focal AP subject is highly sensitive
to the average of AP scores on the other exams taken by the student. For ease of interpretation,
the average AP score on other exams is centered at three, indicating that a student with an
average score of 3.0 on all other exams would be 0.9 percentage points more likely to major in
the AP subject with a score of 5 over a 4. Across all exams, the coefficient of -0.0029 in Row 2,
Column 2 suggests that each one point increase in average AP score on other AP exams mutes
the focal exam’s pull by about 0.3 percentage points. So for a student with an average of 4 on all
other AP exams, scoring a 5 over a 4 on an additional AP exam, would increase the probability
that she majors in that subject by about 0.6 percentage points (calculated as 0.0091-0.0029). It is
also clear from columns 3 and 4 that high average scores on other non-STEM exams have a
notably stronger muting effect than do high average scores on STEM exams.30
6.3. STEM Degree Attainment
Both descriptive statistics in Table 2 and the causal estimates above imply that higher
scores increase the likelihood that a student majors in a specific subject. However, major choice
is typically a zero sum game – if a student majors in one subject, then she is likely forgoing the
opportunity to major in a different subject. This is a key differentiator between this study and our
previous study, which examined bachelor’s degree completion. We show that receiving a higher
integer score on the AP Biology exam increases the likelihood of majoring in Biology, but

30

Regressions that interact the threshold variable with alternate definitions of alternate AP exam performance,
such as counts of the number of exams with scores of 3, 4, or 5, produce similar results.

27

STEM production increases only if the student’s counterfactual degree was in a non-STEM field,
such as English or social sciences, rather than an alternate STEM degree, such as chemistry. This
is important as a shortage of STEM majors is frequently cited as a deficit in our current
educational system, and multiple policy levers have been enacted to combat this problem.
Table 11 suggests that, in general, we are unable to conclude that simply receiving a
higher AP score on a STEM AP exam, while having similar exam performance to students who
received the adjacent, lower AP exam integer score, positively impacts STEM major completion,
although we do observe a positive and statistically significant effect in the full sample at the 2/3
threshold. By contrast, we find some suggestive evidence that higher integer scores on non AP
STEM exams may draw students away from STEM fields in other non-STEM disciplines. These
results show that positive signals of high AP scores alone may not be enough to shift students
into STEM fields, as STEM-focused students may enter college with stronger major intentions.
Yet it is important to remember that exposure to any subject may have independent effects on
majoring in that subject (Fricke, Grogger, and Steinmayr, 2015) and this includes exposure to
STEM curriculum in the promotion of STEM degrees, which we cannot test here.

7. Discussion and Conclusion
This paper shows that students incorporate signals of their relative academic performance
in determining an important human capital decision: choice of college major. Although high
school graduates have received countless sources of feedback over their lifetime, our results
suggest that performance labels provided late in secondary school can have large impacts of
subsequent educational investment decisions. We find that this is predominately a behavioral
response and is strongest when the students have few other competing signals of academic

28

excellence on AP exams. This result is consistent with recent research by Papay, Willett, and
Murnane (forthcoming), who find that students are more likely to attend college when they have
a positive label that summarizes their score performance on a standardized test, as well as with
the broader literature on the effects of positive signals of ability.31
The impacts on student major found in this research, in combination with the decrease in
time to degree found in our previous study, show that that AP scores affect the postsecondary
choices and outcomes of different students in different ways. Our earlier study finds that at the
minimum credit-granting margin (generally the 2/3 scaled score margin), students receiving the
higher integer score, despite otherwise similar performance on that AP exam, are more likely to
complete a BA degree in four years, principally because credit receipt generally reduces the
minimum credits for BA completion. By contrast, this study finds that the AP integer score
primarily influences the choice of college major for students at the higher scaled score cutoff of
4/5 on most exams, when performance on that AP exam is otherwise similar to students who
simply fell on the other side of the cut score. Although the magnitudes of these effects are
generally less than 1 percentage point per test, they are not negligible by comparison to the
cross-sectional correlations between AP score and college major. On average, the signaling
effect of the higher score explains approximately 16 percent of the difference in the probability
of majoring in the subject for students who receive a 5 versus a 4. Also, given the national scope
of AP, small magnitudes in parameter estimates translate into thousands of students in each high
school cohort.
Our results highlight that timely signals of academic preparation can impact major choice,
yet we generally find statistically significant evidence of changes in college major within the

31

See for example, Diamond and Perrson (2016), Foote, Schulkind and Shapiro (2015), Jackson (2015), Kosfeld &
Neckermann (2011), Fryer, Levitt & List (2008) and Steele and Aronson (1995).

29

broader classifications of “STEM” vs. “Non-STEM”, not across these broad classifications. Our
estimates of the effect of a higher integer score on an AP STEM exam and the probability of
choosing a STEM major are consistently positive (Table 11), even though they lack statistical
precision. That is, there may be small positive effects of AP integer scores on the choice of a
STEM major that are beyond the power of the tests we can perform on existing data.
Why might we find differences in the effects of ability signals between STEM and nonSTEM AP exams? Signaling effects may be weaker for STEM AP takers because these students
may have already received many alternate and perhaps competing signals of preparation in that
AP subject. For example, STEM AP takers may have received more consistent feedback from
frequent tests that use grading standards on which the student might place more weight. In other
words, students may perceive their evaluations in these subjects to have greater objectivity. This
then suggests that developing skills in rigorous high school courses can help promote STEM
completion. In addition, STEM students tend to take more AP exams, which we show mitigates
any one signal, and so it is certainly possible that variations on signal strength and timeliness in
STEM fields can have sizable impacts. Stinebrickner and Stinebrickner (2013) find that
“students enter school quite optimistic about obtaining a science degree, but that relatively few
students end up graduating with a science degree, … [primarily due to] misperceptions about
their ability to perform well academically in science.” As AP takers enter college amongst the
most highly prepared students in the nation, these results underscore the challenge of carrying
out a plan to complete a major in a STEM field. Interventions that help students navigate
introductory courses, perhaps through counseling or psychological supports (e.g., Walton and
Cohen (2011)) may help retain these high-achievers in STEM fields.

30

Overall, the results in this paper suggest that positive signal of students’ ability can change
their major, and that timely provision of signals might produce larger shifts in outcomes. For
example, providing students similar feedback earlier within their high school careers might
increase subsequent effort or spur additional course-taking within desired fields. More research
that identifies what aspects of various signals students find salient could help identify ability
signals that yield the largest changes in student behavior. This may be a particularly desirable
strand of research because these signals are nearly costless as compared to more traditional
methods of producing STEM majors, such as outreach activities or financial incentives. As there
are many opportunities for individuals and organizations to incentivize strategic goals, such as
efforts to increase STEM majors, these results in this paper show promising evidence of low-cost
signaling interventions to shift the distribution of college majors.

References
Altonji, J. G., Arcidiacono, P., & Maurel, A. (2015). The Analysis of Field Choice in College and Graduate
School: Determinants and Wage Effects Handbook of the Economics of Education Volume 5,
Chapter 7.
Arcidiacono, P., Hotz, V. J., & Kang, S. (2012). Modeling college major choices using elicited measures of
expectations and counterfactuals. Journal of Econometrics, 166(1), 3‐16.
doi:http://dx.doi.org/10.1016/j.jeconom.2011.06.002
Beffy, M., Fougère, D., & Maurel, A. (2011). Choosing the Field of Study in Postsecondary Education: Do
Expected Earnings Matter? Review of Economics and Statistics, 94(1), 334‐347.
doi:10.1162/REST_a_00212
Betts, J. R. (1996). What do students know about wages? Evidence from a survey of undergraduates.
Journal of Human Resources, 31(1), 27‐56.
Calonico, S., Cattaneo, M. D., & Titiunik, R. (2014). Robust Data‐Driven Inference in the Regression‐
Discontinuity Design. Stata Journal, 14(4), 909‐946.

31

Carnevale, A., Cheah, B., & Hanson, A. (2015). The Economic Value of College Majors. Retrieved from
Washington DC: https://cew.georgetown.edu/report/whats‐it‐worth‐the‐economic‐value‐of‐
college‐majors/
Castleman, B. L., Long, B. T., & Mabel, Z. A. (2015). Financial barriers to studying STEM in college: Causal
effect estimates of need‐based grants on the pursuit and completion of courses and degrees in
STEM fields.
Chajewski, M., Mattern, K., & Shaw, E. J. (2011). Examining the role of Advanced Placement exam
participation in 4‐year college enrollment. Education Measurement: Issues and Practice, 30, 16‐
27.
Denning, J. T., & Turley, P. (forthcoming). Was That SMART? Institutional Financial Incentives and Field
of Study. Journal of Human Resources.
Diamond, R. and P. Perrson (2016). "The Long‐Term Consequences of Teacher Discretion in Grading of
High‐Stakes Tests," SIEPER Discussion Paper No. 16‐003.
Dodd, B. G., Fitzpatrick, S. J., De Ayala, R. J., & Jennings, J. A. (2002). An investigation of the validity of AP
grades of 3 and a comparison of AP and non‐AP student groups (College Board Research Report
No. 2002‐9). Retrieved from New York, NY:
http://apcentral.collegeboard.com/apc/public/repository/ap05_research_validit_49428.pdf
Dougherty, C., Mellor, L., & Jian, S. (2006). The relationship between Advanced Placement and college
graduation. Education, 501, 1‐35.
Dynarski, S. M., Hemelt, S. W., & Hyman, J. M. (2015). The missing manual: Using National Student
Clearinghouse data to track postsecondary outcomes. Educational Evaluation and Policy
Analysis, 37, 53S‐79S.
Evans, B. (2013). How do college students use Advanced Placement credit?
Evans, B. (2015). SMART Money: Do Financial Incentives Encourage College Students to Study Science?
Foote, A., Schulkind, L., & Shapiro, T. M. (2015). Missed signals: The effect of ACT college‐readiness
measures on post‐secondary decisions. Economics of Education Review, 46, 39‐51.
Frandsen, B. R. (2014). Party Bias in Union Representation Elections: Testing for Manipulation in the
Regression Discontinuity Design When the Running Variable is Discrete.
Fricke, H., Grogger, J., & Steinmayr, A. (2015). Does exposure to economics brig new majors to the field?
Evidence from a natural experiment (NBER Working Paper 21130). National Bureau of Economic
Research. Cambridge, MA.
Fryer, R. G., Jr., Levitt, S. D., & List, J. A. (2008). Exploring the Impact of Financial Incentives on
Stereotype Threat: Evidence from a Pilot Study. American Economic Review, 98(2), 370‐375.
doi:doi: 10.1257/aer.98.2.370
Goldin, C. (2015). Gender and the Undergraduate Economics Major: Notes on the Undergraduate
Economics Major at a Highly Selective Liberal Arts College. Retrieved from Harvard University.
Hargrove, L., Godin, D., & Dodd, B. (2008). College outcomes comparisons by AP and non‐AP high school
experiences. Higher Education. (Research Rep. No. 2008‐3). Retrieved from New York, NY:
https://research.collegeboard.org/sites/default/files/publications/2012/7/researchreport‐2008‐
3‐college‐outcomes‐ap‐non‐ap‐high‐school‐experiences.pdf
Hastings, J. S., Neilson, C. A., & Zimmerman, S. D. (2013). Are Some Degrees Worth More Than Others?
Evidence from College Admission Cutoffs in Chile, NBER Working Paper No. 19241. Retrieved
from National Bureau of Economic Research:
Imbens, G. W., & Kalyanaram, K. (2012). Optimal bandwidth choice for the regression discontinuity
estimator. Review of Economic Studies, 142(2), 615‐635.
Jackson, K. (2010). A little now for a lot later: An evaluation of a Texas Advanced Placement incentive
program. Journal of Human Resources, 45(3), 591‐639.

32

Jackson, J. S. (2015). Does an Early College Readiness Signal Discourage College Application and
Enrollment? Journal of Research on Educational Effectiveness, 8(3), 380‐399.
Karp, M. M., Calcagno, J. C., Hughes, K. L., Jeong, D. W., & Bailey, T. (2007). The postsecondary
achievement of participants in dual enrollment: An analysis of student outcomes in two states.
Retrieved from St. Paul, MN: http://ccrc.tc.columbia.edu/publications/dual‐enrollment‐student‐
outcomes.html
Keng, L., & Dodd, B. G. (2008). A comparison of college performances of AP and non‐AP student groups in
10 subject areas (College Board Research Report 2008‐7). Retrieved from New York, NY:
http://research.collegeboard.org/publications/content/2012/05/comparison‐college‐
performances‐ap‐and‐non‐ap‐student‐groups‐10‐subject
Kirkebøen, L., Leuven, E., & Mogstad, M. (forthcoming). Field of Study, Earnings, and Self‐Selection.
Quarterly Journal of Economics.
Kosfeld, M., & Neckermann, S. (2011). Getting More Work for Nothing? Symbolic Awards and Worker
Performance. American Economic Journal: Microeconomics, 3(3), 86‐99.
Long, M. C., Conger, D., & Iatarola, P. (2012). Effects of high school course‐taking on secondary and
postsecondary success. American Educational Research Journal, 49(2), 285‐322.
Long, M. C., Conger, D., & McGhee, R. J. (2014). Evaluation of the Sustainability and Effectiveness of
Inquiry‐Based Advanced Placement Science Courses: Evidence from an In‐Depth Formative
Evaluation & Randomized Controlled Study.
Long, M. C., Goldhaber, D., & Huntington‐Klein, N. (2015). Do Completed College Majors Respond to
Changes in Wages? Economics of Education Review, 49, 1‐14.
Mattern, K., E. Shaw, & Ewing, M. (2011). Advanced Placement Exam Participation: Is AP Exam
Participation and Performance Related to Choice of College Major? (College Board Research
Report 2011‐6). Retrieved from New York, NY:
https://research.collegeboard.org/sites/default/files/publications/2012/7/researchreport‐2011‐
6‐ap‐participation‐performance‐major‐choice.pdf
Mattern, K. D., Marini, J. P., & Shaw, E. J. (2013). Are AP students more likely to graduate from college on
time (College Board Research Report 2013‐5). Retrieved from New York, NY:
https://research.collegeboard.org/sites/default/files/publications/2014/1/research‐report‐
2013‐5‐are‐ap‐students‐more‐likely‐graduate‐college.pdf
McCrary, J. (2008). Manipulation of the running variable in the regression discontinuity design: A density
test. Journal of Econometrics, 142(2), 698‐714.
Morgan, S. L., Gelbgiser, D., & Weeden, K. A. (2013). Feeding the pipeline: Gender, occupational plans,
and college major selection. Social Science Research, 42(4), 989‐1005.
Morgan, R., & Klaric, J. (2007). AP students in college : An analysis of five‐year academic careers (College
Board Research Report 2007‐4). Retrieved from New York, NY:
https://research.collegeboard.org/sites/default/files/publications/2012/7/researchreport‐2007‐
4‐ap‐students‐college‐analysis‐five‐year‐academic‐careers.pdf
Murphy, D., & Dodd, B. G. (2009). A Comparison of college performance of matched AP and non‐AP
student groups (College Board Research Report No. 2009‐6). Retrieved from New York, NY:
https://research.collegeboard.org/sites/default/files/publications/2012/7/researchreport‐2009‐
6‐comparision‐college‐performance‐matched‐ap‐non‐ap‐student‐groups.pdf
Oreopoulos, P., & Dunn, R. (2013). Information and College Access: Evidence from a Randomized Field
Experiment. The Scandinavian Journal of Economics, 115(1), 3‐26.
Ost, B. (2010). The Role of Peers and Grades in Determining Major Persistence in the Sciences.
Economics of Education Review, 29(6), 923‐934.

33

Papay, J. P., Willett, J. B., & Murnane, R. J. (forthcoming). How performance information affects human‐
capital investment decisions: The impact of test‐score labels on educational outcomes. Journal
of Human Resources.
Patterson, B. F., & Ewing, M. (2013). Validating the use of AP exam scores for college course placement
(Research Rep. No. 2013‐2). Retrieved from New York, NY:
https://research.collegeboard.org/sites/default/files/publications/2013/7/researchreport‐2013‐
2‐validating‐AP‐exam‐scores‐college‐course‐placement.pdf
Rogers, T., & Feller, A. (2016). Discouraged by Peer Excellence: Exposure to Exemplary Peer Performance
Causes Quitting. Psychological Science, 27(3), 365‐374. doi:10.1177/0956797615623770
Shu, P. (2013). Are the 'Best and Brightest' Going into Finance? Career Choice and Skill Development of
MIT Graduates.
Smith, J., Hurwitz, M., & Avery, C. (forthcoming). Giving Credit Where it is Due: Advanced Placement
Exam Scores and College Outcomes. Journal of Labor Economics.
Stange, K. (2015). Differential Pricing in Undergraduate Education: Effects on Degree Production by
Field. Journal of Policy Analysis and Management, 34(1), 107‐135.
Steele, C. M., & Aronson, J. (1995). Stereotype threat and the intellectual test performance of African
Americans. Journal of Personality and Social Psychology, 69(5), 797‐811.
doi:http://dx.doi.org/10.1037/0022‐3514.69.5.797
Stinebrickner, R., & Stinebrickner, T. R. (2012). Learning about Academic Ability and the College Dropout
Decision. Journal of Labor Economics, 30(4), 707‐748.
Stinebrickner, T., & Stinebrickner, R. (2013). A Major in Science? Initial Beliefs and Final Outcomes for
College Major and Dropout. Review of Economic Studies, 81(1), 426‐472.
Tai, R. H., Liu, C. Q., Almarode, J. T., & Fan, X. (2010). Advanced placement course enrollment and long‐
range educational outcomes. In P. M Sadler, G. Sonnert, R. H. Tai, & K. Klopfenstein (Eds.), AP: A
critical examination of the Advance Placement program (pp. 109‐118). Cambridge, MA: Harvard
Education Press.
Theokas, C., & Saaris, R. (2013). Finding America’s Missing AP and IB Students. Retrieved from
http://edtrust.org/resource/finding‐americas‐missing‐ap‐and‐ib‐students
Turner, S., & Bowen, W. (1999). Choice of Major: The Changing (Unchanging) Gender Gap. Industrial and
Labor Relations Review, 59(2), 289‐313.
Walton, G. M., & Cohen, G. L. (2011). A Brief Social‐Belonging Intervention Improves Academic and
Health Outcomes of Minority Students. Science, 331(6023), 1447‐1451.
doi:10.1126/science.1198364
Wiswall, M., & Zafar, B. (2015a). Determinants of College Major Choice: Identification using an
Information Experiment. Review of Economic Studies, 82, 791‐824.
Wiswall, M., & Zafar, B. (2015b). How Do College Students Respond to Public Information about
Earnings? Journal of Human Capital, 9(2), 117‐169.
Zafar, B. (2011). How do College Students Form Expectations? Journal of Labor Economics, 29(2), 301‐
348.

34

Table 1: Summary Statistics
Mean
Student Demographics
White
Asian
Black
Latino/Hispanic
Male
Parental Education (0: HS; 1: Some college)
Income Less Than $50k
Income $50k‐$100k
Income Great Than $100k
Exam Scores
SAT
Number of AP Exams Taken
Number of STEM AP Exams Taken
Average AP Exam Score
Average Raw Score

Std. Dev.

Min

Max

69.3%
10.7%
6.8%
9.2%
43.2%
49.6%
13.0%
19.1%
18.0%

0.46
0.31
0.25
0.29
0.50
0.50
0.34
0.39
0.38

0
0
0
0
0
0
0
0
0

1
1
1
1
1
1
1
1
1

1176
2.8
1.0
2.7
59.2

173
2.0
1.0
1.1
28.6

400
1
0
1
0

1600
18
8
5
179.3

N
3,148,598
Notes: Summary statistics are calculated using de‐duplicated, individual‐level data. Full
sample includes all students who took one of the 19 most taken AP exams. Some students
do not provide demographics.

35

Table 2: Probability of Majoring in core CIP code or STEM by AP Exam Subject
Major in Core Subject
2
3
4
AP Score
1
Biology
5.4%
9.5%
13.7%
18.5%
Calculus AB
4.4%
7.1%
9.2%
12.0%
Calculus BC
8.7%
11.7%
14.8%
18.3%
Chemistry
1.9%
3.5%
4.7%
6.5%
English Language & Comp.
1.0%
1.9%
3.4%
5.5%
English Literature & Comp.
0.9%
2.0%
3.8%
6.4%
Environmental Science
2.2%
3.9%
5.5%
7.6%
European History
1.2%
1.9%
3.7%
6.5%
French Language and Culture
2.0%
3.9%
6.4%
9.0%
Macroeconomics
7.0%
9.4%
11.1%
13.0%
Microeconomics
7.9%
10.0%
11.6%
14.5%
Physics B
1.4%
2.3%
3.6%
5.0%
Physics C: Mechanics
1.9%
2.9%
3.8%
5.1%
Psychology
4.6%
5.8%
7.1%
9.1%
Spanish Language
2.1%
4.0%
5.3%
6.4%
Statistics
1.9%
3.6%
6.3%
11.9%
US Gov and Politics
5.0%
8.0%
11.1%
14.7%
US History
0.6%
1.4%
2.5%
4.2%
World History
0.5%
1.1%
2.2%
4.0%

5
24.6%
18.4%
26.4%
9.6%
8.1%
9.8%
11.3%
9.8%
10.9%
16.8%
17.8%
8.7%
9.3%
11.2%
7.4%
22.4%
18.1%
7.0%
6.5%

1
8.0%
11.8%
20.4%
14.7%
5.6%
5.6%
4.6%
7.1%
11.4%
8.4%
8.5%
15.2%
20.9%
4.4%
12.4%
5.9%
6.1%
7.0%
6.8%

2
14.4%
17.5%
25.9%
24.6%
10.4%
10.2%
7.6%
10.9%
15.0%
13.6%
12.3%
22.7%
31.0%
6.8%
15.1%
9.6%
11.1%
12.1%
11.0%

Major in STEM
3
20.9%
21.3%
30.8%
32.1%
15.0%
14.5%
10.7%
14.4%
17.7%
17.6%
16.9%
30.4%
38.0%
9.1%
15.2%
14.8%
16.0%
16.0%
16.0%

4
28.7%
26.0%
35.8%
40.2%
18.3%
17.4%
15.7%
18.0%
18.3%
23.6%
22.9%
38.8%
45.2%
13.1%
14.7%
24.1%
20.6%
19.9%
20.4%

Notes: Each cell indicates the probability of majoring in the two‐digit CIP code categorization most closely associated with the AP exam.

36

5
40.9%
35.4%
46.4%
51.7%
20.6%
18.5%
26.1%
20.2%
18.7%
32.4%
34.3%
49.8%
55.9%
20.3%
14.4%
39.5%
24.9%
23.3%
24.7%

Table 3: Probability of Majoring in CIP cody by AP Exam Subject, Student Scoring 3 or Higher
College Major
English
Biological
Foreign
Language
Engineering/Ma
and
Languages,
and
Literatures, and Biomedical Physical thematics and
Literature/Le
Social
Statistics
Sciences
Sciences
Linguistics
tters
History
Sciences
Psychology
AP Exam
CIP CODE
23
54
45
42
16
26
40
14/27
Biology
2.6%
2.0%
8.7%
4.9%
2.3%
18.9%
2.7%
7.8%
Calculus AB
2.0%
1.5%
7.9%
3.6%
2.1%
9.7%
3.1%
13.4%
Calculus BC
1.5%
1.4%
9.1%
3.0%
2.1%
11.4%
4.7%
21.7%
Chemistry
1.5%
1.4%
7.8%
3.1%
2.0%
14.2%
6.7%
18.2%
English Language & Comp.
4.8%
2.5%
10.0%
4.9%
2.8%
7.4%
1.9%
6.6%
2.7%
10.0%
4.9%
2.8%
7.3%
1.9%
6.0%
English Literature & Comp.
5.4%
Environmental Science
3.2%
2.6%
11.5%
4.5%
2.1%
7.6%
1.9%
5.7%
European History
4.5%
5.7%
13.5%
4.0%
3.1%
7.0%
2.1%
6.5%
French Language and Culture
4.8%
3.1%
14.3%
4.8%
7.9%
8.3%
2.5%
6.5%
Macroeconomics
2.3%
2.4%
13.4%
3.3%
2.0%
8.2%
2.4%
11.7%
Microeconomics
2.1%
2.2%
14.3%
3.1%
2.0%
7.7%
2.4%
11.8%
20.4%
Physics B
1.6%
1.4%
7.9%
2.6%
1.7%
9.4%
5.2%
Physics C: Mechanics
1.1%
1.0%
7.3%
1.7%
1.3%
7.6%
6.2%
29.9%
Psychology
3.2%
1.9%
8.5%
9.2%
2.2%
7.1%
1.4%
4.9%
Spanish Language
2.9%
1.9%
11.0%
5.0%
6.3%
6.9%
1.6%
5.7%
Statistics
2.2%
1.8%
10.0%
4.4%
2.0%
7.8%
2.3%
11.8%
US Gov and Politics
3.5%
3.7%
13.5%
3.9%
2.4%
7.6%
2.2%
8.2%
US History
4.0%
4.0%
12.2%
4.3%
2.8%
7.9%
2.2%
7.8%
World History
3.6%
3.7%
11.4%
4.1%
2.7%
7.9%
2.2%
7.9%
Notes: Each cell indicates the probability of majoring in the two‐digit CIP code categorization. Bolded and underlined cells are the outcome major
used in all regressions.

37

Table 4: Covariate Balancing Tests

Male
Above Threshold
N

Above Threshold
N

Above Threshold
N

Above Threshold
N

White

Asian

Black

Hispanic

Parent Educ: Less Parent Educ: HS
Than HS
graduate

Parent Educ:
BA or higher

Income < $50k

Income $50k‐
$100k

Income >
$100k

Took SAT

SAT Score

0.0017
(0.0018)
1473612

0.0002
(0.0013)
1473612

‐0.0014
(0.0014)
1473612

‐0.0004
(0.0013)
1473612

0.0004
(0.0014)
1473612

0.1553
(0.5107)
1195599

0.0017
(0.0018)
1473612

‐0.0009
(0.0017)
1473612

0.0015
(0.0012)
1473612

0.0002
(0.0010)
1473612

‐0.0005
(0.0012)
1473612

‐0.0004
(0.0011)
1473612

1/2 Threshold
‐0.0001
(0.0013)
1473612

‐0.0010
(0.0014)
2383844

‐0.0020
(0.0013)
2383844

0.0013
(0.0009)
2383844

‐0.0005
(0.0006)
2383844

0.0015+
(0.0008)
2383844

0.0000
(0.0007)
2383844

2/3 Threshold
0.0028**
(0.0010)
2383844

‐0.0021
(0.0014)
2383844

0.0011
(0.0009)
2383844

0.0014
(0.0011)
2383844

‐0.0022*
(0.0011)
2383844

0.0015
(0.0011)
2383844

0.7791*
(0.3811)
1972409

‐0.0034*
(0.0014)
2472178

‐0.0035**
(0.0012)
2472178

0.0017+
(0.0010)
2472178

‐0.0008+
(0.0005)
2472178

0.0012+
(0.0007)
2472178

‐0.0007
(0.0006)
2472178

3/4 Threshold
0.0014
(0.0009)
2472178

0.0010
(0.0013)
2472178

‐0.0006
(0.0008)
2472178

‐0.0003
(0.0011)
2472178

0.0022+
(0.0012)
2472178

0.0009
(0.0010)
2472178

‐0.9662**
(0.3649)
2113990

‐0.0016
(0.0016)
1679162

‐0.0011
(0.0015)
1679162

0.0032*
(0.0012)
1679162

‐0.0004
(0.0005)
1679162

‐0.0012
(0.0007)
1679162

‐0.0001
(0.0006)
1679162

4/5 Threshold
‐0.0002
(0.0009)
1679162

0.0020
(0.0016)
1679162

‐0.0001
(0.0009)
1679162

0.0016
(0.0013)
1679162

‐0.0003
(0.0015)
1679162

0.0020+
(0.0011)
1679162

0.6089
(0.4268)
1485920

Notes. + p<0.10, * p<0.05, ** p<0.01, *** p<0.001. All students in the sample first attended a four‐year college within 180 days of high school graduation. An observation is a student AP exam. Results based on local linear
regressions with triangular kernels of bandwidth 10 that include fixed effects for AP exam‐year and high school graduation year. Other variables include the Distance from the threshold and the interaction of Distance and
Above Threshold. Standard errors clustered by individual.

38

Table 5: Effect of Attaining Higher AP Exam Scores on Major

Threshold:
Above Threshold
Mean at Cutoff
N
Above Threshold
Mean at Cutoff
N
Above Threshold
Mean at Cutoff
N

Outcome = Majored in Same Subject as AP Exam
2/3
3/4
4/5
Full Sample
‐0.0003
0.0018**
0.0038**
0.0064**
(0.0007)
(0.0006)
(0.0007)
(0.0011)
4.2%
5.4%
8.1%
12.2%
1473612
2383844
2472178
1679162
1/2

‐0.0006
(0.0012)
5.4%
626287

Only AP STEM Exams
0.0011
0.0022
(0.0013)
(0.0015)
7.5%
10.8%
770240
803432

0.0053**
(0.0019)
15.7%
635615

‐0.0001
(0.0008)
3.3%
847325

Only AP Non‐STEM Exams
0.0022**
0.0045**
(0.0007)
(0.0008)
4.4%
6.8%
1613604
1668746

0.0073**
(0.0012)
10.0%
1043547

Notes. + p<0.10, * p<0.05, ** p<0.01. All students in the sample first attended a four‐year college
within 180 days of high school graduation. An observation is a student AP exam. Results based on
local linear regressions with triangular kernels of bandwidth 10 that include fixed effects for AP
exam‐year and high school graduation year. Other variables include the Distance from the
threshold and the interaction of Distance and Above Threshold. Standard errors clustered by
individual. Means at cutoff are based on all students within one point below the designated
threshold.

39

Table 6: Potential Mechanisms for Impacts of Higher AP Exam Scores on College Major
(1)
(2)
(3)
(4)
(5)
College Choice
Barrons Most,
Schools Offers
College's Average Highly, or Very
Major in Subject; Major in Subject;
Credit at
SAT
Competitive
Senior Exams Only
College FE
Threshold
1/2 Threshold
‐‐
Above Threshold
0.4266
0.0026
‐0.0001
‐0.0004
(0.3993)
(0.0017)
(0.0010)
(0.0007)
‐‐
Mean At Cutoff
1140
59.0%
5.3%
4.2%
‐‐
N
1427550
1473612
928304
1473612
‐‐

Above Threshold
Mean At Cutoff
N

Above Threshold
Mean At Cutoff
N

Above Threshold
Mean At Cutoff
N

(6)
(7)
College Graduation
Bachelor in Six
Years

Major in Subject;
College Graduates

‐0.0037+
(0.0021)
75.0%
831234

‐0.0000
(0.0010)
6.2%
982436

0.4230
(0.3131)
1173
2325531

0.0009
(0.0013)
69.4%
2383844

0.0013
(0.0009)
6.3%
1475603

2/3 Threshold
0.0020**
(0.0006)
5.4%
2383844

0.0001
(0.0015)
59.3%
1956213

0.0027+
(0.0014)
82.0%
1386828

0.0022**
(0.0008)
7.1%
1768736

0.6023+
(0.3219)
1213
2421632

0.0026*
(0.0011)
78.7%
2472178

0.0033**
(0.0010)
9.1%
1553288

3/4 Threshold
0.0035**
(0.0007)
8.1%
2472178

‐0.0031*
(0.0015)
55.6%
2045180

0.0029*
(0.0013)
85.7%
1435783

0.0044**
(0.0009)
10.0%
1966483

0.0042**
(0.0014)
13.3%
1057689

4/5 Threshold
0.0068**
(0.0011)
12.2%
1679162

0.0019
(0.0014)
20.4%
1402697

0.0032*
(0.0014)
88.7%
953759

0.0076**
(0.0012)
14.5%
1401213

0.9922*
(0.4087)
1258
1650548

0.0006
(0.0012)
85.8%
1679162

Notes. + p<0.10, * p<0.05, ** p<0.01. All students in the sample first attended a four‐year college within 180 days of high school graduation. An observation is a
student AP exam. Results based on local linear regressions with triangular kernels of bandwidth 10 that include fixed effects for AP exam‐year and high school
graduation year. Other variables include the Distance from the threshold and the interaction of Distance and Above Threshold. Standard errors clustered by
individual.

40

Table 7: Effect of Attaining Higher AP Exam Scores on Major ‐ Credit or Signal?
Policy Sample
With AP
Without AP
All
Policy
Policy
All
Above Threshold
Mean At Threshold
N
Above Threshold
Mean At Threshold
N

Above Threshold
Mean At Threshold
N

0.0021**
(0.0007)
5.4%
1956213

0.0028**
(0.0009)
5.4%
1164325

0.0012
(0.0011)
5.4%
791888

0.0014
(0.0014)
7.6%
638044

STEM AP Exams
With AP
Without AP
Policy
Policy
2/3 Threshold
0.0030
‐0.0012
(0.0018)
(0.0023)
7.9%
7.2%
391487
246557

0.0036**
(0.0008)
8.1%
2045180

0.0042**
(0.0011)
8.2%
1137975

0.0028*
(0.0012)
8.0%
907205

0.0019
(0.0016)
11.1%
674183

3/4 Threshold
0.0027
0.0010
(0.0022)
(0.0023)
11.8%
10.3%
363711
310472

0.0068**
(0.0012)
12.4%
1402697

0.0053*
(0.0026)
12.5%
277830

0.0072**
(0.0013)
12.4%
1124867

0.0069**
(0.0021)
16.2%
540619

4/5 Threshold
0.0024
0.0085**
(0.0041)
(0.0024)
15.2%
16.6%
130449
410170

Non‐STEM AP Exams
With AP
Without AP
All
Policy
Policy
0.0025**
(0.0008)
4.3%
1318169

0.0026**
(0.0010)
4.1%
772838

0.0022+
(0.0012)
4.6%
545331

0.0044**
(0.0009)
6.7%
1370997

0.0049**
(0.0012)
6.6%
774264

0.0037**
(0.0014)
6.8%
596733

0.0069**
(0.0014)
9.9%
862078

0.0080*
(0.0032)
10.0%
147381

0.0066**
(0.0015)
9.9%
714697

Notes. + p<0.10, * p<0.05, ** p<0.01. All students in the sample first attended a four‐year college within 180 days of high school graduation. Policy sample
includes 500 colleges where credit policies are collected. Colleges are defined as "with a policy" if there is any alteration in the units or courses offered at the
threshold. An observation is a student AP exam. Results based on local linear regressions with triangular kernels of bandwidth 10 that include fixed effects for AP
exam‐year and high school graduation year. Other variables include the Distance from the threshold and the interaction of Distance and Above Threshold.
Standard errors clustered by individual. Means at cutoff are based on all students within one point below the designated threshold.

41

Table 8: Effect of Attaining Higher AP Exam Scores on Major ‐ Credit or Signal with Uniform Credit Policies
Threshold:
No Credit Given for Exam at Any Threshold

Sample
311 school‐exam combinations (106 schools) that give no credit at Above Threshold
any threshold. Environmental Science, World History, and European
History are 1/2 of the sample.
N

2/3
‐0.0011
(0.0050)
34048

3/4
0.0084+
(0.0045)
56323

4/5
0.0047
(0.0050)
62216

Credit Given for All Thresholds

435 school‐exam combinations (203 schools) that given credit at the Above Threshold
2/3, 3/4, and 4/5 thresholds. Biology, Chemistry, Spanish Language,
N
and French Language are 4/5 of the sample.

0.0087*
(0.0042)
58256

0.0099+
(0.0054)
50920

0.0074
(0.0078)
31721

Uniform Credit Policy Across AP Subjects

Above Threshold
71 schools that offer AP credit at either the 2/3 or 3/4 threshold for
N
every exam

0.0009
(0.0019)
283142

0.0022
(0.0020)
315673

0.0088**
(0.0029)
222507

Above Threshold

0.0019
(0.0021)
233759

0.0026
(0.0023)
256960

0.0083*
(0.0033)
180238

Uniform Credit Policy Across AP Subjects (2/3 Threshold Only)
52 schools that offer AP credit at the 2/3 threshold for every exam

N

Notes. + p<0.10, * p<0.05, ** p<0.01. All students in the sample first attended a four‐year college within 180 days of high school graduation. Analyses use credit policy sample, whereby policies are collected
for 500 colleges. An observation is a student AP exam. Results based on local linear regressions with triangular kernels of bandwidth 10 that include fixed effects for AP exam‐year and high school graduation
year. Other variables include the Distance from the threshold and the interaction of Distance and Above Threshold. Standard errors clustered by individual.

42

Table 9: Effect of Attaining Higher AP Exam Scores on Major ‐ Heterogeneity
Threshold:
Male
N
Female
N
White
N
Asian
N
Minority (Black/Hispanic)
N
Income < $50k
N
Income $50k ‐ $100k
N
Income > $100k
N
Took One AP
N
Took Two or More AP
N
Bottom Third SAT
N
Middle Third SAT
N
Top Third SAT
N
Bottom Third College Quality (Avg. SAT)
N
Middle Third College Quality (Avg. SAT)
N
Top Third College Quality (Avg. SAT)
N

2/3
0.0023*
(0.0010)
1024316

All AP Exams
3/4
4/5
0.0033**
0.0067**
(0.0011)
(0.0015)
1140410
836630

STEM AP Exams
2/3
3/4
4/5
0.0022
0.0028
0.0055*
(0.0020) (0.0021) (0.0027)
369339
418061
359260

Non‐STEM AP Exams
2/3
3/4
4/5
0.0022* 0.0037** 0.0078**
(0.0010) (0.0012) (0.0018)
654977
722349
477370

0.0016*
(0.0008)
1359528

0.0040**
(0.0010)
1331768

0.0062**
(0.0015)
842532

0.0001
(0.0016)
400901

0.0016
(0.0019)
385371

0.0050+
(0.0027)
276355

0.0022* 0.0050** 0.0068**
(0.0009) (0.0011) (0.0017)
958627
946397
566177

0.0020**
(0.0007)
1656577

0.0040**
(0.0009)
1789749

0.0075**
(0.0013)
1204179

0.0012
(0.0015)
538372

0.0026
(0.0017)
573035

0.0051*
(0.0023)
449550

0.0024** 0.0047** 0.0091**
(0.0008) (0.0010) (0.0015)
1118205 1216714 754629

0.0023
(0.0017)
308939

0.0028
(0.0019)
345783

0.0029
(0.0025)
273790

0.0000
(0.0034)
119323

0.0016
(0.0037)
137425

0.0040
(0.0044)
125712

0.0037* 0.0036+ 0.0022
(0.0018) (0.0021) (0.0029)
189616
208358
148078

0.0023
(0.0017)
323417

0.0041+
(0.0023)
239491

0.0026
(0.0036)
134227

0.0051
(0.0040)
83214

‐0.0002
(0.0053)
63093

0.0026
(0.0082)
36986

0.0013
(0.0018)
240203

0.0045*
(0.0018)
299503

0.0046*
(0.0023)
248206

‐0.0020
(0.0036)
144763

0.0059
(0.0038)
91086

0.0031
(0.0048)
79173

‐0.0047
(0.0068)
52964

0.0039* 0.0055* ‐0.0003
(0.0019) (0.0025) (0.0041)
208417
169033
91799

0.0017
(0.0014)
485175

0.0038*
(0.0016)
483721

0.0098**
(0.0025)
308762

0.0016
(0.0029)
153935

0.0031
(0.0034)
153702

0.0137**
(0.0046)
115658

0.0018
(0.0015)
331240

0.0043* 0.0080**
(0.0018) (0.0029)
330019
193104

0.0001
(0.0014)
474661

0.0051**
(0.0015)
557844

0.0089**
(0.0021)
409834

‐0.0008
(0.0027)
157629

0.0036
(0.0030)
179685

0.0090*
(0.0039)
151643

0.0006
(0.0016)
317032

0.0058** 0.0090**
(0.0017) (0.0025)
378159
258191

‐0.0007
(0.0017)
328563

0.0035
(0.0025)
225638

0.0041
(0.0047)
101150

‐0.0025
(0.0034)
114393

‐0.0017
(0.0045)
86042

‐0.0016
(0.0075)
45804

0.0003
(0.0019)
214170

0.0070* 0.0090
(0.0030) (0.0057)
55346
139596

0.0023**
(0.0007)
2055281

0.0038**
(0.0008)
2246540

0.0066**
(0.0011)
1578012

0.0017
(0.0014)
655847

0.0026+ 0.0058**
(0.0015) (0.0020)
717390
589811

0.0025** 0.0044** 0.0073**
(0.0007) (0.0008) (0.0013)
1399434 1529150 988201

0.0024*
(0.0010)
834173

0.0062**
(0.0019)
434741

0.0030
(0.0041)
131157

0.0033
(0.0024)
218393

0.0023
(0.0039)
123701

0.0025
(0.0084)
41141

0.0021+ 0.0080** 0.0033
(0.0011) (0.0021) (0.0045)
615780
311040
90016

0.0005
(0.0011)
798336

0.0035**
(0.0012)
908774

0.0052*
(0.0022)
469918

‐0.0010
(0.0021)
280039

0.0021
(0.0024)
296351

0.0019
(0.0037)
184270

0.0012
(0.0012)
518297

0.0043** 0.0077**
(0.0014) (0.0026)
612423
285648

‐0.0003
(0.0017)
339900

0.0016
(0.0012)
770475

0.0083**
(0.0014)
884845

‐0.0014
(0.0028)
143872

0.0002
(0.0024)
265633

0.0096**
(0.0025)
331807

0.0005
(0.0022)
196028

0.0023+ 0.0076**
(0.0014) (0.0016)
553038
504842

0.0030**
(0.0009)
975176

0.0026*
(0.0013)
734177

0.0064**
(0.0023)
341542

0.0052*
(0.0021)
278649

‐0.0011
(0.0028)
220467

0.0065
(0.0044)
123894

0.0021* 0.0042** 0.0063*
(0.0009) (0.0014) (0.0026)
696527
513710
217648

0.0016
(0.0011)
822881

0.0039**
(0.0013)
838322

0.0083**
(0.0020)
493909

0.0002
(0.0023)
270060

0.0037
(0.0026)
274458

0.0094*
(0.0037)
192741

0.0023* 0.0040** 0.0079**
(0.0012) (0.0014) (0.0023)
552821
563864
301168

‐0.0001
(0.0015)
527474

0.0043**
(0.0013)
849133

0.0054**
(0.0015)
815097

‐0.0025
(0.0024)
204439

0.0029
(0.0023)
293389

0.0028
(0.0027)
309072

0.0014
(0.0019)
323035

0.0056* 0.0026
(0.0025) (0.0038)
176398
97241

0.0051** 0.0071**
(0.0015) (0.0018)
555744
506025

Notes. + p<0.10, * p<0.05, ** p<0.01. Each estimate is a separate regression that is restricted to the identified sample. All students in the sample first attended a four‐year
college within 180 days of high school graduation. An observation is a student AP exam. Results based on local linear regressions with triangular kernels of bandwidth 10 that
include fixed effects for AP exam‐year and high school graduation year. Other variables include the Distance from the threshold and the interaction of Distance and Above
Threshold. Standard errors clustered by individual.

43

Table 10: Impact of Earning Multiple High Scores on AP Exams

Above 4/5 Threshold (Primary Exam)
Above 4/5 Threshold (Primary Exam)*Other Exam
Above 4/5 Threshold (Primary Exam)*Other STEM Exam
Above 4/5 Threshold (Primary Exam)*Other Non‐STEM Exam

N

Multiple AP
Takers
(1)
0.0068***
(0.0011)

Other Exam = Average of exam scores
(Centered at 3)
(2)
(3)
(4)
0.0091*** 0.0077***
0.0093***
(0.0013)
(0.0014)
(0.0014)

‐‐
‐‐
‐‐
‐‐
‐‐
‐‐

‐0.0029***
(0.0008)
‐‐
‐‐
‐‐
‐‐

‐‐
‐‐
‐0.0011+
(0.0007)
‐‐
‐‐

‐‐
‐‐
‐‐
‐‐
‐0.0030***
(0.0008)

1578216

1578012

1256934

1449178

Notes. + p<0.10, * p<0.05, ** p<0.01. All students in the sample first attended a four‐year college within 180 days of high
school graduation. An observation is a student AP exam but only for students near the 4/5 threshold on at least one exam.
Results based on local linear regressions with triangular kernels of bandwidth 10 that include fixed effects for AP exam
subject of the forcing variable, AP exam‐year and high school graduation year. These regressions also contain fixed effects
for the exact set of total AP exams taken by the student. Other variables include the Distance from the threshold and the
interaction of Distance and Above Threshold. Standard errors clustered by individual.

44

Table 11: Effect of Attaining Higher AP Exam Scores on Majoring in Any STEM Field

Threshold:
Above Threshold
Mean at Cutoff
N
Above Threshold
Mean at Cutoff
N
Above Threshold
Mean at Cutoff
N

‐0.0002
(0.0011)
11.7%
1473612

Outcome = Majored in STEM
2/3
3/4
Full Sample
0.0021*
0.0001
(0.0010)
(0.0011)
15.8%
20.2%
2383844
2472178

‐0.0021
(0.0014)
26.0%
1679162

‐0.0012
(0.0019)
15.5%
626287

Only AP STEM Exams
0.0028
0.0010
(0.0019)
(0.0021)
20.5%
26.7%
770240
803432

0.0006
(0.0026)
34.9%
635615

0.0005
(0.0014)
9.0%
847325

Only AP Non‐STEM Exams
0.0018
‐0.0003
(0.0012)
(0.0013)
13.5%
17.1%
1613604
1668746

‐0.0035*
(0.0017)
20.4%
1043547

1/2

4/5

Notes. + p<0.10, * p<0.05, ** p<0.01. All students in the sample first attended a four‐year college within
180 days of high school graduation. An observation is a student AP exam. Results based on local linear
regressions with triangular kernels of bandwidth 10 that include fixed effects for AP exam‐year and high
school graduation year. Other variables include the Distance from the threshold and the interaction of
Distance and Above Threshold. Standard errors clustered by individual. Means at cutoff are based on all
students within one point below the designated threshold.

45

46

Figure 2 ‐ Main Results

Percent Majoring in AP Field

-5

0

5

10

-10

-5

0

5

Distance from Threshold

Distance from Threshold

3/4 Threshold

4/5 Threshold

10

.06 .07 .08 .09

.1

.09 .1 .11 .12 .13 .14

-10

2/3 Threshold

.04.045.05.055.06.065

.03 .035 .04 .045 .05

1/2 Threshold

-10

-5

0

5

10

-10

-5

Distance from Threshold

0

5

Distance from Threshold

47

10

Figure 3 ‐ Main Results ‐ Stem and Non‐STEM Fields

Percent Majoring in AP Field
4/5 Threshold, STEM AP Exams

.12

.14

.16

.18

.08 .09 .1 .11 .12 .13

3/4 Threshold, STEM AP Exams

-5

0

5

10

-10

-5

0

5

Distance from Threshold

3/4 Threshold, Non-STEM AP Exams

4/5 Threshold, Non-STEM AP Exams

.11

Distance from Threshold

10

.05

.06

.07 .08 .09

.07

.1

.08

-10

-10

-5

0

5

10

-10

-5

Distance from Threshold

0

5

Distance from Threshold

48

10

Figure 4. Subject by Subject Results

49

Appendix Table 1: Distribution of Credit‐Granting Scores and Test Timing
AP subject
English Literature & Comp.
US History
English Language & Comp.
Calculus AB
US Gov and Politics
Biology
Psychology
Spanish Language
Chemistry
Statistics
European History
Calculus BC
Macroeconomics
World History
Physics B
Environmental Science
Microeconomics
Physics C: Mechanics
French Language and Culture
Art History
Human Geography
Spanish Literature
Comparative Gov.and Politics
Computer Science A
Physics C: E&M
Studio Art 2‐D
Studio Art Drawing
Music Theory
Computer Science AB
German Language and Culture
Latin Vergil
Latin Literature
Studio Art 3‐D
French Literature
Chinese
Italian Language and Culture
Japanese Lang. and Culture

In
Sample

STEM
exam

Total
obs.

Y
Y
Y
Y
Y
Y
Y
Y
Y
Y
Y
Y
Y
Y
Y
Y
Y
Y
Y
N
N
N
N
N
N
N
N
N
N
N
N
N
N
N
N
N
N

N
N
N
Y
N
Y
N
N
Y
Y
N
Y
N
N
Y
Y
N
Y
N
‐‐
‐‐
‐‐
‐‐
‐‐
‐‐
‐‐
‐‐
‐‐
‐‐
‐‐
‐‐
‐‐
‐‐
‐‐
‐‐
‐‐
‐‐

1,641,172
1,438,063
1,228,818
1,120,442
847,245
690,772
510,673
472,437
444,396
436,090
406,442
330,823
313,155
305,650
276,199
257,417
192,262
142,707
106,032
94,143
80,677
76,242
74,051
72,446
63,715
62,215
61,579
52,425
25,564
24,368
24,040
18,154
10,622
10,142
7,382
6,467
3,949

Percent distribution of high school
years during which exam was
Fresh. Soph.
Jun.
Sen.
0.0
0.1
5.9
94.0
0.0
5.9
86.8
7.3
0.0
1.0
79.5
19.5
0.0
0.8
14.8
84.4
0.2
3.2
8.5
88.2
0.4
6.4
34.4
58.8
0.0
1.7
26.5
71.8
1.3
8.8
33.8
56.1
0.0
4.1
48.5
47.3
0.1
2.3
15.6
82.0
0.3
42.3
16.7
40.8
0.1
1.2
18.0
80.7
0.0
0.7
7.8
91.5
2.7
73.5
13.3
10.5
0.1
1.4
31.4
67.1
0.4
2.3
28.4
68.9
0.1
1.3
10.2
88.4
0.0
0.5
10.8
88.7
0.5
3.3
23.8
72.4
0.1
6.3
27.6
66.0
17.9
17.9
18.9
45.3
0.4
4.8
26.5
68.2
0.1
5.1
14.1
80.7
0.6
11.6
35.9
51.9
0.0
0.6
8.8
90.5
0.0
0.9
11.8
87.2
0.0
1.1
14.2
84.7
0.3
5.4
28.1
66.2
0.3
8.8
36.0
54.8
0.8
4.3
20.9
74.0
0.2
5.2
37.4
57.3
0.1
3.5
37.6
58.7
0.0
0.9
10.5
88.5
0.2
3.3
20.5
76.0
0.0
4.2
35.5
60.3
0.1
0.9
11.1
87.9
0.0
2.1
20.1
77.9

Exists credit policy at score of X, relative
to X‐1 (for 500 in‐sample colleges):
3
4
5
61.3%
55.8%
17.1%
62.9%
47.7%
12.5%
64.7%
52.6%
19.1%
71.2%
43.3%
7.3%
65.7%
31.6%
4.8%
64.3%
59.3%
26.5%
64.9%
33.4%
3.8%
76.6%
64.3%
38.6%
66.5%
65.1%
32.0%
69.0%
30.4%
5.9%
59.8%
44.4%
10.4%
75.5%
52.4%
8.8%
63.3%
35.2%
4.4%
58.6%
42.3%
11.7%
62.6%
46.2%
12.3%
60.1%
33.2%
3.8%
63.7%
35.0%
4.4%
58.7%
50.6%
11.0%
76.7%
62.6%
37.0%

Notes: Includes AP exams taken by the 2004‐2009 cohorts. On‐time students are those who began at a four‐year college within 180 days of high school
graduation. Credit policies collected from college websites in August and September of 2015 and include any mention of college credit or placement.

50

Appendix Table 2: AP Subject, Classification of Instructional Program (CIP) Code, Major Crosswalk
AP Subject
CIP Code
Assigned Major
STEM
Biology
26
Biological Sciences
Calculus AB
14, 15, 27
Engineering / Engineering Technologies / Mathematics
Calculus BC
14, 15, 27
Engineering / Engineering Technologies / Mathematics
Chemistry
40
Physical Sciences
Environmental Science
26
Biological Sciences
Physics (Mechanics)
40
Physical Sciences
Physics B
40
Physical Sciences
Statistics
14, 15, 27
Engineering / Engineering Technologies / Mathematics
Non‐STEM
English Language
23
English Language and Literature/Letters
English Literature
23
English Language and Literature/Letters
European History
54
History
French Language
16
Foreign Languages, Literatures, and Linguistics
Macroeconomics
45
Social Sciences
Microeconomics
45
Social Sciences
Psychology
42
Psychology
Spanish Language
16
Foreign Languages, Literatures, and Linguistics
US Government
45
Social Sciences
US History
54
History
World History
54
History
Notes. CIP categories taken from 2010 NCES categorization (see
https://nces.ed.gov/ipeds/cipcode/browse.aspx?y=55).

51

Appendix Table 3: Subject‐by‐Subject Selected Results
2/3 Threshold
Policy Sample

Biology ‐ Above Threshold
N
Calc AB ‐ Above Threshold
N
Calc BC ‐ Above Threshold
N
Chemistry ‐ Above Threshold
N
Env Sci ‐ Above Threshold
N
Physics B ‐ Above Threshold
N
Physics M ‐ Above Threshold
N
Statistics ‐ Above Threshold
N
English Language ‐ Above Threshold
N

3/4 Threshold
Policy Sample

4/5 Threshold
Policy Sample

Full Sample
0.0030
(0.0039)
134134

All
0.0026
(0.0044)
107805

With AP Policy
0.0052
(0.0057)
61950

Without AP Policy
‐0.0009
(0.0067)
45855

Full Sample
0.0075+
(0.0043)
135445

All
0.0072
(0.0048)
110575

With AP Policy
0.0027
(0.0060)
70435

Without AP Policy
0.0148+
(0.0081)
40140

Full Sample
0.0117*
(0.0055)
106010

All
0.0114+
(0.0061)
88085

With AP Policy
0.0110
(0.0093)
34771

Without AP Policy
0.0122
(0.0080)
53314

0.0018
(0.0024)
237829

0.0029
(0.0027)
195003

0.0031
(0.0034)
124721

0.0027
(0.0047)
70282

0.0002
(0.0026)
248500

0.0008
(0.0030)
205351

0.0031
(0.0044)
99448

‐0.0011
(0.0040)
105903

0.0005
(0.0033)
212499

0.0025
(0.0036)
177148

‐0.0147
(0.0094)
25939

0.0056
(0.0039)
151209

0.0037
(0.0062)
54462

0.0018
(0.0068)
47121

0.0020
(0.0082)
33031

0.0017
(0.0122)
14090

0.0074
(0.0056)
84679

0.0077
(0.0061)
74005

0.0170*
(0.0079)
45483

‐0.0072
(0.0094)
28522

0.0058
(0.0057)
92320

0.0073
(0.0061)
81275

0.0035
(0.0125)
17391

0.0089
(0.0070)
63884

0.0026
(0.0031)
71210

0.0007
(0.0032)
59320

0.0054
(0.0042)
35555

‐0.0064
(0.0051)
23765

0.0016
(0.0038)
67984

‐0.0003
(0.0039)
57690

0.0019
(0.0049)
40629

‐0.0053
(0.0066)
17061

0.0016
(0.0051)
51440

0.0053
(0.0053)
44526

‐0.0055
(0.0078)
20100

0.0145*
(0.0071)
24426

‐0.0021
(0.0040)
55311

‐0.0023
(0.0045)
45910

‐0.0023
(0.0060)
27781

‐0.0024
(0.0067)
18129

‐0.0001
(0.0045)
54626

0.0008
(0.0050)
45306

0.0037
(0.0072)
21157

‐0.0019
(0.0070)
24149

0.0036
(0.0073)
32135

0.0057
(0.0080)
26707

‐0.0207
(0.0283)
2263

0.0082
(0.0084)
24444

0.0034
(0.0034)
46392

0.0057
(0.0036)
39111

0.0142**
(0.0052)
20730

‐0.0038
(0.0049)
18381

0.0040
(0.0045)
39348

0.0033
(0.0046)
33608

0.0026
(0.0070)
16740

0.0042
(0.0060)
16868

0.0079
(0.0068)
24366

0.0089
(0.0071)
21135

0.0311*
(0.0124)
6478

‐0.0002
(0.0086)
14657

‐0.0047
(0.0038)
42046

‐0.0047
(0.0039)
36594

‐0.0021
(0.0059)
16153

‐0.0066
(0.0053)
20441

0.0006
(0.0040)
47802

0.0004
(0.0040)
42023

‐0.0044
(0.0059)
21741

0.0055
(0.0054)
20282

0.0116*
(0.0055)
38935

0.0111*
(0.0055)
34465

0.0109
(0.0081)
12256

0.0111
(0.0073)
22209

‐0.0024
(0.0025)
128856

‐0.0014
(0.0028)
107180

‐0.0007
(0.0034)
71566

‐0.0030
(0.0049)
35614

‐0.0015
(0.0034)
125048

‐0.0038
(0.0038)
105625

‐0.0083
(0.0057)
48078

‐0.0002
(0.0052)
57547

0.0092
(0.0058)
77910

0.0121+
(0.0063)
67278

0.0109
(0.0150)
11251

0.0127+
(0.0070)
56027

0.0026*
(0.0012)
287384

0.0026+
(0.0013)
236258

0.0023
(0.0017)
153217

0.0032
(0.0023)
83041

0.0031+
(0.0017)
286089

0.0032+
(0.0018)
235356

0.0021
(0.0024)
139639

0.0047+
(0.0028)
95717

0.0123**
(0.0027)
164779

0.0103**
(0.0029)
134770

0.0090
(0.0063)
28218

0.0106**
(0.0033)
106552

52

Appendix Table 3 ‐ Continued : Subject‐by‐Subject Selected Results
2/3 Threshold
Policy Sample
English Literature ‐ Above Threshold
N
European History ‐ Above Threshold
N
French Language ‐ Above Threshold
N
Macroeconomics ‐ Above Threshold
N
Microeconmics ‐ Above Threshold
N
Psychology ‐ Above Threshold
N
Spanish Language ‐ Above Threshold
N
US Government ‐ Above Threshold
N
US History ‐ Above Threshold
N
World History ‐ Above Threshold
N

3/4 Threshold
Policy Sample

4/5 Threshold
Policy Sample

All
0.0025*
(0.0012)
319268

With AP Policy
0.0029+
(0.0016)
185275

Without AP Policy
0.0019
(0.0019)
133993

Full Sample
0.0026+
(0.0014)
424802

All
0.0025
(0.0016)
340753

With AP Policy
0.0021
(0.0020)
215138

Without AP Policy
0.0032
(0.0025)
125615

0.0086**
(0.0026)
68559

0.0077**
(0.0029)
55106

0.0072+
(0.0039)
30009

0.0084+
(0.0044)
25097

0.0049
(0.0035)
76047

0.0077*
(0.0039)
61374

0.0094+
(0.0051)
35888

0.0051
(0.0058)
25486

0.0084
(0.0069)
17678

0.0098
(0.0076)
14038

0.0128
(0.0105)
8261

0.0067
(0.0107)
5777

‐0.0021
(0.0094)
15946

‐0.0016
(0.0105)
12601

0.0099
(0.0128)
8960

‐0.0006
(0.0046)
80885

0.0006
(0.0050)
69407

‐0.0005
(0.0066)
35274

0.0018
(0.0075)
34133

‐0.0007
(0.0048)
87380

‐0.0015
(0.0051)
75690

‐0.0017
(0.0058)
51006

‐0.0019
(0.0063)
43268

‐0.0080
(0.0076)
22744

0.0031
(0.0101)
20524

0.0128*
(0.0060)
58488

0.0080*
(0.0037)
83580

0.0072+
(0.0041)
68261

0.0109*
(0.0050)
43955

0.0011
(0.0071)
24306

‐0.0008
(0.0038)
60926

0.0029
(0.0040)
50185

0.0053
(0.0049)
33774

‐0.0011
(0.0029)
200044

0.0001
(0.0031)
167771

0.0033**
(0.0011)
290107
0.0014
(0.0018)
73566

Full Sample
0.0019+
(0.0011)
399869

Full Sample
‐0.0004
(0.0026)
215421

All
‐0.0016
(0.0029)
171874

With AP Policy
0.0023
(0.0059)
36485

Without AP Policy
‐0.0026
(0.0033)
135389

0.0199**
(0.0055)
48174

0.0202**
(0.0061)
38916

0.0231+
(0.0134)
7356

0.0196**
(0.0069)
31560

‐0.0305+
(0.0182)
3641

‐0.0005
(0.0127)
10597

0.0092
(0.0141)
8505

0.0321
(0.0216)
3810

‐0.0088
(0.0186)
4695

‐0.0032
(0.0070)
37880

0.0002
(0.0073)
37810

0.0143*
(0.0057)
70345

0.0139*
(0.0060)
61749

0.0224
(0.0198)
8009

0.0127*
(0.0062)
53740

0.0108+
(0.0064)
50329

0.0176+
(0.0091)
24771

0.0040
(0.0091)
25558

0.0084
(0.0075)
45786

0.0110
(0.0080)
39964

‐0.0280
(0.0237)
6176

0.0168*
(0.0083)
33788

0.0167**
(0.0037)
103015

0.0175**
(0.0040)
85052

0.0237**
(0.0063)
36421

0.0129*
(0.0053)
48631

0.0107*
(0.0044)
91387

0.0118*
(0.0048)
76005

0.0229
(0.0187)
5491

0.0108*
(0.0050)
70514

‐0.0021
(0.0068)
16411

0.0021
(0.0040)
67221

0.0002
(0.0043)
55441

0.0038
(0.0057)
34892

‐0.0057
(0.0064)
20549

0.0020
(0.0046)
56173

0.0048
(0.0050)
46388

0.0066
(0.0080)
17651

0.0039
(0.0064)
28737

0.0008
(0.0038)
106102

‐0.0015
(0.0056)
61669

0.0072*
(0.0032)
204511

0.0066+
(0.0035)
172642

0.0067
(0.0056)
72739

0.0064
(0.0044)
99903

0.0069
(0.0045)
132408

0.0044
(0.0048)
112365

‐0.0035
(0.0230)
6341

0.0048
(0.0049)
106024

0.0031**
(0.0012)
233817

0.0026
(0.0016)
124135

0.0036*
(0.0018)
109682

0.0044**
(0.0015)
274145

0.0041**
(0.0016)
222966

0.0039+
(0.0020)
134778

0.0044+
(0.0026)
88188

0.0063*
(0.0025)
159671

0.0064*
(0.0028)
130979

0.0128+
(0.0069)
21922

0.0051+
(0.0030)
109057

0.0001
(0.0020)
60790

‐0.0007
(0.0027)
30092

0.0007
(0.0030)
30698

‐0.0004
(0.0027)
71102

‐0.0001
(0.0029)
58793

0.0091*
(0.0040)
33158

‐0.0124**
(0.0043)
25635

0.0059
(0.0044)
48806

0.0051
(0.0047)
40563

0.0075
(0.0110)
5922

0.0049
(0.0051)
34641

Notes: Notes. + p<0.10, * p<0.05, ** p<0.01. All students in the sample first attended a four‐year college within 180 days of high school graduation. Results based on local linear regressions with triangular kernels of bandwidth 10 that include fixed
effects for AP exam‐year and high school graduation year. Other variables include the Distance from the threshold and the interaction of Distance and Above Threshold. Regressions use heteroskedasticity‐consistent standard errors.

53

Appendix Table 4: Effect of Attaining Higher AP Exam Scores on Majoring in AP Exam Subject ‐ Specification Robustness Tests
Kernel
Functional Form
Bandwidth
Individual Controls

Tri
Linear
5
N

Rect
Linear
5
N

Rect
Quad
5
N

Tri
Linear
5
Y

Rect
Linear
5
Y

‐0.0024+
(0.0013)

‐0.0012
(0.0010)

‐0.0004
(0.0009)

0.0024*
(0.0012)

0.0020*
(0.0009)

0.0017*
(0.0008)

Rect
Quad
5
Y

Tri
Linear
10
N

Rect
Linear
10
N

Rect
Quad
10
N

Tri
Linear
10
Y

Rect
Linear
10
Y

Rect
Quad
10
Y

Tri
Linear
15
N

Rect
Linear
15
N

Rect
Quad
15
N

Tri
Linear
15
Y

Rect
Linear
15
Y

Rect
Quad
15
Y

1/2 Threshold

‐0.0012
(0.0010)

‐0.0004
(0.0009)

‐0.0025+
(0.0013)

‐0.0003
(0.0007)

‐0.0000
(0.0006)

‐0.0007
(0.0010)

‐0.0003
(0.0007)

‐0.0000
(0.0006)

‐0.0007
(0.0010)

0.0002
(0.0006)

0.0010+
(0.0005)

‐0.0009
(0.0008)

0.0002
(0.0006)

0.0009+
(0.0005)

‐0.0009
(0.0008)

2/3 Threshold

0.0020*
(0.0009)

0.0017*
(0.0008)

0.0024*
(0.0012)

0.0018**
(0.0006)

0.0023*** 0.0011
(0.0006)
(0.0008)

0.0019**
(0.0006)

0.0023*** 0.0011
(0.0006)
(0.0008)

3/4 Threshold

0.0035*** 0.0037*** 0.0034*
(0.0010)
(0.0009)
(0.0014)

4/5 Threshold

0.0079*** 0.0065*** 0.0101*** 0.0079*** 0.0066*** 0.0101*** 0.0064*** 0.0063*** 0.0067*** 0.0065*** 0.0064*** 0.0068*** 0.0069*** 0.0071*** 0.0068*** 0.0069*** 0.0071*** 0.0068***
(0.0015)
(0.0014)
(0.0020)
(0.0015)
(0.0014)
(0.0020)
(0.0011)
(0.0010)
(0.0015)
(0.0011)
(0.0010)
(0.0015)
(0.0009)
(0.0008)
(0.0012)
(0.0009)
(0.0008)
(0.0012)

0.0036*** 0.0037*** 0.0034*
(0.0010)
(0.0009)
(0.0014)

0.0024*** 0.0030*** 0.0014*
(0.0005)
(0.0005)
(0.0007)

0.0038*** 0.0037*** 0.0039*** 0.0038*** 0.0037*** 0.0040*** 0.0040*** 0.0049*** 0.0026**
(0.0007)
(0.0007)
(0.0010)
(0.0007)
(0.0007)
(0.0010)
(0.0006)
(0.0006)
(0.0008)

0.0024*** 0.0030*** 0.0014*
(0.0005)
(0.0005)
(0.0007)
0.0040*** 0.0049*** 0.0026**
(0.0006)
(0.0006)
(0.0008)

Notes. + p<0.10, * p<0.05, ** p<0.01, *** p<0.001. All students in the sample first attended a four‐year college within 180 days of high school graduation. An observation is a student AP exam. Results based on local linear regressions with fixed effects for AP exam‐year and high school
graduation year. Other variables include the Distance from the threshold and the interaction of Distance and Above Threshold. Standard errors clustered by individual.

54

Appendix Table 5: Effect of Attaining Higher AP Exam Scores on Majoring in AP Exam Subject ‐ Subsample Robustness Tests
1/2 Threshold
Above Threshold

‐0.0011
(0.0011)
725515

2/3 Threshold
3/4 Threshold
2005‐2007 Cohorts
0.0036***
0.0041***
(0.0009)
(0.0011)
1203950
1241365

Above Threshold

‐0.0003
(0.0006)
1367893

Excluding Manual CIP Codes
0.0010+
0.0037***
(0.0006)
(0.0006)
2200966
2277760

Above Threshold

0.0001
(0.0007)
1458932

Removed Double Majors
0.0015*
0.0031***
(0.0006)
(0.0007)
2347437
2411761

4/5 Threshold
0.0079***
(0.0016)
822227

0.0033***
(0.0009)
1547630

0.0059***
(0.0010)
1619220

Notes. + p<0.10, * p<0.05, ** p<0.01, *** p<0.001. All students in the sample first attended a four‐year college within 180 days of high
school graduation. An observation is a student AP exam. Results based on local linear regressions with triangular kernels of bandwidth
10 that include fixed effects for AP exam‐year and high school graduation year. Other variables include the Distance from the threshold
and the interaction of Distance and Above Threshold. Standard errors clustered by individual.

55

Appendix Table 6: Effect of Attaining Higher AP Exam Scores on Major ‐ Credit or Signal Robustness Test Using Alternative Source of Credit Policies
Full Sample
STEM AP Exams
Non‐STEM AP Exams
With AP
Without AP
With AP
Without AP
Without AP
All
Policy
Policy
All
Policy
Policy
All
With AP Policy
Policy
2/3 Threshold
Above Threshold
0.0021**
0.0025**
0.0011
0.0010
0.0016
‐0.0000
0.0025**
0.0030**
0.0016
(0.0008)
(0.0010)
(0.0014)
(0.0017)
(0.0020)
(0.0031)
(0.0009)
(0.0010)
(0.0015)
Mean At Threshold
5.6%
5.5%
5.7%
8.0%
8.2%
7.8%
4.5%
4.2%
4.8%
N
1488769
981909
506860
465593
322190
143403
1023176
659719
363457
3/4 Threshold
Above Threshold
0.0032**
0.0042**
0.0019
0.0017
0.0035
‐0.0001
0.0039**
0.0046**
0.0029+
(0.0009)
(0.0012)
(0.0014)
(0.0019)
(0.0027)
(0.0027)
(0.0010)
(0.0013)
(0.0016)
Mean At Threshold
8.2%
8.1%
8.2%
11.4%
11.9%
10.7%
6.7%
6.6%
6.9%
N
1540503
834237
706266
485698
248731
236967
1054805
585506
469299
4/5 Threshold
Above Threshold
0.0073**
0.0044
0.0079**
0.0101**
0.0069
0.0111**
0.0058**
0.0026
0.0064**
(0.0014)
(0.0032)
(0.0015)
(0.0025)
(0.0053)
(0.0029)
(0.0016)
(0.0039)
(0.0017)
Mean At Threshold
12.5%
12.1%
12.6%
16.5%
15.2%
16.8%
10.0%
9.5%
10.1%
N
1037245
178498
858747
383588
78861
304727
653657
99637
554020
Notes. + p<0.10, * p<0.05, ** p<0.01. All students in the sample first attended a four‐year college within 180 days of high school graduation. Policy sample includes 500 colleges where credit
policies are collected. Colleges are defined as "with a policy" if there is any alteration in the units or courses offered at the threshold. An observation is a student AP exam. Results based on
local linear regressions with triangular kernels of bandwidth 10 that include fixed effects for AP exam‐year and high school graduation year. Other variables include the Distance from the
threshold and the interaction of Distance and Above Threshold. Standard errors clustered by individual. Means at cutoff are based on all students within one point below the designated
threshold.

56

