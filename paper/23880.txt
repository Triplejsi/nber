NBER WORKING PAPER SERIES

HEALTHY BUSINESS? MANAGERIAL EDUCATION AND MANAGEMENT IN
HEALTHCARE
Nicholas Bloom
Renata Lemos
Raffaella Sadun
John Van Reenen
Working Paper 23880
http://www.nber.org/papers/w23880

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
September 2017

We would like to thank the European Research Council and Economic and Social Research
Centre for financial support through the Centre for Economic Performance. We are grateful to
Daniela Scur for ongoing discussion and feedback on the paper. Dennis Layton, Stephen Dorgan
and John Dowdy were invaluable partners in this project although we have received no financial
support from McKinsey (or any other company). We thank Jonathan Haskel, Carol Propper and
participants in seminars at the AEA, RES and MIT for helpful comments. An earlier version of
this paper was entitled: “Does Management Matter in Healthcare?” The views expressed herein
are those of the authors and do not necessarily reflect the views of the National Bureau of
Economic Research.
NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.
© 2017 by Nicholas Bloom, Renata Lemos, Raffaella Sadun, and John Van Reenen. All rights
reserved. Short sections of text, not to exceed two paragraphs, may be quoted without explicit
permission provided that full credit, including © notice, is given to the source.

Healthy Business? Managerial Education and Management in Healthcare
Nicholas Bloom, Renata Lemos, Raffaella Sadun, and John Van Reenen
NBER Working Paper No. 23880
September 2017
JEL No. I18,L32,M20,M5
ABSTRACT
We investigate the link between hospital performance and managerial education by collecting a
large database of management practices and skills in hospitals across nine countries. We find that
hospitals that are closer to universities offering both medical education and business education
have higher management quality, more MBA trained managers and lower mortality rates. This is
true compared to the distance to universities that offer only business or medical education (or
neither). We argue that supplying joint MBA-healthcare courses may be a channel through which
universities increase medical business skills and raise clinical performance.

Nicholas Bloom
Stanford University
Department of Economics
579 Serra Mall
Stanford, CA 94305-6072
and NBER
nbloom@stanford.edu

Raffaella Sadun
Harvard Business School
Morgan Hall 233
Soldiers Field
Boston, MA 02163
and NBER
rsadun@hbs.edu

Renata Lemos
World Bank
1850 I Street NW
Washington, DC 20433
and Center for Economic Performance
London School of Economics
rlemos@worldbank.org

John Van Reenen
Department of Economics, E62-518
MIT
77 Massachusetts Avenue
Cambridge, MA 02139
and NBER
vanreene@mit.edu

1. INTRODUCTION

Across the world, healthcare systems are under severe pressure due to aging populations, the
rising costs of medical technologies, tight public budgets and increasing expectations. Given the
evidence of enormous variations in efficiency levels across different hospitals and healthcare
systems, these pressures could be mitigated by improving hospital productivity. For example,
high-spending areas in the U.S. incur costs that are 50% higher than low-spending ones (Fisher
et al., 2003, in the “Dartmouth Atlas”).1 Some commentators focus on technologies (such as
Information and Communication Technologies) as a key reason for such differences, but others
have focused on divergent preferences and human capital among medical professionals (Phelps
and Mooney, 1993; Eisenberg, 2002; Sirovich et al., 2008). One aspect of the latter are
management practices such as checklists (e.g. Gawande, 2009). In this paper we seek to measure
management practices across hospitals in the US and eight other countries using a survey tool
originally applied by Bloom and Van Reenen (2007) for the manufacturing sector. The
underlying concepts of the survey tool are very general and provide a metric to measure the
adoption of best practices over operations, monitoring, targets and people management in
hospitals.

We document considerable variation in management practices both between and within
countries. Hospitals with high management scores have high levels of clinical performance, as
proxied by outcomes such as survival rates from emergency heart attacks (acute myocardial
infarction or AMI). These hospitals also tend to have a higher proportion of managers with
greater levels of business skills as measured by whether they have attained MBA-type degrees.
To further investigate the importance of the supply of managerial human capital on managerial
and clinical outcomes we draw on data from the World Higher Education Database (WHED)
providing the location of all universities in our chosen countries (see Valero and Van Reenen,
2016). We calculate geographical closeness measures (the driving times from a hospital to the
nearest university) by geo-coding the location of all hospitals and universities in our sample. We
show that hospitals that are closer to universities offering both medical and business courses
1

Annual Medicare spending per capita ranges from $6,264 to $15,571 across geographic areas (Skinner et al, 2011),
yet health outcomes do not positively co-vary with these spending differentials (e.g. Baicker and Chandra, 2004;
Chandra, Staiger, Skinner, 2010).

2

within their premises have significantly better clinical outcomes and management practices than
those located further away. This relationship holds even after conditioning on a wide range of
location-specific characteristics such as income, population density and climate. In contrast, the
distance to universities with only a business school, only a medical school, or neither—as in a
pure liberal arts college offering only arts, humanities, or religious courses—has no significant
relationship with management quality, suggesting that the results are not entirely driven by
unobserved heterogeneity in location characteristics correlated with educational institutions.
Proximity to schools offering bundles of medical and managerial courses is positively associated
with the fraction of managers with formal business education (MBA-type courses) in hospitals,
consistent with the idea that the courses increase the supply of employees with these combined
skills. We do not have an instrument for the location of universities, and cannot therefore
demonstrate the causality links behind these correlations. Nevertheless, these results are
suggestive of a strong—and so far unexplored—relationship between managerial education and
hospital performance.

Our paper relates to several literatures. First, the paper is related to the literature documenting the
presence of wide productivity differences across hospitals. Chandra et al (2013) estimate a large
heterogeneity in hospital “Total Factor Productivity” across U.S. hospitals of an order of
magnitude similar to the magnitude documented in manufacturing and retail. We contribute to
this literature by suggesting that management education may be a possible factor driving the
productivity dispersion via its effect on management practices. Second, our paper contributes to
the literature on the importance of human capital (especially managerial human capital) for
organizational performance. Examples of this work would include Bertrand and Schoar (2003)
for CEOs, Moretti (2004) for ordinary workers, and Gennaioli et al (2013) at the regional and
national levels. More specifically Doyle, Ewer and Wagner (2010) examine the causal
importance of physician human capital on patient outcomes. Finally, this paper is related to the
work on measuring management practices across firms, sectors and countries—for example,
Osterman (1994), Huselid (1995), Ichniowski, Shaw and Prenushi, (1997), Black and Lynch
(2001) and Bloom et al (2016).

3

The structure of the paper is as follows. In section 2 we provide an overview of the methodology
used to collect the hospital management data, the health outcomes data, the skills data as well as
other data used in the analysis. Section 3 describes the basic summary statistics emerging from
the data and section 4 presents the results. Section 5 concludes. The online Appendices give
much more detail on the data (A), additional results (B), sampling frame (C) and case studies of
management practices in individual hospitals (D).

2. DATA

2.1. Collecting Measures of Management Practices across Countries:
To measure hospital management practices and the share of managers with a MBA-type degree,
we adapt the World Management Survey (Bloom and Van Reenen 2007, Bloom et al 2014)
methodology to healthcare. This is based on the work of international consultants and the
healthcare management literature. The evaluation tool scores a set of 20 basic management
practices on a grid from one (“worst practice”) to five (“best practice”) in four broad areas:
operations (4 questions), monitoring, (5 questions), targets (5 questions) and human resource
management (6 questions). Our management index is the average of all 20 questions. To
compute our main management measure used in our regression analysis, we z-score the average
of the z-scores of the 20 management questions. The full list of dimensions can be found in
Appendix Table A1. To measure manager business and management skills, we asked “What
percentage of managers have an MBA?”, considering management-related courses that are at
least 6-months long.

We used a variety of procedures to persuade hospital employees to participate in the survey.
First, we encouraged our interviewers to be persistent running on average two hour-long
interviews a day. Second, we never asked hospital managers about the hospital’s overall
performance during the interview (these were obtained from external administrative sources).
Third, we sent informational letters, and, if necessary, copies of country endorsements letters
(e.g. UK Health Department).

4

Following these procedures helped us obtain an overall high response rate in terms of interviews
completed. The overall response rate was 34%, which is similar to the response rates for our
manufacturing and school surveys. The country-specific response rates ranged from 66%, 53%
and 49% of eligible hospitals in Sweden, Germany, and Brazil, to 21% of eligible hospitals in the
US. In contrast, the overall explicit refusal rate was 11% and generally low across all countries
surveyed, ranging from no refusals in hospitals in Sweden to 22% of all eligible hospitals in
Germany. In terms of selection bias, we compare our sample of hospitals for which we secured
an interview with the sample of eligible hospitals in each country against size, ownership and
location. Looking at the overall pattern of results, we obtain few significant coefficients with
marginal effects small in magnitude. In our country-specific analysis, the results show that
hospitals with certain location characteristics are more likely to respond in India, public hospitals
are more likely to be interviewed in the US, and larger hospitals are more likely to be
interviewed in Germany and in Italy. We further construct sampling weights and observe that our
main unweighted results hold even when using this alternative sample weighting scheme. We
describe our selection analysis as well as the sampling frame sources and response rates in more
detail in Appendix C.

To elicit candid responses, we took several steps. First, our interviewers received extensive
training in advance on hospital management. Second, we also employed a double-blind
technique. Interviewers are not told in advance about the hospital’s performance – they only had
the hospital’s name and telephone number – and respondents are not told in advance their
answers are scored. Third, we told respondents we were interviewing them about their hospital
management, asking open-ended questions like “Tell me how you track performance?” and “If I
walked through your ward what performance data might I see?”. The combined responses to
these types of questions are scored against a grid. For example, these two questions help to score
question 6, performance monitoring, which goes from 1, which is defined as “Measures tracked
do not indicate directly if overall objectives are being met. Tracking is an ad-hoc process
(certain processes aren’t tracked at all)”, to 5 defined as “Performance is continuously tracked
and communicated, both formally and informally, to all staff using a range of visual management
tools.” Interviewers kept asking questions until they could score each dimension.

5

Other steps to guarantee data quality included: (i) each interviewer conducted on average 39
interviews in order to generate consistent interpretation of responses. They received one week of
intensive initial training and four hours of weekly on-going training;2 (ii) 70% of interviews had
another interviewer silently listening and scoring the responses, which they discussed with the
lead interviewer after the end of the interview. This provided cross-training, consistency and
quality assurance. (iii) We collected a series of ‘noise controls’, such as interviewee and
interviewer characteristics. We include these controls in the regressions to reduce potential
response bias.

The data was collected for Canada, France, Italy, Germany, Sweden, U.S and U.K. (in 2009);
India (2012); and Brazil (2013). For the U.K. we combine two waves of the survey (2006 and
2009).3 The choice of countries was driven by funding availability, the availability of hospital
sampling frames, and research and policy interest. In every country the sampling frame for the
management survey was randomly drawn from administrative register data and included all
hospitals that (i) have an Orthopedics or Cardiology Department, (ii) provide acute care, (iii)
have overnight beds. Interviewers were each given a random list of hospitals from a sampling
frame representative of the population of hospitals with these characteristics in the country. We
interviewed the director of nursing, medical superintendent, nurse manager or administrator of
the specialty, that is, the clinical service lead at the top of the specialty who is still involved in its
management on a daily basis. We describe the country sampling frames, their sources, and
eligibility criteria in Appendices A and C. In most countries, we find that some hospitals are part
of larger networks. Therefore, in our analysis we cluster standard errors by hospital network to
take into account potential similarities across these hospitals, and multiple observations across
years for the UK sample.

2.2. Collecting Hospital Health Outcomes
Given the absence of publicly comparable measures of hospital-level performance across
countries, we collected country-specific measures of AMI (acute myocardial infarction,
commonly called heart attacks) death rates. AMI is a common emergency condition, recorded

2
3

See, for example, the video of the training for our 2009 wave http://worldmanagementsurvey.org/?page_id=187
The 2006 U.K. data has been used in Bloom et al (2015).

6

accurately and believed to be strongly influenced by the organization of hospital care (Kessler
and McClellan 2000), and used as a standard measure of clinical quality. We tried to create a
consistent measure across countries, although there are inevitably some differences in
construction so we include country dummies in almost all of our specifications.4 We observe
substantial differences in spread of this measure across countries—the country specific
coefficient of variation is 0.51 for Brazil, 0.52 for Canada, 0.21 for Sweden, 0.10 for the U.S.
and 0.34 (2006) and 0.15 (2009) for the U.K.

2.3. Classifying differences across universities
In the WHED we can distinguish whether universities offer courses in Business (Management,
Administration, Entrepreneurship, Marketing, Advertising courses), Medical (Clinical courses),
and Humanities (Arts, Language, Religion courses) and a range of other “divisions” (see Feng,
2015; Valero and Van Reenen, 2015). We geocode the location of each school using their
published addresses and compute drive-times between hospitals and universities of different
types using GoogleMaps. The computation of travel times is restricted to hospitals and
universities in the same county (see Appendix A for a more detailed explanation).

2.4. Collecting Location Characteristics Information
Using the geographic coordinates of hospitals in our sample, we also collected a range of other
location characteristics. At the regional level, we use the variables provided in Gennaioli et al
(2013).5 For data at the grid level, we construct a dataset based on the G-Econ Project in Yale
that estimates geographical measures for each grid cell which represents 1 degree in latitude by 1
degree longitude. Table B1 presents descriptive statistics for the sets of location characteristics
used in this analysis.

4

For Brazil we compute a simple risk-adjusted measure by taking the unweighted average across rates for
myocardial infarction specified as acute or with a stated duration of 4 weeks or less from onset for each rage-genderage cell for each hospital for the years of 2012 and 2013. For Canada, we use risk-adjusted rate for acute myocardial
infarction mortality for the years 2004-2005, 2005-2006 and 2006-2007. For Sweden, we use 28-day case fatality
rate from myocardial infarction from 2005 to 2007. For the US, we use the risk-adjusted 30-day death (mortality)
rates from heart attack from July 2005 to June 2008. For the UK we use 30 day risk adjusted mortality rates
purchased from the company “Dr Foster”, the leading provider of NHS clinical data. (See Appendix A for more
information and sources). For each hospital, we consider three years of data (the survey year plus two years
preceding, or the closest years to the survey with available data) to smooth over possible large annual fluctuations.
5
The regional data from Gennaioli et al (2013) consists of NUTS1, NUTS2, State or Provincial level, depending on
the country.

7

3. DESCRIPTIVE STATISTICS

3.1 Basic Descriptives
Table 1 shows the management scores across hospitals (which is the simple average of the
questions ranging between 1 and 5) and Figure 1 shows the differences across countries. The US
has the highest management score (3.0), closely followed by the UK, Sweden, and Germany (all
around 2.7) with Canada, Italy, and France slightly lower (at around 2.5). The emerging
economies of Brazil (2.2) and India (1.9) have the lowest scores. 6 The rankings do not change
substantially (except for Sweden) when we include controls for hospital characteristics and
interview noise. Country fixed effects are significant (p-value on the F-test of joint significance
is 0.00) and account for 32% of the variance in the hospital-level management scores, which is a
greater fraction than for manufacturing firms, where the figure is 25% for the same set of
countries.7

Figure 2 shows the distribution of management scores within each country compared to the
smoothed (kernel) fit of the US distribution. Across OECD countries, lower average countrylevel management scores are associated with an increasing dispersion towards the left tail of the
distribution. Hospitals with very weak management practices (score of 2 or below) have almost
no monitoring, very weak targets (e.g. only an annual hospital-level target) and extremely weak
incentives (e.g. tenure based promotion, no financial or non-financial incentives and no effective
action taken over underperforming nurses or doctors). While the fraction of hospitals with very
weak management practices in OECD countries is small (from 5% in the US to 18% in France),
this fraction rises to 45% in Brazil and 68% in India. At the other end of the distribution, the
fraction of hospitals scoring with some reasonable performance monitoring, a mix of targets and
performance-based promotion, rewards and steps taken to address persistent underperformance
(score 3 or above) ranges from 50% in the US to 3% in India.

6

In the Appendix, we provide examples of management practices in the average hospital in the US (at the top of the
ranking) and in India (at the bottom of the ranking).
7
Table C2 presents hospital characteristics across countries. Although there are many differences in cross country
means (e.g. the median French hospital has 730 beds compared to 45 in Canada). However, within all countries nonresponders were not significantly different from participating hospitals. Characteristics are different because the
healthcare systems differ and our sample reflects this.

8

3.2 AMI Mortality Rates and Management
As an external validation of our management measure across countries, we investigate whether
management is related clinical outcomes. Table 2 shows that management practices are
significantly negatively correlated with AMI mortality rates.8 In column (1) the management
coefficient suggests that a one standard deviation increase in a hospital’s management score is
associated with a fall of -0.188 standard deviations in AMI deaths rates, and this relationship
holds even after controlling for a wide variety of factors. Column (2) includes a measure of size
(hospital beds), ownership dummies (for-profits; non-for-profit and government owned), other
hospital characteristics (local competition and skills) and statistical noise controls. Column (3)
includes regional geographic controls (income per capita, education, population density, climate,
ethnicity, etc.). Column (4) includes regional dummies, and column (5) uses more disaggregated
geographical controls. Although the coefficient on management varies between columns (from 0.188 to -0.223), it is significant at the 1% level throughout.

Table 2 is consistent with findings from other work. For example, Bloom et al (2015) use
English hospitals from 2006 and also find a positive link between management and positive
performance such as survival rates from general surgery, lower staff turnover, lower waiting
lists, shorter lengths of stay and lower infection rates.9 Chandra et al (2016) look at the
management scores and risk-adjusted AMI survival rates in US hospitals and also report a
positive relationship.

3.3. Management and Management Education
We explore the correlation between management scores and management education in Table 3.
First, column (1) shows that country dummies and basic interviewer, department and interview
controls can account for about half of the overall variation in management scores. Column (2)
shows that the management score is positively and significantly correlated with the share of
managers in the hospital who have received managerial education. The coefficient implies that a
100% increase in the managerial skills variable (that is an average hospital that moves from
8

Note that we can only do this for a sub-set of hospitals (478 from the total of 1960 observations), as AMI data is
not available for all hospitals.
9
These are only correlations so may not be causal. The results do indicate that hospitals like Virginia Mason,
ThedaCare and Intermountain that are famous for adopting these types of management practices typically have
better outcomes than others.

9

having 26% to 52% of managers with a MBA-type course) is associated with .88 of standard
deviation increase in the management score.

To evaluate whether the correlation of management scores with managerial skills is due to basic
structural differences across hospitals, we control for hospital size (number of beds) in column
(4) and ownership (dummies for private-for profit and private-not for profit status) in column
(5).10 Larger hospitals tend to have higher management scores, whereas government run
hospitals tend to have lower management scores. While the inclusion of these controls reduces
the coefficient on the management skills variable by 29%, the variable remains positive and
significant. Another possible explanation is that the correlation we observe is due to competition
levels. For example, Bloom, Propper, Seiler, and Van Reenen (2015) show causal evidence of
the impact of higher competition on improved managerial quality in English hospitals. To
account for this, we add a measure of competition in column (5).11 In column (6) we add the
share of managers with a clinical degree to explore whether hospitals perform better when they
are run by managers with a clinical background (Goodall 2011). Finally, in column (7) we add
geographic controls at the regional level to test for whether the relationship found is simply
being driven by differences in location. Management skills remain correlated with management
across all these specifications.

3.4. Summary
Overall, the data show: a) a positive correlation between clinical outcomes and management
practices; and b) a positive correlation between management practices and management
education.

4. MAIN RESULTS

In this section we explore the relationship between the proximity of a university offering both
management and clinical education and three hospital-level variables of interest: (i) AMI

10

See, for example, evidence of firm basic structures as possible explanations for the variation in management
quality in Bloom, Sadun, and Van Reenen (2016).
11
Our measure of competition is collected during the survey itself by asking the interviewee ‘How many other
hospitals with the same specialty are within a 30-minute drive from your hospital?’

10

mortality rates, (ii) management practices, and (iii) the fraction of managers with an MBA-type
qualification.

4.1 AMI Mortality Rates
The average driving time between hospitals and universities is 37 minutes with a median of 19
minutes. Column (1) of Table 4 regresses AMI death rates on driving hours to the nearest
university and includes country dummies and general controls. Column (2) includes hospital
characteristics (size, ownership and competition) and column (3) adds regional controls.
Although there is a positive coefficient on distance from a university, it is statistically
insignificant.

Next, we explore whether distance to universities offering both business and medical/clinical
courses (henceforth, “joint M-B school”) is correlated with clinical performance. We calculate
driving distances from each hospital to the nearest joint M-B school, which is 67 minutes on
average. While we include a range of geographic characteristics in our specification (such as
income, education, population and temperature) there could still be unobserved heterogeneity
specific to university locations confounding the relationship between hospital performance and
the distance to universities. Therefore, in addition to including joint M-B school we also include
driving distance to universities specializing solely on arts, humanities or religious courses
(“stand-alone HUM”) and therefore not offering clinical/medical or business-type courses (and
expect to find no significant relationship between these universities and hospital performance).
To validate the use of this type of school as a placebo, Figure 3 shows that the nearest standalone HUM school and joint M-B school are similar in proximity to the hospitals in our sample:
82% of hospitals have a driving time difference of two hours or less between these two types of
universities. We also observe that the means of a range of location characteristics of the nearest
joint M-B school and stand-alone HUM school are not statistically significant (in Table B2).12
Finally, we also include universities that do not offer medical, business or humanities (“no M, B,
HUM”).

12

The only measures that are statistically significant are latitude and longitude.

11

In column (4) of Table 3 we show that there is a statistically significant and positive relationship
between distance only to the nearest joint M-B school and AMI mortality rates—an additional
hour of driving to a joint M-B school increases AMI mortality rates by 0.393 of a standard
deviation. Reassuringly, we do not observe a significant relationship between hospital
performance and the other university types.

The significance of the joint M-B school in the AMI regressions may be due to other nearby
universities that do not have medical/clinical or business courses, but offer other types of
quantitative courses (such as engineering, etc.). To investigate this issue, we calculate distances
to other schools such as (i) the nearest university offering business courses but no
medical/clinical courses (“B school, no M”), (ii) the nearest university offering medical/clinical
courses but not business courses (“M school, no B”), and (iii) the nearest university offering
other courses but no business nor medical courses (“nearest school, no M nor B”). Figure 4
shows that the distributions are similar across all types of schools. In column (5) of Table 3, we
include variables measuring driving distances to all four types of schools. The distance to joint
M-B schools has explanatory power over and above distances to other school types, and has a
coefficient similar to the previous column in terms of magnitude. Since none of these other
school types are individually or jointly significant we drop them in column (6) which is our
preferred specification.

Could the coefficient on our main variable of interest be due to a failure to control for finer
geographical characteristics? Column (7) of Table 3 includes regional dummies, grid level
geographical controls in the most general specification of column (5) and show that the
coefficient on distance to a joint M-B school is if anything even larger.

Since we do not need the management survey for the results in Table 3, we can in principle
estimate this on a larger sample. We focused on the US where information on AMI is available
for close to the hospital population13 and re-ran a similar specification to column (5) of Table 3.
Although we only have one country, the coefficient on distance remains positive and (weakly)
13

We use a sample of hospitals in the US for which AMI measures are reported in 2009, our year of reference for
the OECD countries. We approximate the sample used in the US to the cross-country sample used in this paper by
excluding sole community providers and hospitals operated by the Catholic Church.

12

significant. Because we have a larger number of hospitals within networks in the US-only
sample we can also estimate a specification with network fixed effects in column (9). This
exploits within network variation in AMI mortality rates and distance to schools, thus controlling
for possible network-level confounders (the sample is smaller as we require at least two hospitals
in the chain for which performance data was available).14 These results confirm that distance to
joint M-B schools is associated with AMI mortality rates, while the distance to other types of
schools is not.15

4.2 Management Practices
Table 5 explores the relationship between distance to universities and management practices the specifications are the same as the first seven columns of Table 3 with a different dependent
variable. There is a negative correlation between distance to the nearest university and
management quality, but it is insignificant in column (3) which controls for regional
characteristics. As with Table 3 columns (4) and (5) show that it is only joint M-B schools that
has explanatory power over and above distances to other school types. The results in our
preferred specification in column (6) suggest that every additional hour of driving to a joint M-B
school is associated with a decrease in hospital management quality of 0.145 of a standard
deviation. 16

4.3 Business education
What could be the reason for this relationship between distance and better hospital outcomes (in
terms of AMI survival rates and management practices)? One obvious mechanism is that there is
a greater supply of workers with managerial skills when a hospital is close to a joint M-B school.

14

This is analogous to a manufacturing context where one could use plant-specific variation within a firm (i.e. firm
fixed effects with plant level data).
15
We also repeat the specification in column (8) but add HRR fixed effects to check if our results are robust to
market characteristics and find similar results. Using a larger UK sample, we explore another dimension of hospital
performance: the average probability of staff intending to leave in the next year as a measure of worker job
satisfaction for the U.K. reported by the NHS staff surveys and used on Bloom et al (2015). Reassuringly, we find
similar patterns to those described in Table 3, indicating a significant positive correlation between distant to the
nearest joint M-B school and the likelihood of the average employee wanting to leave the hospital.
16
In Table B3 we check whether this relationship is driven by joint M-B school quality characteristics such as age
and ranking. While we observe that these measures are to some extent significantly correlated to hospital
management quality (but not to AMI mortality rates) when included in the analysis, our results show that adding
these measures do not result in substantial changes to the magnitude and significant of our distance to joint M-B
coefficient of interest.

13

In Figure 6 we investigate the relationship between the share of managers with an MBA type
degree and the hospital’s closeness to a joint M-B school (left hand side).17 There is a clear
downwards slope – being closer to these types of schools is associated with a higher fraction of
managers with MBAs. By contrast, the right hand side panel of Figure 6, shows that there is no
relationship between the share of MBAs and the distance to stand-alone HUM schools. We
formalize Figure 6 in Table 6 which uses the same specifications as Table 5 except has the share
of managers with MBA-type course as the dependent variable. Consistent with the two earlier
tables, closeness to a joint M-B school (but not other types of school) is associated with
significantly more hospital managers with business education.

We bring these ideas together by instrumenting the share of MBA with the distance to a joint MB school embodying the idea that proximity increases the managerial skill supply which in turn
benefits hospital performance. If the only way that university proximity matters is through skill
supply this should identify the causal impact of managerial education on hospital performance.
With the important caveats that the exclusion restriction may not be valid (as universities could
in principle affect hospitals through other routes than the supply of human capital) and the
instrument is not strong, we observe that results are consistent with a large causal effect. These
results are detailed in Table B4 and described in the Appendix.

5. CONCLUSIONS

We have collected data on management practices in 2,000 hospitals in nine countries. We
document a large variation of these management practices within each country and find that our
index of “better management” is positively associated with improved clinical outcomes such as
survival rates from AMI.
We show evidence that a hospital’s proximity to a university which supplies joint business and
clinical education is associated with a higher management practice score (and better clinical
outcomes). Proximity to universities that do not have medical schools or do not have business
schools does not statistically matter for hospital management scores, suggesting that the bundle
17

All variables in Figure 6 are orthogonalized off geographical controls through a first stage regression.

14

of managerial and clinical skills has an impact on hospital management quality. We find that
hospitals which are closer to the combined clinical and business schools also have a higher
fraction of managers with MBAs which is consistent with this interpretation.

Our work suggests that management matters for hospital performance and that the supply of
managerial human capital may be a way of improving hospital productivity. Given the enormous
pressure health systems are under, this may be a complementary way of dealing with health
demands in addition to the usual recipe of greater medical inputs.

The correlations we describe are only suggestive as we do not have panel data or experimental
evidence to track out causal impacts. Such evidence from either randomized control trials or
natural experiments is an obvious next step in this agenda.

15

REFERENCES
Arrow, Kenneth (1963) “Uncertainty and the Welfare Economics of medical care” American
Economic Review, 53(5) 141-149.
Baicker, Katherine and Amitabh Chandra (2004) “Medicare Spending, the Physician Workforce,
and the Quality of Healthcare Received by Medicare Beneficiaries.” Health Affairs,
April, 184-197.
Bertrand, Marianne, and Antoinette Schoar (2003) “Managing with Style: The Effect of
Managers on Firm Policies.” Quarterly Journal of Economics, 118 (4): 1169-1208.
Black, Sandra and Lisa Lynch (2001) “How to Compete: The Impact of Workplace Practices and
Information Technology on Productivity”, Review of Economics and Statistics, 83(3),
434–445.
Bloom, Nicholas and John Van Reenen (2007) “Measuring and Explaining Management
practices across firms and nations”, Quarterly Journal of Economics, 122, No. 4: 1351–
1408.
Bloom, Nicholas, Stephen Dorgan, Rebecca Homkes, Dennis Layton and Raffaella Sadun (2010)
“Management in Healthcare: Why Good Practice Really Matters” Report
http://cep.lse.ac.uk/textonly/_new/research/productivity/management/PDF/Management_
in_Healthcare_Report.pdf
Bloom, Nicholas, Renata Lemos, Raffaella Sadun, Daniela Scur, John Van Reenen (2014) "The
New Empirical Economics of Management". Journal of the European Economic
Association, 12, No. 4 (August 2014): 835–876.
Bloom, Nicholas, Carol Propper, Stephan Seiler and John Van Reenen (2015) “The Impact of
Competition on Management Quality: Evidence from Public Hospitals” Review of
Economic Studies 82: 457-489.
Bloom, Nicholas, Raffaella Sadun and John Van Reenen (2016) “Management as a
Technology”, CEP Discussion Paper 1433.
Cacace, Mirella, Stefanie Ettelt, Laura Brereton, Janice S. Pedersen and Ellen Nolte (2011)
“How health systems make available information on service providers: Experience in
seven countries.” Mimeo, RAND Corporation.

16

Capelli, Peter and David Neumark, 2001. ‘Do ‘High-Performance’ Work Practices Improve
Establishment-Level Outcomes?’, Industrial and Labor Relations Review, 54(4), 737775.
Chandra, Amitabh and Douglas O. Staiger (2007) “Productivity Spillovers in Healthcare:
Evidence from the Treatment of Heart Attacks.” Journal of Political Economy 115, 103140.
Chandra, Amitabh, Douglas O. Staiger, Skinner Jonathan (2010) Saving Money and Lives, in
The Healthcare Imperative: Lowering Costs and Improving Outcomes. Institute of
Medicine. http://www.ncbi.nlm.nih.gov/books/NBK53920/
Cutler, David (2010) “Where are the Healthcare Entrepreneurs?” Issues in Science and
Technology. (1): 49-56.
Doyle, Joe, Todd Wagner and Steven Ewer (2010) “Returns to Physician Human Capital:
Evidence from Patients Randomized to Physician Teams” Journal of Health
Economics 29(6) 866-882.
Eisenberg, John M. 2002. “Physician Utilization: The State of Research about Physicians’
Practice Patterns.” Medical Care. 40(11): 1016-1035.
Fisher, Elliott S., David Wennberg, Theresa Stukel, Daniel Gottlieb, F.L. Lucas, and Etoile L.
Pinder (2003) “The Implications of Regional Variations in Medicare Spending. Part 1:
The Content, Quality and Accessibility of Care” Annals of Internal Medicine 138(4):
273-287.
Gawande, Atul (2009) The Checklist Manifesto, New York: Henry Holt.
Gennailoi, Nicola, Rafael La Porta, Florencio Lopez-de-Silvanes and Andrei Shleifer (2013)
“Human Capital and Regional Development” Quarterly Journal of Economics 128(1)
105-164.
Goodall, Amanda (2011) “Physician-leaders and hospital performance: Is there an
association?” Social Science and Medicine, 73(4), 535-539.
Huselid, Mark, 1995. ‘The Impact of Human Resource Management Practices on Turnover,
Productivity and Corporate Financial Performance’, Academy of Management Journal,
38, 635-672.

17

Ichniowski, Casey, Katheryn Shaw and Prennushi, Giovanni. (1997) “The effects of human
resource management practices on productivity: A study of steel finishing lines” The
American Economic Review, 87(3), 291–313.
Jamison. D. T. and Martin Sandbu, (2001), “WHO Rankings of Health System Performance”,
Science, 293: 5535, 1595-1596.
Kessler, Daniel P., and Mark B. McClellan (2000) “Is Hospital Competition Socially Wasteful?”
Quarterly Journal of Economics 115: 577–615.
McConnell K, Lindrooth RC, Wholey DR, Maddox TM and Bloom N. (2013) “Management
Practices and the Quality of Care in Cardiac Units” JAMA Intern Med.; 173(8):684-692.
Moretti, Enrico (2004) Workers’ Education, Spillovers and Productivity: Evidence from PlantLevel Production Functions, American Economic Review, 94(3).
Osterman, Paul (1994) “How common is workplace transformation and who adopts it?”
Industrial and Labor Relations Review, 47(2), 173–188.
Paris, V., M. Devaux and L. Wei (2010), "Health Systems Institutional Characteristics: A Survey
of 29 OECD Countries", OECD Health Working Papers, No. 50, OECD Publishing.
Phelps, Charles and Cathleen Mooney (1993) “Variations in Medical Practice Use: Causes and
Consequences” In Competitive Approaches to Health Care Reform, ed. Arnould, Richard,
Robert Rich and William White. Washington DC: The Urban Institute Press.
Sirovich, Brenda, Gallagher, Patricia M., Wennberg, David E., and Elliott S. Fisher. (2008)
“Discretionary Decision Making by Primary Care Physicians and the Cost of U.S. Health
Care.” Health Affairs. 27(3): 813-823.
Valero, Anna and John Van Reenen (2016) “The Economic Impact of Universities: Evidence
from Across the Globe” NBER Discussion Paper 22501.
World Health Organization. The world health report 2000 — Health systems: improving
performance. Geneva: World Health Organization; 2000.

18

ONLINE APPENDICES (NOT INTENDED FOR PUBLICATION)

APPENDIX A: DATA

A1. Management Survey Data
Table A1 lists the 20 management practices questions asked during the survey.
A2. Hospital-Level Performance Data
We use hospital performance data for five countries surveyed, for which data was publicly available. Below is a
description of our hospital performance dataset for each country.
Brazil: We used the rate for myocardial infarction specified as acute or with a stated duration of 4 weeks (28
days) or less from onset (ICD-10, I21) for years 2012 and 2013. We create a simple risk-adjusted measure by
taking the unweighted average across rates for each rage-gender-age cell for each hospital. The raw data was
extracted from Datasus Tabnet (http://tabnet.datasus.gov.br).
Canada: We take the average of the risk-adjusted rate for acute myocardial infarction mortality for the years
2004-2005, 2005-2006 and 2006-2007 for the provinces British Columbia and Ontario. The data was extracted
from hospital reports provided by the Fraser Institute (www.fraserinstitute.org).
Sweden: We use 28-day case fatality rate from myocardial infarction for hospitalized patients for the years of
2004 to 2006 computed and published by the Swedish Association of Local Authorities and Regions (SALAR)
and the Swedish National Board of Health and Welfare (NBHW) in the report "Quality and Efficiency in Swedish
Health Care – Regional Comparisons 2008".
United States: We use the 30-day death (mortality) rates from heart attack from July 2005 to June 2008 (2009 for
the specifications in Table 2, columns 8 and 9) computed and published by Hospital Compare.
United Kingdom: We use 30-day risk adjusted AMI mortality data purchased from “Dr Foster” relative to 2006
(matched with the 2006 survey wave) and 2009 (matched with the 2009 survey wave).
A3. University Data
The University data comes from the World Higher Education Database (WHED) which has the location, foundation
date and list of “divisions” (subjects) of all research universities in our chosen countries (see Feng, 2015; Valero and
Van Reenen, 2016). Divisions are classified into Business (Management, Administration, Entrepreneurship,
Marketing, Advertising courses), Medical (Clinical courses), and Humanities (Arts, Language, Religion courses).
Table A2 shows the number of unique schools in each country used in this analysis.
A4. Distance Information
We geo-code the location of hospitals and universities using addresses available, cross referencing four sources of
coordinates (Geopostcodes datasets purchased, Google geo-coding of address, geo-coding of institution name and
manual searches on search engines) and converging to a final dataset. We compute travel times using Google API
(travel times are not a function of time of day, that it, running the Google distance API at 11pm on a Sunday vs 9am
on a Monday yields the same result). Computation of distance is restricted to hospitals and universities in the same
county.
A5. Location Information
The source data on population density comes from CIESIN and is presented as average density within population
grids identified by the coordinates of the grid’s centroid. Population density is computed using ArGIS. We spatially
join hospital coordinates with centroid coordinates and (1) take the population density of the closest centroid (2)

19

compute the average population density of all centroids within 100km (3) compute the inverse distance weighted
population density of all centroids within 100km. Results are robust to using any one of these three measures.
Computation of distance is restricted to hospitals and universities in the same county.

APPENDIX B: ADDITIONAL RESULTS

Table B1 presents descriptive statistics on the range of regional- and grid-level location characteristics used in the
analysis.
Table B2 presents the Difference in means of grid-level location characteristics of the nearest joint M-B and standalone HUM schools to each hospital in our dataset.
Table B3 explores whether the relationship between hospital performance (as measured by clinical or managerial
quality) and distance to joint M-B school are being driven by school quality characteristics. We show our results are
robust to controlling for the age of the university or the ranking of the university in global league tables.
In Table B4 we bring the results of Tables 2, 3 and 4 together. Columns (1) through (3) use AMI mortality rates as
the dependent variable and regress this on the share of managers with an MBA type degree. We instrument share of
MBA with the distance to a joint M-B school embodying the idea that proximity increases the managerial skill
supply which in turn benefits hospital performance. If the only way that university proximity matters is through this
school supply this should identify the causal impact of managerial education on hospital performance. The negative
and significant effect in column (1) is consistent with a large causal effect. However, an important caveat is that the
exclusion restriction may not be valid. For example, if proximity enabled a hospital to receive other beneficial inputs
(executive education and consultancy that are not reflected in MBA share) this would violate the exclusion
restriction. Columns (4) through (6) of Table 6 repeat the specifications of the first three columns, but use
management practices as the dependent variable instead of AMI death rates. In column (7) and (8) we add distance
to stand-alone HUM schools as a control and as an instrument, respectively, while maintaining distance to joint M-B
as an instrument. There is a positive and significant coefficient on MBA share across all five columns. In column (9)
we perform a placebo test by removing distance to joint M-B schools and using solely distance to stand-alone HUM
schools as an instrument. As expected, the MBA share coefficient is no longer significant and turns negative.
Another caveat to these results is that the instruments are not strong. The F-statistics shown in the lower rows are
about 8 in the simplest specifications, but are much lower when we control for other covariates, especially
geographical controls in columns (3) and (6). The second stage coefficients also become much more imprecise in
these columns which is consistent with the weak instruments problem.
APPENDIX C: SAMPLING FRAME
C1. The Sampling Frame and Eligibility to Participate in the Management Survey
In every country the sampling frame for the management survey included all hospitals that (i) have an Orthopaedics
or Cardiology Department, (ii) provide acute care, (iii) have overnight beds. The source of this sampling frame by
country is shown in Table C1. Interviewers were each given a randomly selected list of hospitals from the sampling
frame. This should therefore be representative of the population of hospitals in the country. At hospitals, we either
interviewed the director of nursing, medical superintendent/nurse manager/administrator of specialty, that is, the
clinical service lead at the top of the speciality who is still involved in its management on a daily basis. The clinical
service leads also had to be in the post for at least one year at the time of the interview.
Table C2 shows the number of healthcare facilities in each country, the number of eligible hospitals randomly drawn
the sampling frame, and hospital characteristics from these eligible hospitals. For the countries where information is

20

available, the sample in Canada, France and the UK present the largest percentage of hospitals which are funded and
managed by government authorities (all above 60% with Canada reaching 99%), while the samples in Brazil and the
US have the lowest percentage (39% and 28%, respectively).
The median hospital size in the sample in France as measured by the number of hospital beds is by far the largest
(730) while the median hospital in the sample in Italy, Germany, the UK and Sweden are of similar size (between
195 and 269 beds). The US and Canada samples present the smallest sized hospitals.
C2. The Survey Response Rates
Table C3 shows the survey response rates by country. The top table represents all hospitals in the randomly selected
list of hospitals given to the interviewers as described above. The bottom table represents all hospitals eligible for
the interview. The eligibility criteria were confirmed by the interviewer during the process of contacting and
scheduling the interview. As the type of healthcare facilities included in the lists sourced in each country varied
substantially, interviewers spent significant time on the phone screening out ineligible hospitals. For example,
interviewers identified 78% of hospitals to be ineligible for the survey in Brazil while in France this number is down
to 16%. This is one of the main reasons for a lower average of hospital interviews conducted per day in comparison
to the average for our manufacturing interviews (2.8 per day).
In terms of interviews completed, we managed to obtain a response rate ranging from 66%, 53% and 49% of eligible
hospitals in Sweden, Germany, and Brazil, to 21% of eligible hospitals in the US. In contrast, the explicit refusal
rate was generally low across all countries surveyed, ranging from no refusals in hospitals in Sweden to 22% of all
eligible hospitals in Germany. The high response rate in general was due to greater persistence in following up nonrespondents in order to meet the target numbers we were aiming for and to the fact that most hospital managers
interviewed in these countries responded with a scheduled time and date soon after the first or second contact with
the interviewer.
“Scheduling in progress” indicates hospitals which have been contacted by an interviewer and which have not
refused to be interviewed (for example they may schedule an interview but cancel or postpone it or simply take more
time to respond). The high share of “scheduling in progress” schools was due to the need for interviewers to keep a
stock of between 100 to 300 hospitals to cycle though when trying to arrange interviews. Since interviewers only ran
an average of 1.1 interviews a day the majority of their time was spent trying to contact hospitals managers to
schedule future interviews.
The ratio of successful interviews to rejections (ignoring “scheduling in progress”) is above 1 in every country.
Hence, managers typically agreed to the survey proposition when interviewers were able to connect with them.
C3. Selection Analysis
Panel A of Table C4 analyses the probability of being interviewed. Within each country, we compare the responding
hospitals with those eligible hospitals in the sampling frame - including “interviews refused” and “scheduling in
progress” but removing “hospital not eligible” for the survey - against three types of selection bias: location
characteristics (income per capita, population size, population average years of education, share of population with a
high school degree, share of population with a college degree, average temperature, inverse distance to coast, oil
production per capital), size (number of hospital beds), ownership (whether the hospital is owned and managed by
government authorities).
Looking at the overall pattern of results, there are very few significant coefficients. The results from the pooled
sample show that only the coefficients for temperature and inverse distance to coast are significant (this is driven by
a few countries as opposed to being an overall trend). One noticeable exception is India where the results show that
hospitals with certain location characteristics are more likely to respond (hospitals in areas less populated, lower
share of population with high school, farther away to the coast, and with a larger number of ethnic groups).
Information on whether the hospital is owned and managed by government authorities and the number of hospital

21

beds is not available for all countries, nonetheless we check for any potential selection bias in the countries for
which we have this information. The results show that public hospitals are more likely to be interviewed, although
this is only significant in the US, and larger hospitals are more likely to be interviewed in Germany (significant at
the 1% level) and in Italy (significant at the 10% level).
To address selection concerns, we used the pooled regression in Column 1 of Table C4 (where data are available for
all countries) to construct sampling weights. We then plot our cross-country ranking using the estimated weights.
We found that the rankings across countries for the unweighted scores in Figure 1 were very robust when using this
alternative sample weighting scheme. Figure C1 below gives the equivalent of Figure 1 using the weights from
Table C4.

APPENDIX D: EXAMPLES OF HOSPITAL MANAGEMENT PRACTICE

United States
A typical US hospital has a set layout of patient flow which has been thought through and streamlined to be as
efficient as possible. If the hospital is spread over a set of floors, it has a dedicated patient elevator to avoid delays in
transporting patients. Diagnostic rooms, operation theatres and pharmacies are fairly close to each other by design,
though there is not much discussion to improve this pathway anymore. There is a certain level of standardization of
clinical processes across the hospital, with a set of "care models" or checklists which are to be followed by
physicians and nurses. The compliance with these is checked infrequently and through an audit once per quarter or
year.
For improvements to the hospital, suggestions are only followed up on if someone mentions it. The hospital has
some informal processes to collect staff feedback via suggestion boxes or an open-door policy for managers. With
respect to their staff, a hospital has fixed sets of staff, which are competent in their specific areas. Staff are not found
performing duties for which they are over-qualified for. Ward nurses are flexible, but there is no cross-ward
movement.
In terms of key performance indicators, a hospital mainly tracks patient satisfaction reports and some other
government indicators. The directors review the reports monthly, and clinical leaders are responsible for sharing this
data with lower level staff. While there is a process, there are no proactive visual cues in the wards or hallways. For
reviewing this data, the managers have a monthly meeting that all staff, care technicians and administration staff are
involved. Metrics regarding different aspects of the hospital management are reviewed, and while there is some
follow up plans drawn up, no clear responsible person, expectations or deadlines are assigned.
For overall targets, there is broad range of targets that include several different aspects, from clinical to operational
and financial. But these are seen as an overall mission rather than day-to-day goals. As a consequence, targets are
not well understood and shared at the lower level of the hospital. Generally, they are set by the regional government
and are not coherently shared with the various levels within the hospital. They usually have short-term and longterm components, with at least a 3-year plan that is loosely linked to the short-term targets. These targets are
challenging but not pushy for most departments. Hospital meets 70-80% of its targets. Not all departments have the
same difficulty of targets (for instance, surgery gets easier targets than cardiology), and while nurses are held
accountable
for
budget
targets,
doctors
are
not
held
responsible.
There are yearly appraisal conversations with staff. These try to detect development necessities or possibilities for
the staff, but there is no bonus system. Rewards are sometimes given in form of flowers or a voucher to a movie
theatre. For poor performers, this evaluation system triggers a training system when under-performance is identified.

22

If the person does not get “fixed” after training, a disciplinary process starts. However, the process can last years
and, if the person is eventually fired, the likelihood that he or she will be reinstated in the post is very high because
of pressures from the unions and the infinite bureaucratic procedures.
India
The typical hospital in India is spread over a set of floors, with diagnostic centers and the emergency room on the
ground floor, the Operation Theatres and post-op rooms on the first floor. General wards would usually be in the
floors above the OT, though there are usually a set of "deluxe" rooms in the same floor of the OT for higher-paying
patients. There is one elevator, which is shared, and a ramp in case the elevator fails. There is a general push for
standardization and a willingness to develop protocols to seek accreditation, though this is not fully implemented
yet. There is usually a basic lab certification, and an ISO certificate for very basic processes (i.e. are the basic
procedures and infrastructure to carry out the operations of the hospital?). Checklists are not used. There is a patient
history file, but processes are not thoroughly documented. Monitoring of these processes are done by ad-hoc peerchecking and not through a set procedure.
Nurses are trained in a particular department and then rotated every six months. They are cross-trained, and any staff
movement is coordinated by the matron. There is no documentation of skills, and only the matron would know who
could be allocated where based on her experience.
Performance is generally not tracked, apart from patient satisfaction surveys. The average hospital will sometimes
track infection rates and occupancy rates, but not in a systematic manner and nothing beyond this. Whatever is
tracked, is normally done on a monthly basis. Managers have monthly meetings to review the state of the hospital,
but there is not much data to review. Conversations revolve around issues that happened in the month, any problems
that arose, and they record the minutes of the meeting which are shared only with the attendees. The heads of
department are then expected to share the information with other staff, though this is not checked or followed up on.
Overall hospital targets are very vague and not quantitative, such as "we would like to improve our specialty" or "we
aim to get more equipment." There are no financial or operational targets. Since there are no targets, there is not a
general concept of short-term or long-term targets, interconnection or difficulty of targets.
There is a yearly appraisal system, mostly done by observation of work, and it is not well defined in terms of
quantifiable parameters. For instance, there is not a specific attendance rate that is expected or measured. The
evaluation is based on more qualitative perceptions, such as "does the person do their job well" (without a clear
measure of what "well" means). There is an increment to salary if the appraisal goes "well," but bonuses are not
based on performance. Promotions are based on tenure first, and then, among the set of most senior people,
performance is taken into account. There are no opportunities for professional development beyond sending people
to courses and conferences, which are not frequent (once per year at most). Poor performers are dealt with through a
3-step process of verbal warning, written warning followed by termination. This usually takes at most one month,
and if the problem is not fixed their employment is terminated.

23

Figure 1: Management practices across countries

3.0

United States

3.1
2.8

United Kingdom

3.0
2.7

Sweden

3.1
2.6

Germany

2.8
2.5

Canada

2.6
2.5

Italy

2.3
2.4

France

2.3
2.2

Brazil

2.0

1.5

Average

1.9

India

1.8

1.7

1.9

Average with controls

2.1
2.3
2.5
2.7
2.9
Management practices score

3.1

3.3

Notes: The number of observations in each country is as follows: Brazil = 286, Canada = 174, France = 147, Germany
= 124, India = 490, Italy= 154, Sweden = 43, United Kingdom = 235, and United States = 307. Controls include
hospital characteristics - log of the number of hospital beds, dummies for private for profit and non for profit - and noise
controls -interviewee seniority, tenure, department (orthopeadics, surgery, Cardiology, or other), and type (nurse, doctor, or
non-clinical manager), year and duration of the interview, an indicator of the reliability of the information as coded by the
interviewer, and 55 interviewer dummies .

24

Figure 2: Management practices within countries
2 UK

3 Sweden

4 Germany

5 Canada

6 Italy

7 France

8 Brazil

9 India

0 .5 1 1.5 2

0 .5 1 1.5 2

0 .5 1 1.5 2

1 US

1

2

3

4

5

1

2

3

4

5

1

2

3

4

5

Management practices score
Graphs by Country
Notes: The number of observations in each country is as follows: Brazil = 286, Canada = 174, France = 147, Germany =
124, India = 490, Italy= 154, Sweden = 43, United Kingdom = 235, and United States = 307 .

25

Less than 2−hour
difference for 82%
of hospitals

Additional time to
joint M−B schools
Additional time to
stand−alone HUM

0

200

# of hospitals
400
600

800

1000

Figure 3: Driving time difference between placebo and IV

−8 −7 −6 −5 −4 −3 −2 −1 0
1
2
3
4
5
6
7
8
Driving time difference in hours between stand−alone HUM and joint M−B schools
Notes: 1,960 observations. Driving time difference capped at 8 hours.

26

Figure 4: Driving hours between hospital location and nearest school

Density
.5
0

0

Density
.5

1

B school, no M

1

Joint M−B school

0

1

2

3

4

5

6

7

8

0

1

3

4

5

6

7

8

7

8

Density
.5
0

0

Density
.5

1

No M−B school

1

M school, no B

2

0

1

2

3

4

5

6

7

8

0

1

2

3

4

5

6

Driving hours from hospital to nearest school (15min bins)
Notes: 1,960 observations. Joint M-B school offers both business and medical courses. B school, no M offers business but
no medical courses. M school, no B offers medical but no business courses. No M-B school offers neither types of courses.
Figure excludes hospitals with driving hours longer than 8 hours for presentation purposes (Number excluded: Top-left panel
= 13, Top-right panel = 20, Bottom-left panel = 25, Bottom-right panel = 17) .

27

0

1

Density
2

3

4

Figure 5: Share of hospital managers with a MBA-type course

0

.2
.4
.6
.8
Share of managers with MBA−type courses (.10 bins)

Notes: 1,960 observations.

28

1

Figure 6: Share of managers with MBA-type course and driving hours to nearest school

.4
.3
.1

.2

.3

.4

Stand−Alone HUM schools

.2
.1

Share of Managers with MBA−type course

Joint M−B schools

Unconditional correlation: −.085 (p−level: 0.00)

−4

−2

0

2

4

Unconditional correlation: −.028 (p−level: 0.21)

−4

−2

0

2

4

6

Driving hours from hospital to nearest school (15min bins), controls added
Notes: Mean of share of managers with MBA-type courses and travel time in 15 minute bins. Controls include general
controls - interviewee seniority, tenure, department (Orthopeadics, Surgery, Cardiology, or Other), and type (Nurse, Doctor,
or non-clinical Manager), year and duration of the interview, an indicator of the reliability of the information as coded by the
interviewer, and 55 interviewer dummies, and geographic controls at the regional level - log of income per capita, years
of education, share of population with high school degree, share of population with college degree, population, temperature,
inverse distance to coast, log of oil production per capita, log of number of ethnic groups. Excludes 31 hospitals with driving
hours longer than 5 hours. Weighted markers represent the number of hospitals in each bin. Unconditional correlation with
full-sample of 1,960 observations at the bottom or each panel.

29

Table 1: Descriptive statistics

Management Quality and Performance
Management
Measures of Managerial Skills
Share of managers with MBA-type course
Hospital Characteristics
Hospital beds
# of competitors: 0
# of competitors: 1 to 5
# of competitors: more than 5
Dummy public
Dummy private for profit
Dummy private not for profit
Distances to Universities
Driving hrs, nearest joint M-B schools
Driving distance (km) to nearest joint M-B schools
Driving hrs, nearest B school, no M
Driving hrs, nearest M school, no B
Driving hrs, nearest school, no M or B
Driving hrs, nearest stand-alone humanities school
Driving hrs, nearest university in general

30

mean

p50

sd

min

max

count

2.42

2.40

(0.65)

1.0

4.3

1960

0.26

0.15

(0.29)

0.0

1.0

1960

270.39
0.14
0.61
0.24
0.51
0.30
0.19

133.00
0.00
1.00
0.00
1.00
0.00
0.00

(365.40)
(0.35)
(0.49)
(0.43)
(0.50)
(0.46)
(0.39)

6.0
0.0
0.0
0.0
0.0
0.0
0.0

4000.0
1.0
1.0
1.0
1.0
1.0
1.0

1959
1955
1955
1955
1960
1960
1960

1.16
80.28
1.46
1.47
1.24
1.86
0.62

0.65
36.59
0.86
0.89
0.71
1.14
0.32

(1.84)
(135.39)
(2.16)
(2.19)
(2.06)
(2.42)
(1.47)

0.0
0.0
0.0
0.0
0.0
0.0
0.0

41.8
2842.4
44.4
44.4
44.4
44.4
41.8

1960
1960
1960
1960
1960
1960
1960

Table 2: Hospital management is strongly correlated with health outcomes

Dependent variable:
Z(Mgmt)

(1)
Z(AMI)

(2)
Z(AMI)

(3)
Z(AMI)

(4)
Z(AMI)

(5)
Z(AMI)

-0.188***
(0.055)

-0.223***
(0.067)
-0.041
(0.081)
-0.129
(0.209)
-0.340**
(0.147)
Y
Y

-0.203***
(0.065)
-0.035
(0.084)
-0.089
(0.213)
-0.256*
(0.140)
Y
Y
Y

-0.204***
(0.071)
-0.093
(0.090)
0.000
(0.272)
-0.224
(0.145)
Y
Y
Y

-0.203***
(0.066)
-0.047
(0.082)
-0.027
(0.214)
-0.199
(0.143)
Y
Y

Ln(Hospital beds)
Dummy private for profit
Dummy private not for profit
General controls
Hospital characteristics
Geographic controls - Regional level
Geographic controls - Grid level
Observations
No of clusters
Fixed effects
R-squared

Y
478
397
country
0.02

478
397
country
0.17

478
397
country
0.20

478
397
region
0.34

478
397
country
0.19

Notes: * p < 0.1, ** p < 0.05, *** p < 0.01. All columns estimated by OLS. Standard errors clustered by hospital network in
parentheses. Dependent variable Z(AMI) refers to a pooled measure of country-specific acute myocardial infarction mortality
rates (measures are standardized by country and year of survey). General controls include interviewee seniority, tenure, department (orthopeadics, surgery, Cardiology, or other), and type (nurse, doctor, or non-clinical manager), year and duration of the
interview, an indicator of the reliability of the information as coded by the interviewer, and 55 interviewer dummies. Hospital
characteristics include number of competitors constructed from the response to the survey question on number of competitors,
and is coded as zero for none (16% of responses), 1 for “less than 5" (59% of responses), and 2 for “5 or more" (25% of responses), and log of share of managers with a clinical degrees. Geographic controls - Regional level include log of income
per capita, years of education, share of population with high school degree, share of population with college degree, population,
temperature, inverse distance to coast, log of oil production per capita, log of number of ethnic groups. Geographic controls Grid level include log of gross product per capita, 2005 USD at market exchange rates, log of gross product per capita, 2005
USD at pp exchange rates, 2005, distance to major navigable river, distance to ice-free ocean, average precipitation, average
temperature, and elevation. Whenever one of these two sets of geographic controls are added, hospital latitude, hospital longitude and population density within 100km radius is also added.

31

Table 3: Is management education driving hospital management?
Main Specification
Dependent variable:

(1)
Z(Mgmt)

Ln(% of managers with MBA-type course)

Robustness

(2)
Z(Mgmt)

(3)
Z(Mgmt)

(4)
Z(Mgmt)

(5)
Z(Mgmt)

(6)
Z(Mgmt)

(7)
Z(Mgmt)

(8)
Z(Mgmt)

(9)
Z(Mgmt)

0.878***
(0.086)

0.676***
(0.085)
0.180***
(0.017)

0.629***
(0.085)
0.198***
(0.017)
0.283***
(0.056)
0.263***
(0.050)

0.625***
(0.085)
0.193***
(0.017)
0.269***
(0.056)
0.256***
(0.050)
0.049*
(0.026)

0.630***
(0.084)
0.192***
(0.017)
0.271***
(0.056)
0.260***
(0.050)
0.052*
(0.026)
0.189**
(0.092)

Y

Y

Y

Y

Y

0.613***
(0.084)
0.186***
(0.017)
0.277***
(0.055)
0.233***
(0.052)
0.030
(0.028)
0.165*
(0.091)
0.002
(0.005)
0.003
(0.002)
0.029*
(0.018)
Y
Y

0.597***
(0.084)
0.183***
(0.017)
0.258***
(0.056)
0.237***
(0.051)
0.030
(0.028)
0.169*
(0.091)
-0.003
(0.004)
0.005***
(0.002)
0.032**
(0.016)
Y

0.611***
(0.089)
0.177***
(0.019)
0.223***
(0.059)
0.174***
(0.055)
0.034
(0.030)
0.220**
(0.096)
-0.010
(0.014)
-0.004
(0.007)
0.045**
(0.023)
Y

Y

Y

1960
1869
country
0.63

1960
1869
region
0.67

Ln(Hospital beds)
Dummy private for profit
Dummy private not for profit
Number of Competitors
Ln(% of managers with clinical degree)

32

Hospital latitude
Hospital longitude
Ln(Population density within 100km radius)
General controls
Geographic controls - Regional level
Geographic controls - Grid level
Observations
No of clusters
Fixed effects
R-squared

Y

1960
1869
country
0.55

1960
1869
country
0.58

1960
1869
country
0.60

1960
1869
country
0.61

1960
1869
country
0.61

1960
1869
country
0.62

1960
1869
country
0.63

Notes: * p < 0.1, ** p < 0.05, *** p < 0.01. All columns estimated by OLS. Standard errors clustered by hospital network in parentheses. Dependent variable Z(Mgmt) refers to the hospital’s
z-score of management (the z-score of the average z-scores of the 20 management questions). General controls include interviewee seniority, tenure, department (orthopeadics, surgery, Cardiology, or other), and type (nurse, doctor, or non-clinical manager), year and duration of the interview, an indicator of the reliability of the information as coded by the interviewer, and 55 interviewer
dummies. Geographic controls - Regional level include log of income per capita, years of education, share of population with high school degree, share of population with college degree, population, temperature, inverse distance to coast, log of oil production per capita, log of number of ethnic groups. Geographic controls - Grid level include log of gross product per capita, 2005
USD at market exchange rates, log of gross product per capita, 2005 USD at pp exchange rates, 2005, distance to major navigable river, distance to ice-free ocean, average precipitation, average
temperature, and elevation. Whenever one of these two sets of geographic controls are added, hospital latitude, hospital longitude and population density within 100km radius is also added.

Table 4: Hospital health outcomes and distance to nearest schools
Main Specification
Dependent variable:
Ln(Driving hrs, nearest school)iiiiiiiiiiiiiiiiiiiiiiiiiii

(1)
Z(AMI)

(2)
Z(AMI)

(3)
Z(AMI)

0.226
(0.208)

0.035
(0.232)

0.038
(0.234)

Ln(Driving hrs, nearest joint M-B schools)
Ln(Driving hrs, nearest school, no M, B, HUM)
Ln(Driving hrs, nearest stand-alone HUM)

Robustness

(4)
Z(AMI)

(5)
Z(AMI)

(6)
Z(AMI)

(7)
Z(AMI)

(8)
Z(AMI)

(9)
Z(AMI)

0.393**
(0.160)
0.072
(0.159)
-0.196
(0.173)

0.358**
(0.163)

0.344**
(0.154)

0.482**
(0.214)

0.210*
(0.111)

0.284*
(0.164)

-0.026
(0.215)
-0.035
(0.176)
-0.003
(0.219)
Y
Y

-0.023
(0.105)
0.090
(0.093)
-0.065
(0.085)

0.097
(0.184)
-0.018
(0.146)
-0.088
(0.159)

Y
Y

Y
Y

478
397
region

2034
1071

1175
212
network

0.12
0.10

0.14
0.41

0.47
0.16

1.00
0.37

0.72
0.09

0.90
0.36

Ln(Driving hrs, nearest B school, no M)
Ln(Driving hrs, nearest M school, no B)

33

Ln(Driving hrs, nearest school, no M or B)
General controls
Hospital characteristics
Geographic controls - Regional level
Geographic controls - Grid level
Observations
No of clusters
Fixed effects
Test of Equality: Joint M-B = HUM
Test of Equality: Joint M-B = B, no M
Test of Equality: Joint M-B = M, no B
Test of Joint Sig.: HUM, no M-B-HUM
Test of Joint Sig.: B, M, No B-M
R-squared

Y

Y
Y

Y
Y
Y

Robustness - US

Y
Y
Y

0.066
(0.156)
0.075
(0.162)
-0.180
(0.194)
Y
Y
Y

Y
Y
Y

Y
478
397
country

478
397
country

478
397
country

478
397
country
0.03

478
397
country

478
397
country

0.20
0.28
0.47
0.12

0.15

0.19

0.20

0.72
0.20

0.20

Notes: * p < 0.1, ** p < 0.05, *** p < 0.01. All columns estimated by OLS. Standard errors clustered by hospital network in parentheses. Dependent variable Z(AMI) refers to a pooled
measure of country-specific acute myocardial infarction mortality rates (measures are standardized by country and year of survey). General controls include interviewee seniority, tenure,
department (orthopeadics, surgery, cardiology, or other), and type (nurse, doctor, or non-clinical manager), year and duration of the interview, an indicator of the reliability of the information as coded by the interviewer, and 55 interviewer dummies. Hospital characteristics include log of the number of hospital beds, dummies for private for profit and non for profit,
and number of competitors constructed from the response to the survey question on number of competitors, and is coded as zero for none (16% of responses), 1 for “less than 5" (59% of
responses), and 2 for “5 or more" (25% of responses). Geographic controls - Regional level include log of income per capita, years of education, share of population with high school
degree, share of population with college degree, population, temperature, inverse distance to coast, log of oil production per capita, log of number of ethnic groups. Geographic controls
- Grid level include log of gross product per capita, 2005 USD at market exchange rates, log of gross product per capita, 2005 USD at pp exchange rates, 2005, distance to major navigable river, distance to ice-free ocean, average precipitation, average temperature, and elevation. Whenever one of these two sets of geographic controls are added, hospital latitude, hospital
longitude and population density within 100km radius is also added.

Table 5: Hospital management and distance to nearest schools
Main Specification
Dependent variable:
Ln(Driving hrs, nearest school)iiiiiiiiiiiiiiiiiiiiiiiiiii

(1)
Z(Mgmt)

(2)
Z(Mgmt)

(3)
Z(Mgmt)

-0.339***
(0.046)

-0.139***
(0.045)

-0.080
(0.049)

Ln(Driving hrs, nearest joint M-B schools)
Ln(Driving hrs, nearest school, no M, B, HUM)
Ln(Driving hrs, nearest stand-alone HUM)

Robustness

(4)
Z(Mgmt)

(5)
Z(Mgmt)

(6)
Z(Mgmt)

(7)
Z(Mgmt)

-0.112**
(0.044)
-0.054
(0.042)
-0.019
(0.039)

-0.107**
(0.044)

-0.145***
(0.038)

-0.128**
(0.051)

Ln(Driving hrs, nearest B school, no M)
Ln(Driving hrs, nearest M school, no B)

34

Ln(Driving hrs, nearest school, no M or B)
General controls
Hospital characteristics
Geographic controls - Regional level
Geographic controls - Grid level
Observations
No of clusters
Fixed effects
Test of Equality: Joint M-B = HUM
Test of Equality: Joint M-B = B, no M
Test of Equality: Joint M-B = M, no B
Test of Joint Sig.: HUM, no M-B-HUM
Test of Joint Sig.: B, M, No B-M
R-squared

Y

Y
Y

Y
Y
Y

Y
Y
Y

0.001
(0.041)
-0.034
(0.043)
-0.053
(0.045)
Y
Y
Y

Y
Y
Y

-0.002
(0.049)
-0.010
(0.049)
-0.072
(0.052)
Y
Y
Y

1960
1869
country

1960
1869
country

1960
1869
country

1960
1869
country
0.16

1960
1869
country

1960
1869
country

0.09
0.25

1960
1869
region
0.09
0.11

0.28
0.56

0.60

0.61

0.61

0.39
0.61

0.61

0.52
0.66

Notes: * p < 0.1, ** p < 0.05, *** p < 0.01. All columns estimated by OLS. Standard errors clustered by hospital network in parentheses. Dependent variable Z(Mgmt)
refers to the hospital’s z-score of management (the z-score of the average z-scores of the 20 management questions).General controls include interviewee seniority, tenure,
department (orthopeadics, surgery, cardiology, or other), and type (nurse, doctor, or non-clinical manager), year and duration of the interview, an indicator of the reliability
of the information as coded by the interviewer, and 55 interviewer dummies. Hospital characteristics include log of the number of hospital beds, dummies for private for
profit and non for profit, and number of competitors constructed from the response to the survey question on number of competitors, and is coded as zero for none (16% of
responses), 1 for “less than 5" (59% of responses), and 2 for “5 or more" (25% of responses). Geographic controls - Regional level include log of income per capita, years
of education, share of population with high school degree, share of population with college degree, population, temperature, inverse distance to coast, log of oil production
per capita, log of number of ethnic groups. Geographic controls - Grid level include log of gross product per capita, 2005 USD at market exchange rates, log of gross product per capita, 2005 USD at pp exchange rates, 2005, distance to major navigable river, distance to ice-free ocean, average precipitation, average temperature, and elevation.
Whenever one of these two sets of geographic controls are added, hospital latitude, hospital longitude and population density within 100km radius is also added.

Table 6: Share of MBA-type education and distance to schools
Main Specification
Dependent variable:
Ln(Driving hrs, nearest school)iiiiiiiiiiiiiiiiiiiiiiiiiii

(1)
Ln(MBA)

(2)
Ln(MBA)

(3)
Ln(MBA)

-0.063***
(0.016)

-0.023
(0.017)

-0.004
(0.016)

Ln(Driving hrs, nearest joint M-B schools)
Ln(Driving hrs, nearest school, no M, B, HUM)
Ln(Driving hrs, nearest stand-alone HUM)

Robustness

(4)
Ln(MBA)

(5)
Ln(MBA)

(6)
Ln(MBA)

(7)
Ln(MBA)

-0.028*
(0.014)
-0.002
(0.013)
0.014
(0.011)

-0.030**
(0.015)

-0.023*
(0.013)

-0.031*
(0.017)

Ln(Driving hrs, nearest B school, no M)
Ln(Driving hrs, nearest M school, no B)

35

Ln(Driving hrs, nearest school, no M or B)
General controls
Hospital characteristics
Geographic controls - Regional level
Geographic controls - Grid level
Observations
No of clusters
Fixed effects
Test of Equality: Joint M-B = HUM
Test of Equality: Joint M-B = B, no M
Test of Equality: Joint M-B = M, no B
Test of Joint Sig.: HUM, no M-B-HUM
Test of Joint Sig.: B, M, No B-M
R-squared

Y

Y
Y

Y
Y
Y

Y
Y
Y

0.016
(0.013)
-0.019
(0.012)
0.016
(0.013)
Y
Y
Y

Y
Y
Y

0.014
(0.016)
-0.033**
(0.015)
0.008
(0.016)
Y
Y
Y

1960
1869
country

1960
1869
country

1960
1869
country

1960
1869
country
0.04

1960
1869
country

1960
1869
country

0.03
0.62

1960
1869
region
0.07
0.91

0.48
0.23

0.27

0.28

0.29

0.19
0.29

0.28

0.17
0.37

Notes: * p < 0.1, ** p < 0.05, *** p < 0.01. All columns estimated by OLS. Standard errors clustered by hospital network in parentheses. Dependent variable Ln(MBA) refers
to the log of the share of hospital managers with a MBA-type course. General controls include interviewee seniority, tenure, department (orthopeadics, surgery, cardiology, or
other), and type (nurse, doctor, or non-clinical manager), year and duration of the interview, an indicator of the reliability of the information as coded by the interviewer, and 55
interviewer dummies. Hospital characteristics include log of the number of hospital beds, dummies for private for profit and non for profit, and number of competitors constructed from the response to the survey question on number of competitors, and is coded as zero for none (16% of responses), 1 for “less than 5" (59% of responses), and 2 for
“5 or more" (25% of responses). Geographic controls - Regional level include log of income per capita, years of education, share of population with high school degree, share
of population with college degree, population, temperature, inverse distance to coast, log of oil production per capita, log of number of ethnic groups. Geographic controls Grid level include log of gross product per capita, 2005 USD at market exchange rates, log of gross product per capita, 2005 USD at pp exchange rates, 2005, distance to major
navigable river, distance to ice-free ocean, average precipitation, average temperature, and elevation. Whenever one of these two sets of geographic controls are added, hospital
latitude, hospital longitude and population density within 100km radius is also added.

Table A1: List of management practices

Operations Management
Topic
Q1. Layout of Patient Flow

Q2. Rationale for Introducing Standardisation/ Pathway Management
Q3. Standardisation and Protocols
Q4. Good Use of Human Resources

Description:
Measures how well the patient pathway is configured at the infrastructure level and whether staff proactively improve their own work-place
organization
Measures the motivation and impetus behind changes to operations and
what change story was communicated
Measures whether there are standardised procedures (e.g. integrated
clinical pathways) that are applied and monitored systematically
Measures whether staff are deployed to do what they are best qualified
for, but nevertheless help out elsewhere when needed

Performance Monitoring
Topic
Q5. Continuous Improvement

Q6. Performance Tracking
Q7. Performance Review
Q8. Performance Dialogue
Q9. Consequence Management

Description:
Measures how well the patient pathway is configured at the infrastructure level and whether staff proactively improve their own work-place
organization
Measures whether hospital performance is tracked using meaningful
metrics and with appropriate regularity
Measures whether hospital performance is reviewed with appropriate
frequency and communicated to staff
Measures the quality of hospital performance review conversations
Measures whether differing levels of hospital performance (not personal
but plan/ process based) lead to different consequence

Target Setting
Topic
Q10. Target Balance
Q11. Target Interconnection
Q12. Time Horizon of Targets
Q13. Target Stretch
Q14. Clarity and Comparability of
Targets

Description:
Measures whether targets cover a sufficiently broad set of metrics
Measures whether targets are tied to hospital objectives and how well
they cascade down the organisation
Measures whether hospital has a ‘3 horizons’ approach to planning and
targets
Measures whether targets are appropriately difficult to achieve
Measures how easily understandable performance measures are and
whether performance is openly communicated

People Management
Topic
Q15. Rewarding High Performers
Q16. Fixing Poor Performers
Q17. Promoting High Performers
Q18. Managing Talent
Q19. Retaining Talent
Q20. Creating a Distinctive Employee
Value Proposition

Description:
Measures whether good performance is rewarded proportionately
Measures whether the hospital is able to deal with underperformers
Measures whether promotions and career progression are based on performance
Measures what emphasis is put on talent management
Measures whether the hospital will go out of its way to keep its top
talent
Measures how strong employee value proposition is to work in the individual hospital

Notes: Detailed survey instrument available at www.worldmanagementsurvey.org

36

Table A2: Number of unique universities used in each country

Brazil
Canada
France
Germany
India
Italy
Sweden
United Kingdom
United States
Total

(1)
Joint M-B
Schools

(2)
M, no B
Schools

(3)
B, no M
Schools

(4)
No M nor B
Schools

(5)
Stand-alone
HUM
Schools

(6)
Universities
in general

120
57
40
47
121
13
12
63
235
708

127
39
59
60
113
17
6
27
204
652

198
35
23
32
55
41
7
29
165
585

225
49
64
66
90
29
8
26
180
737

146
47
28
53
40
12
10
21
156
513

244
78
92
94
208
64
20
100
276
1176

37

Table B1: Descriptive statistics

Geographic Characteristics
Hospital latitude
Hospital longitude
Population density within 100km radius
Geographic Characteristics - Regional level
Ln(Income per capita), regional
Years of education, regional
Share of pop with high school degree, regional
Share of pop with college degree, regional
Population, regional
Temperature, regional
Inverse distance to coast, regional
Ln(Oil production per capita), regional
Ln(# of ethnic groups), regional
Geographic Characteristics - Grid level
Gross prod. p.c, 2005 USD at market xrt, 2005
Gross prod. p.c, 2005 USD at ppp xrt, 2005
Distance to major navigable river (km)
Distance to ice-free ocean (km)
Average precipitation
Average temperature
Elevation

mean

p50

sd

min

max

count

30.39
-8.48
956.46

40.79
-0.17
450.01

(24.40)
(63.16)
(1552.22)

-32.0
-157.8
0.2

68.4
94.9
12667.0

1960
1960
1960

9.58
7.51
0.31
0.18
16.14
14.89
0.84
0.09
1.10

10.23
9.53
0.29
0.16
16.03
12.38
0.87
0.00
1.10

(1.13)
(10.55)
(0.20)
(0.12)
(1.38)
(8.62)
(0.14)
(0.32)
(0.80)

6.6
-99.0
0.0
0.0
10.3
-12.2
0.5
0.0
0.0

11.0
12.8
0.7
0.5
19.0
28.3
1.0
4.2
3.0

1960
1960
1960
1960
1960
1960
1960
1960
1960

1.87
2.11
879422.83
314802.57
1101.90
15.05
401.15

2.26
2.52
537973.40
154694.60
1009.80
12.73
280.70

(1.52)
(1.50)
(833327.76)
(371156.10)
(422.77)
(8.16)
(437.14)

0.0
0.0
2821.7
312.1
92.1
-9.2
1.8

8.0
9.4
4030517.0
1804279.0
3495.1
28.9
4731.4

1957
1957
1958
1958
1960
1899
1960

38

Table B2: Difference in means of location characteristics of the nearest joint M-B and stand-alone HUM schools to each hospital

Population density within 100km radius
Latitude
Longitude
Gross product per capita, 2005 USD at market exchange rates, 2005
Gross product per capita, 2005 USD at market exchange rates, 1990
Gross product per capita, 2005 USD at ppp exchange rates, 2005
Gross product per capita, 2005 USD at ppp exchange rates, 1990
Distance to major navigable river (km)
Distance to ice-free ocean (km)
Average precipitation
Average temperature
Elevation

Humanities
Schools
Mean
978.18
25.55
-41.18
2.21
1.75
2.46
1.95
683143.98
383102.62
1198.19
13.52
473.68

Medicine & Business
Schools
Mean
1105.39
30.06
-30.27
2.21
1.73
2.40
1.88
756754.61
375410.09
1159.67
12.36
437.22

Diff in
means

T Stat

127.20
4.51**
10.91**
-0.01
-0.02
-0.05
-0.07
73610.62
-7692.54
-38.52
-1.16
-36.46

1.34
2.95
3.25
-0.08
-0.32
-0.61
-1.01
1.92
-0.34
-1.37
-1.40
-1.21

Humanities
Schools
N
534
534
534
532
532
532
532
534
534
534
534
534

Medicine & Business
Schools
N
725
726
726
724
724
724
724
724
724
726
726
726

39

Table B3: Is the performance-distance to university relationship being driven by university characteristics?

Dependent variable:
Ln(D-hrs to joint M-B)

(1)
Z(Mgmt)
-0.189***
(0.035)

Log(Age of joint M-B)

(2)
Z(Mgmt)
-0.142***
(0.038)
0.048***
(0.017)

Global QS Rank Dummy for joint M-B
General controls
Hospital characteristics
Geographic controls - Regional level
Observations
No of clusters
R-squared

Y
Y
1960
1869
0.61

Y
Y
Y
1960
1869
0.62

(3)
Z(Mgmt)
-0.143***
(0.038)

0.080*
(0.044)
Y
Y
Y
1960
1869
0.61

(4)
Z(Mgmt)
-0.141***
(0.038)
0.042**
(0.020)
0.033
(0.051)
Y
Y
Y
1960
1869
0.62

(5)
Z(AMI)
0.376**
(0.157)

Y
Y
478
397
0.16

(6)
Z(AMI)
0.334**
(0.155)
0.068
(0.085)

Y
Y
Y
478
397
0.20

(7)
Z(AMI)
0.352**
(0.155)

0.160
(0.170)
Y
Y
Y
478
397
0.20

(8)
Z(AMI)
0.342**
(0.157)
0.045
(0.090)
0.131
(0.180)
Y
Y
Y
478
397
0.20

Notes: * p < 0.1, ** p < 0.05, *** p < 0.01. Standard errors clustered by hospital network in parentheses. Dependent variable Z(AMI) refers to a pooled measure of

40

country-specific acute myocardial infarction mortality rates (measures are standardized by country and year of survey. Dependent variable Z(Mgmt) refers to the hospital’s
z-score of management (the z-score of the average z-scores of the 20 management questions). Age of joint M-B refers to the age of the university hosting both business
and medical schools in the year the hospital survey was conducted in each country. Global QS Rank Dummy equals to 1 if the university hosting both business and
medical schools was mentioned in the Quacquarelli Symonds World University Ranking in 2011. General controls are 55 interviewer dummies, the seniority and tenure
of the manager who responded, the duration of the interview, and an indicator of the reliability of the information as coded by the interviewer, interviewee type (nurse,
doctor or non clinical manager). Hospital characteristics refers to the log of the number of hospital beds, dummies for private for profit and non for profit, and number
of competitors (hospitals within a 30-minute drive). Geographic controls - Regional level include log of income per capita, years of education, share of population with
high school degree, share of population with college degree, population, temperature, inverse distance to coast, log of oil production per capita, log of number of ethnic
groups. Hospital latitude, hospital longitude and population density within 100km radius is also added.

Table B4: The effects of MBA-trained managers on hospital management
2nd Stage in Top Panel, 1st Stage in Bottom Panel
Dependent variable:
Endogenous Variable: xxxxxxxxxx
Ln(% of managers with MBA-type course)

Ln(Driving hrs, nearest joint M-B schools)

Placebo

(1)
Z(AMI)

(2)
Z(AMI)

(3)
Z(AMI)

(4)
Z(Mgmt)

(5)
Z(Mgmt)

(6)
Z(Mgmt)

(7)
Z(Mgmt)

(8)
Z(Mgmt)

(9)
Z(Mgmt)

(10)
Z(Mgmt)

-6.082***
(2.355)

-8.052*
(4.759)

-13.833
(14.491)

5.050***
(1.020)

5.090***
(1.827)

6.346*
(3.600)

4.548**
(2.313)

3.775*
(1.984)

-17.076
(42.620)

4.707**
(1.957)

x(1)xxx

x(1)xxx

x(1)xxx

x(1)xxx

x(1)xxx

x(1)xxx

x(1)xxx

x(1)xxx

-0.074***
(0.026)

-0.047*
(0.028)

-0.025
(0.029)

-0.062***
(0.012)

-0.037***
(0.013)

-0.023*
(0.013)

-0.029**
(0.014)
0.013
(0.011)
Y
Y
Y

-0.029**
(0.014)
0.013
(0.011)
Y
Y
Y

Ln(Driving hrs, nearest stand-alone HUM)

41

General controls
Hospital characteristics
Geographic controls - Regional level
Geographic controls - Grid level
Observations
No of clusters
Fixed effects
First stage F-stat
Placebo added as

Robustness

Y

Y
Y

Y
Y
Y

Y

Y
Y

Y
Y
Y

x(1)xxx

x(1)xxx
-0.035**
(0.014)

0.004
(0.011)
Y
Y
Y

Y
Y
Y

478
397
country
7.90

478
397
country
2.82

478
397
country
0.72

1960
1869
country
24.90

1960
1869
country
8.42

1960
1869
country
3.14

1960
1869
country
4.39
control

1960
1869
country
2.33
instrument

1960
1869
country
0.17
instrument

1960
1869
region
6.09

Notes: * p < 0.1, ** p < 0.05, *** p < 0.01. Standard errors clustered by hospital network in parentheses. Dependent variable Z(AMI) refers to a pooled measure of country-specific acute myocardial infarction
mortality rates (measures are standardized by country and year of survey). Dependent variable Z(Mgmt) refers to the hospital’s z-score of management (the z-score of the average z-scores of the 20 management questions). General controls are 55 interviewer dummies, the seniority and tenure of the manager who responded, the duration of the interview, and an indicator of the reliability of the information as
coded by the interviewer, interviewee type (nurse, doctor or non clinical manager). Geographic controls - Regional level include log of income per capita, years of education, share of population with high
school degree, share of population with college degree, population, temperature, inverse distance to coast, log of oil production per capita, log of number of ethnic groups. Geographic controls - Grid level
include log of gross product per capita, 2005 USD at market exchange rates, log of gross product per capita, 2005 USD at pp exchange rates, 2005, distance to major navigable river, distance to ice-free ocean,
average precipitation, average temperature, and elevation. Whenever one of these two sets of geographic controls are added, hospital latitude, hospital longitude and population density within 100km radius is
also added. Other hospital drivers refers to the log of the number of hospital beds, dummies for private for profit and non for profit, and number of competitors (hospitals within a 30-minute drive).

Figure C1: Management practices across countries corrected for sampling response rates

United States

3.0

United Kingdom

2.8

Sweden

2.7

Germany

2.6

Canada

2.5

Italy

2.5

France

2.4

Brazil

2.2

India
1.5

1.9

1.7

1.9

2.1
2.3
2.5
2.7
2.9
Management practices score

3.1

3.3

Notes: Average management score using sample weights constructed from the sample selection model in Column 1 of Table
C4. The number of observations in each country is as follows: Brazil = 286, Canada = 174, France = 147, Germany = 124,
India = 490, Italy= 154, Sweden = 43, United Kingdom = 235, and United States = 307. .

42

Table C1: Sampling frame sources

Country
Brazil
Canada
India

Source
National Registry of Health Facilities (Cadastro nacional de estabelecimentos de saúde).
Scott’s Directories (https://secure.scottsdirectories.com/)
The hospital sampling frame was constructed using several online sources.
• National Accreditation Board for Hospitals and
(http://www.nabh.co/main/hospitals/accredited.asp)

Healthcare

Providers

(NABH)

• Medicards.in (https://www.medicards.in/)
• Hospital Khoj (http://www.hospitalkhoj.com/general.htm)
• Cite HR (http://www.citehr.com/110771-all-india-hospitals-adresses-contact-nos.html)
• Hospitals in India (http://www.hospitalsinindia.org/)

Italy
France
Germany
Sweden
US
UK

The process used to construct the sampling frame was the following. First, we extracted hospital
names, contact info and all other info available from these five sources. This yielded a total of 15,431
entries. Second, we appended all lists and remove duplicate entries and ineligible hospitals using
(i) exact match with hospital name and (ii) exact match with state and city, (iii) and dropping hospitals containing the following words in the name (acupuncture, advanced glaucoma, plastic, ENT
research foundation, neuro, mental, maternity, maternity, cosmetic, child care, ENT, communicable
diseases, bone and joint, day care, clinic of integrated medicine, diabetes, integrated organ transplant,
reproductive, poly clinic, polyclinic, community hospital, surgical clinic, physiotheraphy, nursing, digestive, diabetic, leprosy, scanning, laproscopic, micro surgery). This yielded a total of 7,191 entries.
This number is in agreement with statistics from the Ministry of Health reporting that 7,008 rural and
urban hospitals exist in India (http://cbhidghs.nic.in/hia2005/8.01.htm)
Ministry of Health (Ministero della Sanita’)
Federation Hospitaliere de France
Hospital directory acquired separately for each state
Sveriges Kommuner och Landsting (Swedish Association of Local Authorities and Regions)
American Hospital Association
National Health Service and Private Healthcare UK

43

Table C2: Sampling frame characteristics

Healthcare facilities (N)
Eligible hospitals in random sample (N)
Public hospitals in eligible random sample (%)
Beds in eligible random sample (median)

BR

CA

DE

FR

IN

IT

SE

UK

US

5861
591
39

902
527
99
45

1559
553

3926
292
86
730

3831
1309

1572
376

153
85

269

197

1219
483
61
195

6388
1526
28
110

238

Notes: BR=Brazil, CA=Canada, DE=Germany, FR=France, IN=India, IT=Italy, SE=Sweden, UK=United Kingdom, US=United States. Sampling frame is the total number of hospitals eligible for the survey drawn from a random sample of hospitals from the universe of healthcare
facilities in the country. Public Hospitals refers to the percentage of hospitals which are funded and managed by government authorities. This
information is not available for Germany, India, Italy, and Sweden. Beds is the median number of beds in the hospital. This information is not
available for Brazil and India.

44

Table C3: Survey response rates

Interviews completed (%)
Scheduling in progress (%)
Interviews refused (%)
Hospital not eligible (%)
Sample, all (N)

Interviews completed (%)
Scheduling in progress (%)
Interviews refused (%)
Sample, eligible (N)
Interviews completed (N)

All Hospitals in Random Sample
DE
FR
IN
IT
SE

BR

CA

10.73
9.58
1.63
78.06
2694

24.61
45.4
4.53
25.46
707

BR

CA

48.9
43.65
7.45
591

33.02
60.91
6.07
527

23.51
53.89
22.6
553

53.42
37.67
8.9
292

37.66
42.02
20.32
1309

44.15
50.27
5.59
376

289

174

130

156

493

166

19.4
44.48
18.66
17.46
670

44.96
31.7
7.49
15.85
347

12.87
14.36
6.94
65.83
3831

30.18
34.36
3.82
31.64
550

UK

US

20.18
30.6
2.77
46.45
902

16.7
57.78
4.18
21.34
1940

UK

US

65.88
34.12
0
85

37.68
57.14
5.18
483

21.23
73.46
5.31
1526

56

182

324

41.18
21.32
0
37.5
136

Eligible Hospitals in Random Sample
DE
FR
IN
IT
SE

Notes: BR=Brazil, CA=Canada, DE=Germany, FR=France, IN=India, IT=Italy, SE=Sweden, UK=United Kingdom, US=United
States. 1) Interviews completed reports all the hospitals contacted for which a management interview was completed. 2) Scheduling in progress reports all the hospitals contacted with no interview run or manager refusing to be interviewed. 3) Interviews
refused reports all hospitals contacted in which the manager refused to take part in the interview. 4) No longer eligible reports
all hospitals contacted which do not have an Orthopeadics or Cardiology Department, do not provide acute care, and do not have
overnight beds. It also included organizations out-of business or for which no phone number was found. Sample, all is the total
number of hospitals that were randomly selected and contacted from the complete sampling frame. Sample, eligible is the total
number of hospitals that were randomly selected, contacted from the complete sampling frame, and eligible for the survey.

45

Table C4: Selection analysis

Dependent variable:
Ln(Income per capita)
Population
Years of education
Share of pop with high school degree
Temperature
Inverse distance to coast
Ln(# of ethnic groups)

(1)
Interview
-0.022
(0.090)
0.035
(0.023)
-0.042
(0.048)
0.239
(0.733)
-0.025***
(0.008)
-0.287*
(0.166)
0.012
(0.033)

46

Public Hospital

(2)
Interview
0.410
(0.589)
0.066
(0.073)
-0.006
(0.365)
-4.474
(9.182)
-0.050
(0.054)
-0.396
(0.908)
0.008
(0.107)
0.059
(0.114)

Ln(# of Hospital Beds)
Observations
Sample

5742
ALL

591
BR

(3)
Interview
0.318
(0.611)
-0.026
(0.101)
0.062
(0.407)
-3.390
(8.408)
-0.003
(0.041)
1.315
(0.992)
0.106
(0.237)
-0.654
(0.473)
0.032
(0.052)
526
CA

(4)
Interview
-1.000
(0.714)
0.378***
(0.144)
0.121
(0.232)
-6.654
(4.444)
-0.280
(0.224)
0.849
(1.513)
-0.185
(0.166)

0.185***
(0.069)
553
DE

(5)
Interview
-1.715
(1.406)
0.468
(0.306)
0.363
(0.347)
0.725
(3.684)
0.140
(0.108)
-0.788
(1.940)
0.056
(0.240)
0.186
(0.220)

292
FR

(6)
Interview
-0.134
(0.197)
-0.171**
(0.084)
0.080
(0.119)
-7.106**
(2.855)
-0.047
(0.036)
-1.152***
(0.422)
0.203*
(0.120)

(7)
Interview
0.697
(0.627)
0.170
(0.169)
0.039
(1.559)
-5.292
(20.402)
-0.166
(0.104)
13.259**
(5.825)
0.007
(0.227)

(8)
Interview
1.361
(2.589)
-2.187
(5.514)
5.131
(12.106)
102.795
(124.026)
1.274
(2.855)
33.055
(22.453)
2.130
(4.048)

1288
IN

0.133*
(0.070)
375
IT

-0.019
(0.148)
85
SW

(9)
Interview
2.482
(1.600)
-0.420
(0.302)
-0.391
(0.424)
20.042*
(10.569)
0.074
(0.178)
-1.692
(7.519)
0.296
(0.377)
0.054
(0.208)
0.080
(0.068)
448
UK

(10)
Interview
-0.813*
(0.448)
0.100*
(0.055)
0.185
(0.212)
0.031
(1.640)
-0.025*
(0.013)
0.029
(0.318)
0.033
(0.062)
0.789***
(0.082)
-0.027
(0.036)
1434
US

Notes: Estimate by Probit ML (marginal effects reported with robust standard errors in parentheses). The dependent variable Interview equals to 1 if hospital has been interviewed. BR=Brazil, CA=Canada,
DE=Germany, FR=France, IN=India, IT=Italy, SE=Sweden, UK=United Kingdom, US=United States.

