NBER WORKING PAPER SERIES

INCREASING COMMUNITY COLLEGE COMPLETION RATES
AMONG LOW-INCOME STUDENTS:
EVIDENCE FROM A RANDOMIZED CONTROLLED TRIAL EVALUATION
OF A CASE MANAGEMENT INTERVENTION
William N. Evans
Melissa S. Kearney
Brendan C. Perry
James X. Sullivan
Working Paper 24150
http://www.nber.org/papers/w24150

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
December 2017

We are indebted to Erin Byrne and Luke Horvath for their project and research support and we
gratefully acknowledge the research assistance of Sreeraahul Kancherla, Fernando Saltiel, and
Tim Seida. The paper has benefitted from comments from Susan Dynarski, Josh Goodman,
Jonathon Guryan, Judy Hellerstein, Brad Hershbein, Isaac McFarlin, Lesley Turner, Marci
Ybarra, and seminar participants at the University of Wisconsin, IRP Summer Workshop,
University of Notre Dame, the NBER's Education Program, the IFS/CEP Joint Conference :
Wages, Labour Market Policy and the Safety Net, the DC Economics of Education working
group, and at the APPAM Fall Research Conference. We are grateful to our research partners at
Catholic Charities Fort Worth and Tarrant County College. This study was registered in the
American Economic Association’s RCT Registry under ID AEARCTR-0000223. This research
was financially supported by funding from the Wilson Sheehan Lab for Economic Opportunities
at Notre Dame, the Fischer Family Foundation, the Abdul Latif Jameel Poverty Action Lab, and
NIH Grant #1R21HD081399-01A1. The views expressed herein are those of the authors and do
not necessarily reflect the views of the National Bureau of Economic Research.
NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.
© 2017 by William N. Evans, Melissa S. Kearney, Brendan C. Perry, and James X. Sullivan. All
rights reserved. Short sections of text, not to exceed two paragraphs, may be quoted without
explicit permission provided that full credit, including © notice, is given to the source.

Increasing Community College Completion Rates among Low-Income Students: Evidence
from a Randomized Controlled Trial Evaluation of a Case Management Intervention
William N. Evans, Melissa S. Kearney, Brendan C. Perry, and James X. Sullivan
NBER Working Paper No. 24150
December 2017
JEL No. I23,I3
ABSTRACT
Community colleges are an important part of the higher education landscape in the United States,
but completion rates are extremely low, especially among low-income students. Much of the
existing policy and research attention to this issue has focused on addressing academic and
financial challenges. However, there is ample reason to think that non-academic obstacles might
be key drivers of dropout rates for students living with the burden of poverty. This study
examines the impact of a comprehensive case management intervention that is designed
specifically to help low-income students overcome the multitude of barriers to college
completion. We evaluate the impact of this intervention through a randomized controlled trial
evaluation (RCT) conducted between 2013 and 2016 in Fort Worth, Texas. Eligible students were
randomly assigned to a treatment group that was offered comprehensive case management,
including emergency financial assistance (EFA), a separate treatment group offered only EFA, or
a control group. Data from school administrative records indicate that the comprehensive case
management program significantly increases persistence and degree completion, especially for
women. Estimates for the full sample are imprecise, but the estimates for women imply that the
case management intervention tripled associate degree receipt (31 percentage point increase).We
find no difference in outcomes between the EFA-only treatment arm and the control group. A
back-of-the-envelope calculation using average earnings gains associated with community
college completion implies that program benefits exceed program costs ($5,640 per student for
three year program) after only 4.25 years in the workforce post schooling.
William N. Evans
Keough-Hesburgh Professor of Economics
Department of Economics
University of Notre Dame
3111 Jenkins Nanovic Halls
Notre Dame, IN 46556-7000
and NBER
wevans1@nd.edu
Melissa S. Kearney
Department of Economics
University of Maryland
3105 Tydings Hall
College Park, MD 20742
and NBER
kearney@econ.umd.edu

Brendan C. Perry
Wilson Sheehan Lab for Economic Opportunities
3104 Jenkins Nanovic Halls
University of Notre Dame
Notre Dame, IN 45630
bperry3@nd.edu
James X. Sullivan
Department of Economics
3108 Jenkins Nanovic Halls
University of Notre Dame
Notre Dame, IN 46556
James.X.Sullivan.197@nd.edu

I.

INTRODUCTION
Community college is a crucial component of the United States’ education system, offering

millions of students the opportunity to earn a low-cost, two-year associate’s degree, gain career and
technical credentials, or embark on a path to a four-year institution. Low tuition rates and open-access
policies at community colleges make them accessible to students who might face significant barriers to
attending four-year selective schools. Federal grants and loans mean that many low-income students
are paying little if any out-of-pocket for a community college education.1 Nearly half of all
undergraduate students in the U.S. in 2014-15 were enrolled in a two-year institution (U.S. Department
of Education, 2016) and half of all bachelor’s recipients were at one point enrolled at a community
college before transferring to a four-year institution (National Student Clearinghouse (NSC) Research
Center, 2017). Many studies find employment and earnings benefits associated with community college
degree completion and credits earned (e.g., Kane and Rouse, 1995; Marcotte et al., 2005; Jepsen et al.,
2014; Stevens et al., 2015). A recent estimate suggests that for the cohort of students who attended
college in the mid-2000s, an associate’s degree yields an earnings premium of about 30 percent over a
high school degree (Marcotte, 2016).
Despite low tuition costs and the expected economic returns, a large fraction of community
college students drop out before earning a credential or degree. The National Student Clearinghouse
(2017) notes that among students who first enrolled full-time at a two-year public institution in 2010,
nearly 42 percent had not received any degree or were no longer enrolled in school six-years later. Many
observers argue that there is a “completion crisis” at all type of colleges. The NSC estimates that of
students that started at four-year public and private institutions in 2010, only 59 and 72 percent have
bachelor’s degrees after six years. The President of Arizona State University recently noted that “…the

Data from the 2011/12 National Postsecondary Student Aid Study indicates that 38 percent of community college
students have zero out of pocket expenses for tuition and fees.
https://www.usnews.com/news/articles/2015/02/17/how-many-already-attend-community-college-for-free

1

1

discussion of a debt crisis often fails to address what I would argue is the greater crisis: the fact that
more than half of those who start college fail to finish.”2 Likewise, Deming (2017) argues that the key
policy issue is college completion rather than college attendance. Not completing can be financially
crippling for a community college student as they incur debt but do not obtain a degree. Although only
40 percent of community college students acquire education-related debt,3 90 percent of community
college students who have defaulted on debt left college with no degree or certificate.4
The completion crisis is occurring at a time when a greater share of students are going to
college.5 The high dropout numbers might be driven in part by the fact that less prepared, lower
income students are now more likely to attend college, and these students tend to drop out at much
higher rates (Baum and Scott-Clayton, 2013). A likely culprit, especially for low-income community
college students, is that many of these students face a wide range of challenges, beyond academic
preparation issues, that they are not necessarily able to overcome. Given that community college
students tend to be financially independent and older, financial and family issues frequently arise and
pose challenges to staying in school.6 These problems include balancing work and school, finding
appropriate and affordable day care, and dealing with shocks that occur during the school year. In
addition, many students report having trouble navigating the complex community college system,
particularly first generation college students and new immigrants who may have limited knowledge
about how colleges function (Bailey, Jenkins, and Leinbach, 2005; Scott-Clayton, 2011). Students might
also lack the necessary commitment and/or planning and time management skills necessary to set out a
https://president.asu.edu/node/2241
https://trends.collegeboard.org/sites/default/files/trends-in-community-colleges-research-brief.pdf
4 https://www.insidehighered.com/news/2015/09/28/four-surprising-findings-debt-and-default-among-communitycollege-students
5 Using data from the 1 Percent Census PUMS from 1980 through 2000 and the 2010 and 2015 American Communities
Survey, the fraction of those aged 25-29 who have ever attended college or is currently attending college is the following
(year, percent); 1980, 50.1 percent; 1990, 55.1 percent; 2000, 60.3 percent; 2010, 64.3 percent; 2015, 67.3 percent.
6 Survey evidence from Johnson et al. (2011) suggests that the leading self-reported reason why students drop out of college
is a need to work full time (71 percent). Another common reason reported was not having enough time to spend with family
(41 percent.) The reason that ranked the lowest was “some classes were too difficult” (10 percent reported this as a primary
reason and an additional 24 percent noted it as a secondary reason.) The survey is based on telephone interviews conducted
in 2009 with 614 young adults aged 22 to 30 years old who have experience with some post-secondary education.
2
3

2

path to graduation and stay committed to that plan. Students who lack clear goals and a genuine
understanding of why college is important often become derailed by relatively minor challenges and
setbacks (Grubb, 2006).
Postsecondary institutions are unfortunately not always set up to handle this collection of
problems.7 Deming (2017) puts it succinctly: “less-selective public institutions often have large classes
and provide little in the way of academic counseling, mentoring, and other student supports (page 6.)”
Bound, Lovenheim, and Turner (2010) find that shifts in the types of institutions students attend
toward lower-ranked, public schools along with declines in institutional resources per student are more
important than shifts in student characteristics in explaining the decline in college completion rates
between the 1970s and 1990s. Deming and Walters (2017) compare the impact of changes in tuition
and changes in spending on enrollment and degree completion in US public postsecondary institutions
between 1990 and 2013. Their analysis finds that spending increases are more effective per-dollar than
price cuts in terms of increasing completion rates. This finding is consistent with a view that
institutional resources are a critical component to driving student completion rates. It is also the case
that over recent decades, colleges and universities have experienced declining state appropriations
alongside rising enrollment, leading to fewer resources per student.
In this paper, we report the results from a randomized controlled trial (RCT) investigation of a
comprehensive case management intervention that was designed to help low-income students
overcome the myriad obstacles that might threaten their persistence in community college. The
program, Stay the Course (STC), offers case management services provided by a social service agency that
are substantially more intensive than what community college academic counselors tend to provide.
Each STC student is paired with a trained social worker, called a navigator, who offers students

In their book “Making College Work,” Holzer and Baum (2017) outline a number of institutional weaknesses that might
hinder the success of disadvantaged students attending public universities and community colleges and they discuss a
number of possible policy and programmatic remedies.

7

3

coaching, mentoring, and referral services. Navigators work with students to help them overcome their
individual barriers to college completion such as finding affordable child care, selecting courses that
keep them on track towards graduation, making decisions about transferring to four-year colleges, and
locating social services in the community. In addition, students in the STC program have access to
limited emergency financial assistance (EFA) that can be used for non-academic expenses that could
negatively impact their persistence in college.
The RCT demonstration was rolled out in the fall of 2013 at the Trinity River Campus of
Tarrant County College (TCC) in Fort Worth, Texas. Eligible students were randomly assigned to one
of two treatment groups or a control group. Treatment group 1 was offered the full STC
comprehensive case management treatment including referrals, mentoring, coaching, and access to
EFA; treatment group 2 was offered access to EFA only; and the control group received no special
services. We use administrative records to track academic outcomes for study participants for three
years post random assignment. We find no difference in outcomes between the EFA-only treatment
group and the control group.
The results indicate that the full STC comprehensive case management program significantly
increased persistence and degree completion through six semesters, especially for female students.
Estimated effects are imprecise for the full sample, but intention-to-treat estimates for females show a
7.4 percentage point (3.3 percentage point standard error) increase in the likelihood of earning an
associate’s degree off a control group mean of 15.7 percent. This translates into a treatment-on-thetreated effect of 31.5 percentage points (14.1 percentage point standard error). Based on the estimated
earnings premium for individuals with community college credentials, we estimate that the earnings
gains associated with the program (for the full sample) exceed program costs in just over four years.
The completion crisis has led to a number of interventions designed to increase college
persistence and completion rates and this paper contributes to this literature. One group of studies
include interventions designed to address the issue of academic under-preparation among community
4

college students,8 generally with disappointing results (Long, 2014; Martorell and McFarlin, 2011). An
evaluation of the Bottom Line intervention, a long-term college advising program offered to lowincome students beginning in high school, found positive effects on early college persistence. While
Bottom Line provides some social supports, such as helping students acclimate to college, the
intervention focuses on advising students, the bulk of whom attend 4-year college, through the college
and financial aid application process and offering some academic advising while in college (Barr &
Castleman, 2017). More closely related to our paper, there are a number of well-designed studies
investigating whether enhanced student support services and/or mentoring can lead to improved
educational outcomes for college students. The evidence is mixed. Two of the sites that were part of
MDRC’s “Opening Doors” demonstration project focused on enhanced student services. Students
were given two semesters of access to counselors with much smaller caseloads than the traditional
caseload of 1000 students per counselor. The evaluation found no improvements in ultimate academic
outcomes (Scrivener and Weiss, 2009). Angrist, Lang, and Oreopoulos (2009) found that first-year
female students (but not males) at a large 4-year public school in Canada demonstrated improved
academic outcomes in terms of GPA and credits earned when they had access to peer advising and
organized study groups as part of the Project STAR intervention, but only when those services were
combined with merit-based financial incentives. Bettinger and Baker (2014) found that college students
randomly assigned to student coaches with the InsideTrack program have higher persistence and
completion rates, but this program did not focus on low-income students or a community college
setting.
The most promising results to date have been found for the comprehensive Accelerated Study
in Associates Program (ASAP) at the City University of New York, which offered tuition waivers,

About 60 percent of students entering community college are referred to at least one remedial education class (Bailey,
2009; Attewell et al., 2006). Community colleges devote upwards of $2 billion annually towards these developmental
education programs (Strong American Schools, 2008).

8

5

enhanced student services, and special course offerings, among other innovations. The evaluation
found that this three-year program nearly doubled graduation rates (Scrivener et al., 2015). It should be
noted that this program is multi-faceted and extremely expensive, which raises questions about how
readily such a program might be replicated in other settings. Our study complements this existing work
by investigating whether a comprehensive case management program delivered by a social service
provider, as opposed to a school counselor, can lead to increased completion rates for very low income
students in a community college.
As a policy matter, the federal government spends billions of dollars a year subsidizing
community college attendance. In 2015, the Pell Grant program provided $30 billion in aid for lowincome individuals to attend college. More than a third of Pell recipients attend community college
(Baime and Mullin, 2011). States and local governments often provide financial aid and need-based
scholarships as well. Identifying successful ways to better realize the potential of the community college
investment, both for the students themselves and for society more generally, is of paramount research
and policy importance.9
II. THE “STAY THE COURSE” INTERVENTION
Stay the Course is a comprehensive case management intervention that was designed by Catholic
Charities Fort Worth (CCFW) to help low-income community college students address personal
obstacles so they can persist in school and complete their intended degree. CCFW is a large nonprofit
social service provider with a mission to improve outcomes for low-income families and individuals.
They provide services to over 100,000 unduplicated clients each year.

Improving persistence in community college was an explicit priority of the Obama administration, which launched the
American Graduation Initiative with a goal of producing 5 million more community college graduates by 2020.
http://www.whitehouse.gov/blog/Investing-in-Education-The-American-Graduation-Initiative.

9

6

A. Features of the intervention
Upon enrollment in STC, a student is assigned to a trained social worker called a “navigator”
who serves as their case manager. The navigator meets with the student initially to conduct a client
assessment that identifies the client’s long-term goals, likely barriers to these goals, and their strengths
and weaknesses. The student and navigator then collaboratively develop and implement a
comprehensive service plan that sets out the steps necessary for the student to accomplish their
educational goals. The service plan is tailored to devise intermediate goals for the student to accomplish
along the way, discuss the action steps necessary to accomplish these goals within established
timeframes, and address potential barriers through a range of available services. Action steps are
developed for each specified goal in the service plan. For example, if a participant has a goal of earning
a grade of at least a “B” in a specific course, the action steps for that goal might include attending all
classes for the course or meeting once a week with a tutor. The service plan is reviewed and updated
every 90 days. The construction of the service plan is a time-consuming but important process in that
it helps build trust between the navigator and the client. The service provider’s view is that for case
management to work students must feel comfortable coming to the navigator to help solve intimate
and personal problems, e.g., domestic violence, substance abuse, mental illness, etc.
Participation in the program involves comprehensive case management services for the student
on an ongoing basis. There are four main components to these services: referrals, mentoring, coaching,
and emergency financial assistance. The navigators refer STC participants to a variety of resources
within the TCC system such as access to tutors, financial aid, etc., as well as to external resources
outside the college such as employment and child-care services, health services, government programs
and benefits such as SNAP, and other social services (Ybarra, 2016).10 Mentoring involves the process

As part of the RCT evaluation, we collaborated with an independent, qualitative researcher to conduct an implementation
study of Stay the Course at the Trinity River Campus, which is available as Ybarra (2016). This study drew from interviews of
STC staff in the spring of 2015 and 60 hours of observations of all aspects of STC staff work in the fall of 2015, about two
years after the launch of the evaluation.
10

7

of navigators developing a personal relationship of trust with each of their student clients. This sort of
personal relationship is likely different from the typical relationship that academic advisors at
community colleges have with their students, as college advisors tend to have caseloads that are in the
hundreds or thousands of students (as compared to 34 for STC navigators) and have a different
professional orientation toward educational and academic counseling, as opposed to social work. To
establish this mentoring relationship, navigators encourage open communication and build trust so that
students are engaged in the program and they continue to seek the navigator’s advice on educational
and personal issues that affect their progress in school.
In the coaching component of comprehensive case management, the navigator and student
have ongoing meetings to work on resolving unforeseen problems that might threaten the ability of the
student to complete their degree. Students might encounter situations along many dimensions that
could derail their education, such as problems with housing, child-care arrangements, transportation, or
work schedules. Students are encouraged from the outset to meet with their navigator for help
addressing such circumstances. The thought behind the implementing agency’s approach is that the
stronger is the trust between the navigator and the student, the more likely it is that the student will
come to the navigator to discuss personal issues that might inhibit success in school. Another feature of
the coaching component is helping students navigate the community college system. Navigators remind
students to register for the necessary and appropriate classes. Depending on student need, navigators
may also assist students in finding campus-provided tutors and help students avail themselves of
campus-provided services.
The implementing agency emphasizes that personal interactions, as opposed to emails or phone
calls, are at the heart of their approach to comprehensive case management. Program guidelines
recommend that navigators and students meet in person at least once per month.11 However, case notes

At the launch of the study in fall 2013 there were no explicit benchmarks in place requiring navigators to meet with
students a certain number of times per week or month. The frequency of meetings was at the discretion of the navigator and
11

8

data reveal that the frequency of in-person interactions varied widely. Table 1 reports summary statistics
of all navigator/student interactions as reported in the navigator case notes. On average, navigators
interacted with their clients about 34 times each semester. About half of these interactions were via text
or email and about a third were over the phone. There were an average of 4.1 in-person meetings per
semester, with a typical duration of 41 minutes. The frequency and type of navigator-student
interactions did not differ noticeably by gender.
Figure 1 shows the frequency of discussion topics covered during navigator-student interactions
based on these electronic case notes. We include as navigator-student interactions in-person meetings,
phone calls, or individualized emails/texts, but not mass communication such as group emails or
administrative reminders. Academic discussion topics such as class registration and gaining access to
tutors were the most popular; they were discussed in over a third of the interactions between navigators
and students. Ten of the next 11 most frequent topics have little to do with academics but rather, are
aspects about the student’s life outside of school, such as work, transportation, health, child care, etc.
Work/employment issues were discussed in nearly a quarter of all interactions, which is consistent with
the evidence that this issue is one that often leads low-income students to drop out of community
college (Johnson et al., 2011). Students discussed referrals to other specialized service programs in
almost 17 percent of their interactions with their navigators. Housing, finances, and transportation were
each mentioned in at least 12 percent of interactions. The one other academic issue included among the
12 most frequent topics is transferring to a four-year college, which was discussed in 11 percent of
interactions.
The fourth component of comprehensive case management is access to emergency financial
assistance (EFA). Students in the STC program are eligible to apply for EFA for non-academic

student. In the spring of 2015, the program supervisor set explicit benchmarks for navigator-student interactions to ensure
fidelity of program implementation. These benchmarks included reciprocal contact (email, text, phone) at least once per
week, in-person meetings every two weeks, and completion of a service planning goal once every three weeks (Ybarra 2016).

9

expenses or income shortfalls that could negatively impact a student’s persistence in college. EFA is not
meant to constitute an academic grant or scholarship, but rather, to provide the buffer resources that a
low-income student might need to address personal issues and stay in school. The motivation for this
assistance is that for many low-income community college students, small negative shocks like a family
emergency, higher than expected child-care costs, a necessary vehicle repair, or not having a security
deposit for a new apartment, can sometimes have lasting impacts on academic outcomes. It is widely
recognized in other contexts many low-income families live perpetually on the brink of crisis and deep
hardship (Barr and Blank 2009; Shipler 2008). Bertrand et al., (2004) describe this aspect of poverty in
terms of some families having “narrow margins for error.” The EFA is designed to reduce the
vulnerability to negative shocks that many low-income families experience.
To receive EFA, students must successfully demonstrate both that they have an imminent
financial need and that not meeting this need would be detrimental to their academic progress.
Additional factors that determine whether the event would qualify for assistance include the extent to
which the event is foreseeable, controllable, and temporary. Examples of qualified costs include a car
repair, rent and utilities, a bus pass, or emergency medical care. Eligibility for EFA is restricted to those
students with a cumulative GPA of a 2.0 or higher at TCC (unless they are in their first semester) and
those enrolled in at least 9 credits the semester in which they apply. An individual student could apply
to receive up to $500 per semester, capped at $1,500 total over a three-year period. A program Funds
Coordinator makes determinations for all EFA applications, subject to a supervisor’s review.
Navigators may assist clients in completing the financial assistance application, but they do not attend
the student’s meeting with the Funds Coordinator nor do they intercede with the Funds Coordinator
on behalf of the student. This separation is designed to keep navigators from having to deny financial
assistance from their own clients.
Based on Funds Coordinator records, over a three-year period, students enrolled into the STC
treatment group (N = 94) submitted 126 requests for EFA, of which 82 percent were approved, with
10

an average payout of $276. As shown in Figure 2, 29 percent of the requests granted were for
transportation needs, 23 percent for housing, 33 percent for utilities, and 15 percent for other (school
supplies, child care, etc.). About half of the students in the program never applied for any funds, and
less than 10 percent of students collected more than $1,001 over the three-year period. After six
semesters, only one STC student had collected the max amount of $1,500.

B. Comparisons to similar interventions
STC differs from existing interventions designed to increase college completion. The STC
intervention differs from these other programs in several important ways. Table 2 facilitates a
comparison of features across programs by highlighting the key aspects of four other interventions
evaluated with RCTs alongside STC. We highlight a few unique characteristics of the STC case
management approach here. First, STC comprehensive case management services are more involved
and intensive than those typically available at community colleges, as well as those that have been
offered in previous demonstration projects.12 The services extend beyond academic counseling as
navigators work with each student to develop a personal relationship of trust and help them address
their unique social, financial, academic, and personal impediments to college success. Second, the case
management services provided by STC are provided by trained social workers working for a non-profit
agency outside the community college system. Third, the caseloads for STC navigators are much lower
than those of the typical community college guidance counselor, and are even considerably smaller than
those found in the other highlighted demonstration projects. Fourth, the STC case management
services also include access to emergency financial assistance for non-tuition financial impediments.13
By way of contrast, the coaching provided as part of the InsideTrack program is limited to
telephone-based coaching. Though coaches also work to help students overcome non-academic “real

12 A study conducted by the American College Counseling Association found that over half of community colleges have
counselor to student ratios between 1:1500 and 1:3500 (Gallagher, 2010).
13 Ultimately, our results suggest that providing EFA alone does not improve academic outcomes. However, this evidence
does not imply that EFA, offered as part of case management services, is ineffective.

11

life” barriers, it is unlikely that they develop the type of personal mentoring relationships that the STC
navigators work to build. The enhanced student counseling services implemented as part of the “Open
Doors” demonstration were short-term, limited to two semesters, and delivered by college counselors
who did not necessarily have the expertise in dealing with the non-academic issues that trained social
workers help clients address. The enhanced student services in the ASAP program were provided by
community college counselors, who may or may not have offered as much dedicated attention to life
barriers and outside referrals as the STC case managers, but more importantly, in the ASAP program,
those services are embedded in a much larger set of intervention features, including tuition waivers,
blocked classes, and special courses and registration access on campus.

III.

THE RANDOMIZED CONTROL TRIAL

A. The Research Design
To determine the impact of this comprehensive case management program on persistence and
degree completion, we implemented a randomized controlled trial (RCT) evaluation at Tarrant County
College (TCC), a large community college in Fort Worth, Texas enrolling more than 50,000 students in
associate degree and technical programs across five campuses. TCC students typically come from
disadvantaged backgrounds and have very high dropout rates. Among first-time, degree-seeking
students who entered in fall 2011, only 14.8 percent earned a degree in four years and only 2.6 percent
graduated in two years. The leadership at TCC is aware of this challenge and readily agreed to partner
with the research team and service provider on this intervention and evaluation. TCC provided
dedicated space for the navigators to meet privately with students and provided us with the necessary
administrative data to evaluate the program and to perform the randomization.

12

The universe for the sample consisted of the 8,849 students currently enrolled at the Trinity
River campus of TCC in the fall semester of 2013.14 The research demonstration project took place at a
single campus because it was more feasible for CCFW to implement this new intervention on a single
campus. RCT eligibility was limited to students who met the following criteria: 1) enrolled in at least 9
credit hours at TCC; 2) degree seeking; 3) age 18 years or older; 4) satisfied at least 1 Texas Success
Initiative (TSI) standard;15 5) newly enrolled or have earned a Cumulative GPA of at least 2.0 at TCC to
date; 6) accumulated less than 30 credit hours at TCC to date; and 7) Pell eligible or fall below 200% of
the poverty line (based on reported income on the FASFA). Eligibility criteria (1) through (5) are
intended to target students who may feasibly complete a degree in three years. The credit cap in
eligibility criteria (6) is meant to target students who might be at risk of dropping out; a student with
more than 30 credits is perceived to be successfully on a path to graduation. The final eligibility rule is
to target the sample to low-income students. Imposing these eligibility criteria left us with a final study
sample of 1,168 students.
Table 3 reports summary statistics on all community college students at the national and state
level, all TCC Trinity River Campus students, and finally, STC study participants. Overall, TCC
students are similar to other community college students around the nation, with the exception of TCC
enrolling considerably more Hispanic and part-time students. STC participants differ from typical TCC
students and the average community college student in a few important ways. STC students are more
likely to be female, and are on average more than two years younger than other TCC students. Students
in the study are much more likely to be full time when compared to the rest of the TCC campus and

14 The Trinity River campus, located in downtown Fort Worth, Texas, enrolls nearly 9,000 students each year. It offers
primarily Associate of Arts (AA) degrees, which requires 60 credit hours to complete. Some of the larger programs housed
at the Trinity River campus include Nursing, Surgical Technology, Physical Health Information Technology, Sign Language,
and Service Learning.
15 TCC students are given placement examines (TSIs) in three subjects: math, reading and writing. Failure to pass the TSI
in a subject means that a student starts their community college career in a remedial version of that subject.

13

much more likely to receive Pell grants when compared to the national average, differences driven by
the eligibility criteria described above.
At the close of the academic enrollment period on August 20, 2013, the Office of Institutional
Intelligence and Research (OIIR) at TCC extracted data necessary to identify the eligible sample (N =
1,168).16 The research team used these data to randomly assign eligible students into one of three
groups. The randomization procedure is displayed in Figure 3. 430 students were offered the STC
treatment, which included case management and EFA. Another 299 students were assigned to an
EFA-only treatment, while 439 students were assigned to a control group. Students in this final group
received no additional services, but still had full access to any existing college or community services,
just as they would in the absence of this intervention. The study includes two treatment arms to help
determine how much of the effectiveness of the fully implemented program could be achieved with
only the financial assistance feature.17 The EFA treatment group is smaller because the provider had
limited resources to provide this separate treatment arm.
After randomly assigning each eligible student to one of the three groups, the research team
notified TCC of the results and the college sent specific emails and letters by regular mail, signed by the
president of the college, to each student selected for the different treatment groups.18 These emails and
letters introduced the program and explained that the student had been randomly selected to
participate. TCC also sent a data file to CCFW containing student IDs, names and contact information.
In these communications, selected students were directed to a web page to electronically sign a consent
We have continued to enroll and randomize additional students into STC in more recent semesters, but this paper will
focus on the fall 2013 cohort, as this is the only group for which we currently have outcome data six semesters after
enrollment.
17 The EF-only treatment is most comparable to the “Dreamkeepers” program created by Scholarship America
(https://scholarshipamerica.org/dreamkeepers/). That program provides monetary assistance to students who face shortterm financial emergencies. A descriptive review conducted by MDRC examined the outcomes of recipients of
Dreamkeepers funds from 11 different schools in the 2004-2006 period and found that recipients have “disproportionate
need” and were “more academically challenged” than the average student, but their reenrollment rates were roughly
comparable to other students (Geckeler et al., 2008). Though the findings of that report are consistent with the notion that
limited financial assistance can promote persistence, the MDRC study was not an RCT, and the comparisons reported
should not be interpreted as indicative of a causal effect of the program.
18 Copies of these emails and letters are included in the appendix to the paper.
16

14

form for services and enroll in the program (http://www.staythecourse-cc.org/). Of the 430 students
offered the STC treatment, 94 students completed the intake process to enroll in STC a take-up rate of
22 percent. The EFA treatment group had 126 students enroll, reflecting a take-up rate of 42 percent.
The low take up rate of the program appears to have been a feature of the way the RCT was
rolled out. We randomly assigned a treatment/control group status to all eligible students and then
invited them via mailed letters and emails to visit a website and enroll.19 In the second phase of the
program, we reversed the order and invited all eligible students to visit a website and enroll, and then
after enrolling in the demonstration project, students were randomly assigned to a treatment or control
group. This reversed procedure led to a take-up rate of 87.3 percent. We thus do not view the low takeup rate in phase 1 to suggest that the program itself does not hold appeal to students. That said, it is
likely the case that a new program that is not familiar to students will have a lower take-up rate in early
years as compared to an established program with a reputation on campus as a legitimate source of
support. Importantly, these issues do not threaten the internal validity of the study in any way, but they
are relevant to considerations of how to most effectively roll out such a program and reach the
intended population of students.
Table 4 provides descriptive information about the students in the study for both treatment
groups and the control group for the fall of 2013. As shown by the p-values in columns 4 and 5, in all
cases the data fail to reject the hypothesis that the mean characteristics are the same, when comparing
either of the treatment groups to the control group, indicating that the randomization procedure
generated appropriate balance across groups.

B. Data and Methods
Our empirical analysis relies on student-level administrative school records provided to us from
TCC. A few months after the end of each semester, OIIR at TCC sent the research team a file

19

The college would not allow us to text students on mobile devices.

15

containing the student baseline characteristics that were used to determine eligibility, additional
characteristics used in the analyses, and academic outcomes. Through TCC we were able to link these
records to data from the National Student Clearinghouse (NSC), which allows us to observe whether a
student transfers to a two- or four-year college and completes a degree at another post-secondary
institution.20
The outcomes we consider include:


Enrolled in College: An indicator for whether a student was enrolled in classes at TCC or any
other NSC reporting institution at the start of the relevant semester, which is defined as spring
2016 in six-semester results, spring 2015 in four-semester results, and spring 2014 in twosemester results. For the two- and four-semester results, we will also look at enrollment at TCC
as a separate outcome as fewer students have transferred to a different college by that point.



Total Credits Earned: The cumulative number of college credits that a student has earned by
the end of the relevant semester. Because we only observe credits earned for students while
they are enrolled at TCC, we impute credits for students who are enrolled elsewhere using the
average credits earned by students in the study who are still enrolled at TCC in the current
semester.



Cumulative GPA: Cumulative TCC GPA by the end of the relevant semester.



Earned any Degree: An indicator for whether a student earned a degree (certificate,
associate’s, or bachelor’s) at TCC or any other NSC reporting institution by the end of the
relevant semester.

The National Student Clearinghouse is a nonprofit organization that works with more than 3,600 post-secondary
institutions to provide data on student enrollment and degree completion. The NSC participating colleges enroll 98% of all
post-secondary students in the U.S. (http://www.studentclearinghouse.org/about/).
20

16



Earned an Associate’s Degree: An indicator for whether a student earned an associate’s
degree at TCC or any other NSC reporting institution by the end of the relevant semester.21

Because we are utilizing random assignment, we measure the impact of STC by comparing
outcomes for students in the treatment and control groups. We estimate the differences in outcomes
using a standard intent-to-treat (ITT) model:
yi =β0 + Tiβ1 + Xiβ2 + εi

(1)

where yi is an indicator for one of our outcome measures for student i in the semester of interest, T
equals 1 if the respondent is in the relevant treatment group and zero otherwise, and i is an individuallevel error term that is assumed to be i.i.d. The vector Xi includes a set of person-level characteristics:
age, age squared, gender, whether a student is Black, Asian or a different race, whether the student is
Hispanic, the number of basics skills assessments the student has passed at entry, family income, and
family income squared from the student’s FASFA form. When measuring the effect of the full STC
intervention, the estimation sample includes the STC treatment group and the control group; it
excludes students in the EFA treatment group. When measuring the effect of EFA, the estimation
sample includes the EFA treatment group and the control group; it excludes students in STC treatment
group.
Our main results focus on outcome measures six semesters after enrollment in the study, but to
examine how any impact of the intervention changes over time, we also report some shorter-term
results. Because many students assigned to the treatment groups do not participate in services (the takeup rate was 22 percent for the STC treatment group and 42 percent for the EFA treatment group), we

While we also have data on whether a student has completed a certificate or a bachelor’s degree, we do not report these
outcomes separately because they occur infrequently—after 6 semesters less than 3 percent of the sample had obtained a
certificate, and just over 1 percent had obtained a BA degree.
21

17

also estimate the effect of the intervention for those who participate, or the treatment-on-the-treated
(TOT) effect. Specifically, we estimate:
yi =γ0 + Piγ1 + Xiγ2 + ηi

(2)

where Pi is an indicator for participation in the program. We estimate these effects via an instrumental
variable (IV) model, using assignment to treatment (Ti) as an instrument for participation in the
program (Pi). Program participation (or take-up) is defined as attending the intake meeting and
completing an intake form.

IV.

SIX SEMESTER RESULTS
Table 5 reports the six-semester results associated with the STC intervention. We report results

for the full sample, as well as separately by gender. For each outcome, we report both ITT and TOT
effects. As a benchmark for the magnitude of these effects, we report the mean of each outcome for
the control group in the ITT columns and the control complier mean (CCM) in the TOT columns. The
CCM is calculated as the mean of the outcome for the compliers (those who take-up the treatment) in
the treatment group less the IV estimate.22
STC has a large effect on persistence in school after six semesters, but the estimate is only
significant at the 10 percent level. The point estimate indicates that students in the treatment group are
5.6 percentage points more likely to be enrolled in school after six semesters. The TOT estimate
indicates that those who participate in STC are 25.1 percentage points more likely to persist, more than
double the CCM. For the full sample, all the other estimates are positive, indicating improved outcomes
for the treatment group, but none of these estimates are statistically significant.

22 For binary outcomes, sampling variation can produce negative estimates of the CCM. For these cases we report the CCM
as zero, following (Kling, Liebman, and Katz, 2007). To determine the nature of selection into take-up based on observable
characteristics, we examine the mean characteristics of treatment compliers and non-compliers respectively (Appendix Table
1). Students who take up the program tend to be slightly older, but overall the mean characteristics of compliers and noncompliers are very similar. We observe that those who take up the program have a slightly lower propensity score of earning
a degree ex ante, though the difference is not statistically significant.

18

The positive effect of STC is driven by females. Females assigned to the STC treatment group
are 8.4 percentage points more likely to still be enrolled in college after six semesters than females in
the control group, and this difference is statistically significant. The TOT estimate (35.8 percentage
points) indicates that female program participants were nearly four times more likely to persist in
college relative to the CCM. Through six semesters, we also see that females in the treatment group
have accumulated more total credits, although this effect is only marginally significant.
There is a large and statistically significant effect on completing an associate’s degree for
females. Three years after enrollment in the study, females in the treatment group are 7.4 percentage
points more likely to have completed an associate’s degree than females in the control group,
corresponding to a TOT effect of 31.5 percentage points. There is little evidence of a positive effect of
STC participation for male students, and at the 10% level, we can reject the hypothesis that the effect is
the same for females and males.
We also investigate whether there are heterogeneous treatment effects by other key student
characteristics. Table 6a reports results separately for white and non-white students and separately for
those with family income above and below the STC sample median ($18,500). Those in the STC
treatment group with family income greater than the median family income of the study sample are 8.3
percentage points (standard error 4.8) more likely to stay enrolled in classes anywhere through their
sixth semester (Table 6a, column 3), which implies a TOT effect of 44.1 percentage points. The ITT
estimate on this same outcome for students with lower levels of family income implies a much smaller,
2.4 percentage point increase (standard error 4.7). Given the standard errors, we cannot reject similar
effects across income groups.
The estimated effects for non-white students are generally similar to what we report for the full
sample in Table 5, which is not surprising given that about 70 percent of the sample is non-white. The
estimated TOT effect for non-white students implies a 31.8 percentage point increase in the likelihood
of being enrolled anywhere after six semesters (standard error 18.1). When we limit the sample to
19

whites, the estimated TOT estimate is very small (2.3 percentage points) but with a standard error ten
times that size. Given the large standard error associated with that estimate, we cannot reject the null
that there are similar effects by race.
In the first four columns of Table 6b, we report estimates based on whether students had more
or fewer initial credit hours than the median at enrollment (10 credit hours). Our motivation for
looking separately by credit hours was to observe whether students who were further along the
education process had a different treatment effect. Perhaps students with more credits when enrolled
may not need as much help because they were further along. Alternatively, these same students might
be more likely to be on the margin of completing a degree, and comprehensive case management
provides the critical support needed to graduate. Point estimates indicate large TOT effects for both
groups but neither are statistically significant. Overall, the data do not indicate any persistent
differences across students based on this simple cut of the data.
In the second half of the table, we consider whether results vary based on “outcome
propensity,” or the estimated probability to achieve a particular outcome of interest (i.e. earning a
degree) based on baseline characteristics. We implement the repeated split sampling (RSS) method
proposed by Abadie et al. (2013).23 Under RSS, the control group is randomly divided in half and one
half of the group is used to generate the prediction equation. These estimates are applied to the
treatment group and the other half of the control group. This split sample is repeated multiple times.
The estimated treatment effect is the simple average across these iterations. Standard errors are
calculated by bootstrap subsamples of the split samples. In Abadie et al. (2013), the first-stage equation
is estimated by OLS for the outcome regardless of whether the outcome is continuous or dichotomous.
This equation is called the prognosis score. In our work, we use a logit model when the outcome of

23 This method builds on the practice of testing for heterogeneous treatment effects by propensity score, where
the propensity score for the full sample is constructed based on estimated betas from an initial comparison
group. Abadie et al. (2013) demonstrate that this approach is systematically biased in favor of finding the largest
effects for the lowest probability group.

20

interest is dichotomous and generate a propensity score, and use the prognosis score when the outcome
is continuous. We use 1000 split samples to calculate means and a 100 bootstrap iterations for each
split sample to calculate standard errors.
Results for the subsamples indicate that STC is particularly effective for students with higher
baseline propensity scores of success. Among those in the top tercile of propensities to be enrolled in
school, students assigned to the STC treatment group are 11.8 percentage points more likely to still be
enrolled in college after six semesters (TOT estimate 65.7 with a standard error of 29.9). For those in
the top tercile, STC also appears to increase total accumulated credits and the likelihood of earning a
degree, but these estimates are only statistically significant at the 10 percent level. In general, the results
for those in the lower and middle thirds indicate that STC had little effect on academic outcomes for
these groups (Table 6b, column 5-8). However, given the large standard errors on the estimated
treatment effects these subgroups, we cannot reject the hypotheses that the effects of STC is the same
across terciles.
All of the analysis discussed up to this point has focused on the differences in outcomes
between the STC treatment group, which was offered comprehensive case management and access to
emergency financial assistance, and the control group. Our research design also allows us to directly
estimate the effect of providing only emergency financial assistance, by comparing the EFA treatment
group to the control group. We report these results in Table 7 for the same outcomes reported above.
After six semesters, those who had access to emergency financial assistance earned degrees and
remained enrolled in classes at remarkably similar rates to the control group. We find no statistically
significant differences in outcomes in the overall sample or for the male and female subsamples. In
nearly all cases, the point estimates are small, and in many cases they are negative. However, given the
standard errors we are unable to reject the hypothesis of small positive effects.
Although this evidence suggests that EFA itself does not have a sizeable impact on persistence
and degree completion in community college, this does not mean that EFA is not an effective
21

component of comprehensive case management. We have not tested case management with EFA
against case management without EFA, which is what would be needed to draw such a conclusion.

V.

TWO- AND FOUR-SEMESTER RESULTS
Because we have received outcome data from TCC each semester, we are able to examine how

the impact of STC evolves over time. Comparing short- and medium-term outcomes helps us
understand whether the intervention has an immediate impact or whether effects appear more
gradually. Many community college students drop out after just one or two semesters, so an
intervention like STC has the potential to affect outcomes nearly immediately. In our study sample,
about 20 percent of students drop out by the end of the second semester.
Table 8 reports two semester results for the same five outcomes as reported after six semesters
in Table 5, plus the additional outcome of whether the student is enrolled at TCC. We do not report
this outcome with the six-semester results because by six semesters after enrollment in the study many
students have transferred to a different school. After just two semesters, however, less than 1.5% of the
study sample is enrolled at a post-secondary institution other than TCC, so enrollment at TCC captures
college enrollment status for most of the students.
The data indicate that after two semesters not enough time has passed for students to obtain a
degree—only 0.7 percent of the control group has completed a degree by this point. It is not surprising
that we find no effect on degree completion for the full sample or for the female and male subsamples.
However, the data indicate that two semesters is enough time to observe an effect on intermediate
outcomes. The TOT estimate for enrolled in classes at TCC indicates that STC participation leads to a
28.9 percentage point increase (standard error 12.1). In terms of gender comparisons, the data already
start to show some indication that the effect is stronger for females. When looking at whether the
student is enrolled anywhere, however, we do not see a noticeable difference between the treatment
and control groups after two-semesters. It appears that after only two semesters, STC is effective at
22

keeping kids from transferring from TCC, but not necessarily at increasing overall persistence in
community college. We also find that the treatment group has accumulated more credits. STC
participants have nearly 5 more credit hours (the equivalent of 1.66 additional classes), but this
difference is marginally significant.
Table 9 reports four-semester results, which includes the summer between years one and two, a
time during which many community college students drop out. This is evident in our four-semester
results, by which point more than half the sample is no longer at TCC, and only about three-fifths of
the sample is still enrolled in school. After four semesters, we still see the positive effect on credit hours
that was evident after two semesters. However, we still see no effect of STC on degree completion or
enrollment at any college, and we no longer see an effect of STC on enrollment at TCC.
Together, our results after two, four, and six semesters indicate that the intervention did not
have a meaningful impact on enrollment in college or degree completion until after six semesters. This
suggests that the STC intervention is more effective at keeping students in school after they have been
enrolled for several semesters than it is at preventing dropouts in the short-run. Perhaps this is because
it takes time for the navigators and students to develop the relationship that allows comprehensive
coaching and mentoring to have a substantive impact on persistence and completion, so the impact of
these efforts on success in school is not evident until after a few years.
Another possible explanation is related to the implementation of the program. Throughout the
course of this intervention, the provider has been monitoring what services the navigators provide and
the form of the interactions in an effort to ensure fidelity of implementation. In the Spring 2015
semester, the provider re-emphasized to the navigators the importance of regular, direct interaction
with their students, and case notes indicate a rise in student-navigator interactions after this point. This
increased engagement may have contributed to the impact of the program after six semesters.

23

VI.

DISCUSSION

A. Estimated benefit-to-cost ratio
Because STC is a “heavy touch” intervention with relatively high per-student costs, it is
important to consider the positive effects of the program alongside the costs. The total cost per student
for three years of STC case management (including access to EFA) is $5,640, or $1,880 per year.24
This cost includes STC staff salary (manager, navigators, and an EFA coordinator), fringe benefits,
training, and EFA payouts. To measure program benefits, we plan to follow the students in this RCT
demonstration project for additional years and link their student records to administrative earnings
records. We will then compare the causal impact estimates on earnings to the program costs. However,
until enough time has elapsed, we cannot calculate a benefit-to-cost ratio based on realized earnings.
Instead, we conduct a back-of-the-envelope calculation using average earnings differences observed in
national survey data.
The TOT estimate for the full sample from Table 5 indicates that STC increased the probability
an enrolled client received an associate’s degrees by 16 percentage points. Data from the 2015 five-year
American Communities Survey (ACS) for individuals age 25-39 indicate that those with an associate’s
degree earn about $7,050/year more than people with less than a year of college education.25 In
addition, the TOT estimate suggests that STC participation increases enrollment in school after six
semesters by 25 percentage points. Some of this increase is the result of students who persist in order
to obtain a degree, so we net out the additional persistence that comes from degree completion (i.e.
0.25 – 0.16 = 0.09), and assume greater persistence means enrolling in college beyond one year. This
implies that for each additional treated student who does not earn an associate’s degree, 0.09 more
students persist in school beyond one year. The same ACS data used above show that individuals with

24
25

This cost estimate assumes that each navigator has a caseload of 34.
We use the IPUMS.org version of the ACS (Ruggles et al., 2015).

24

at least a year of college (without an associate’s degree) earn about $2,200 more than people with less
than a full year of college.
Combining these estimated returns to community college with our estimates from the full
sample indicates that treating an additional student increases annual earnings by 0.16*$7,050 +
0.09*$2,200 = $1,326. Comparing this benefit to the total three-year program cost of $5,640, indicates
that program costs are offset by increased earnings in about 4.25 years. This estimate overstates the
pay-back period as it does not allow for the possibility that those with an associate’s degree eventually
earn a bachelor’s degree. Nor does it consider benefits to a degree beyond earnings. On the other hand,
this simple calculation only accounts for direct program costs, and does not attempt to consider the
opportunity cost of any foregone wages while attending schools. Making such adjustments will lead to a
pay-back period that is larger or smaller, but the main takeaway will remain, which is that the costs of
this program are fairly small as compared to a reasonable assumption about lifetime earnings increases
associated with higher educational attainment.

B. Additional interpretation issues
The results for STC raise three critical questions. First, why is there strong evidence of a
positive effect for females, but not for males? Second, why did the EFA program not yield any
discernible benefits? Third, are these results replicable? We offer some speculative observations here.
The finding of sizable positive effects of this intervention for females but no statistically
significant effects for males is consistent with findings from other similar types of interventions.
Angrist et al. (2009) found a larger positive effect of the Project STAR intervention for females. Carroll
and Sacerdote (2017) implemented a college-going mentoring programs for high school students,
focusing on helping more students enroll in college, and found that the program leads to large increases
in college enrollment rates among female students, but much smaller effects for males. Like those
authors, we can only speculate as to what might be driving the difference. One obvious issue in the
STC evaluation is that all case managers in the program were female. This was not by design, but rather
25

a consequence of the social work profession, from which STC navigators are drawn, being
overwhelmingly dominated by females. Perhaps a program that so heavily relies on personal connection
is more effective when the mentor/mentee pair is of the same gender.26
We conjectured that perhaps females would be more likely to meet with their case managers,
both because they would be more comfortable talking with a female and because they would have been
more likely to have participated in safety net programs and interacted with a case manager previously.
Females are slightly more likely than males to take-up the offer of participating in STC (23.3% versus
19.3%), but case notes on student/navigator interactions reveal little difference in these interactions by
gender. Male students appear no less likely to have met with their navigator than female students. Still,
perhaps females were more likely to take navigator’s advice to heart, even if they received advice in
roughly equal measure. Future implementations of the program would benefit from the recruitment of
male caseworkers to the navigator role so that this hypothesis could be explored. However, all this
should be considered with the caveat that the results for males are statistically imprecise. There may, in
fact, have been a positive effect for some males. A large sample size of treated male students would
likely yield better insight into whether this type of a program tends to be effective for male students.
The finding of no discernible benefit associated with access to EFA without associated case
management raises the possibility that such an intervention is only effective if it is offered in
conjunction with additional services. These results suggest that giving very low income students access
to cash aid without the requirement or benefit of having a case manager to help address the causes of
the underlying financial distress is not sufficient. Perhaps with a less disadvantaged population, a onetime infusion of cash could help, but for students in our low-income sample, we found no evidence
that having access to up to $1,500 to cover non-tuition financial shocks increased either enrollment

26 Interestingly, the ASAP program yielded similar benefits for men and women. But as described above, that program is not
just a case management program, but also includes tuition benefits and academic and classroom features. The contrast
between the gender similarity in the ASAP program and the gender differences in the mentoring programs suggests that the
greater effect for females is specific for mentoring programs.

26

persistence or degree attainment. We also stress that our study is not able to shed light on whether EFA
is a critical aspect of case management. There might be important interactions between the coaching
and mentoring aspects of STC and the ability of case managers to offer limited financial help. This is
something future work should investigate.
Replicability is a key concern with any successful but small scale RCT. STC was designed with
the goal of subsequent replication. The research team has worked closely with our implementing
partners over the past three years to document the key aspects of the program such as how to train
navigators and how much to expect to pay in the way of EFA so the program can be replicated. We
are collaborating with the implementing agency partner, CCFW, to roll out the program in an RCT
context on other college campuses in Fort Worth. In addition, we are in the process of working with
other social service agencies outside of Fort Worth to implement the program with an RCT research
design on other campuses. It will be instructive to investigate whether the results are reproduced with a
different implementing agency, with a different student population, and in a different community
college setting.
A related replication question is whether it is fundamental to the effectiveness of the
intervention that the program is implemented by a third-party non-profit rather than community
college counselors. We offer the observation that the implementing agency, CCFW, considers
individualized case management to be their comparative advantage. To the best of our understanding,
this tends not to be the particular focus or training of community college counselors. Perhaps that
dedicated focus is what makes this application of the program so effective. If individuals without a
background in social work, or with a different background in social work, were to serve as navigators,
the results might be different. Again, this points to a need for replication to learn under what contexts
specifically such a program can be expected to generate beneficial effects for students.

27

VII.

CONCLUSION
This paper has investigated whether a case-management intervention could increase the rates of

enrollment persistence and degree completion among low-income community college students. To
study this question, we conducted an RCT evaluation of the STC intervention. The main elements of
this program are comprehensive case management – including mentoring, coaching, referrals, and
limited access to emergency financial assistance – conducted by a trained social worker with a caseload
of no more than 34 students at a time. The paper has described an RCT evaluation of this program
implemented by the research team in partnership with a local social service agency at a community
college campus in Fort Worth, Texas.
The results indicate sizable increases in school persistence and degree completion through six
semesters, driven by female students. Intention-to-treat estimates based on regression-adjusted
differences between females randomly assigned to case management services and those randomly
assigned to a control group show a 7.4 percentage point increase in the likelihood of earning an
associate’s degree (standard error of 3.3), off a control group mean of 15.7 percent. This translates into
a treatment-on-the-treated effect of 31.5 percentage points (standard error of 14.1).
Point estimates for the full sample of females and males combined are positive, but not
statistically significant. We report a back-of-the-envelope calculation that takes as program benefits the
point estimates for the full sample combined with projected earnings increases. This simple calculation
suggests that the benefits of the program, as captured by increased earnings, exceeds the per-student
costs ($5,640 total for three years of enrollment) after only 4.25 years in the workforce post schooling.
There is no evidence of a positive effect of a limited version of the program that only offered access to
emergency financial assistance (EFA) without associated case management services. We offer
speculative explanations above for why the program was particularly effective for females and why the
EFA-only treatment did not lead to positive outcomes.

28

This paper contributes to multiple literatures. First, it contributes to the literature on college
completion, in particular, the sets of studies focusing on ways to increase college completion rates
among low-income students. As noted in the introduction, income gaps in college completion have
widened despite expansions to the Pell Grant program that have made financial aid more generous for
low-income families. Research and policy attention to this challenge has tended to focus on
interventions run through community colleges themselves, in particular, academic programs and
enhanced school counseling. The research demonstration project studied in this paper is novel in that it
is an comprehensive case-management program run by a third party non-profit with a particular
expertise in case management.
The paper contributes more generally to the literature on anti-poverty strategies and ways to
effectively help individuals achieve economic self-sufficiency. This paper has demonstrated that case
management can be a cost-effective way to increase rates of educational persistence and degree
completion among poor and near poor students. Future work will follow these same students to
investigate longer term effects on earnings. A supplementary project being conducted by a subset of the
research team is investigating the effectiveness of case management in improving a wide variety of
economic outcomes for a non-student population in the same community. Together, this body of
research will contribute to our collective knowledge about the types of barriers facing low-income
individuals and the most cost-effective ways of helping them achieve economic security.

29

References
Abadie, Alberto, Matthew M. Chingos, and Martin R. West. Endogenous stratification in randomized
experiments. No. w19742. National Bureau of Economic Research, 2013.
Angrist, Joshua, Daniel Lang, and Phil Oreopoulos. 2009. “Incentives and Services for College
Achievement: Evidence from a Randomized Trial.” American Economic Journal: Applied Economics
1(1): 136-163.
Attewell, P., Lavin, D., Domina, T., & Levey, T. (2006). New evidence on college remediation. The
Journal of Higher Education, 77(5), 886-924.
Bailey, Thomas, Davis Jenkins, and Timothy Leinbach. 2005. "What We Know About Community
College Low-Income and Minority Student Outcomes: Descriptive Statistics from National
Surveys." Columbia University, Teachers College, Community College Research Center.
Bailey, Thomas. 2009. "Challenge and Opportunity: Rethinking the Role and Function of
Developmental Education in Community College." New Directions for Community Colleges
2009(145): 11-30.
Barr, Andrew, and Benjamin Castleman. 2017. "The Bottom Line on College Counseling." Working
Paper.
Barr, Michael and Rebecca Blank. 2009. Insufficient Funds: Savings, Assets, Credit, and Banking
Among Low-Income Households. New Rork: Russell Sage Foundation.
Baime, D. S., & Mullin, C. M. (2011). Promoting educational opportunity: The Pell Grant program at
community colleges. Washington, DC: AACC Policy Brief.
Baum, Sandy, and Judith Scott-Clayton. 2013. "Redesigning the Pell Grant Program for the TwentyFirst Century." The Hamilton Project, Discussion Paper 2013-04.
Bertrand, Marianne, Sendhil Mullainathan, and Eldar Shafir. 2004. "A Behavioral-Economics View of
Poverty." American Economic Review 94(2): 419-423.
Bettinger, Eric P., and Rachel B. Baker. 2014. “The Effects of Student Coaching: An Evaluation of a
Randomized Experiment in Student Advising.” Educational Evaluation and Policy Analysis 36(1): 319.
Bound, John, Michael Lovenheim, and Sarah Turner. 2010. “Why Have College Completion Rates
Declined? An Analysis of Changing Student Preparation and Collegiate Resources,” American
Economic Journal: Applied Economics 2: 129-157.
Carrell, Scott and Bruce Sacerdote. 2017. “Why do college-going interventions work?” American
Economic Journal: Applied Economics 9(3): 124-151.
Deming, David. 2017. “Increasing College Completion with a Federal Higher Education Matching
Grant.” The Hamilton Project.
Deming, David and Christopher Walters. 2017. “The Impact of Price Caps and Spending Cuts on U.S.
Postsecondary Attainment,” NBER working paper 23736.
"Diploma to Nowhere." Strong American Schools. (2008).
Gallagher, Robert. 2010. “National Survey of Counseling Center Directors 2010.” The International
Association of Counseling Services, Inc.
30

Geckeler, Christian, Carrie Beach, Michael Pih, and Leo Yan. 2008. "Helping Community College
Students Cope with Financial Emergencies: Lessons from the Dreamkeepers and Angel Fund
Emergency Financial Aid Programs." DMRC.
Grubb, W. Norton. 2006. “’Like, what do I do now?’: The Dilemmas of Guidance Counseling.” In T.
Bailey and V. Morest (Eds.), Defending the Community College Equity Agenda. Baltimore,
MD: Johns Hopkins University Press, 195-222.
Hiler, Tamara, and Lanae Erickson Hatalsky. 2016. “What Free Won’t Fix: Too Many Public Colleges
are Dropout Factories.” Third Way.
Holzer, Harry and Sandy Baum. 2017. “Making College Work: Pathways to Success for Disadvantaged
Students.” Washington DC: Brookings Institution Press.
Jepsen, Christopher, Troske, Kenneth and Coomes, Paul. 2014. “The Labor-Market Returns to
Community College Degrees, Diplomas, and Certificates.” Journal of Labor Economics, 32, issue 1,
p. 95 - 121.
Johnson, Jean, Jon Rochkind, Amber Ott, and Samantha DuPont. 2011. "With Their Whole Lives
Ahead of Them: Myths and Realities About Why So Many Students Fail to Finish College."
Public Agenda. http://files.eric.ed.gov/fulltext/ED507432.pdf
Kane, Thomas, and Cecilia Rouse. 1995. "Labor-Market Returns to Two and Four-Year College."
American Economic Review 1983(3): 11-30.
Kling, Jeffrey R., Jeffrey B. Liebman, and Lawrence F. Katz. 2007. "Experimental Analysis of
Neighborhood Effects." Econometrica 75(1): 83-119.
Long, Bridget Terry. 2014. “Addressing the Academic Barriers to Higher Education,” in Policies to
Address Poverty in America, ed. Melissa S. Kearney and Benjamin H. Harris. Brookings Institution,
The Hamilton Project.
Marcotte, Dave E., Thomas Bailey, Carey Borkoski, and Greg S. Kienzl. 2005. “The Returns of a
Community College Education: Evidence from the National Education Longitudinal Survey.”
Educational Evaluation and Policy Analysis, v 27, n.2, pp 157-176.
Marcotte, Dave. 2016. "The Returns to Education at Community Colleges: New Evidence from the
Education Longitudinal Survey." IZA Discussion Papers 10202, Institute for the Study of Labor
(IZA).
Martorell, Paco and Isaac McFarlin Jr. 2011. “Help or Hindrance? The Effects of College Remediation
on Academic and Labor Market Outcomes,” The Review of Economics and Statistics, 93:2, 436-454.
National Student Clearinghouse. 2017. Web site: www.studentclearinghouse.com.
Richburg-Hayes, Lashawn, et al. "Rewarding persistence: Effects of a performance-based scholarship
program for low-income parents." (2009).
Ruggles, Steven, Katie Genadek, Ronald Goeken, Josiah Grover, and Matthew Sobek. Integrated Public
Use Microdata Series: Version 6.0 [dataset]. Minneapolis: University of Minnesota, 2015.
http://doi.org/10.18128/D010.V6.0.
Scott-Clayton, Judith. 2011. "The Shapeless River: Does a Lack of Structure Inhibit Students' Progress
at Community Colleges." Columbia University, Teachers College, Community College Research
Center Working Paper No. 25.

31

Scrivener, Susan, Michael J. Weiss, Alyssa Ratledge, Timothy Rudd, Colleen Sommo and Hannah
Freaques. 2015. "Doubling graduation rates: Three-year effects of CUNY's Accelerated Study in
Associate Programs (ASAP) for Developmental Education Students."
Scrivener, Susan, and Michael J. Weiss. 2009. "More Guidance, Better Results?: Three-Year Effects of
an Enhanced Student Services Program at Two Community Colleges." New York: MDRC.
Shipler, David K. The working poor: Invisible in America. Vintage, 2008.Stevens, Ann H., Michael
Kurlaender, and Michel Grosz. 2015. “Career Technical Education and Labor Market
Outcomes: Evidence from California Community Colleges.” NBER Working Paper 21137.
U.S. Department of Education. 2016. National Center for Education Statistics, NCES-2016-112rev.
“Postsecondary Institutions and Cost of Attendance in 2015-16; Degrees and Other Awards
Conferred, 2014-15; and 12-Month Enrollment”:
https://nces.ed.gov/pubs2016/2016112rev.pdf.
U.S. Department of Education. 2013. National Center for Education Statistics, NCES-2013-037. “The
Condition of Education 2013.” https://nces.ed.gov/pubs2013/2013037.pdf.
U.S. Department of Education. 2010. National Center for Education Statistics, NCES-2011-151:
“Persistence and Attainment of 2003-04 Beginning Postsecondary Students: After 6 Years”:
https://nces.ed.gov/pubs2011/2011151.pdf.
van der Steeg, Marc, Roel van Elk, Dinand Webbink. 2015. “Does Intensive Coaching Reduce School
Dropout? Evidence from a Randomized Experiment.” Economics of Education Review
48(October): 184-197.
Ybarra, Marci. 2016. “An Implementation Study of Stay the Course, 2013-2015.” University of Chicago
Working Paper.

32

Appendix: Correspondence used to enroll study participants into treatment
The following letters and emails were sent to eligible students who were assigned to one of the two
treatment arms. The letters were printed on Trinity River letterhead and mailed in TCC marked
envelopes. The emails were sent via the college’s mass communication system and therefore appeared
to the students as emails from TCC. The initial letters and emails are below. Similar emails reminding
eligible students about the opportunity to participate were sent periodically throughout the enrollment
window.

Solicitation Emails
Email 1 (Sent to the students assigned to the full Stay the Course treatment):
Dear Student,
You have been selected to participate in an exciting new opportunity at Trinity River Campus
called Stay the Course. Designed to help students persist in school and attain their degrees, this
program is being offered at no cost to you through a partnership with Catholic Charities Fort
Worth, a major non-profit in the Fort Worth community. Stay the Course is part of a research
project, and due to limited funding, only a small number of Trinity River students have been
selected to participate. Through a lottery, you were chosen to participate. Eligibility for this
program cannot be transferred to another student.
As a participant in Stay the Course, you will have the opportunity to work with a Navigator on
campus to assist you in dealing with the many obstacles that students often face as they
progress through college. The Navigator will also work with you to develop a personalized Path
to Graduation.
Another tremendous benefit of Stay the Course is access to financial assistance to assist you in
overcoming unexpected financial hardships that threaten your ability to stay enrolled in school.
If you enroll in the program, you will be eligible for up to $500 of assistance per semester, with
a cap of $1500 that you can receive over the next three years of enrollment at TCC.
To sign up, please visit the Stay the Course website at staythecourse-cc.org. Your unique login
information for the site is as follows:
USERNAME: Student ID #
PASSWORD: […]
To participate in Stay the Course, you must sign up by September 9, 2013. If you would like to
remove yourself from our contact list, you can opt-out of the program at any time by logging
into the Stay the Course website and selecting “opt out.”
To learn more, please attend one of the Stay the Course information sessions in the Speed Room
(TRTR 4207, 4th Floor) on the Trinity River Campus on August 28th at 9am or August 29th at
4pm. Light refreshments will be served. Stay the Course staff will be there to explain how the
33

program works and to help you enroll. In the meantime, if you have any questions about the
program, please contact the Stay the Course staff at [#].
We at Trinity River Campus are excited to be the first TCC campus participating in this
program and encourage you to take full advantage of this unique opportunity.
Sincerely,
[College President]
Email 2 (Sent to the students assigned to the Emergency Financial Assistance only treatment):
Dear Student,
You have been selected to participate in an exciting new opportunity at Trinity River Campus
called Stay the Course Fund. The program is designed to assist students in overcoming unexpected
financial hardships that threaten their ability to stay enrolled in school. It is being offered at no
cost to you through a partnership with Catholic Charities Fort Worth, a major non-profit in the
Fort Worth community. Stay the Course Fund is part of a research project, and due to limited
funding, only a small number of Trinity River students have been selected to participate.
Through a lottery, you were chosen to participate. Eligibility for this program cannot be
transferred to another student.
As a participant in Stay the Course Fund, you will have access to financial assistance to help you
overcome unexpected financial hardships that threaten your ability to stay enrolled in school. If
you enroll in the program, you will be eligible for up to $500 of assistance per semester, with a
cap of $1500 that you can receive over the next three years of enrollment at TCC. If you would
like to be eligible for this $1500 of financial assistance, you must enroll in Stay the Course Fund by
September 9, 2013.
To sign up, first visit the Stay the Course Fund website at staythecourse-cc.org. Your unique login
information for the site is as follows:
USERNAME: Student ID #
PASSWORD: […]
To complete the enrollment process, you must pick up a Stay the Course Fund welcome packet.
These packets are available on the Trinity River Campus in room TREF 6402 during normal
business hours. If you would like to remove yourself from our contact list, you can opt-out of
the program at any time by logging into Stay the Course Fund website and selecting “opt out.”
To learn more, please attend one of the Stay the Course Fund information sessions in the Speed
Room (TRTR 4207, 4th floor) on the Trinity River Campus on August 28th at 4pm or August
29th at 9am. Light refreshments will be served. Stay the Course Fund staff will be there to explain
how the program works and to help you enroll. You may also pick up your welcome packet at
this event. In the meantime, if you have any questions about the program, please contact the
Stay the Course Fund staff at [#].

34

We at Trinity River Campus are excited to be the first TCC campus participating in this
program and encourage you to take full advantage of this unique opportunity.
Sincerely,
[College President]

Solicitation Letters
Letter 1 (Sent to the students assigned to the full Stay the Course treatment):
Dear Student,
This letter is to follow up on an email you recently received regarding your eligibility to
participate in an exciting new opportunity at Trinity River Campus called Stay the Course. This
program is designed to help students persist in school and attain their degrees. It is being
offered at no cost to you through a partnership with Catholic Charities Fort Worth, a major
non-profit in the Fort Worth community. Stay the Course is part of a research project, and due
to limited funding, only a small number of Trinity River students were selected to participate.
Through a lottery, you were chosen to participate. Eligibility for this program cannot be
transferred to another student.
As a participant in Stay the Course, you will have the opportunity to work with a Navigator who
is here to assist you in dealing with the many obstacles that students often face as they progress
through college. The Navigator will also work with you to develop a personalized Path to
Graduation.
Another tremendous benefit of Stay the Course is access to financial assistance to help you
overcome unexpected financial hardships that threaten your ability to stay enrolled in school. If
you enroll in the program, you will be eligible for up to $500 of assistance per semester, with a
cap of $1500 that you can receive over the next three years of enrollment at TCC.
To enroll, please visit the Stay the Course website at staythecourse-cc.org. Your unique login
information for the site is as follows:
USERNAME: Student ID #
PASSWORD: […]
To participate in Stay the Course, you must enroll by September 9, 2013. If you would like to
remove yourself from our contact list, you can opt-out of the program at any time by logging
into the Stay the Course website and selecting “opt out.”

35

To learn more, please attend one of the Stay the Course information sessions in the Speed Room
(TRTR 4207, 4th Floor) on the Trinity River Campus on August 28th at 9am or August 29th at
4pm. Light refreshments will be served. Stay the Course staff will be there to explain how the
program works and to help you enroll. In the meantime, if you have any questions about the
program, please contact the Stay the Course staff at [#].
We at Trinity River Campus are excited to be the first TCC campus participating in this
program and encourage you to take full advantage of this unique opportunity.
Sincerely,
[TCC President]

Letter 2 (Sent to the students assigned to the Emergency Financial Assistance only treatment):
Dear Student,
This letter is to follow up on an email you recently received regarding your eligibility to
participate in an exciting new opportunity at Trinity River Campus called Stay the Course Fund.
This program is designed to assist students overcome financial hardships they may face during
their college careers. It is being offered at no cost to you through a partnership with Catholic
Charities Fort Worth, a major non-profit in the Fort Worth community. Stay the Course Fund is
part of a research project, and due to limited funding, only a small number of Trinity River
students have been selected to participate. Through a lottery, you were chosen to participate.
Eligibility for this program cannot be transferred to another student.
As a participant in Stay the Course Fund, you will have access to financial assistance to help you
overcome unexpected financial hardships that threaten your ability to stay enrolled in school. If
you enroll in the program, you will be eligible for up to $500 of assistance per semester, with a
cap of $1500 that you can receive over the next three years of enrollment at TCC. If you would
like to be eligible for this $1500 of financial assistance, you must enroll in Stay the Course Fund by
September 9, 2013.
To enroll, first visit the Stay the Course Fund website at staythecourse-cc.org. Your unique login
information for the site is as follows:
USERNAME: Student ID #
PASSWORD: enrollme
Further, you must pick up a Stay the Course Fund welcome packet. These packets are available on
the Trinity River campus in room TREF 6402 during normal business hours. If you would like
to remove yourself from our contact list, you can opt-out of the program at any time by logging
into the Stay the Course Fund website and selecting “opt out.”

36

To learn more, please attend one of the Stay the Course Fund information sessions in the Speed
Room (TRTR 4207, 4th floor) on the Trinity River Campus on August 28th at 4pm or August
29th at 9am. Light refreshments will be served. Stay the Course Fund staff will be there to explain
how the program works and to help you enroll. You may also pick up your welcome packet at
this event. In the meantime, if you have any questions about the program, please contact the
Stay the Course Fund staff at
[#].
We at Trinity River Campus are excited to be the first TCC campus participating in this
program and encourage you to take full advantage of this unique opportunity.
Sincerely,
[College President]

37

Table 1
Summary of Navigator-Student Interactions for the STC Program
Mean per Student
Variable
Total Interactions per Semester

Overall
33.81
(16.39)

Females
33.61
(16.04)

Males
34.17
(17.11)

In-Person Meetings per Semester

4.13
(3.65)

3.75
(3.18)

4.85
(4.33)

Duration of In-Person Meeting (Minutes)

41.25
(25.96)

43.19
(25.90)

38.44
(25.43)

Text/Email Interactions per Semester

17.08
(9.99)

17.81
(10.15)

15.71
(9.56)

Phone Interactions per Semester

9.70
(11.64)

9.23
(11.49)

10.59
(11.91)

Duration of Phone Meeting (Minutes)

12.35
(20.35)

11.57
(19.79)

13.76
(21.27)

94

63

31

Number of Students

Notes: Calculations were made using CCFW case note data from Fall 2013 through Spring 2016 for the 94 treatment
compliers in semesters where they were still active in the program, so these means are conditional on students meeting
in-person with a Navigator at least once in the semester. Standard deviations are in parentheses.

38

Table 2
Characteristics of Select RCT Interventions Promoting College Persistence or Completion

Reference

Stay the Course

Inside Track

-

Bettinger & Baker,
2014
Multiple anonymous
locations. 2003-2004,
2007-2008 (N =
13,555)

Opening Doors Ohio
Scrivener & Weiss,
2009
Multiple sites.
2003-2006 (N =
2,139)

Opening Doors Louisiana
Richburg-Hayes et
al., 2009
New Orleans, LA.
2004-2005
(N= 1,019)

ASAP

New York, NY.
2010-2013
(N=896)

Scrivener et al., 2015

Project STAR
Angrist, Lang,
Oreopoulis, 2009.
Canada.
2005-2006
(N= 1,656)

RCT Demonstration

Fort Worth, TX.
2013 -2016
(N = 869)

Type of Institution

Community college
(one campus)

Private, public, twoyear, and four-year

Community college
(two campuses)

Community college
(two campuses)

Community college
(three campuses)

Public 4-year
university (one
campus)

Cost per Student

$5,640 total for three
years of enrollment

$500 per semester

Cost analysis not
included

Cost analysis not
included

$739 for one year
program

Primary Finding

31.5 pp increase in
associate’s degree
completion among
enrolled women,
nearly 3 times the
graduation rate of
females in the
control group
-Pell eligible or
below 200% FPL
-Must be enrolled in
at least 9 credit hours
at baseline
- 30 or fewer
accumulated credits
at baseline

Coached students 3
to 4 pp more likely
to persist after 18
mos, 24 mos; 4 pp
more likely to
graduate

No sig. increase in
credits ended or over
the 3-year follow-up
period

6.5 pp increase in
persistence thru 4
semesters post
random assignment

$16,284 in additional
services above
control group
($42,065 total) for
three year program
18 pp increase in
degree completion,
nearly 2 times the
graduation rate of
students in the
control group

None

-Below 250% FPL
-Full-time or parttime
- 12 or fewer
accumulated credits
at baseline

-Parents of at least
one dependent child
under 19 with
household income
below 200% FPL.
- Full-time or parttime
- No students with
degrees or
occupational

-Pell eligible or
below 200% FPL.
-Restricted to all
majors except: allied
Health Sciences, PreClinical Nursing,
Forensic Science,
and Engineering
Science
- Full-time only

- No income
restrictions
- Full-time only
- Entering first-year

Eligible student
population

39

GPA improvement
& increase in credits
earned for first-year
female students (but
not males) in the full
SFSP program

certificate from
accredited college or
university

- 12 or fewer
accumulated credits
at baseline

Case management
Coaching,
Mentoring,
Referrals

Intensive case
management,
involving, coaching,
mentoring, and
referrals for all
aspects of the
student’s life.
Emphasis on inperson meetings

Coaching by phone
to help student
develop time
management, selfadvocacy, and study
skills

Counselor assists
with personal and
academic issues.
Counselor refers
students to services
on and off campus

Coaching and
referral services
available but
underutilized

-Comprehensive
coaching from an
ASAP-dedicated
adviser.
-Career information
from an ASAPdedicated career and
employment services
staff member

-Peer mentoring
from upper-class
students in the same
field of study at the
University.
-Peer Advisors were
trained to identify
circumstances that
called for more
professional help
and to make
appropriate referrals

Student:Counselor
Ratio

34:1

Not reported

Varied, but rarely
exceed 100:1

Between 80:1 and
60:1

Not reported

Educational
Planning/Advising

Navigator helps
student identify goals
and steps necessary
to achieve those
goals

The coach works
with the student to
develop a clear
vision of his/her
goals and set up
steps necessary to
achieve those goals

Lorain Campus:
81:1;
Owens Campus:
157:1
Counselor helps with
work-based, learning
efforts, juggling
school and work,
and career
aspirations

Available but
underutilized

Students enroll in an
ASAP seminar
covering topics such
as goal-setting, study
skills, and academic
planning

Peer advisors emailed advisees at
least biweekly to
solicit questions
about university
assimilation,
scheduling, studying,
and time
management

Students with a GPA
of 2.0 or above are
eligible up $500 of
emergency financial
assistance a semester,
capped at $1,500

No

No

Students receive free
use of textbooks and
free MetroCards for
use on public
transportation,
contingent on
participation in the
program.

No

Financial Supports
Non-tuition Financial
Assistance

Students are eligible
for a $150 stipend
per semester for two
semesters, usable for
any purpose

40

Tuition Waivers

No

No

No

No

3-11 percent of
students received
waiver in a given
semester
No

No

Grade Bonus

No

No

No

$250 after midterms
contingent on
staying enrolled at
least halftime &
earning passing
grades; $500 upon
completion of
courses with a C
average or better.
Extended for two
semesters; students
can earn up to
$2,000.

Enrollment Assistance

Advised on course
enrollment.

No

Yes

No

Yes

No

Tutoring

Referrals to tutoring

No

Referrals to tutoring

No

No

No

No

Students receive
ASAP dedicated
tutoring services
separate from the
usual college tutoring
services
Students enroll in
blocked or linked
courses in their first
year. Students can
register for courses
early so that they can
create convenient
schedules and get
seats in the courses
they need

Learning
Communities/ Block
Classes

No

No

Substantial cash
awards, up to $5,000,
for meeting a target
GPA.

Academic

41

No

Table 3
Descriptive Characteristics of Community College Students

Variable
Age
Under 30 years old
30 years old and over
Female
Male
White, non-Hispanic
Black, non-Hispanic
Asian/Pacific Islander
Other Race
Hispanic
Part Time
Full Time
Receive Pell Grants
First Generation College Student
N

U.S.

Texas

TCC

(1)
28.00
0.71
0.28
0.57
0.43
0.51
0.14
0.06
0.09
0.19
0.60
0.40
0.33
0.36
7.3 million

(2)
0.719
0.280
0.558
0.442
0.342
0.132
0.044
0.062
0.420
0.748
0.252

(3)
26.92
0.750
0.251
0.579
0.421
0.389
0.181
0.044
0.033
0.354
0.869
0.131

700,963

8,849

Full Stay the
Course Sample
(4)
24.21
0.833
0.167
0.655
0.345
0.273
0.198
0.031
0.030
0.468
0.446
0.554
0.986
0.583
869

Notes: National statistics are taken from the American Association of Community Colleges (AACC) 2014 Fact Sheet. Texas
statewide statistics were collected from txhighereddata.org. The TCC statistics represent averages from the Trinity River
Campus in Fall 2013. Due to the limited age data available, the age ranges for the TCC column are under 31 and 31 and
over. For students in the Stay the Course sample, full time students are defined as students who are enrolled in 12 or more
credits at the Fall 2013 census date.

42

Table 4
Mean Characteristics of Treatment Groups and Control Group, Fall 2013
P-value on Test that Means are the
Means by Group Assignment
Same Across Groups

Variable
Age at Entry
Female
TSI's Remaining at Entry
Dependent
Cumulative Hours Earned Prior to Entry
Family Income
Between 0% and 50% of FPL
Between 50% and 100% of FPL
Between 100% and 150% of FPL
Between 150% and 200% of FPL
Above 200% of FPL
Estimated Family Contribution (FAFSA)
Age < 20
Age 20 - 25
Age 26+
Black
White
Asian
Other Race
Hispanic
Declared Intention to Earn Associate's Degree
N

STC
Treatment
(1)
24.09
0.628
0.537
0.516
11.34
$22,576
0.228
0.291
0.216
0.158
0.107
$768
0.449
0.256
0.295
0.184
0.405
0.027
0.377
0.477
0.677

EFA
Treatment
(2)
24.865
0.642
0.525
0.552
11.505
$22,906
0.264
0.241
0.221
0.167
0.107
$761
0.421
0.274
0.304
0.241
0.418
0.037
0.304
0.438
0.679

430

299

Control
(3)
24.33
0.681
0.572
0.519
11.15
$20,756
0.262
0.294
0.198
0.15
0.096
$650
0.405
0.301
0.294
0.216
0.408
0.035
0.349
0.460
0.690

STC &
Control
(4)
0.664
0.099
0.477
0.928
0.795
0.111
0.244
0.919
0.511
0.751
0.581
0.242
0.197
0.140
0.961
0.229
0.926
0.522
0.387
0.624
0.690

EFA &
Control
(5)
0.388
0.272
0.382
0.386
0.660
0.098
0.946
0.112
0.459
0.537
0.615
0.292
0.666
0.438
0.760
0.437
0.780
0.469
0.211
0.556
0.746

439

Notes: Means are from TCC administrative data for Fall 2016 for subgroups of the full STC study sample (N = 1,168). Degree propensity is the predicted
probability of earning a degree after six semesters, which is estimated on the control group using a probit model that includes as controls observable characteristics
at baseline. See Section V of the text for more details.

43

Table 5
The Effect of STC on Outcomes after Six Semesters for Main Sample and by Gender
Full Sample
ITT
TOT
(2)
(1)
0.056*
0.251*
(0.033)
(0.152)
[0.440]
{0.238}

Female Sample
ITT
TOT
(3)
(4)
0.084**
0.358**
(0.041)
(0.178)
[0.425]
{0.134}

Male Sample
ITT
TOT
(5)
(6)
-0.003
-0.014
(0.058)
(0.293)
[0.471]
{0.498}

Total Credits Earned

1.764
(1.314)
[26.829]

7.717
(5.697)
{24.171}

2.846*
(1.682)
[26.414]

11.793*
(6.931)
{20.269}

-0.307
(2.117)
27.725

-1.526
(10.361)
{33.083}

Cumulative GPA

0.026
(0.067)
[2.495]

0.116
(0.295)
{0.189}

0.046
(0.084)
[2.490]

0.195
(0.352)
{0.117}

-0.005
(0.112)
[2.504]

-0.025
(0.552)
{0.426}

Earned any Degree

0.037
(0.026)
[0.182]

0.165
(0.119)
{0.058}

0.065*
(0.034)
[0.187]

0.278*
(0.146)
{0.000}

-0.009
(0.042)
[0.171]

-0.046
(0.212)
{0.207}

Earned an Associate's
Degree

0.036
(0.025)
[0.159]

0.162
(0.115)
{0.029}

0.074**
(0.033)
[0.157]

0.315**
(0.141)
{0.000}

-0.025
(0.040)
[0.164]

-0.129
(0.205)
{0.258}

869

869

569

569

300

300

Outcomes
Enrolled in College

N

Notes : The Main Sample includes students assigned to the full STC treatment and those assigned to the control group. ITT
estimates (β1 from equation 1) are from OLS regressions of the outcomes listed in each row on assignment to treatment age, age
squared, income, income squared, an indicator for female, and a set of race dummies. TOT estimates (γ1 from equation 2) are
from 2SLS regressions using assignment to treatment as an instrument for program participation. Take up = 1 if client completes
an intake form. 20 observations are lost when analyzing cumulative GPA (11 females, 9 males) due to missing data. In instances
in which the Control Complier Mean (CCM) is negative, it is reported as zero--see Section V of the text for more details.
Statistics reported under point estimate: (Standard error) [Mean outcome in control group] {CCM}. *Significant at the 10%
level, **significant at the 5% level.

44

Table 6a
The Effect of STC on Outcomes after Six Semesters by Subsamples
Income
Race / Ethnicity
≤ Median Income
ITT
TOT
(2)
(1)
0.024
0.091
(0.047)
(0.178)
[0.413]
{0.371}

> Median Income
ITT
TOT
(3)
(4)
0.083*
0.441*
(0.048)
(0.259)
[0.469]
{0.083}

White, Non-Hispanic
ITT
TOT
(5)
(6)
0.005
0.023
(0.066)
(0.284)
[0.424]
{0.533}

Non-White
ITT
TOT
(7)
(8)
0.069*
0.318*
(0.039)
(0.181)
[0.455]
{0.145}

Total Credits Earned

0.459
(1.831)
[23.785]

1.720
(6.754)
{26.281}

2.817
(1.885)
[30.214]

14.203
(9.439)
{22.544}

2.403
(2.604)
[28.336]

9.965
(10.441)
{38.414}

1.615
(1.520)
[26.270]

7.233
(6.760)
{29.091}

Cumulative GPA

0.009
(0.101)
[2.354]

0.033
(0.374)
{0.105}

0.031
(0.088)
[2.647]

0.166
(0.461)
{0.341}

-0.039
(0.125)
[2.803]

-0.168
(0.528)
{0.335}

0.053
(0.079)
[2.391]

0.238
(0.356)
{0.140}

Earned any Degree

0.024
(0.036)
[0.161]

0.092
(0.135)
{0.100}

0.050
(0.039)
[0.206]

0.267
(0.210)
{0.000}

0.035
(0.051)
[0.203]

0.155
(0.224)
{0.104}

0.041
(0.031)
[0.176]

0.189
(0.142)
{0.020}

Earned an Associate's
Degree

0.029
(0.034)
[0.135]

0.109
(0.128)
{0.045}

0.045
(0.038)
[0.187]

0.240
(0.204)
{0.000}

0.065
(0.048)
[0.153]

0.289
(0.217)
{0.000}

0.028
(0.030)
[0.157]

0.127
(0.136)
{0.067}

435

435

434

434

237

237

632

632

Outcomes
Enrolled in College

N

Notes : Results are for subgroups of the Main Sample that includes students assigned to the full STC treatment and those assigned to the control group.
Statistics reported under point estimate: (Standard error) [Mean outcome in control group] {CCM}. *Significant at the 10% level, **significant at the
5% level. See notes to Table 5 for more details.

45

Table 6b
The Effect of STC on Outcomes after Six Semesters by Subsamples
Initial Credit Hours

Outcome Propensity

> Median Hours
ITT
TOT
(1)
(2)
0.068
0.310
(0.048)
(0.217)
[0.478]
{0.222}

≤ Median Hours
ITT
TOT
(3)
(4)
0.051
0.228
(0.047)
(0.211)
[0.399]
{0.219}

Lower Third
ITT
TOT
(5)
(6)
0.008
0.034
(0.054)
(0.210)
[0.411]
{0.320}

Middle Third
ITT
TOT
(7)
(8)
0.027
0.134
(0.049)
(0.233)
[0.464]
{0.417}

Upper Third
ITT
TOT
(9)
(10)
0.118**
0.657**
(0.053)
(0.299)
[0.448]
{0.000}

Total Credits Earned

0.886
(1.751)
[27.373]

3.904
(7.601)
{26.223}

2.604
(1.973)
[26.279]

11.304
(8.394)
{22.269}

0.404
(2.245)
[21.764]

1.603
(9.447)
{23.975}

-0.246
(1.759)
[28.741]

-1.106
(7.617)
{33.689}

4.066*
(2.146)
[31.164]

21.048*
(11.290)
{17.996}

Cumulative GPA

0.012
(0.043)
[2.704]

0.055
(0.192)
{0.243}

0.043
(0.042)
[2.258]

0.194
(0.188)
{0.125}

-0.053
(0.131)
[2.177]

-0.237
(0.663)
{2.702}

0.061
(0.088)
[2.581]

0.308
(0.449)
{2.288}

0.050
(0.103)
[2.757]

0.214
(0.457)
{2.614}

Earned any Degree

0.010
(0.040)
[0.239]

0.047
(0.182)
{0.230}

0.056*
(0.034)
[0.122]

0.251
(0.153)
{0.000}

0.008
(0.035)
[0.096]

0.037
(0.162)
{0.067}

-0.002
(0.042)
[0.205]

-0.016
(0.209)
{0.218}

0.094*
(0.054)
[0.251]

0.419*
(0.255)
{0.000}

Earned an Associate's
Degree

0.018
(0.039)
[0.208]

0.080
(0.176)
{0.154}

0.047
(0.032)
[0.108]

0.214
(0.144)
{0.000}

0.012
(0.030)
[0.095]

0.053
(0.141)
{0.031}

0.023
(0.035)
[0.163]

0.098
(0.163)
{0.089}

0.068
(0.049)
[0.223]

0.334
(0.163)
{0.000}

444

444

425

425

290

290

289

289

290

290

Outcomes
Enrolled in College

N

Notes : Results are for subgroups of the Main Sample that includes students assigned to the full STC treatment and those assigned to the control group. Degree propensity is the
predicted probability of earning a degree after six semesters, which is estimated on the control group using a probit model that includes as controls observable characteristics at
baseline. See Section V of the text for more details. Statistics reported under point estimate: (Standard error) [Mean outcome in control group] {CCM}. *Significant at the 10% level,
**significant at the 5% level. See notes to Table 5 for more details.

46

Table 7
The Effect of EFA on Outcomes after Six Semesters for the Full EFA Sample and by Gender
Full Sample
ITT
TOT
(2)
(1)
0.015
0.036
(0.037)
(0.088)
[0.440]
{0.456}

Female Sample
ITT
TOT
(3)
(4)
0.010
0.024
(0.046)
(0.104)
[0.425]
{0.505}

Male Sample
ITT
TOT
(5)
(6)
0.027
0.073
(0.065)
(0.168)
[0.471]
{0.342}

Total Credits Earned

-0.443
(1.448)
[26.829]

-1.080
(3.509)
{29.756}

-1.068
(1.761)
[26.414]

-2.508
(4.110)
{31.548}

0.706
(2.615)
[27.725]

1.883
(6.803)
{26.057}

Cumulative GPA

-0.108
(0.079)
[2.495]

-0.259
(0.190)
{2.784}

-0.089
(0.097)
[2.490]

-0.206
(0.223)
{2.825}

-0.131
(0.139)
[2.504]

-0.348
(0.363)
{2.678}

Earned any Degree

-0.014
(0.029)
0.182

-0.034
(0.068)
{0.248}

-0.032
(0.035)
[0.187]

-0.073
(0.080)
{0.285}

0.017
(0.050)
[0.171]

0.045
(0.130)
{0.175}

Earned an Associate's
Degree

-0.012
(0.027)
[0.159]

-0.028
(0.065)
{0.218}

-0.014
(0.033)
[0.157]

-0.032
(0.076)
{0.208}

-0.007
(0.048)
[0.164]

-0.018
(0.126)
{0.238}

738

738

491

491

247

247

Outcomes
Enrolled in College

N

Notes : Results are for the EFA Sample (N = 772) that includes students assigned to the EFA only treatment and those assigned to the
control group. Statistics reported under point estimate: (Standard error) [Mean outcome in control group] {CCM}. *Significant at the
10% level, **significant at the 5% level. See notes to Table 5 for more details.

47

Table 8
The Effect of STC on Outcomes after Two Semesters for Main Sample and by Gender
Full Sample
ITT
TOT
(2)
(1)
0.064**
0.289**
(0.027)
(0.121)
[0.759]
{0.544}

Female Sample
ITT
TOT
(3)
(4)
0.075**
0.319**
(0.034)
(0.143)
[0.749]
{0.586}

Male Sample
ITT
TOT
(5)
(6)
0.040
0.206
(0.045)
(0.225)
[0.779]
{0.625}

Enrolled in College

0.016
(0.026)
[0.797]

0.072
(0.117)
{0.811}

0.036
(0.033)
[0.783]

0.153
(0.140)
{0.720}

-0.027
(0.042)
[0.829]

-0.140
(0.218)
{1.043}

Total Credits Earned

1.064*
(0.560)
[13.897]

4.749*
(2.486)
{11.832}

1.238*
(0.698)
[13.772]

5.200*
(2.912)
{11.467}

0.781
(0.950)
[14.168]

4.028
(4.807)
{12.372}

Cumulative GPA

0.055
(0.070)
[2.468]

0.243
(0.309)
{2.442}

0.063
(0.088)
[2.469]

0.266
(0.369)
{2.365}

0.054
(0.118)
[2.465]

0.271
(0.577)
{2.522}

Earned any Degree

0.012
(0.008)
[0.007]

0.054
(0.035)
{0.000}

0.011
(0.010)
[0.007]

0.011
(0.010)
{0.005}

0.012
(0.013)
[0.007]

0.064
(0.069)
{0.000}

Earned an Associate's
Degree

0.008
(0.006)
[0.005]

0.035
(0.029)
{0.000}

0.009
(0.008)
[0.003]

0.038
(0.033)
{0.000}

0.006
(0.012)
[0.007]

0.029
(0.059)
{0.000}

869

869

569

569

300

300

Outcomes
Enrolled in Classes at
TCC

N

Notes : Results are for the Main Sample that includes students assigned to the full STC treatment and those assigned to the control
group. Statistics reported under point estimate: (Standard error) [Mean outcome in control group] {CCM}. *Significant at the 10%
level, **significant at the 5% level. See notes to Table 5 for more details.

48

Table 9
The Effect of STC on Outcomes after Four Semesters for Main Sample and by Gender
Full Sample
ITT
TOT
(2)
(1)
-0.008
-0.037
(0.034)
(0.152)
[0.456]
{0.473}

Female Sample
ITT
TOT
(3)
(4)
-0.008
-0.035
(0.042)
(0.177)
[0.468]
{0.463}

Male Sample
ITT
TOT
(5)
(6)
0.009
0.047
(0.057)
(0.290)
[0.429]
{0.405}

Enrolled in College

-0.017
(0.032)
[0.604]

-0.077
(0.145)
{0.609}

-0.005
(0.041)
[0.582]

-0.021
(0.172)
{0.528}

-0.030
(0.054)
[0.650]

-0.155
(0.276)
{0.736}

Total Credits Earned

1.097
(1.031)
[23.138]

4.914
(4.579)
{21.449}

1.895
(1.309)
[22.756]

8.016
(5.506)
{18.428}

-0.155
(1.670)
[23.962]

-0.794
(8.380)
{26.996}

Cumulative GPA

0.022
(0.068)
[2.476]

0.097
(0.299)
{2.544}

0.038
(0.087)
[2.466]

0.159
(0.360)
{2.460}

0.012
(0.114)
[2.463]

0.061
(0.558)
{2.661}

Earned any Degree

-0.013
(0.020)
[0.100]

-0.061
(0.087)
{0.114}

-0.012
(0.026)
[0.110]

-0.050
(0.108)
{0.129}

-0.010
(0.029)
[0.079]

-0.053
(0.146)
{0.053}

Earned an Associate's
Degree

-0.004
(0.019)
[0.087]

-0.020
(0.084)
{0.063}

0.002
(0.025)
[0.094]

0.008
(0.104)
{0.055}

-0.007
(0.027)
[0.071]

-0.037
(0.139)
{0.037}

869

869

569

569

300

300

Outcomes
Enrolled in Classes at
TCC

N

Notes : Results are for the Main Sample that includes students assigned to the full STC treatment and those assigned to the control
group. Statistics reported under point estimate: (Standard error) [Mean outcome in control group] {CCM}. *Significant at the 10%
level, **significant at the 5% level. See notes to Table 5 for more details.

49

Figure 1

Frequency of Discussion Topics During Student-Navigator Meetings
40%
35%
30%
25%
20%
15%
10%
5%
0%

35.3%
24.1%
16.9% 16.8%

13.1% 12.1% 11.3%

9.1%
4.2%

1.7%

0.6%

0.5%

Notes: Topics such as academic, work, and health are an aggregate of several, more specific categories. Mass emails and
administrative records have been excluded (meaningful interactions only, N=2,382). All data are for the Main Sample. Topic
Discussion data is only available for meetings that occurred between 8/23/13 - 7/14/15.

50

Figure 2
Breakdown of EFA for STC Participants by Payment Type
Childcare: 2%
Housing: 23%

Utilities: 33%

Other: 5%
School Supplies: 9%
Transportation: 29%

Notes : Data are from CCFW case notes. Sample includes all EFA payments to STC participants (N = 94).

51

Figure 3
Consort Diagram for RCT Research Design

52

Appendix Table 1
Baseline Descriptive Statistics by Compliance Status
STC Treatment Group

Varaible
Age at Entry
Female
TSI's Remaining at Entry
Dependent
Cumulative Hours Earned Prior to Entry
Family Income
Between 0% and 50% of FPL
Between 50% and 100% of FPL
Between 100% and 150% of FPL
Between 150% and 200% of FPL
Above 200% of FPL
Estimated Family Contribution (FAFSA)
Under 20 Years Old
Between 20 and 25 Years Old
Above 25 Years Old
Black
White
Asian
Other Race
Hispanic
Declared Intention to Earn Associate's Degree
N

Compliers

Noncompliers

P-value on
Test that
Means are
the same
Across
Groups

(1)
25.78
0.67
0.574
0.457
10.69
$20,121
0.287
0.309
0.181
0.138
0.085
$730
0.372
0.266
0.362
0.181
0.415
0.036
0.372
0.436
0.723

(2)
23.62
0.616
0.527
0.533
11.52
$23,263
0.211
0.286
0.226
0.164
0.113
$779
0.47
0.253
0.277
0.185
0.402
0.032
0.378
0.488
0.664

(3)
0.017
0.338
0.571
0.197
0.52
0.116
0.121
0.668
0.346
0.552
0.439
0.793
0.092
0.799
0.111
0.935
0.819
0.86
0.921
0.374
0.275

94

336

EFA Treatment Group

Compliers

Noncompliers

P-value on
Test that
Means are
the same
Across
Groups

(4)
26.751
0.675
0.587
0.484
11.817
$23,812
0.262
0.230
0.214
0.175
0.119
$801
0.365
0.262
0.373
0.262
0.421
0.040
0.278
0.413
0.722

(5)
23.491
0.618
0.480
0.601
11.277
$22,246
0.266
0.249
0.225
0.162
0.098
$732
0.462
0.283
0.254
0.225
0.416
0.035
0.324
0.457
0.647

(6)
0.001
0.319
0.197
0.045
0.676
0.467
0.939
0.714
0.819
0.771
0.568
0.677
0.093
0.684
0.028
0.468
0.939
0.821
0.396
0.451
0.172

126

173

Notes: Table includes all students that were randomized into either the STC treatment group or the EFA treatment group. Compliance (or take-up) equals 1 if client signed
an intake form at their first meeting with the service providers.

53

