NBER WORKING PAPER SERIES

LEVELING THE PLAYING FIELD FOR HIGH SCHOOL CHOICE:
RESULTS FROM A FIELD EXPERIMENT OF INFORMATIONAL INTERVENTIONS
Sean P. Corcoran
Jennifer L. Jennings
Sarah R. Cohodes
Carolyn Sattin-Bajaj
Working Paper 24471
http://www.nber.org/papers/w24471

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
March 2018

This labor-intensive field experiment was possible thanks to the hard work of research
assistants and staff of the NYC High School Admissions Study. In particular, we would like
to thank Christine Baker-Smith, Alexandra Bray, Duwa Alebdy, Alex Clothier, Florangel
DeLeon, Shaked Landor, Dhanya Madugalle, Marina Makram, Zach Malter, Eric Sturm, and
Hailey Vogel. Peter Bergman, Adam Gamoran, Jim Kemple, Mike Lovenheim, Stewart Burns
Wade, and seminar participants at Harvard University, Princeton University, the University of
Connecticut, the University of Arkansas, and Teachers College Columbia University all provided
helpful comments. We thank the William T. Grant Foundation for financial support. The
Research Alliance for New York City Schools enabled access to NYC administrative data. The
Spencer Foundation and the NYU Institute for Human Development and Social Change provided
critical seed funding. We are grateful for input and feedback from the NYCDOE enrollment
office, in particular Amy Basile, Nadiya Chadha, Sonali Murarka, and Lianna Wright. All errors
are our own. The views expressed herein are those of the authors and do not necessarily reflect
the views of the National Bureau of Economic Research.
NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.
© 2018 by Sean P. Corcoran, Jennifer L. Jennings, Sarah R. Cohodes, and Carolyn Sattin-Bajaj.
All rights reserved. Short sections of text, not to exceed two paragraphs, may be quoted without
explicit permission provided that full credit, including © notice, is given to the source.

Leveling the Playing Field for High School Choice: Results from a Field Experiment of Informational
Interventions
Sean P. Corcoran, Jennifer L. Jennings, Sarah R. Cohodes, and Carolyn Sattin-Bajaj
NBER Working Paper No. 24471
March 2018
JEL No. D83,I21,I24
ABSTRACT
We conducted a field experiment in 165 high-poverty New York City middle schools to help
students navigate a complex high school choice process and access higher-performing schools.
Students in treatment schools were given a customized one-page list of proximate high schools
with a graduation rate at or above the city median (70%). Some also received a supplemental list
highlighting academically non-selective schools or high schools organized by academic interest
area. The interventions changed student application behavior in ways that led to more matches to
higher-performing schools. While treatment students did not apply to higher graduation rate
schools, they applied to schools where their odds of admission were higher, were more likely to
receive their first-choice high school, and were less likely to match to a school with a low
graduation rate. Our findings also suggest that informational interventions may not reduce
inequality, since both disadvantaged and comparatively advantaged students used our materials,
and in some cases the latter benefited more from them by applying and matching to more schools
on our lists. Students in non-English speaking households, who were particularly responsive to
the intervention and were much less likely to match to a low-performing school, were one notable
exception to this pattern.
Sean P. Corcoran
New York University
246 Greene Street Suite 300
New York, NY 10003
sean.corcoran@nyu.edu
Jennifer L. Jennings
Princeton University
Department of Sociology
159 Wallace Hall
Princeton, NJ 08544
jlj@princeton.edu

Sarah R. Cohodes
Teachers College
Columbia University
525 West 120th Street
New York, NY 10027
and NBER
cohodes@tc.columbia.edu
Carolyn Sattin-Bajaj
Seton Hall University
400 South Orange Ave
South Orange, NJ 07079
carolyn.sattinbajaj@shu.edu

A online appendix is available at http://www.nber.org/data-appendix/w24471

3

1

Introduction

School choice policies aim to reduce racial and socioeconomic gaps in educational outcomes
by allowing families to access schools outside their own neighborhood. Their efficacy depends,
however, on families’ ability to navigate their school options and gain admission to higherperforming schools. If disadvantaged families lack the information and supports needed to
identify, apply, and enroll in better schools, the long-run effects of choice on inequality will
be limited.
Available evidence suggests that, on average, disadvantaged families put less weight on
academic quality when making school choices than their more-advantaged counterparts (Abdulkadiroğlu, Agarwal, & Pathak 2017; Abdulkadiroğlu, Pathak, & Walters 2018; Harris &
Larsen 2015; Hastings, Kane, & Staiger 2009). It is less clear whether this is attributable to
preferences, supply-side constraints, or other factors, such as unequal access to information
(Burgess et al. 2014; Glazerman & Dotter 2017; Hastings & Weinstein 2008). School choice
can be a time- and resource-intensive activity, and disadvantaged families are more likely to
lack the necessary information or resources to choose schools with better academic outcomes.
Like other public programs, school choice can involve administrative or procedural barriers
that make it more difficult for less well-resourced families to realize its full benefits (Gross
et al. 2015; Jochim et al. 2014; Lareau et al. 2006). At the secondary level, low-income and
immigrant students have been found to make school choices on their own with little adult
direction (Condliffe et al. 2015; Sattin-Bajaj 2014).
New York City’s universal high school admissions process is an ideal setting to examine whether informational and other supports can reduce inequality in access to higherperforming schools. As part of the largest public school choice program in the country, the
NYC Department of Education (NYCDOE) requires all 8th graders to submit applications
ranking up to 12 high school programs from more than 750 offered in 440 schools citywide
(Abdulkadiroğlu, Pathak, & Roth 2005).1 Academic programs vary in admissions method
(from academically screened to non-selective), admissions priorities, and academic interest
area (e.g., STEM, health professions, humanities). While the sheer number and variety of
schools provide opportunities for students to seek out the best high school for them, the scale
and complexity of the system raises the risk that existing inequalities will be exacerbated.
1

As we describe later, students apply to programs, not schools. Most schools offer only one program, but
some offer multiple programs. We use these terms interchangeably when the distinction is unimportant.

4
In this paper, we report findings from a school-based randomized trial designed to help
students in high-poverty middle schools navigate the high school choice process and access
higher-performing schools. Our field experiment was conducted in 165 NYC middle schools
that together serve nearly 20,000 8th graders. Students in treatment schools received a onepage list of 30 geographically proximate high schools with a graduation rate at or above the
city median (≥70%). These lists were customized to each participating middle school and
were designed to be relevant to a heterogeneous student population that varied in achievement levels, English language proficiency, academic interests, and likelihood of admission to
academically selective schools. This tool explained admissions methods in plain language,
listed schools in descending order by graduation rate, and reported estimated travel time by
public transportation from the middle school. Some treatment schools also received supplemental lists highlighting non-academically selective high schools or high schools organized
by their academic interest area (e.g., performing and visual arts; law and government).
Our experiment had three primary aims. First, we sought to test whether providing
simplified information about the admissions process and a custom list of school options can
increase middle school students’ propensity to apply and be admitted to higher-performing
high schools. In contrast to prior studies, we provided the information directly to students,
who play a significant role in high school choice. Second, we wished to test whether school
information is more effective at altering choices and match outcomes when it is accompanied
by supports to help students overcome administrative barriers in the applications process. In
NYC, the quality of schools to which students match depends not only on students’ choices
but also on their attention to geographic priorities and other requirements that affect their
odds of admission. This is especially important for gaining admission to higher-performing
schools that are often over-subscribed. Our supplemental list of non-academically selective
high schools emphasized the importance of attending a school open house or information
session and signing in to receive priority admission. Students receiving this list were also
invited to sign up for weekly text message reminders about these events. Our second supplemental list of high schools organized by academic interest area emphasized the importance
of meeting requirements for screened programs, including auditions, interviews, essays, and
grade minimums. Third, we sought to examine whether students varied in the extent to
which they used and benefited from the interventions. Whether informational interventions
can “level the playing field” for high school choice depends on the degree to which less and

5
more advantaged students benefit from them. Our large study sample permits us to estimate
heterogeneous treatment effects by subgroup.
Three key findings emerge from this work. First, we find that students in treatment
schools used our custom lists when making choices and were more likely to apply to our
specific school recommendations than students in the control group. The extent to which
students used these lists further depended on whether they were provided information beyond
the basic list. Students receiving the basic list drew more of their school choices from this list
than students who received supplementary information, which is consistent with evidence
suggesting that providing more options can reduce utilization. Second, students in treatment
schools were more likely to match to their first-choice high school and were less likely to match
to a school with a low graduation rate (below 70%). Rather than applying to higher graduation rate schools, students shifted their applications toward similarly-performing schools
where their odds of admission were higher.2 The treatment group receiving the basic list
alone matched to high schools with a 1.7 percentage point higher graduation rate, on average, a 0.12σ effect. The option to receive text message reminders did not appear to increase
rates of priority admission status. Third, both disadvantaged and comparatively advantaged
students used our lists to make choices, and in some cases the latter saw greater benefits
from them. For example, higher-achieving students in treatment schools applied to more
schools on our lists than did lower-achieving students, and saw greater reductions in their
likelihood of matching to a low graduation rate school. White and Asian students were more
responsive to the intervention than black and Hispanic students. A notable exception was
for students from non-English speaking households, a subgroup that represents nearly half
our study sample. These students were more likely than students who speak English at home
to draw their choices from our lists and to avoid lower-performing schools as a result. This
finding suggests that the benefits of simplified information may be greater for families with
limited English proficiency.
Taken together, our findings demonstrate that providing simplified and customized information to middle school students can impact their high school choices and increase the
quality of schools to which they match. Beyond simply inducing students to apply to higherperforming schools, the intervention improved match outcomes by incorporating odds of ad2

As we show later, the mean graduation rate for the control group’s top three choices was already quite
high, at 81%.

6
mission into its design, and limiting applications to low-performing schools. Our findings also
suggest that broad-based informational interventions will not necessarily reduce inequality,
since both more- and less-advantaged students in the same schools responded to and benefited from the intervention. This is particularly salient in NYC, where an additional layer of
academic selectivity and admissions priorities inhibit some students from fully capitalizing
on information related to school quality.
In the next section, we review recent literature on informational and other frictions in
educational decision-making, provide a description of the NYC high school admissions process, and demonstrate the potential for an informational intervention through a descriptive
analysis of choices and placements by student background in NYC. We also describe our intervention materials in detail. Section 3 describes our data sources and experimental design.
Sections 4-6 report our results, and Section 7 concludes with a discussion of implications for
public policy.

2
2.1

Background
Information and other frictions in school choice

Research has identified three main frictions associated with school choice and enrollment
decisions. The first relates to the cost of acquiring information. If families lack full information about their available choices and opportunities—or if obtaining and processing this
information is costly—they may make suboptimal decisions. The second friction relates to
information and/or choice overload, where information is readily available, but the number or
complexity of choices inhibits decision-making. The third relates to administrative or other
barriers that make it more difficult to actualize or reap the full benefits of an educational
decision.
A large literature in economics, psychology, and education finds that simplified information, choice architecture, and behavioral “nudges” can help reduce such frictions. These
approaches typically aim to increase the salience of information, narrow the scope of choices,
facilitate comparisons, and/or mitigate procedural barriers. In doing so, they can ameliorate
frictions that disproportionately affect less advantaged decision makers. Examples abound,
from the selection of insurance plans (Abaluck & Gruber 2016; Johnson et al. 2013) to the

7
choice of college and major (e.g., Hoxby & Turner 2013; Wiswall & Zafar 2015) to the claiming of financial aid or tax benefits (Bettinger, Long, & Oreopoulos 2012; Bhargava & Manoli
2015; Page, Castleman, & Meyer 2016).
Two prior randomized experiments for public school choice found that providing simplified information about K-12 schools can improve families’ choices and later student outcomes
(Hastings & Weinstein 2008; Valant & Loeb 2014).3 In a seminal paper, Hastings and Weinstein mailed information about school test performance and odds of admission to randomlyselected parents in the Charlotte-Mecklenburg Public Schools. They found that providing
this information increased the fraction of parents choosing high-performing schools by 5 to
7 percentage points, on a baseline of 31%. Students whose families were induced by the
treatment to apply to a higher-performing school later benefited through higher test scores.
Valant and Loeb (2014) conducted a similar experiment in Milwaukee and Washington, D.C.
schools and at a high school fair in Philadelphia. They found that families applying to middle
schools selected higher-performing schools after being shown an informational booklet while
older students applying to high school chose lower -performing schools when given similar
information. To explain the latter finding, the authors speculate that students focused on
non-academic aspects of schools when making their choices.
In a related study at the postsecondary level, Hoxby and Turner (2013) randomly assigned
high-achieving, low-income high school students to receive direct mailings about applying to
college and their estimated net cost of attending a selective college or university. They found
this information had a sizable effect on the number and selectivity of institutions to which
students applied. Treatment students applied to one additional college, were 11 percentage
points more likely to apply to more than five colleges, and were 12 percentage points more
likely to apply to a selective college. This change in application behavior resulted in a higher
rate of admission to selective institutions (by 9 percentage points) and an increased likelihood
of attending a selective school (by 5 percentage points). All of these are “intent-to-treat”
3

Bobba and Frisancho (2016) conducted an informational experiment in Mexico City, where high school
admission is centralized and based entirely on an admissions test. They provided disadvantaged students the
opportunity to take a mock entrance exam and to receive performance feedback. Positive shocks to students’
beliefs about their own abilities increased their propensity to apply to a high school with an academic track
but did not increase the number of choices on students’ applications or the selectivity of those choices. The
focus of that study was more on students’ information about their own abilities than about schools per se.
As part of an ongoing school-based informational experiment in Ghana, Ajayi, Friedman, and Lucas (2017)
found that information sessions increased parents’ involvement in the high school choice decision.

8
effects; with only 40 percent of students recalling having seen the mailings, treatment effects
for the treated were plausibly much larger.
Several studies find that even small barriers in access to information can limit its use.
For example, in their study of Medicare Part D participants, Kling et al. (2012) found that
a letter with personalized information about drug plan costs increased plan switching by
11 percentage points over notification via a website with the same information. They cite
this as evidence of “comparison friction,” a gap between the availability of comparative
information and consumers’ use of it. In an experiment with eligible tax filers who failed
to claim the Earned Income Tax Credit, Bhargava and Manoli (2015) found that simple
eligibility reminders reduced “psychological frictions” associated with benefits claims and
substantially improved take-up, particularly among low earners with dependents and filers
less likely to speak English at home.
With respect to choice overload, a large literature finds that people have difficulty making
choices when faced with a large and complex set of options, and respond by using simplified
strategies or by delaying the decision (Iyengar 2010; Shafir, Simonson, & Tversky 1993;
Thaler & Sunstein 2008). The potential for this behavioral response is high in NYC, where
the environment is information-rich but overwhelming. Guidance counselors informed us
that the primary tool students use in NYC is the printed high school directory, which spans
more than 600 pages and includes detailed information about each school (Sattin-Bajaj et
al. 2018). Students can also learn about high schools from websites, other printed guides,
and by attending high school fairs where hundreds of schools are present.4
Research in higher education provides multiple examples of administrative barriers that
inhibit educational choices. In an experiment contrasting a treatment providing information about financial aid eligibility against a treatment providing eligibility information and
FAFSA filing assistance, Bettinger et al. (2009) found that filing assistance was necessary
for increasing financial aid application and subsequent college enrollment. Carrell and Sacerdote (2013) similarly found that information alone was not sufficient to increase college
attendance; rather, a direct mentoring approach was more effective. Despite the large economic returns to college, Bulman (2015) found that students’ propensity to take the SAT
4

In the year following our study, the NYC Department of Education introduced School Finder, a website
that allows users to search for and obtain information about NYC high schools. The site largely provides the
same information as the printed high school directory and does not make direct head-to-head comparisons
between schools.

9
was sensitive to the availability of nearby testing centers, and to default registration. Hoxby
and Turner’s (2013) study found that accompanying college information with fee waivers was
pivotal to increasing the number of college applications, even though their study population
was already likely to be eligible for fee waivers at selective institutions. The general finding
that emerges from these studies is that information coupled with supports can be effective
at helping individuals follow through with an educational decision or choice.
Finally, related work finds that reminders about discrete deadlines—rather than new information per se—can help educational decision-makers overcome procrastination or aversion
to administrative tasks. These experiments have been fielded primarily in the postsecondary
sector. Castleman and Page (2015), for example, found that text messages sent to students
the summer before matriculation increased their likelihood of actually enrolling in college,
thus reducing “summer melt.” Similarly, Page, Castleman, and Meyer (2016) found that
personalized text messages about FAFSA filing status increased financial aid receipt and
college matriculation. Page and Gehlbach (2017), using a virtual assistant to advise students on matriculation questions and deadlines, found that this tool increased enrollment by
3.3 percentage points. Our study is among the first to target middle school-aged students
and their families with reminders of this type.5
The interventions in our study were informed by the literature described here, and insights
from a pilot study we conducted in 2014-15. The pilot study included trial interventions and
interviews with guidance counselors in approximately 17% of all 8th grade serving schools
in NYC (Sattin-Bajaj et al. 2018).6 In the next section, we describe the NYC high school
choice process in greater detail, highlighting ways in which its design makes informational
and other supports potentially beneficial to students and their families.

2.2

High school choice in New York City

New York City uses a deferred acceptance algorithm to match 8th grade students with high
schools (Abdulkadiroğlu, Pathak, & Roth 2005, 2009). The algorithm takes into account
students’ ranked choices, available space, and schools’ own rankings and priorities. It is
“strategy-proof” in that students can do no worse than by ranking schools in their true
5

In one randomized controlled trial carried out at the K-12 level, Fryer (2016) sent text messages to
students reinforcing the link between education and labor market outcomes. While the messages appear to
have updated students’ beliefs, they did not measurably increase student effort or academic outcomes.
6
We piloted an early version of the intervention described here in nine schools.

10
order of preference. Put another way, there is no penalty for applicants to rank “aspirational”
schools highly even if their odds of admission at those schools are low. (Of course, students
must also carefully consider their next-best alternatives when doing so). In 8th grade,
students submit an application ranking up to 12 high school programs. An application
is required; no student is permitted to attend a default neighborhood school and avoid an
active choice, and only in rare cases are they guaranteed admission to their first-choice
school.7
High school applications are typically submitted in early December. Roughly 92% of
applicants are offered a school placement in March or April in the first round of matching,
and just over half are offered their first choice school. Students who do not receive an offer
in the first round re-apply in a second round to schools with open seats. Students not
matched in the second round are administratively assigned, and those who enter the system
after the second round work with a counselor or Family Welcome Center staff to discuss
available options. Subsequent transfers are difficult, although schools with available seats
admit students in 10th grade using the same algorithm.
NYC students choose from a large variety of high school types, including small themed
schools, large comprehensive schools, career academies, and performing arts schools.8 The
programs to which students apply have admissions methods and—in many cases—admissions
priorities that impact which students are admitted. Excluding the specialized (exam) high
schools, there are seven admissions methods: four that are academically non-selective (limited unscreened, unscreened, zoned, and screened for language), two that are selective
(screened and audition), and one that is partially selective with an intentionally balanced
test score distribution (educational option). Priorities give preference to students based on
residential or middle school location, and in the case of limited unscreened schools, demonstrated interest. For example, a school may give priority admission to residents of the same
borough or geographic area, and/or to students who visit an open house or information ses7

For example, students in combined middle-high schools are allowed to continue in their existing school
if it is their first choice. Admission to one’s zoned school is also guaranteed, where applicable, but zoned
schools no longer exist in most parts of the city. Since 2002, more than 48 large, predominately zoned high
schools have closed for poor performance (Kemple 2015; Quint et al. 2010). Our field experiment excluded
middle schools where the opportunity to continue into 9th grade was available.
8
Specialized high schools, charter schools, and the LaGuardia Performing Arts High School are outside of
the main high school choice process. The specialized high schools, which include the well-known Stuyvesant
High School and Bronx Science, admit students on the basis of an entrance exam. At the time of this study,
only 5.7% of 9th grade students were enrolled in charter schools.

11
sion and sign in. To maximize their odds of admission to a desired school, students must be
attentive to these program priorities and admissions requirements (Corcoran et al. 2017).

2.3

The potential for an informational intervention in NYC

An analysis of students’ high school choices and placements in the year prior to our study
demonstrates the potential for an intervention to support the school choices of disadvantaged
students. First, there is substantial variation in NYC high school performance. The average
4-year graduation rate for NYC high schools was 72% in 2014-15, with a standard deviation of
16 percentage points. One in four high schools had a graduation rate of 61% or lower. While
it remains an open question whether attending a school with a higher graduation rate has a
causal effect on high school completion, the available evidence suggests school quality matters
(e.g., Deming, Hastings, Kane, & Staiger 2014; Jackson 2010; Pop-Eleches & Urquiola 2013).
Especially relevant to this paper is quasi-experimental evidence from NYC which found that
attendance at a small, academically non-selective high school has significant positive effects
on the likelihood of graduation and students’ subsequent educational attainment (Bloom &
Unterman 2014; see also Abdulkadiroğlu, Wu, & Pathak 2013.). That study found effects as
large or larger for academically at-risk students—including low income, low-achieving, and
black students—leading us to expect that the students in our study stand to benefit from
attending higher-quality schools.9
Table 1 shows the results of descriptive regressions that highlight differences in the graduation rates of 1st-3rd choice high schools and school matches by student background. These
regressions use NYC high school applications data from 2014-15, one year prior to our intervention. Columns (1)-(4) show results without controls for prior achievement, while (5)-(8)
include these controls. The regressions without controls for prior achievement are useful in
that they show mean differences in the schools chosen and attended by different groups of
NYC students. Of course, these gaps cannot be entirely attributed to preferences, application behavior, or access to information, since geographic priorities, capacity constraints, and
academic screens affect the odds of admission to most schools. Both student choices and
matches will rationally respond to these supply-side constraints. The regressions with con9

Because their design relied on randomization via the matching algorithm, Bloom and Unterman (2014)
excluded schools that were not oversubscribed. Our interventions highlight schools with high graduation
rates—which tend to be oversubscribed—and thus the high-impact schools in their study appear regularly
on our intervention materials.

12
trols for achievement address this to some degree by describing differences in the graduation
rates of choices and placements for students with comparable prior achievement.
As seen in Table 1, less-advantaged subgroups (and boys) chose and were matched to
lower-performing high schools than their more-advantaged (and female) counterparts. For
example, the top three choices of students eligible for free lunch had a mean graduation rate
almost 4 percentage points lower than the top choices of students not eligible for free lunch
(col. 1). For reference, 4 percentage points is about 0.25σ in the distribution of high school
graduation rates in NYC in 2014-15. Free lunch eligible students were also much more likely
to rank schools with a graduation rate below 70% in their top three (+7.3 percentage points,
col. 3). Above and beyond the income gap, black and Hispanic students ranked schools
among their top three that had graduation rates at least 4 percentage points lower than
Asian and white students, and their top choices included a greater share of low graduation
rate schools (by 13-14 percentage points). These differences in choices in part explain why
these groups matched to schools with lower graduation rates (cols. 2 and 4). Free lunch
eligible students, for example, matched to high schools with graduation rates 4.2 percentage
points lower than the matches of non-free lunch eligible students, and they were 10 percentage
points more likely to match to a low graduation rate school. Black and Hispanic students
were 20-22 percentage points more likely to be matched to a low graduation rate school
(< 70%) than white and Asian students. When controlling for prior achievement (cols. 5-8),
these gaps attenuate, but all remain sizable. Controlling for residential borough—which
helps to address spatial variation in the supply of higher-performing schools—also narrows
these gaps, but all remain statistically significant and meaningful in size.
In addition to choosing lower-performing schools, our analyses find that disadvantaged
students are less likely to take steps that would increase their chances of admission to desired
schools. For example, priority admission to limited unscreened high schools is often given to
students who attend an open house or information session and sign in, or who sign in with a
school representative at a high school fair. In 2014-15, we find that only 41% of students who
ranked a limited unscreened school as their first choice had open house priority at that school
(see Table C.1 in the appendix). The rate was lower still for low income students (38%),
English learners (ELs; 33%), and special education students (36%).10 As we show in another
10

Open house priority is not a clean measure of actual open house attendance, since high schools self-report
whether or not a student attended an open house. In 2017, the NYCDOE announced it would eliminate the
open house priority in a future admissions cycle (Disare 2017).

13
paper (Corcoran et al. 2017), having information session priority substantially increases the
odds of admission to higher-performing limited unscreened high schools, which are typically
oversubscribed. The small high schools in the aforementioned Bloom and Unterman (2014)
study were all of this type.
While the regressions in Table 1 are purely descriptive, they are qualitatively consistent
with structural estimates of preference parameters that find disadvantaged families place
less implicit weight on academic quality when choosing schools (Abdulkadiroğlu, Agarwal,
& Pathak 2017; Harris & Larsen 2015; Hastings, Kane, & Staiger 2009). To the extent
variation in choices is at least in part driven by informational frictions, these findings suggest
that interventions to inform students’ choices could raise the quality of schools to which they
match.

2.4

Description of interventions

Informed by the existing literature and our understanding of the challenges faced by NYC
students choosing high schools, we developed a one-page informational tool called “Fast
Facts,” a customized list of 30 high schools for each middle school in our study. We designed
Fast Facts to be an accessible starting point for students, and a useful reference for school
performance information and admissions requirements. The intent was not for students to
limit their search to these schools, but rather to begin with a initially smaller set of choices,
and to be more aware of higher-performing schools in their proximity.
Schools recruited to the study were randomized into three treatment groups and a control
group (details provided later). Eighth grade students in the first treatment arm (FF1)
received the basic Fast Facts school list described above. Students in the second treatment
arm (FF2) received Fast Facts and a supplementary list of academically non-selective schools
that give priority admission to students who attend an open house or information session
and sign in. This group could also opt in to receive weekly text message reminders about
open house dates, time, and locations. Schools in the third treatment arm (FF3) received
Fast Facts and a supplementary list of high school programs organized by academic interest
area. Both supplemental lists were attached to Fast Facts, on the inside of a bi-folded sheet.
All treatment schools received a separate one-page insert of “screened language” programs
citywide that serve recent immigrants and students learning English.
Materials specific to each intervention were delivered direct to students by trained re-

14
search assistants via a 40-minute standardized lesson in a group setting (often but not always
in a classroom). This lesson explained how to use the tools and emphasized the importance of graduation rates, admissions methods, and location when making school choices.
All materials—including text messages—were available in English and Spanish, and lessons
were delivered in Spanish when requested by the school guidance counselor. Control schools
did not receive any materials until after the study was complete. (These schools were later
provided Fast Facts lists that they could used with their 7th grade students). School visits
took place in September (43 visits), October (72 visits) and early November 2015 (5 visits).
Table 2 provides an overview of the treatment groups and intervention materials. Importantly, we generated Fast Facts and the two supplementary lists for all study schools, regardless of treatment or control assignment. Doing so provided “counterfactual” treatments that
characterize the information each school would have received had they been in a particular
treatment group. The same was done for weekly text messages. Among other things, this
aids in estimating the treatment effect of the intervention on specific school choices. Additional details about the intervention materials follow, and examples are pictured in Appendix
Figures A.1-A.4. For a full description of the methodology used to generate high school lists,
see Appendix B.
Fast Facts: Fast Facts is a one-page custom list of 30 proximate high schools with a 4-year
graduation rate above the city median (≥70%). Unique lists were generated for each middle
school. Except in rare cases where the rule had to be relaxed, Fast Facts high schools were
within a 45-minute trip by public transportation from the middle school. New schools (which
lack graduation rates) and academically screened high schools were included but limited to
a maximum of ten each.11 Our procedure for selecting Fast Facts high schools prioritized
shorter travel times, and schools were listed in descending order by graduation rate (as in
Hastings & Weinstein 2008). The front of the sheet listed the 30 high schools, along with
their borough, graduation rate, travel time, page number in the High School Directory, and
11

A list of the highest-performing high schools in a geographic area could be dominated by screened schools,
which are selective and have a lower odds of admission. We limited the number of these schools to make the
list relevant to a heterogeneous student population. NYC has a large number of recently-opened high schools
that did not yet have a graduating cohort as of 2015-16, and we did not wish to exclude these entirely. As
explained in Appendix B, we used data on 9th grade credit accumulation to predict graduation rates for
these schools. The imputed graduation rate did not appear on Fast Facts; rather, the graduation rate reads
“*new school” with a note explaining that it had recently opened and therefore lacked a graduation rate.

15
admissions method(s). The reverse side explained admissions methods in plain language and
offered guidance for applying to schools of each type (“What do I need to do?”). Students
were reminded of the importance of listing 12 choices on their application to increase their
odds of a match. Descriptive characteristics of high schools appearing on Fast Facts are
reported in Appendix Table B.1. The mean graduation rate of schools appearing on the
average Fast Facts list was 81.5%.
Academically non-selective school supplement: The non-selective school supplement
was intended to increase student participation in open houses and information sessions for
high schools that give priority admission to students who attend and sign in. Unique supplementary lists were generated for each middle school. Programs on the supplementary
list were drawn from schools on the Fast Facts sheet (if the limited unscreened type) and
more were added when necessary. A total of 18-25 limited unscreened programs appeared
on each list.12 The criteria for inclusion was the same as Fast Facts, and programs were
listed in descending order by their school’s graduation rate. The supplementary list emphasized the importance of attending and signing in at open houses, and included a calendar on
which to write dates and times of scheduled admissions events. Parents and students were
invited to sign up for weekly text message reminders about upcoming information sessions
and fairs.13 Descriptive statistics for high schools appearing on the (combined) Fast Facts
and non-selective school supplement are reported in Appendix Table B.2.
Schools by academic interest area: The supplementary list of schools by academic
interest area was intended to help students identify high schools that match their academic or
career interests. Unique lists were generated for each middle school. A total of 49 programs
were featured on each supplementary list, with seven in each of the following categories:
Performing & Visual Arts; Health Professions; “Academically Selective”; STEM; Humanities
& Global Studies; Law, Government, Civics, & History; and Business & Communication.
12
Unlike Fast Facts, which did not include program codes (since schools may offer multiple programs), the
non-selective school supplement listed the 4-character program code required for the student application.
The graduation rate was not shown on the supplement, since in most cases it appeared on the front page
(Fast Facts).
13
Schools in the FF2 treatment arm were given a 3-digit numeric code that they could text to our project
phone number to sign up. This code was prominently displayed on the non-selective school supplement, and
posters were given to FF2 treatment schools to advertise the text messaging opportunity. See Appendix B
for details on our process for generating text messages.

16
The criteria for inclusion was the same as Fast Facts. The supplement showed the school and
program name, borough, program code, and admissions method. Multiple programs from the
same school were permitted to appear. Descriptive statistics for high schools represented on
the (combined) Fast Facts and academic interest area supplement are reported in Appendix
Table B.3.
Text message reminders: Two text message reminders were sent weekly to FF2 students
and/or family members who opted in. In most cases, these texts contained information
about an open house taking place that week at an academically non-selective high school.
There was no central calendar for these events, so we compiled them ourselves from high
schools and other sources.14 Reminders were specific to the receiving school and were chosen
using an algorithm that prioritized schools with higher graduation rates and fewer scheduled
open house opportunities. Roughly 40% of the high schools referenced in the text messages
appeared on the school’s non-selective high school supplement. The remaining 60% were
drawn from other schools in the borough holding open houses that week. (It was not possible
to populate open house reminders each week exclusively from a middle school’s non-selective
supplement).
Screened language insert: The screened language insert was a one-page list of 42 programs
citywide that exclusively serve students who are new to the United States or who are learning
English. To be included on the list, the program must have been in a school with a 6-year
graduation rate above 70%. All treatment schools were provided this insert to ensure that
students in this special population were reached.
Control condition: As noted earlier, the NYC context is information-rich, and in theory
students can access many resources about high schools. These include fairs, school counselors and other middle school personnel, friends and family, websites and apps, and the
printed directory. Students in our control group have access to these resources, and thus
any estimated treatment effect is relative to “business as usual.” While there was nothing
to prevent treatment schools from sharing our materials with control schools, we actively
14

If too few open houses were scheduled in a given week, we sent general information about a high school
instead (e.g., its name, location, and public transit access). Our team compiled a list of 762 open house
dates via the High School Directory, the NYCDOE website, individual school websites, and weekly phone
calls to high schools. See Appendix B for details.

17
discouraged this, and emphasized the customized nature of the information for their school.
(The middle school name was also prominently displayed at the top of each school list).
It is worth reiterating that our intervention materials were delivered to students, rather
than parents or school counselors. The materials were designed with students in mind, but
we expected (and encouraged) them to share the information with their families. Counselors
were also encouraged to integrate the resources into their advising as they saw fit. All
materials were delivered in the form of colorful printed flyers, rather than through digital
means.15 This decision was made to reduce comparison friction (Kling et al. 2012), to
facilitate head-to-head comparisons of school graduation rates, and to support students with
limited or no access to the internet at home.
The existing literature provides little guidance about the relative roles of students, parents, and school personnel in secondary school choices. Sattin-Bajaj (2014), however, described immigrant students in NYC as “unaccompanied minors” making high school choices
with little adult guidance. Valant and Loeb (2014) also noted that 8th grade students in
their study were deeply involved in their school decision. Qualitative interviews during our
pilot study confirmed that NYC students play a significant role in shaping their application,
especially in disadvantaged households where adults may face language barriers or time
constraints, leaving the ultimate decision to the child (Sattin-Bajaj et al. 2017).16
Nevertheless, the existing literature points to potential perils of providing information to
students. In Valant and Loeb (2014), for example, older students more often chose lowerquality high schools after being shown informational guides. This may reflect the influence
of sports and extracurricular offerings, which Harris and Larsen (2015) found were valued
highly by older students. While we acknowledge the importance of activities to students
when making school choices, our materials purposefully omitted this information, which can
easily be found in the high school directory.
15

In 2016-17, we conducted a “scale-up” experiment that tested the relative benefits of paper versus digital
access to Fast Facts. Results from the scale-up study will be available at a later date.
16
Ajayi et al. (2017) report that only 34% of secondary school parents in Ghana had the final say in their
child’s school choices. There is a related literature on parent involvement in college choices, particularly
those of lower-income and first-generation students, which finds that students often navigate these processes
alone (Pérez & McDonough 2008; Perna 2000; Venezia & Kirst 2005).

18

3
3.1

Data and Research Design
Data sources

For our analysis we used school and student-level administrative data from the NYCDOE.17
Our main analytic dataset was constructed by matching student records from the 2015-16
high school admissions process with demographic and other student background information.
Characteristics of high schools, including graduation rates, were obtained from the NYCDOE
2015-16 High School Directory.
High school admissions data include each student’s ranked high school choices (up to 12
programs in the first round), his or her eligibility and priority group for each choice, rankings
of the student by the school in cases where screening is permitted, and their final school
assignment. From this information we created variables characterizing students’ choices,
matches, and other outcomes. These variables fall into three categories: (1) school presence
on the Fast Facts and/or supplementary lists, (2) high school characteristics, and (3) other
admissions process and enrollment outcomes. Examples of the second category include
the school’s 4-year graduation rate, whether the graduation rate was below the Fast Facts
threshold of 70%, travel time from the middle school to the high school, location in the same
borough, applications per seat in the prior year (a measure of demand), and admissions
method (e.g. screened or limited unscreened). All of these variables were created for the
1st, 1st-3rd, and all choices, as well as the matched and enrolled school. Examples in
the third category of outcome variables include the number of choices submitted (up to
12); open house priority status for limited unscreened programs; ranking of the student by
screened programs; whether or not the student was matched to his or her 1st choice, 1st-3rd
choice, or any choice in the first round; participation in the second round after a successful
match; and matriculation to the matched school in 9th grade. Other outcome variables
include measures of within-application variability in the graduation rate of school choices
and consistency in academic interest area. Variability in graduation rates was calculated
as the difference between the highest and lowest graduation rate of schools appearing on a
student’s application. Within-application consistency in interest area was calculated as the
highest percentage of choices from the same interest area.
17

Access to de-identified and confidential data was possible through a secure data use agreement with the
Research Alliance for New York City Schools.

19
Demographic and other background characteristics measured prior to our experiment
include student race/ethnicity, gender, free or reduced price lunch eligibility, special education services received, EL and foreign born status, and 7th grade English Language Arts
(ELA) and mathematics test scores standardized to mean zero and standard deviation one
by subject.18 These student-level variables were used as covariates to increase precision of
our impact estimates and for estimating subgroup effects. Aggregates of these variables at
the middle school level were also included as covariates. Means for the full study sample of
19,109 students are reported in Table 3. Notably, students in the study sample are majority
Hispanic (55%) and free lunch eligible (74%). 16% of students are classified as ELs, and 49%
speak a language other than English at home. The average student scored 0.29-0.31σ below
the city average in 7th grade ELA and math, and 11% were missing 7th grade test scores,
suggesting they were not enrolled in the NYC public schools in the prior year.

3.2

Recruitment and treatment assignment

We recruited 165 schools from the more than 500 schools serving 8th grade students in
NYC, focusing on some of the highest-poverty schools in the city.19 Appendix Tables A.1
and A.2 report mean characteristics and prior choice outcomes from 2014-15 for schools in
our study, schools in the sampling and recruitment frames, and all schools citywide. Schools
in the study were disproportionately located in the Bronx and Brooklyn and enrolled a
higher share of Hispanic students, ELs, and free lunch eligible students than the citywide
average. Two thirds were in the highest two quartiles of residential poverty in NYC, and
the remaining were in the next highest quartile. Students in study schools applied to high
schools with lower graduation rates, on average, than did students in the full population,
and a larger share of schools on their application were academically non-selective. 23 schools
participated in our 2014-15 pilot study, although just 8 of these received a Fast Facts list in
that year.
To increase power over a simple cluster randomized trial in which schools are randomly
assigned to treatment conditions, we randomized schools within blocks of similar schools
located in the same borough. Blocks were matched quadruplets of schools selected using a
18

We also have 8th grade ELA and math test scores, but admission to academically screened programs is
dependent upon 7th grade performance.
19
A detailed description of our sampling and recruitment procedures is provided in Appendix A. We
excluded combination middle-high schools, special education schools, and schools in Staten Island.

20
Mahalanobis distance measure of difference between schools (see Bruhn & McKenzie 2009;
King et al. 2007). School variables used in the matching procedure included prior choice outcomes (e.g., the mean graduation rate of first round matches in 2013-14), prior achievement
(mean ELA and math scores in 2013-14), economic disadvantage (the percent eligible for free
or reduced price meals), and school size.20 The 23 schools in our pilot study were blocked
separately. By matching on observable characteristics before randomization and controlling
for the randomization blocks in our regressions, we increase the likelihood that the schools
assigned to the treatment and control groups are similar at baseline, and account for some
of the extant variation in our outcomes.
Tables A.4 and A.5 in the appendix report descriptive statistics and the results of balance
tests for observed school characteristics in our three treatment arms and control group. Other
than pilot study participation, there are no statistically significant differences in mean school
characteristics across groups, indicating the randomization was successful. Additionally,
there are no statistically significant differences in the mean characteristics of high schools
appearing on the Fast Facts and supplementary lists generated for the treatment and control
groups (Appendix Tables B.1-B.3).

3.3

Estimating treatment effects

For a student i in middle school j, we are interested in the effect of each of the three treatments (indicator variables F F1j , F F2j , and F F3j ) on an outcome Yij . These outcomes,
described in Section 3.1, include applications to schools listed on Fast Facts and the supplementary school lists, characteristics of high school choices, final match and enrolled school,
and other outcomes of the admissions process. β1 -β3 are the parameters of interest for the
casual effect of the three treatments. We include controls for randomization block Wb and a
vector of student and school demographic characteristics measured prior to the intervention
(Xi and Sj respectively). Standard errors ij are adjusted to allow for clustering at the
middle school level, the unit of randomization. The estimating equation is therefore:
Yij = β1 F F1j + β2 F F2j + β3 F F3j + γXi + δSj +

39
X

αb Wbj + ij

(1)

b=1
20

See Appendix A for details. 2013-14 was the most recent data on choices available at the time of
matching.

21
To remove bias due to student mobility, we assigned students to their middle school of
record in October of 8th grade. Recall that the “treatment” in our experiment consists of
the provision of materials via a short in-school presentation (and in the case of FF2, the
offer of text message reminders). Beyond our inference from systematic differences in the
specific choices of treatment and control group students, we cannot observe whether students
actually received or used the materials. Thus, our main impact estimates are best interpreted
as intent-to-treat (ITT).
We additionally estimate the local average treatment effect (LATE) on characteristics of
the matched high school for students induced by the intervention to apply to specific schools
on Fast Facts. While there are multiple pathways through which our intervention might
affect choices and/or the final school match, the most obvious and direct way is through
application to schools specifically on our customized lists. In a first-stage regression, we
regress the number of student i ’s choices from Fast Facts (Nij ) on the three indicators of
treatment assignment (F F1j -F F3j ), student and school covariates, and block indicators:
Nij = λ1 F F1j + λ2 F F2j + λ3 F F3j + θXi + πSj +

39
X

φb Wbj + ηij

(2)

b=1

Characteristics of the final matched high school Yij are then regressed in the second stage
on the fitted values of Nij from equation (2):
cij + ρXi + ψSj +
Yij = ψ N

39
X

ωb Wbj + υij

(3)

b=1

In the second stage, ψ is interpreted as the extent to which a student’s final school match was
affected by applying to additional schools from Fast Facts. It is possible the interventions
influenced students’ choices and outcomes through other paths correlated with application
to more Fast Facts schools; for example, our materials might have raised general awareness
about high school graduation rates or the importance of listing 12 schools. To abstract from
individual student responses, we alternatively substitute for Nij the middle school average
number of Fast Facts schools appearing on high school applications. (This is calculated as a
leave-out mean where the focal student i is excluded). This measure has some advantages,
since schools vary in their propensity to apply to schools on Fast Facts in part due to
idiosyncratic variation in the relevance of our high school lists. As described in Section 2.4,

22
we used a common set of rules to generate Fast Facts lists for each middle school. For a
variety of reasons, these lists will be better fits to some middle schools than others.21
A description of our approach to analyzing text messaging effects on choices is provided
in a later section.

4
4.1

Main Results
Impact on high school choices

Tables 4 - 7 provide our main impact estimates. Given the experimental design and our
interest in variability across treatments, we focus our discussion on the separate estimates
by treatment arm. However, we include pooled impact estimates in these tables and in
the Appendix. While we find a number of interesting and meaningful differences across the
treatment arms, few were precise enough to be statistically significant. Consequently, any
observed differences across treatment groups should be taken as suggestive.
Table 4 reports estimates of the intervention effects on students’ high school choices. Understanding whether students used the lists we provided is complicated by the fact that high
schools with higher graduation rates—like those on Fast Facts—receive more applications in
general. To address this, we created Fast Facts and supplementary lists for schools in the
control group and calculated the percent of high schools their students chose from the list
they would have received had their school been assigned to receive one. The top panel of
Table 4 shows the estimated effect of the three interventions on the percent of 1st, 1st-3rd,
and all choices drawn from the custom lists. Each impact estimate pertains to the list(s) of
high schools actually received by the treatment group.
We found students in all three treatment arms were significantly more likely to apply to
schools on their custom lists than were students in the control group. For example, students
who received Fast Facts alone (FF1) were 9.3 percentage points more likely to rank a Fast
21

In a post-implementation analysis, we noticed that some middle schools were significantly less likely
to apply to high schools on Fast Facts than others, both in the current and prior year (see Figure 2).
For example, Bronx students frequently applied to high schools in Manhattan, but the opposite was not
true, even holding commuting time constant. Consequently, application to Fast Facts schools was lower for
Manhattan middle schools when the list included high schools in the Bronx. Another plausible explanation
for variation in take-up is measurement error in the travel time reported on Fast Facts. We estimated this
using public transit time from the middle to high school, which is a good approximation of home-to-school
travel time for the average student in some schools, but less so in others.

23
Facts school as their first choice than students in the control group. Similarly, the percent
of top three and all choices from Fast Facts were 10.4 percentage points higher among FF1
students. Each of these point estimates is statistically significant at the 0.001 level, and
these effects are large given that 37.2 (33.5) percent of control students’ top three (all)
choices appeared on their “counterfactual” Fast Facts list.22 With a control group standard
deviation of 32.6, a 9-10 percentage point increase in choices from Fast Facts represents a
0.28 − 0.31σ effect. To put this in perspective, a 10.4 percentage point increase in top three
choices is equivalent to 1 in 3 students listing an additional Fast Facts school among their
application’s top three choices.
The extent to which students used the Fast Facts list depended on whether supplementary
lists were provided. Students who received Fast Facts alone (FF1) chose comparatively more
schools from their customized list than students who received additional information (FF2
and FF3). In contrast to FF1, students in the FF2 and FF3 treatment arms were 3.3 and
4.4 percentage points more likely to rank a school from their combined lists as their first
choice than students in the control group, though only the latter is statistically different
from zero. The percent of top three choices from their respective lists were 5.5 percentage
points higher among FF2 and FF3 students (in both cases p <0.01 and an effect size of
0.17σ). The percent of all choices from their lists were 6.2 and 6.8 percentage points higher,
respectively (p <0.001 and an effect size of 0.27−0.29σ). In sum, it appears our interventions
had measurable effects on students’ propensity to choose high schools from our custom lists.
The point estimates suggest greater usage among students who received Fast Facts alone
(FF1), but we cannot reject the hypothesis of an equal effect across treatment arms.23 The
pooled estimates suggest a 5.7, 7.4, and 8.2 percentage point impact on 1st, top three, and
all choices from Fast Facts, respectively.
While students in all treatment groups were more likely to apply to schools on their
intervention-specific lists, these lists each included a minimum of 30 schools. This raises
the question of which schools students included on their application, and where they ranked
them. Figure 1 shows estimated treatment effects by individual choice (1-12). The top panel
shows that students’ higher-ranked choices were significantly more impacted than their lower22

Because Fast Facts consists of high-performing high schools within a short travel distance from the
middle school, it is not surprising that more than 1 in 3 of the control group’s choices are these schools.
23
We examined other measures of application to Fast Facts schools, including the use of school-level data
to estimate differential changes over time in the propensity to apply to these high schools. See Figure 2.

24
ranked choices. This is relevant as the majority of students match to one of their top choices.
The bottom two panels suggest that the FF1 treatment had a larger impact on students’
propensity to apply to the last 15 high schools (of the 30) than the first 15. This finding
is intuitive when looking at the control group means and recalling that Fast Facts schools
were sorted in descending order by graduation rate. A relatively high percentage of the
control group’s choices (22-27%) came from the first 15 schools on their “counterfactual”
Fast Facts list, while a much lower percentage (10-11%) were drawn from the last 15. Thus,
control group students were already more likely to apply to the first 15, which comprise
some of the highest-performing schools in their vicinity. The last 15, which were also above
our graduation rate threshold, appear to have been more novel options to the students in
our study. This is noteworthy in a context where a surplus of applications to the city’s
highest-performing schools can result in congestion and limit the general equilibrium effect
of applying to quality schools.
Finally, we note that students in the FF2 treatment arm were significantly more likely
to apply to schools appearing on the academically non-selective school supplement than
students in the control group, by 6.7 percentage points (Appendix Table C.10). While not
statistically different from FF1 and FF3, the point estimate for FF2 is nearly twice as large,
suggesting FF2 students were receptive to the schools highlighted on their supplemental list.
At the same time, we noted earlier the smaller apparent effect of FF2 on students’ overall
application relative to FF1. As we show later, these findings together reflect a shift away
from academically screened choices toward non-selective school choices. We did not observe
a significant difference between FF3 and other students in the propensity to apply to schools
specifically listed on the academic interest area supplement.24

4.2

Impact on graduation rate of choices and matches

Table 5 reports the estimated effects of our interventions on the graduation rates of students’
high school choices and matches. Students in the three treatment arms did not apply to
higher-performing high schools, on average, but they were less likely to apply to a low
graduation rate school (<70%) than students in the control group. Though we expected to
see an increase in the average graduation rate of students’ choices, the control group average
24

One exception is a small, statistically significant effect on the propensity to list a school from the interest
area supplement as a first choice (not shown).

25
was already quite high, averaging 81% for choices 1-3 (approximately the 70th percentile in
the distribution of NYC high schools in 2015-16, and the average for high schools appearing
on Fast Facts). We did find that the informational interventions reduced within-application
variability in graduation rates by 1.8 to 2.1 percentage points, on average, relative to the
control group. The largest point estimate was for FF2 (p < 0.01), with a reduction of
2.0 percentile points in graduation rate variability, an an effect size of 0.16σ. Remarkably,
the mean within-application range in graduation rates for applications in the control group
exceeded 30 percentage points. The impact of the intervention on variability appears to
have come from a reduced propensity to apply to low graduation rate schools. In particular,
students in the FF1 treatment arm were 3.0 percentage points less likely to apply to schools
with graduation rates below 70%, a statistically significant effect (p < 0.10). With a baseline
standard deviation in the control group of 31.6 points, this represents an effect size of 0.09σ.
The effects of FF2 and FF3 on within-application variability are statistically insignificant
and closer to zero.
Of greater consequence to students’ educational opportunities, we find that students who
received Fast Facts alone (FF1) matched to schools with a higher average graduation rate
than students in the control group, by 1.7 percentage points, a statistically significant effect
(p < 0.01) and an effect size of 0.12σ. Moreover, students in two of the three treatment
arms were significantly less likely to match to a high school with a graduation rate below
70%. Students who received Fast Facts alone (FF1) were 6.3 percentage points less likely
to match to a low graduation rate school, a 14.6 percent reduction relative to the control
group. Students who also received supplemental lists (FF2 and FF3) were 5.1 percentage
points (p < 0.10) and 3.0 percentage points (statistically insignificant) less likely to match to
a high school with a graduation rate below 70%, respectively. Each of these point estimates
are meaningful effects, given that 43 percent of students in the control group matched to a
low graduation rate school.
We also estimated treatment effects on the graduation rate of students’ enrolled school
in 9th grade, which can differ from the final match for several reasons. First, students may
appeal their match or apply for a transfer if they experience a residential move. Second,
some students enroll in a charter high school or are admitted to one of the nine specialized
high schools, which in NYC are outside the main high school choice process (admission to
the specialized high schools was not common in our study population). Third, students

26
may leave the district or are held back in middle school. Our point estimate for the impact
of FF1 on the graduation rate of the enrolled school is smaller than that for the matched
school (1.1 versus 1.7 percentage points). We cannot, however, reject the hypothesis of equal
effects. The same holds for the impact on enrollment in a low graduation rate school versus
match to a low graduation rate school. The smaller point estimates suggest that the effect
of informational interventions for school choice can be muted when there are competing
alternatives outside the main assignment process.

4.3

Impact on other school choice characteristics and outcomes

Table 6 shows that students in treatment schools were 3.1 to 3.5 percentage points more
likely to be matched to their first choice high school (a 7-8% increase over the control group,
in which 44.6% received their first choice), and 2.1 to 3.5 percentage points more likely to be
matched to one of their top three choices (a 3-5% increase over the control group, in which
73.3% received a top three choice). Rather than applying to higher-performing schools, students in treatment schools applied to fewer lower-graduation rate schools and to more schools
where their odds of admission were higher. Table 7 shows that treated students were more
likely to apply to academically non-selective schools, schools located in the same borough as
the middle school, and schools in lower demand, all factors associated with a greater odds of
admission. To provide an example, FF2 and FF3 students applied to programs with roughly
10% fewer applications per seat in 2014-15 than the programs on control students’ applications. Students in the FF2 treatment group applied to 23 percent fewer limited unscreened
high schools in their top three (7.9 percentage points on a baseline of 34.7%), which again
is consistent with their receipt of the non-selective high school supplement. The increase in
applications to academically non-selective programs appears to have come at the expense
of applications to screened programs, which fell in all treatment groups, with a statistically
significant decline in FF1 and especially FF2 (3.0 and 5.7 percentage points, respectively).
Several other aspects of treatment students’ choices may have contributed to a higher
likelihood of matching to their top choices. First, students in the FF1 treatment arm included
more same-borough schools in their top three than the control group (by 6.6 percentage
points, a 0.18σ effect; p < 0.01). Given the frequent use of geographic admissions priorities,
this may have improved their odds of a match. Point estimates for FF2 and FF3 were
also positive but statistically insignificant. Despite the impact on same-borough choices and

27
our prioritizing of geographically proximate schools when generating high school lists, we
did not find a significant difference between treatment and control groups in the estimated
travel time to their top three high school choices. Second, students in the FF1 and FF3
treatment arms were more likely to have been ranked by a screened or audition school.
(Students generally must be ranked by a selective admissions program to be considered for
admission). Conditional on listing at least one screened or audition program in their top
three, FF1 students were ranked by 6.7 percent more of these choices than the control group
(p < 0.001), and FF3 students were ranked by an additional 4.7 percent (p < 0.05). These
are small to modest-sized effects, given the control group standard deviation of 43.0. The
mechanism behind this increased propensity to be ranked by screened schools is less clear.
Students may have been more attentive to the admissions criteria of selective programs,
something emphasized on our intervention materials. Alternatively, the interventions may
have altered the composition of screened schools to which students applied (perhaps to a
less selective set), or altered the composition of students applying to screened schools, if
the marginal student was induced to apply to more non-selective schools. Third, there is
suggestive evidence that students in treatment schools were more likely to have open house
priority at non-selective limited unscreened schools ranked in their top three. These point
estimates are positive—and largest for students in the FF2 treatment which emphasized
open house attendance in its printed materials and text messages—but none are statistically
significant (Table 7).25
The informational interventions did not have an impact on the number of first round
choices, despite our explicit encouragement to list 12 schools (Table 6). In fact, there is
some evidence that the FF2 and FF3 treatments reduced their average number of choices by
approximately 0.6. This had no apparent effect on the odds of matching in the first round,
however, and as noted earlier, treated students were more likely to receive their first choice.26
Students in the FF1 and FF2 treatment arms were less likely to participate in the second
round of high school admissions conditional on being matched in the first round, although
the point estimates are below the threshold of statistical significance. If negative, this might
25

We did not find that the FF3 treatment yielded more internal consistency in the academic interest areas
of school choices; if anything, treated students’ choices appear to be less concentrated in one interest area
than students in the control group. The only specific area for which we found a statistically significant
increase in applications among FF3 students was Performing & Visual Arts (not shown).
26
More than 93% of students in the control group were matched in the first round.

28
indicate greater satisfaction with their initial match. We find the opposite effect for students
in the FF3 treatment arm, however, where the percentage of students returning to the second
round was 1.6 percentage points higher than that in the control group (p < 0.10).
Roughly 88 percent of students in control schools ultimately enrolled in their matched
school in 9th grade. We find the FF1 and FF3 interventions increased students’ likelihood of
doing so, by 2.6 and 1.8 percentage points, respectively (p < 0.01 and p < 0.10). This may
also indicate greater satisfaction with their match. Notably, we find that FF1 students were
1.5 percentage points less likely to enroll in a charter school for 9th grade than students in the
control group. This is a relatively large effect when compared to the 5 percent of students
in control schools that enrolled in a charter high school. The difference is important, as
it tends to weaken the intervention’s effect on enrolled school performance. (Charter high
schools in 2015-16 had higher average graduation rates than schools in the traditional high
school match process to which our study students matched).

4.4

Sensitivity analyses

We conducted several sensitivity analyses for our main impact estimates. First, for the
graduation rate models (Table 5) we imputed graduation rates for schools that did not yet
have a graduating cohort, using the same method applied when generating Fast Facts lists
(see Appendix A). The graduation rates used in Section 4.2 were missing for schools projected
to have a graduation rate above 70% that were included on Fast Facts lists—as well as those
projected to have a graduation rate below 70%—to which some students applied. The use
of imputed graduation rates increased the number of students used in the estimation, but
had little effect on the impact estimates (see Appendix Table C.2). Second, we re-estimated
all models excluding schools that participated in our pilot study (Appendix Table C.3), and
excluding charter schools, which may counsel students differently about high school choice by
steering them to charter schools (Appendix Table C.4). The results were again very similar.
Finally, we examined the impact of our interventions on other measures of high school
quality beyond graduation rates, including a 9th grade “on-track” indicator, a measure of
college readiness, and the percent of students who feel safe at the high school (Appendix
Table C.5). The first two are strongly correlated with four-year graduation rates and thus
yielded estimates qualitatively similar to those in Table 5. An exception is a negative and
statistically significant effect of the FF3 treatment on the mean on-track and college readiness

29
rates at students’ choices and matches, which corresponds to the negative FF3 point estimate
in Table 5. We find a small but statistically significant negative effect of the interventions on
the perceived safety at treatment students’ choices and matches (the latter only significant
for FF3, p < 0.10) For example, the FF2 and FF3 interventions led to a 0.84 and 0.92
percentage point reduction in the mean safety rating of students’ top 3 choices, respectively
(p < 0.05 and p < 0.01). These are modestly-sized effects given the control group standard
deviation of 6.8. The mechanism behind this change is less clear, although it is consistent
with the treatment students in our study applying to more schools in their home borough
(largely the Bronx and Brooklyn). It is also notable that perceptions of safety are not as
strongly correlated with high school graduation rates as one might expect, with a school-level
correlation coefficient of 0.43, as compared to 0.85 between graduation and college readiness
rates.

4.5

Impact of applying to Fast Facts schools on matched school

As noted earlier, our main impact estimates are intent-to-treat, interpreted as the effect of
providing 8th grade students with custom high school lists and supplementary information
(and in the case of FF2, text message reminders). Of course, some fraction of students will
not reference or use the materials at all. This suggests the ITT underestimates the impact
of using the provided lists to inform one’s application. While the ITT may be the policy
parameter of interest, the effect of the informational interventions on students who drew
choices from our lists is also informative.
As described in Section 3.3, we estimated local average treatment effects of the interventions on measures of matched school performance, for students induced by the intervention to
apply to our specific school recommendations. We instrument for the number of a student’s
choices appearing on Fast Facts using the randomly assigned treatment groups.27 The first
stage—as well as results in Table 4—indicate that students in treatment schools responded
to the intervention by applying to more schools from these lists. Under the exclusion restriction assumption that the interventions had no effect on students’ choices except through
the identity of specific choices, the 2SLS estimator will identify the LATE of applying to
additional schools from the Fast Facts lists.
27

Rather than differentiate between the three intervention-specific school lists, we reduce this measure to
choices from the basic Fast Facts list provided to all treatment groups.

30
Of course, the interventions may influence a student’s choices and outcomes through
other pathways that increase applications to Fast Facts schools and changes in outcomes.
To abstract from individual student actions, we substitute for Nij (the student’s number of
choices from Fast Facts) with the leave-out mean of Fast Facts choices at the school level.
The school-level average has some advantages, given extant variation in schools’ propensity
to apply to schools on Fast Facts. The top panel of Figure 2 shows treatment and control
school variation in the percent of all and top three choices appearing on Fast Facts. In the
control group, the percentage of top three choices appearing on their “counterfactual” Fast
Facts ranges from above 60% to below 20%, suggesting these lists were better-aligned with
some middle schools’ typical choice set than others.28 Similar heterogeneity is observed when
looking at within-school changes over time in the percent of choices appearing on Fast Facts,
shown in the bottom panel of Figure 2. The school-level instrument aims to exploit some of
this variation in schools’ baseline propensity to apply to Fast Facts schools.
First and second stage estimates are reported in Table 8. The first two columns report
estimates using the student-level number of choices from Fast Facts (all choices and top 3),
while the estimates in the latter two columns use the school-level mean number of choices
from Fast Facts. The results are comparable. First stage effects of treatment on the number
of choices from Fast Facts mirror the main student-level results in Table 4, in which random
assignment to FF1-FF3 was associated with statistically significant increases in choices from
the custom lists. For example, the student-level measures indicate that exposure to FF1
resulted in 0.78 more choices from Fast Facts overall, or 0.30 among the top three.
The 2SLS estimate for the impact of applying to an additional Fast Facts school on
the graduation rate of the matched school are 2.2 and 5.4 percentage points for all choices
and the top three, respectively, using the student-level measure, and 2.2 and 5.1 percentage
points using the school-level measure. The corresponding point estimates for match to a low
(<70%) graduation rate school are also sizable: a 7.3 and 21.2 percentage point reduction
in this probability, using the student-level measure, and a 7.0 and 19.9 percentage point
reduction using the school-level measure. The interpretation is that students induced to list
one additional Fast Facts school on their application—especially when included among their
top three choices—matched to significantly higher-performing schools that they otherwise
would have. Similarly, these students saw a sharp reduction in their likelihood of matching
28

For more on this see the footnote in Section 3.3.

31
to low graduation rate school.

5

Heterogeneity of effects across subgroups

Our informational interventions were motivated in part by the observation that disadvantaged students in NYC—including free lunch eligible, black and Hispanic, and students who
do not speak English at home—are more likely to choose and subsequently match to high
schools with lower graduation rates (Table 1). Gaps remain even after conditioning on prior
achievement, which affects students’ odds of admission to academically screened schools.
While we targeted high-poverty middle schools for this experiment, our study sample still
exhibits heterogeneity by income, achievement, race/ethnicity, EL and special education
status, and other factors (Table 3).
It is plausible that the take-up and treatment effects of our interventions vary by these
measures of student background. For example, our tools might be more valuable to comparatively “information-poor” groups and those with fewer at-home or in-school supports
for making school choices. Other groups, such as families who speak a language other than
English at home, may derive greater value from the simplified presentation of our materials.
Finally, some groups may be better positioned to take advantage of these tools than others.
Comparatively high-achieving students, for example, will be more competitive for the academically screened schools included on our lists. Lower-achieving students may benefit from
the inclusion of higher-performing but academically non-screened schools on the lists.
Tables 9 and 10 report separate impact estimates for select subgroups, focusing on four
key outcomes: the percent of top three high school choices from the intervention-specific
school list, match to a first-choice high school, the graduation rate of the matched high
school, and match to a high school with a graduation rate below 70%. Following Table 1,
we look specifically at estimates by family income (free or reduced price lunch eligible versus
not), language spoken at home (English, Spanish, or other non-English), prior achievement
(bottom or top quartile in 7th grade math), “new to the school district” (i.e., not enrolled in
a NYC public school in 7th grade), and race/ethnicity.29 We include students not enrolled
in a NYC public school in 7th grade as a subgroup since are plausibly least likely to be
29

Subgroup estimates with a pooled treatment effect are reported in Appendix Tables C.6 and C.7. Impact estimates by gender, immigrant status, EL status, disability status, and other groups are reported in
Appendix Tables C.8 and C.9.

32
informed about the school choice process. As a reference, the first rows of Tables 9 and 10
show our main impact estimates for the full study sample.
We find both disadvantaged and comparatively advantaged groups used our informational
tools to make their school choices. However, disadvantaged students were typically no more
likely to use them than their more-advantaged counterparts in the same schools, and in
some cases, take-up was greater among more advantaged student populations. The first
three columns of Table 9 report the impact of the interventions on the percent of 1st-3rd
choices from the Fast Facts and supplementary lists. The effect on usage was positive and
statistically significant for nearly every subgroup and treatment arm. However, Asian, white,
and Hispanic students in treatment schools drew considerably more choices from our custom
lists than black students.30 The point estimates are largest for Asian and white students,
though the standard errors are too large to rule out effects equal to those for the other
racial/ethnic groups. In the same way, the intervention had a larger impact on higherachieving students’ choices than lower-achieving students’ choices. This is most striking for
FF1, where the percentage of top three choices from Fast Facts increased by 16 percentage
points for top quartile students (relative to the control group) but only 6.8 percentage points
for bottom quartile students. We observe few differences in take-up between lower-income
(FRPL) and non-poor (non-FRPL) students.
In a notable exception to this pattern, the interventions had larger effects on the choices
of students who speak a language other than English at home than the choices of students
in English-speaking households. For example, we find the percentage of top three choices
appearing on Fast Facts was 12.7 and 13.7 percentage points higher for Spanish-speaking
and other non-English language students in FF1, respectively, versus the control group.
For English-speaking students, the estimated effect was 6.2 percentage points. The gaps
are generally larger for the FF2 and FF3 treatments. To take one example, we find that
the percentages of top three choices appearing on the (combined) Fast Facts and interest
area supplement were 8.0 and 8.9 points higher for Spanish-speaking and other language
students, respectively, versus students in the control group. The effect for English-speaking
students was 1.8 percentage points and statistically insignificant. The difference in FF3
effects may suggest something about the relative appeal of academic and career interest
30

It is important to note that students identifying as “white” in our study sample come from a wide variety
of backgrounds. 23 percent were born outside of the United States, with the largest shares born in Yemen,
Uzbekistan, Russia, Algeria, and Egypt. Only 46% of white students spoke English at home.

33
areas to immigrant families in NYC.
The latter three columns of Table 9 report the impact of the interventions on the propensity to be matched to a first-choice high school. Here again, the interventions broadly had a
larger impact on comparatively advantaged students. For example, we find that non-FRPL
students in FF1 and FF2 schools were 3.7 and 9.4 percentage points more likely to match
to their first-choice high school than students in the control group, respectively (p < 0.10
and p < 0.001). The effects were not statistically significant for FRPL students. FRPL
students in the FF3 treatment arm were 3.8 percentage points more likely to match to their
first-choice high school than students in the control group (p < 0.05). The FF3 effect was
not significant for non-FRPL students. In the same way, the effect on first-choice match
rates was significant for students in English-speaking households (FF1 and FF2) but not
for students who speak a different language at home. (For FF3 the largest point estimate
is for students who speak Spanish at home, at 4.4 percentage points, p < 0.10). Likewise,
the point estimates for FF1 and FF3 are larger for students in the top (vs. bottom) quartile
of achievement. Together, these findings may be explained by the fact that comparatively
advantaged students applying to selective schools face fewer barriers to admission to these
schools. For example, higher-achieving students are more likely to qualify for admission to
the academically selective schools on our list (which tend to have higher graduation rates).
These barriers may also explain why the large treatment effects on usage for students who
do not speak English at home fail to translate into higher match rates. Finally, we note the
particularly large positive effects of FF1 and FF2 on the match rates of students new to the
school district (14-21 percentage points for first choices). This subgroup, however, is small
(N=801).
We find little evidence that the interventions led any group to apply to choices with a
higher average graduation rate. In fact, we find negative and marginally significant effects
for non-FRPL students (FF2 and FF3), FRPL students (FF3), students who speak English
at home (FF3), students who scored below the median in 7th grade (FF3), and students new
to the district (FF2).31 Despite this finding, we see in the first three columns of Table 10 that
most subgroups in FF1 treatment schools matched to high schools with a higher graduation
rate than the control group. These include FRPL and non-FRPL eligible students (1.7
31

These are not shown here, but see the pooled estimates in Appendix Tables C.6 and C.7. Spanishspeaking students in FF2 treatment schools applied to high schools with a higher graduation rate, a 2.7
percentage point difference over the control group.

34
and 1.5 percentage points), students who speak Spanish at home (1.4 points) or English at
home (1.3 points), students in the bottom quartile of achievement (1.7 points), and black
(1.3), Hispanic (1.8), and Asian students (4.3 points). The largest point estimate was for
students new to the school district (5.4 percentage points). Given the standard errors on
these estimates, we cannot reject the hypothesis that these subgroup effects are the same.
However, these results do show that the positive effect of FF1 on the graduation rate of the
matched school is not driven any particular subgroup.
The final three columns of Table 10 show that most subgroups in treatment schools
were less likely to match to a high school with a graduation rate below 70%. Here again,
however, the point estimates tend to be larger for comparatively advantaged students. For
example, FF1 students in the top quartile of achievement were 11.3 percentage points less
likely to match to a low graduation rate school than those in the control group, compared
to 6 percentage points for students in bottom quartile. (The difference is larger for FF3,
but smaller for FF2). Similarly, Asian and white students in treatment schools saw the
greatest reductions in their likelihood of matching to a low graduation rate school, relative
to black and Hispanic students. The point estimates for FRPL and non-FRPL students were
comparable. Finally, students in treatment schools who speak a language other than English
at home generally saw larger reductions in their likelihood of matching to a low graduation
rate school, particularly when assigned the FF1 treatment. For example, treatment students
who speak Spanish at home were 6.3 percentage points less likely to match to a low graduation
rate school when assigned FF1, while students who speak another non-English language were
9.5 percentage points less likely to do so. All point estimates for students who speak English
at home are negative but statistically insignificant. Again, the differences in these subgroup
effects are statistically imprecise.
In summary, both disadvantaged and comparatively advantaged students in our study
schools responded to the interventions by applying to more high schools on our customized
lists. While this was true for all three treatment arms, the effect was commonly largest when
students were provided Fast Facts alone (FF1). Few subgroups responded to the intervention
by applying to higher graduation rate schools, but all subgroups in treatment schools were
less likely to match to a school with a graduation rate below our 70% threshold. Almost all
subgroups offered the FF1 lists on average matched to a higher graduation rate high school.
It is notable that, in some cases, comparatively advantaged students appeared to benefit

35
more from the interventions by applying and matching to more high schools on our lists. For
example, white, Asian, and high-achieving students saw the largest usage effect, and these
choices translated into a higher match rate to their first-choice high school and lower odds
of matching to a low graduation rate school. While we might have expected larger effects
for less advantaged and lower-achieving students, it is important to keep in mind that all
students in our study attended high-poverty middle schools. It may be that the supports
for high school choice in these schools are targeted to lower-achieving students, creating
an opportunity to intervene for higher-achieving students (Avery & Pathak 2017). Finally,
students from non-English speaking families were particularly impacted by the intervention,
a significant finding given nearly half of our study population does not speak English at
home.
While all of the subgroup differences noted here are interesting and warrant additional
research, we emphasize that—in most, but not all cases—the estimates are not precise enough
to reject the hypothesis of equal effects.

6

Text messaging effects

Estimating the marginal effect of the text messaging component of FF2 on students’ choices
and other process outcomes, including open house priority status, is complicated by several
factors. First, FF2 students were not randomly assigned to receive text messages. All 8th
graders in FF2 treatment schools were given printed materials and the opportunity to receive
text message reminders. Thus, it is conceptually difficult to separate the two treatment
components. Second, participation was voluntary and take-up rates varied (see Appendix
B). Many participants did not opt in until the last 4-5 weeks of the study. Third, text
messages were sent for only a select subset of limited unscreened high schools. If enrolled for
the full study period of 11 weeks, a family would receive at most 22 open house reminders.
In practice, due to repeat messages, the average treatment school was notified about 19.4
unique high schools and 17.4 unique high schools holding open houses. Families who signed
up late received even fewer.
In sum, the causal effect of text messaging alone is not identified by our design, and the
ITT effect of text messages alone is likely to be small unless the treatment-on-treated effect
is large. That said, we can look descriptively at students’ propensity to apply to schools

36
that were the subject of our text messages. The first row of Table 11 reports the results of a
regression in which the outcome Yij is defined as the percent of top three choices for which
student i ’s middle school j was sent a text message. (Recall we have both the actual messages
sent and counterfactual messages that would have been sent to the other treatment arms and
control group had they been eligible to receive them). The effect is small, but positive and
statistically significant for students in the FF2 treatment. Whether these effects are due to
the text messages themselves is less clear. As Table 7 showed, students in FF2 schools were
induced to apply to more limited unscreened schools in general. The open house reminders
pertained to limited unscreened schools, and it is possible the effect shown in Table 11 is
driven by this increase.
In an attempt to address this, we estimated impacts on students’ propensity to apply
to high schools for which their middle school was sent a text message, but the high school
did not appear on their Fast Facts list or non-selective school supplement. More than half
of all text messages to a middle school pertained to high schools that did not appear on
their printed list, since the non-selective school supplement was insufficient to populate text
messages every week. These results are reported in the last two rows of Table 11. We observe
no effect of FF2 or any treatment on this outcome. It is important to keep in mind that
this outcome represents applications to a rather small subset of schools that—for whatever
reason—were chosen for a text message but did not appear on the school’s non-selective
supplement. Only 2.7 percent of the control group ranked one of these schools as their first
choice, suggesting these schools are mostly outside the typical choice set.
Finally, we find a marginally statistically significant effect (p < 0.10) of FF2 on the
number of student choices that were the subject of text messages and for which the student
had open house priority (second row of Table 11). The point estimate is small (0.12), but
meaningful relative to the control group standard deviation (1.1). However, the coefficient
is similar to that estimated for FF1, which did not participate in text messaging, so it is
unlikely to be due to the messaging component.
Taken together, while our experiment was not designed to test the separate effects of
FF2 materials and text messaging, the data do not suggest a strong response to the specific
text messages that were sent. This may be due to low take-up, or the fact that the messages
focused on a relatively narrow set of schools. Of course, the texting component may have
affected students’ choices and behavior in other ways, by generally underscoring the impor-

37
tance of open houses. Or, students may have attended the open house and decided not to
apply to the school, an outcome we cannot observe.

7

Discussion

The New York City high school choice process is inherently complex, involving hundreds of
school options. To increase their prospect of enrolling in a school that will help them succeed
academically, rising 9th graders and their families must be informed of their available choices
and be attentive to admissions methods, screening criteria, and other priorities that affect
their odds of admission. While opportunities exist to learn more about the process and
available school options, prior evidence suggests that families with limited time and resources
will nevertheless struggle with the system’s scale and complexity.
Our field experiment was designed to address these challenges. Using a set of standardized
rules, we created custom one-page lists of high schools for each participating middle school.
Our aim was not for students to restrict their search to these high schools, but to begin with
an initially smaller, focused set of choices with salient performance information. Recognizing
that many of the students in our study population would not be competitive for admission
at academically selective schools, our lists included a mix of selective and non-selective high
schools. All had a strong track record of graduating their students within four years. Our
materials explained key process elements in plain language and emphasized the importance of
listing 12 choices, attending open houses, and meeting academic or audition requirements for
admission. Unlike prior work, our intervention was focused on students as the key decision
maker for school choice.
Several key findings emerged from this work. First, students in treatment schools responded to our informational tools by applying to high schools on our custom lists. How
students used these lists further depended on whether additional information was provided.
Students who also received supplementary information were less likely to draw choices from
our lists than those who received Fast Facts alone. Second, students in treatment schools
made choices that resulted in a higher-performing high school match. This is not because
they chose higher-performing schools, but rather because they avoided low graduation rate
schools and applied to schools where their odds of admission were higher. These included less
academically selective schools, schools with fewer applications per seat, and schools where

38
the student was more likely to have geographic priority. We found suggestive evidence that
students engaged more with the process, as captured by their likelihood of attending an open
house or meeting the requirements to be ranked by an audition or screened school. Third, all
subgroups appeared to use our informational tools, although some appeared to benefit more
by choosing and matching to more schools from our custom lists. Students in non-English
speaking households were especially impacted by the intervention and were substantially less
likely to match to a low-performing school.
Our experiment was conducted in high-poverty middle schools under the presumption
that students in these schools would be most likely to benefit from them. Because moreand less-advantaged groups vary in their access to and use of information, we expected the
interventions would reduce socioeconomic and racial disparities in choice behaviors and outcomes. The assumption underlying this is that more advantaged groups are already near the
ceiling of information use, so disadvantaged groups have more to gain. Our results suggest
reasons to be wary of this claim, since disadvantaged students were no more likely to use our
informational tools than comparatively advantaged students in the same schools. Moreover,
higher-achieving students were better positioned to take advantage of our tools, since their
odds of matching to the academically screened schools on our lists were higher. The implication is that informational interventions for school choice are not clearly inequality-reducing.
To be sure, there are students who could be more ambitious with their top-ranked choices
and apply to higher-performing schools. Under the deferred acceptance algorithm used to
assign students to high schools in NYC, there is no penalty to ranking “reach” schools highly
on one’s application. On the other hand, it is as common for students to mix popular—
and often highly selective—high schools with markedly lower-performing schools on their
application. The odds of admission are low at the former, leading to a match at the latter.
In this case the student would be better served by giving more consideration to schools that
are performing well but have higher odds of admission. These schools may be less well-known
“under the radar” options. Our interventions directed students to these schools.
It is natural to be concerned about the general equilibrium implications of an informational intervention like ours operating at scale. In a city in which the supply of seats at
high-performing schools is limited, an intervention that encourages more students to apply to
already-oversubscribed top-performing schools will not necessarily improve equity or overall
access to school quality. This is particularly true in a city like New York, where nearly a third

39
of all high school programs use academic or other screening mechanisms (e.g., auditions) for
admission, rather than pure lotteries. We are encouraged that our intervention—carried out
in 118 treatment schools—did not increase congestion at a small subset of schools. Rather,
students in all treatment groups were more likely to receive their first-choice high school.
Of course, it is difficult to extrapolate to a wider dissemination of these tools. For similar
reasons, it is difficult to determine whether the intervention would pass a cost-benefit test
at scale. The intervention described in this paper was labor-intensive, since we delivered a
short presentation in each school, and cost approximately $13 per treated student.
As school choice options have grown across the country, so has our knowledge that not
all families and children are equally prepared to navigate these often-complex systems. If
a goal of these programs is to reduce disparities in access to higher-performing schools, our
results suggest that disadvantaged students and their families need additional supports to
realize this outcome. We implemented school-level informational interventions, rather than
targeting only certain groups, because these most closely mimicked school districts’ policy
options. More narrow targeting of information, which could potentially reduce inequality, is
likely to be controversial and difficult to implement in practice.

References
Abaluck, J., & Gruber, J. (2016). Improving the quality of choices in health insurance markets.
National Bureau of Economic Research Working Paper No. 22917.
Abdulkadiroğlu, A., Agarwal, N., & Pathak, P. A. (2017). The welfare effects of coordinated
assignment: Evidence from the New York City high school match. American Economic Review,
107(12), 3635—3689.
Abdulkadiroğlu, A., Hu, W., & Pathak, P. A. (2013). Small high schools and student achievement:
Lottery-based evidence from New York City. National Bureau of Economic Research Working
Paper No. 19576.
Abdulkadiroğlu, A., Pathak, P. A., & Roth, A. E. (2005). The New York City high school match.
The American Economic Review, 95, 364—367.
Abdulkadiroğlu, A., Pathak, P. A., & Roth, A. E. (2009). Strategy-proofness versus efficiency
in matching with indifferences: Redesigning the NYC high school match. American Economic
Review, 99(5), 1954—1978.

40
Abdulkadiroğlu, A., Pathak, P. A., & Walters, C. R. (2018). Free to choose: Can school choice
reduce student achievement? American Economic Journal: Applied Economics, 10(1), 175—206.
Ajayi, K. F., Friedman, W. H., & Lucas, A. M. (2017). The importance of information targeting
for school choice. American Economic Review, 107(5), 638—643.
Avery, C. & Pathak, P. A. (2017). Missing “one-offs” in high school choice in New York City.
Unpublished book chapter.
Bettinger, E. P., Long, B. T., Oreopoulos, P., & Sanbonmatsu, L. (2012). The role of application
assistance and information in college decisions: Results from the H&R Block FAFSA experiment.
The Quarterly Journal of Economics, 127(3), 1205—1242.
Bhargava, S., & Manoli, D. (2015). psychological frictions and the incomplete take-up of social
benefits: Evidence from an IRS field experiment. American Economic Review, 105(11), 3489—
3529.
Bloom, H. S., & Unterman, R. (2014). Can small high schools of choice improve educational
prospects for disadvantaged students? Journal of Policy Analysis and Management, 33(2), 290—
319.
Bobba, M., & Frisancho, V. (2016). Learning about oneself: The effects of performance feedback
on school choice. IZA Discussion Paper No. 10360.
Bruhn, M., & McKenzie, D. (2009). In pursuit of balance: Randomization in practice in development field experiments. American Economic Journal: Applied Economics, 1(4), 200—232.
Bulman, G. (2015). The effect of access to college assessments on enrollment and attainment.
American Economic Journal: Applied Economics, 7(4), 1—36.
Burgess, S., Greaves, E., Vignoles, A., & Wilson, D. (2015). What parents want: School preferences
and school choice. The Economic Journal, 125(587), 1262—1289.
Carrell, S. E., & Sacerdote, B. (2013). Late interventions matter too: The case of college coaching
New Hampshire. National Bureau of Economic Research Working Paper No. 19031.
Castleman, B. L., & Page, L. C. (2015). Summer nudging: Can personalized text messages and
peer mentor outreach increase college going among low-income high school graduates? Journal of
Economic Behavior & Organization, 115, 144—160.
Condliffe, B. F., Boyd, M. L., & DeLuca, S. (2015). Stuck in school: How social context shapes
school choice for inner-city students. Teachers College Record, 117(3), 1—36.
Corcoran, S. P., Jennings, J. L., Cohodes, S. R., & Sattin-Bajaj, C. (2017). Administrative complexity as a barrier to school choice: Evidence from New York City. Unpublished working paper,
New York University.

41
Deming, D. J., Hastings, J. S., Kane, T. J., & Staiger, D. O. (2014). School choice, school quality,
and postsecondary attainment. American Economic Review, 104(3), 991—1013.
Disare, M. (2017, June 6). City to eliminate high school admissions method
that
favored
families
with
time
and
resources.
Chalkbeat.
Retrieved
from
https://www.chalkbeat.org/posts/ny/2017/06/06/city-to-eliminate-high-school-admissionsmethod-that-favored-families-with-time-and-resources/
Fryer Jr., R. G. (2016). Information, non-financial incentives, and student achievement: Evidence
from a text messaging experiment. Journal of Public Economics, 144, 109—121.
Glazerman, S., & Dotter, D. (2017). Market signals: Evidence on the determinants and consequences of school choice from a citywide lottery. Educational Evaluation and Policy Analysis,
39(4), 593—619.
Gross, B., DeArmond, M., & Denice, P. (2015). Common enrollment, parents, and
school choice: Early evidence from Denver and New Orleans. Seattle. Retrieved from
http://www.crpe.org/sites/default/files/cpe-report-common-enrollment-denver-nola.pdf
Harris, D. N., & Larsen, M. (2015). What schools do families want (and why)?
New Orleans:
Education Research Alliance for New Orleans. Retrieved from
http://educationresearchalliancenola.org/files/publications/Technical-Report-FinalCombined.pdf
Hastings, J. S., Kane, T. J., & Staiger, D. O. (2009). Heterogeneous preferences and the efficacy
of public school choice. Unpublished working paper.
Hastings, J. S., & Weinstein, J. M. (2008). Information, school choice, and academic achievement:
Evidence from two experiments. Quarterly Journal of Economics, 123(4), 1373—1414.
Hoxby, C., & Turner, S. (2013). Expanding college opportunities for high-achieving, low income
students. Stanford Institute for Economic Policy Research Discussion Paper 12014. Retrieved from
http://www-siepr.stanford.edu/repec/sip/12-014.pdf
Iyengar, S. (2010). The art of choosing. New York, NY: Twelve.
Jackson, C. K. (2010). Do students benefit from attending better schools? Evidence from rulebased student assignments in Trinidad and Tobago. The Economic Journal, 120(549), 1399—1429.
Jochim, A., DeArmond, M., Gross, B., & Lake, R. (2014). How parents experience
public school choice. Seattle: Center for Reinventing Public Education. Retrieved from
http://www.crpe.org/publications/how-parents-experience-public-school-choice
Johnson, E. J., Hassin, R., Baker, T., Bajger, A. T., & Treuer, G. (2013). Can consumers make
affordable care affordable? The value of choice architecture. PloS One, 8(12), e81521.

42
Kemple, J. J. (2015). High school closures in New York City: Impacts on students’ academic
outcomes, attendance, and mobility. New York: Research Alliance for New York City Schools.
King, G., et al. (2007). A “politically robust” experimental design for public policy evaluation,
with application to the Mexican Universal Health Insurance program. Journal of Policy Analysis
and Management, 26(3), 479—506.
Kling, J. R., Mullainathan, S., Shafir, E., Vermeulen, L. C., & Wrobel, M. V. (2012). Comparison
friction: Experimental evidence from Medicare drug plans. The Quarterly Journal of Economics,
127(1), 199—235.
Lareau, A., Adia Evans, S., & Yee, A. (2016). The rules of the game and the uncertain transmission
of advantage. Sociology of Education, 89(4), 279—299.
Page, L. C., Castleman, B., & Meyer, K. (2016). Customized nudging to improve
FAFSA completion and income verification. SSRN Electronic Journal. Retrieved from
https://doi.org/10.2139/ssrn.2854345
Page, L. C., & Gehlbach, H. (2017). How an artificially intelligent virtual assistant helps students
navigate the road to college. Working paper.
Pérez, P. A., & McDonough, P. M. (2008). Understanding Latina and Latino college choice: A
social capital and chain migration analysis. Journal of Hispanic Higher Education, 7(3), 249—265.
Perna, L. W. (2000). Differences in the decision to attend college among African Americans,
Hispanics, and Whites. The Journal of Higher Education, 71(2), 117—141.
Pop-Eleches, C., & Urquiola, M. (2013). Going to a better school: Effects and behavioral responses.
American Economic Review, 103(4), 1289—1324.
Quint, J. C., Smith, J. K., Unterman, R., & Moedano, A. E. (2010). New York City’s changing high
school landscape: High schools and their characteristics 2002-2008. New York: MDRC. Retrieved
from http://www.mdrc.org/publications/543/overview.html
Sattin-Bajaj, C., Jennings, J. L., Corcoran, S. P., Baker-Smith, E. C., & Hailey, C. (2018).
Surviving at the street level: How counselors’ implementation of school choice policy shapes
students’ high school destinations. Sociology of Education, 91(1), 4671.
Sattin-Bajaj, C. (2014). Unaccompanied minors: Immigrant youth, school choice, and the pursuit
of equity. Cambridge: Harvard Education Press.
Shafir, E., Simonson, I., & Tversky, A. (1993). Reason-based choice. Cognition, 49(1), 11—36.
Thaler, R. H., & Sunstein, C. R. (2008). Nudge: Improving decisions about health, wealth, and
happiness. New York: Yale University Press.

43
Valant, J., & Loeb, S. (2014). Information, choice, and decision-making: Field experiments with
adult and student school choosers. Unpublished working paper.
Venezia, A., & Kirst, M. W. (2005). Inequitable opportunities: How current education systems
and policies undermine the chances for student persistence and success in college. Educational
Policy, 19(2), 283—307.
Wiswall, M., & Zafar, B. (2015). Determinants of college major choice: Identification using an
information experiment. The Review of Economic Studies, 82(2), 791—824.

44

Figure 1: Impact of informational intervention on students’ propensity to choose Fast Facts
schools

Notes: each point estimate comes from a separate regression where the outcome is an indicator equal to one
if the student chose a Fast Facts school as their k th choice (k =1 to 12). For clarity of presentation, a 95%
confidence interval is shown for the FF1 point estimate only.

45

Figure 2: School-level variation in the percent of choices from Fast Facts

Notes: each point is a school. The top row shows the percent of choices (either top three or all) that appeared
on Fast Facts in 2015-16. The bottom row shows the 2014-15 to 2015-16 change in the percent of choices
that appeared on the 2015-16 Fast Facts sheet.

-1.558***
(0.129)
-0.661***
(0.138)
-3.902***
(0.141)
-3.692***
(0.156)
2.450***
(0.158)
1.511***
(0.0817)

Spanish at home

Other language at
home (not English)

Black

Hispanic

Asian

Female

69,058

57,326

NO

2.087***
(0.113)

0.135
(0.227)

-5.850***
(0.218)

-6.149***
(0.196)

-0.297
(0.195)

-1.308***
(0.177)

-1.060***
(0.236)

-4.237***
(0.150)

69,058

NO

-4.283***
(0.236)

-0.982*
(0.458)

12.90***
(0.452)

13.99***
(0.407)

0.351
(0.398)

3.413***
(0.373)

0.201
(0.485)

7.275***
(0.308)

57,326

NO

-6.683***
(0.394)

5.627***
(0.789)

20.24***
(0.758)

21.66***
(0.680)

0.144
(0.678)

4.811***
(0.614)

1.867*
(0.821)

10.12***
(0.521)

69,058

YES

1.056***
(0.0773)

1.700***
(0.149)

-1.305***
(0.148)

-0.778***
(0.136)

-0.203
(0.130)

-0.703***
(0.121)

-0.531***
(0.157)

-2.032***
(0.101)

57,326

YES

1.519***
(0.108)

-0.226
(0.215)

-2.907***
(0.209)

-2.391***
(0.190)

0.285
(0.186)

-0.522**
(0.167)

-0.630**
(0.223)

-2.353***
(0.143)

69,058

YES

-3.258***
(0.231)

0.315
(0.445)

8.225***
(0.444)

7.749***
(0.406)

-0.843*
(0.387)

1.524***
(0.363)

-0.0992
(0.469)

4.159***
(0.303)

57,326

YES

-5.190***
(0.388)

6.400***
(0.769)

13.16***
(0.748)

12.53***
(0.681)

-1.427*
(0.665)

2.816***
(0.600)

1.042
(0.800)

5.638***
(0.514)

With test score controls:
(5)
(6)
(7)
(8)
Graduation rate
% Low graduation rate
Choices 1-3
Match
Choices 1-3
Match

Notes: descriptive regressions using data from the 2014-15 high school admissions process. The regression models also include controls
for special education status, “other race,” and “other language spoken at home” (coefficient estimates not shown). Models in columns
(5)-(8) include a quadratic function of 7th grade ELA and math z -scores as controls. Sample sizes are smaller for match regressions, as
a greater proportion of matched high schools versus chosen schools lack published graduation rates (i.e., are newer schools). Standard
errors in parentheses, * p < 0.05 ** p < 0.01 *** p < 0.001.

N

NO

-0.823***
(0.168)

Reduced price eligible

Quadratic in reading and math
and math z-scores

-3.668***
(0.106)

Free lunch eligible

Without test score controls:
(1)
(2)
(3)
(4)
Graduation rate
% Low graduation rate
Choices 1-3
Match
Choices 1-3
Match

Table 1: Regression-adjusted differences in the graduation rates of high school choices and matches, by student
background, 2014-15

46

47

Table 2: Overview of treatment arms
Treatment group

Fast Facts

EL insert

Supplementary list

Other

FF1

Yes

Yes

None

None

FF2

Yes

Yes

Nonselective
schools (18-25)

Opt-in to weekly text message
reminders about open houses

FF3

Yes

Yes

Programs by
academic interest area

None

Control

No

No

No

None

In all three treatment groups, trained research assistants delivered the materials via a 40-minute
standardized lesson in a group setting. All materials were available in both English and Spanish.

48

Table 3: Student-level descriptive statistics, full study sample 2015-16
Mean

Std. Dev.

Student achievement:
7th grade ELA z -score
-0.285
7th grade math z -score
-0.313
Missing 7th grade ELA (%)
9.3
Missing 7th grade math (%)
7.2

0.924
0.913
–
–

School characteristics:
Grade 8 enrollment
% Female
% Asian
% Black
% Hispanic
% White
% SWDs
% ELs
% Free/reduced price lunch
8th grade math
8th grade ELA
Missing 8th grade math (%)
Missing 8th grade ELA (%)

199.7
48.5
8.7
29.7
54.9
5.7
21.8
16.9
90.4
287.3
288.5
11.0
10.2

178.3
4.2
12.2
25.6
24.5
9.4
5.6
9.4
10.9
17.1
11.0
–
–

School in pilot study (%)
Charter school student (%)

10.6
4.2

–
–

%
Student characteristics:
White
Black
Hispanic
Asian
Other race/ethnicity
Female
Free lunch eligible
Reduced price eligible
Special education
English learner (EL)
Immigrant

5.7
30.0
54.9
8.5
0.9
49.0
74.2
3.7
21.7
16.1
16.0

Language spoken at home:
Spanish
36.7
Other non-English
12.7
English
50.6
Borough of middle school:
Brooklyn
Manhattan
Queens
Bronx

34.9
11.8
16.6
36.7

Notes: Authors’ calculations using data from the NYC DOE. N=19,109

49

Table 4: Impact of informational interventions on choices from Fast Facts lists
FF1

Treatment groups
FF2
FF3

Pooled

Fast Facts
only

Fast Facts +
nonselective
supplement

9.268***
(2.082)

3.257
(2.055)

4.410*
(2.148)

5.689**
(1.735)

1st-3rd choices

10.430***
(2.112)

5.503**
(2.051)

5.482**
(1.957)

7.425***
(1.739)

All choices

10.430***
(1.835)

6.159***
(1.782)

6.740***
(1.754)

8.228***
(1.559)

40.5

41.0

43.4

40.5

1st-3rd choices

37.2
[32.6]

37.9
[32.6]

40.5
[32.8]

37.2
[32.6]

All choices

33.5
[23.1]

34.2
[23.1]

37.3
[23.1]

33.5
[23.1]

List of schools:
% of choices from
intervention-specific list:
1st choice

Control group mean [SD]:
1st choice

Fast Facts +
interest area Fast Facts
supplement
only

Notes: each cell in the top panel is the estimated effect of the FF1, FF2, FF3, or pooled treatment on
the percent of 1st, 1st-3rd, or all choices from the intervention list of schools. The FF1-FF3 columns
relate to the intervention-specific school lists. Pooled estimates relate to the list of schools common to all
treatment groups (Fast Facts). Means and standard deviations for the control group are shown in the bottom
panel. N=19,109 student observations in each regression. All models include the following controls: school
randomization block, student race/ethnicity, female, free lunch eligible, reduced-price lunch eligible, special
education, EL, foreign born, quadratic in 7th grade ELA and mathematics z-scores, missing indicators for
z-scores and other covariates, and indicator for students in schools that received a treatment in our 2014-15
pilot study. School-level controls include a charter indicator, 8th grade enrollment, percent female, percent
by race/ethnicity, percent with disabilities, percent EL, and mean 8th grade math and ELA scores. All
school controls are measured in the year prior to treatment. Standard errors in parentheses, adjusted for
clustering at the school level. + p < 0.10 * p < 0.05 ** p < 0.01 *** p < 0.001.

50

Table 5: Impact of informational interventions on graduation rate of choices and matches
Treatment groups
FF2
FF3

Pooled

0.326
(0.480)

-0.367
(0.665)

-1.019+
(0.553)

-0.339
(0.447)

80.9

11.2

Final matched school

1.664**
(0.571)

0.526
(0.662)

-0.066
(0.596)

0.742
(0.488)

73.4

13.7

9th grade enrolled school

1.066+
(0.582)

0.298
(0.678)

-0.154
(0.619)

0.425
(0.501)

74.3

14.2

-3.008+
(1.718)

-0.755
(2.221)

0.363
(2.080)

-1.210
(1.684)

23.1

31.6

Final matched school

-6.274*
(2.418)

-5.147+
(2.959)

-3.346
(2.865)

-4.914*
(2.322)

42.9

49.5

9th grade enrolled school

-5.133*
(2.422)

-3.768
(2.918)

-3.072
(2.864)

-4.034+
(2.320)

40.7

49.1

-1.780**
(0.647)

-2.051**
(0.665)

-1.803**
(0.618)

-1.857***
(0.503)

30.2

13.7

FF1
Graduation rate:
1st-3rd choices (mean)

Graduation rate <70%:
1st-3rd choices (mean)

Within-application
variability in gradrate:
All choices (range)

Control group
Mean
SD

Notes: each row reports estimates from two regressions. The first includes indicator variables for the
separate treatment groups (FF1-FF3). The second pools the three treatment groups into one indicator
variable. Sample sizes vary from 16,075 (9th grade enrolled school) to 19,090 (variability in graduation rates).
All models include the following controls: school randomization block, student race/ethnicity, female, free
lunch eligible, reduced-price lunch eligible, special education, EL, foreign born, quadratic in 7th grade ELA
and mathematics z-scores, missing indicators for z-scores and other covariates, and indicator for students in
schools that received a treatment in our 2014-15 pilot study. School-level controls include a charter indicator,
8th grade enrollment, percent female, percent by race/ethnicity, percent with disabilities, percent EL, and
mean 8th grade math and ELA scores. All school controls are measured in the year prior to treatment.
Standard errors in parentheses, adjusted for clustering at the school level. + p < 0.10 * p < 0.05 ** p < 0.01
*** p < 0.001.

51

Table 6: Impact of informational interventions on admissions and enrollment outcomes
FF1
Round 1:
Number of Round 1 choices

Treatment groups
FF2
FF3
Pooled

Control group
Mean
SD

-0.067
(0.227)

-0.570*
(0.266)

-0.603*
(0.255)

-0.390+
(0.209)

8.7

3.0

Matched to 1st choice

3.104+
(1.651)

3.530+
(1.794)

3.539*
(1.655)

3.370*
(1.351)

44.6

–

Matched to 1st-3rd choice

2.116
(1.437)

2.725+
(1.590)

3.499*
(1.527)

2.773*
(1.233)

73.3

–

-1.432
(0.906)

-1.355
(1.001)

1.640+
(0.913)

-0.304
(0.720)

12.6

–

9th grade enrollment
in matched school

2.577**
(0.954)

-0.289
(1.023)

1.787+
(1.034)

1.558+
(0.810)

88.0

–

Enrolled in a charter
high school

-1.506+
(0.774)

-0.207
(0.852)

-0.666
(0.769)

-0.869
(0.650)

5.2

–

Round 2 and later:
Participation in Round
2 after main round match

Notes: each row represents estimates from two regressions. The first includes indicator variables for the
separate treatment groups (FF1-FF3). The second pools the three treatment groups into one indicator variable. Sample sizes vary from 18,019 (participation in supplemental round conditional on first round match)
to 19,109 (match to 1st choice). All regression models include the following controls: school randomization
block, student race/ethnicity, female, free lunch eligible, reduced-price lunch eligible, special education, EL,
foreign born, quadratic in 7th grade ELA and mathematics z-scores, missing indicators for z-scores and other
covariates, and indicator for students in schools that received a treatment in our 2014-15 pilot study. Schoollevel controls include a charter indicator, 8th grade enrollment, percent female, percent by race/ethnicity,
percent with disabilities, percent EL, and mean 8th grade math and ELA scores. All school controls are
measured in the year prior to treatment. Standard errors in parentheses, adjusted for clustering at the school
level. + p < 0.10 * p < 0.05 ** p < 0.01 *** p < 0.001.

52

Table 7: Impact of informational interventions on other characteristics of chosen schools
FF1
School location:
Travel time (minutes),
1st-3rd choices

Treatment groups
FF2
FF3

Pooled

Control group
Mean
SD

-1.160
(1.052)

0.855
(1.071)

1.394
(0.877)

0.281
(0.797)

32.4

13.1

Percent in same borough,
1st-3rd choices

6.577**
(2.014)

1.017
(2.190)

2.758
(1.841)

3.771*
(1.572)

76.9

35.8

School popularity:
Demand (apps per seat),
1st-3rd choices

-0.319
(0.312)

-0.751+
(0.407)

-0.796*
(0.340)

-0.602*
(0.281)

14.1

7.7

Admissions methods and priority:
Limited unscreened,
1st-3rd choices

2.811+
(1.637)

7.875***
(1.869)

2.591
(2.015)

4.032**
(1.434)

34.7

35.0

Screened,
1st-3rd choices

-3.040+
(1.765)

-5.676**
(1.757)

-2.577
(2.089)

-3.547*
(1.453)

35.1

35.1

Limited unscreened, % 1st-3rd
choices with open house priority

2.513
(1.825)

2.906
(2.063)

1.466
(2.147)

2.268
(1.662)

51.4

43.2

Screened, % 1st-3rd
choices where ranked by school

6.653***
(1.686)

0.223
(1.963)

4.669*
(1.860)

4.228**
(1.499)

41.0

43.0

-2.721**
(0.913)

-1.268
(1.105)

-0.790
(1.109)

-1.650+
(0.911)

55.0

18.4

Interest areas:
Percent largest interest area
category (all choices)

Notes: each row represents estimates from two regressions. The first includes indicator variables for the
separate treatment groups (FF1-FF3). The second pools the three treatment groups into one indicator
variable. Sample sizes vary from 11,826 (percent of screened choices where ranked by school) to 19,109
(percent in same borough). All regression models include the following controls: school randomization
block, student race/ethnicity, female, free lunch eligible, reduced-price lunch eligible, special education, EL,
foreign born, quadratic in 7th grade ELA and mathematics z-scores, missing indicators for z-scores and other
covariates, and indicator for students in schools that received a treatment in our 2014-15 pilot study. Schoollevel controls include a charter indicator, 8th grade enrollment, percent female, percent by race/ethnicity,
percent with disabilities, percent EL, and mean 8th grade math and ELA scores. All school controls are
measured in the year prior to treatment. Standard errors in parentheses, adjusted for clustering at the school
level. + p < 0.10 * p < 0.05 ** p < 0.01 *** p < 0.001.

53

Table 8: 2SLS estimates of the impact of applying to Fast Facts schools
Student-level:
# all choices # top 3 choices
from FF1
from FF1
First stage coefficients:
FF1

School-level mean:
# all choices # top 3 choices
from FF1
from FF1

0.776***
(0.145)

0.298***
(0.063)

0.810***
(0.148)

0.320***
(0.064)

FF2

0.276+
(0.153)

0.163**
(0.061)

0.288+
(0.152)

0.179**
(0.060)

FF3

0.209
(0.148)

0.149*
(0.059)

0.204
(0.151)

0.154**
(0.059)

9.95
16,657

7.63
16,657

10.30
16,657

8.62
16,657

5.386**
(1.703)

2.175***
(0.576)

5.073***
(1.581)

-6.955**
(2.306)

-19.877**
(6.360)

First stage F-statistic
N

2SLS:
Graduation rate of matched school:
# choices from FF
2.262***
(all or top 3)
(0.608)

Final matched school graduation rate <70%:
# choices from FF
-7.300**
-21.220**
(all or top 3)
(2.430)
(6.822)

Notes: Each column represents two 2SLS regressions, where the endogenous explanatory variable is the
number of all or top 3 choices from the basic Fast Facts list. (This measure is calculated separately for
each student, leaving that student out of the calculation). All regression models include the following
controls: school randomization block, student race/ethnicity, female, free lunch eligible, reduced-price lunch
eligible, special education, EL, foreign born, quadratic in 7th grade ELA and mathematics z-scores, missing
indicators for z-scores and other covariates, and indicator for students in schools that received a treatment
in our 2014-15 pilot study. School-level controls include a charter indicator, 8th grade enrollment, percent
female, percent by race/ethnicity, percent with disabilities, percent EL, and mean 8th grade math and ELA
scores. All school controls are measured in the year prior to treatment. Standard errors in parentheses,
adjusted for clustering at the school level. + p < 0.10 * p < 0.05 ** p < 0.01 *** p < 0.001.

54

Table 9: Subgroup impact estimates: usage and match rates
Usage: % of 1st-3rd choices
from intervention-specific list
FF1
FF2
FF3

Matched to 1st choice
FF2
FF3
FF1

N

Full study sample

10.43***
(2.112)

5.503**
(2.051)

5.482**
(1.957)

3.104+
(1.651)

3.530+
(1.794)

3.539* 19109
(1.655)

FRPL eligible

10.45***
(2.143)

4.974*
(2.092)

5.344**
(1.916)

2.905
(1.771)

1.616
(1.963)

3.769* 14822
(1.750)

Not FRPL eligible

9.815***
(2.301)

7.187**
(2.382)

5.224*
(2.417)

3.704+
(2.170)

9.380***
(2.319)

2.791
(2.190)

4224

Spanish spoken
at home

12.65***
(2.078)

5.830**
(2.174)

8.016***
(1.956)

0.0137
(2.081)

-1.474
(2.505)

4.396+
(2.343)

7022

Other non-English
spoken at home

13.72***
(3.183)

14.00***
(4.167)

8.856**
(2.908)

0.762
(4.334)

5.644
(4.433)

-0.729
(3.372)

2419

English spoken
at home

6.219***
(1.827)

3.942*
(1.795)

1.836
(1.815)

4.128*
(1.783)

3.957*
(1.803)

2.571
(1.887)

9668

7th grade math
bottom quartile

6.812**
(2.136)

5.041*
(2.131)

6.157**
(1.874)

1.714
(2.212)

2.601
(2.316)

5.281*
(2.151)

6018

7th grade math
top quartile

16.05***
(3.211)

8.420**
(3.149)

6.842*
(3.024)

6.988+
(3.551)

-0.181
(3.821)

9.400*
(3.656)

2128

Not present in
7th grade

9.087*
(3.973)

4.904
(4.559)

5.641
(3.535)

14.25**
(5.384)

20.62*** -1.498
(5.474) (5.282)

801

White

13.06***
(3.359)

8.578*
(4.184)

19.25***
(3.683)

12.26**
(4.346)

13.01*
(5.819)

-0.900
(4.968)

1091

Black

4.528*
(1.785)

2.638
(1.745)

0.302
(1.575)

5.254*
(2.108)

4.988*
(2.201)

3.431
(2.373)

5718

Hispanic

11.34***
(2.143)

5.798**
(2.075)

6.934***
(1.799)

0.321
(1.872)

-0.412
(2.098)

2.536 10454
(1.961)

Asian

14.20**
(4.613)

17.50**
(5.652)

10.93**
(3.494)

14.22**
(5.423)

16.92**
(5.648)

-0.383
(4.584)

1612

Notes: Each row and column set (FF1-FF3) represents estimates from a separate regression for the indicated
subgroup. Student and school covariates and block effects included (as in earlier tables). Standard errors in
parentheses, adjusted for clustering at the school level. + p < 0.10 * p < 0.05 ** p < 0.01 *** p < 0.001.

55

Table 10: Subgroup impact estimates: graduation rates of matched school
Graduation rate
matched school
FF1
FF2
FF3

Graduation rate: below
70% matched school
FF2
FF3
FF1

N

Full study sample

1.664**
(0.571)

0.526
(0.662)

-0.066
(0.596)

-6.274*
(2.418)

-5.147+
(2.959)

-3.346
(2.865)

16657

FRPL eligible

1.690**
(0.604)

0.635
(0.712)

0.0213
(0.619)

-6.577*
(2.565)

-5.483+
(3.124)

-3.071
(2.944)

12949

Not FRPL eligible

1.518*
(0.688)

0.430
(0.658)

-0.099
(0.795)

-5.493+
(2.814)

-4.695
(3.016)

-4.959
(3.696)

3659

Spanish spoken
at home

1.415*
(0.623)

-0.334
(0.752)

-0.368
(0.854)

-6.290**
(2.352)

-2.716
(3.121)

-3.654
(3.172)

6180

Other non-English
spoken at home

0.936
(1.050)

2.828*
(1.334)

-2.114+
(1.153)

-9.456*
(4.084)

-19.53***
(4.964)

1.488
(4.664)

2069

English spoken
at home

1.309*
(0.653)

0.586
(0.721)

0.0836
(0.615)

-3.755
(2.409)

-4.679
(2.862)

-1.923
(2.515)

8408

7th grade math
bottom quartile

1.700*
(0.701)

1.146
(0.771)

-0.404
(0.711)

-6.036*
(2.442)

-8.132**
(2.978)

-0.756
(2.740)

5313

7th grade math
top quartile

2.055
(1.263)

0.632
(1.475)

1.233
(1.477)

-11.29*
(4.877)

-7.377
(5.301)

-11.12*
(5.160)

1693

Not present in
7th grade

5.430*
(2.189)

0.837
(2.201)

2.756
(1.857)

-12.95+
(6.752)

2.554
(7.935)

-10.34+
(6.219)

675

White

0.896
(1.635)

2.493
(2.308)

0.0262
(1.846)

-10.27+
(5.696)

-16.01+
(9.270)

-18.29**
(6.961)

947

Black

1.330+
(0.744)

0.149
(0.803)

-0.380
(0.732)

-3.935
(2.472)

-4.025
(2.862)

1.230
(2.578)

5032

1.801*** 0.570
(0.514) (0.691)

0.182
(0.674)

-6.680**
(2.135)

-4.606
(2.942)

-4.858+
(2.697)

9147

0.945
(1.934)

-18.56**
(6.860)

-20.13*
(7.747)

-11.75+
(6.730)

1344

Hispanic

Asian

4.304*
(1.810)

1.781
(2.268)

Each row and column set (FF1-FF3) represents estimates from a separate regression for the indicated subgroup. Student and school covariates and block effects included (as in earlier tables). Standard errors in
parentheses, adjusted for clustering at the school level. + p < 0.10 * p < 0.05 ** p < 0.01 *** p < 0.001.

56

Table 11: Applications to schools for which a text message was sent
Treatment groups
FF1
FF2
FF3
Percent text message schools,
1st-3rd choices

1.435
(1.415)

3.411*
(1.356)

-0.079
(1.419)

Number of choices that were text
0.114
message schools and student was (0.0754)
in open house priority group

0.119+
(0.0656)

0.0293
(0.0721)

Any 1st-3rd choice school was
text message school not on list

0.112
(1.000)

0.616
(1.030)

Percent of all choices that were
text message school not on list

-0.051
(0.357)

-0.078
(0.375)

Control group
Mean
SD
12.8

21.8

0.7

1.1

0.222
(0.956)

8.1

27.4

0.049
(0.359)

3.2

6.8

Notes: Each row represents estimates from a separate regression. Sample sizes 19,109 in each case. All
regression models include the following controls: school randomization block, student race/ethnicity, female,
free lunch eligible, reduced-price lunch eligible, special education, EL, foreign born, quadratic in 7th grade
ELA and mathematics z-scores, missing indicators for z-score and other covariates, and an indicator for
students in schools that received a treatment in our 2014-15 pilot study. School-level controls include a
charter indicator, 8th grade enrollment, percent female, percent by race/ethnicity, percent with disabilities,
percent EL, and mean 8th grade math and ELA scores. All school controls are measured in the year prior to
treatment. Standard errors in parentheses, adjusted for clustering at the school level. + p < 0.10 * p < 0.05
** p < 0.01 *** p < 0.001.

57

A
A.1

Sampling, recruitment and treatment assignment
Sampling

To construct our initial middle school sampling frame, we began with two school-level
datasets from the NYCDOE: the 2014-15 Demographic Snapshot, and the LCGMS extract
from March 22, 2015. The latter is a file updated daily showing all NYC schools in operation,
allowing us to identify school status changes since the Demographic Snapshot was released.
From these two files we identified 566 schools that enrolled a minimum of 30 students in
8th grade or had zero 8th graders but at least one student in 7th grade. (This second condition retained some newer schools that did not serve 8th grade in 2014-15 but may have in
2015-16). We retained charter schools but excluded District 75 (special education) schools.
All 16 schools in Staten Island were dropped from this initial set, as were 109 schools that
enrolled at least one 9th grader. We excluded Staten Island middle schools because they
were comparatively more advantaged than those targeted by this study. Their effective set of
high school choices is also more limited due to Staten Island’s lower population density and
geographic isolation. Schools that enrolled 9th graders were excluded because 8th graders in
those schools frequently remain there for 9th grade. An additional three schools that served
unusually high proportions of students with disabilities (>50%) or English language learners
(>90%) were dropped. 438 eligible schools remained after these drops.
Geocoded student residential addresses from 2012-13 were used to calculate for each
middle school the percent of 8th graders living in low-income Census tracts, defined using the
population share with income below 150% of the poverty line from the American Community
Survey. (2012-13 was the most recent address file available at the time this sampling frame
was produced).32 The working sample of 438 schools was split into quartiles based on this
poverty measure.
Schools in the top two quartiles of poverty comprised our “high-poverty” recruitment
pool (N=217). We sorted these in random order and began recruiting from the top of this
list (see the following subsection for details on recruitment). When it became apparent we
would need schools beyond this list, we created a “mid-poverty” recruitment pool consisting
of the next quartile of schools (N=108).
Table A.1 provides mean characteristics of: (1) all NYC schools that served 8th grade
in 2014-15 or served 7th grade in 2014-15 with the potential to serve 8th grade in 2015-16
(N=592); (2) all NYC schools in the baseline sampling frame (N=438); (3) all schools in the
high-poverty recruitment pool (N=217); (4) all schools in the mid-poverty recruitment pool
(N=108); and (5) all schools that participated in the study (N=165). (The fifth group is
described later). Notably, the recruitment pools and study sample include a greater share of
32

Schools in the working sample not observed in the 2012-13 data were geocoded to Census tracts. In
place of the student average measure, we used the 5-year (2009-2013) poverty estimate for the Census tract
in which the school was located.

58
schools located in the Bronx and Brooklyn relative to the full population of schools serving
8th graders. Study schools also enrolled a higher share of Hispanic students, English language
learners, and (by design) low-income students. They also tended to be smaller, and were
less likely to be charter schools than the full population.
Table A.2 provides mean outcomes of the high school admissions process in 2013-14 for
the same five groups of schools. (These outcomes are observed two years prior to the study,
and were the latest available at the time of sampling). The sample sizes reported in this table
are smaller than those in Table A.1, as not all schools had 8th graders participating in the
admissions process in 2013-14. In that year, 8th graders in our study schools applied to high
schools with lower graduation rates, on average, than did students in the full population.
A larger share of high schools on their application used the limited unscreened admissions
method, and a smaller share of students were unmatched after the main round.

A.2

Treatment assignment

As of August 12, 2015, 167 schools had agreed to participate in the study. We dropped two
schools that we learned were screened middle schools that required an exam for admission,
and a third that shared a guidance counselor with another recruited school.33 This left 164
schools: 61 in the Bronx, 58 in Brooklyn, 29 in Manhattan, and 16 in Queens (Table A.3).
Of these we aimed to assign 39 to each treatment arm (117 total) and 47 to the control
group. The top panel of Table A.3 shows how these counts are divided by borough.
We randomly assigned schools to treatment and control groups within matched blocks
of similar schools. Blocks were formed within the eight strata shown in the bottom panel
of Table A.3. These include four borough strata, a fifth stratum of eight schools in the
geographically isolated Rockaways section of Queens, and three strata of schools (23 total)
that participated in our 2014-15 pilot study. Because pilot schools had previously been offered
a treatment, had prior interactions with our team, and agreed to participate again, they
likely differ systematically from other recruited schools. We therefore blocked these schools
separately within borough. We also wished to ensure these schools received a treatment as
a reward for past participation, so all of them were forced into one of the three treatment
groups, chosen at random. Nearest neighbor matches were drawn from the borough at large
to serve as controls for the pilot schools. (This explains why the total number of schools in
the pilot blocks [32] exceeds the number of pilot schools [23]).
Within each matched block we aimed to have one school assigned to each treatment arm
(FF1, FF2, and FF3) and at least one school assigned to the control group. Since there were
33

Students in the two screened schools fare well in the high school choice process and a large fraction
are admitted to the city’s specialized high schools. We dropped these schools since they are outside the
target population for this study. The third school was dropped because it would be impossible to randomly
assign schools that share a guidance counselor to different treatment conditions and maintain compliance.
As described later, these three schools were returned to the study sample after randomization.

59
more schools planned for the control group than any single treatment arm, some blocks have
more than one control. In total, 39 blocks were formed, 8 of which were blocks consisting
primarily of pilot schools.34
Mahalanobis nearest-neighbor matching was used to form blocks of similar schools within
each of the eight blocking strata listed in Table A.3. This procedure began by sorting schools
randomly within strata. The first school was drawn and its three nearest neighbors identified.
These four schools were removed, and the next school was drawn along with its three nearest
neighbors, and so on. The school variables used in the matching procedure were as follows:
• Percent of high school applicants in 2013-14 with no main round match
• Mean graduation rate of students’ top three choices in 2013-14 (main round)
• The percent of top three choices in 2013-14 (main round) that were limited unscreened
schools
• Mean scale score of 8th grade students in 2013-14 in English language arts (ELA) and
mathematics
• Grade 8 enrollment in 2013-14 (or if none, grade 7)
• Percent eligible for free or reduced price meals in 2013-14 (school-wide)
Means for several of these variables were reported in Table A.1-A.2. Some schools lacked 8th
grade scale scores or choice outcomes from 2013-14 if they did not have an 8th grade class
in that year. In these cases we imputed using the mean for other recruited schools in the
same borough. After matched blocks were formed, we used the original random number to
assign schools to the three treatment and control conditions. One school that was originally
dropped because it shared a guidance counselor with another recruited school was added
back at this point, and assigned to the same block and treatment as its companion school.
This brought the total number of study schools to 165.
After forming matched blocks, we ran several tests for balance. First, we estimated
a set of regression models in which the dependent variables differed but the same set of
explanatory variables were used (mvreg in Stata). Explanatory variables included the three
treatment group indicators, an indicator for pilot study participation, and block fixed effects.
A p-value was obtained for the joint hypothesis that coefficients on the treatment indicators
were zero across all regression models. Next, in separate models we regressed treatment
group assignment (FF1, FF2, or FF3) on a full set of school covariates. These covariates
34
The pilot study blocks consist of schools in the same borough, but not necessarily the same randomization
block from the pilot study. In forming the 8 pilot study blocks we aimed to group schools that were in the
same randomization block from the pilot study, or the same geographic school district when the former
option was not possible.

60
included all of the matching variables listed above, as well as the percent English language
learners, percent with disabilities, percent female, percent by race and ethnicity, percent of
students scoring at the lowest level in ELA (Level 1), percent scoring at the lowest level in
mathematics (Level 1), and a charter school indicator. (These same variables were used as
dependent variables in the first balance test). In these regressions a p-value was obtained
for the joint significance of school characteristics in explaining treatment assignment.
We had no reason to expect the first iteration of matching and blocked randomization to
yield the “best” possible balance. In the interest of identifying an ex ante well-balanced set of
treatment assignments, we executed the above blocked randomization procedure—beginning
with nearest neighbor matching—50 times. We then looked for iterations with the largest
p-values and few (if any) statistically significant associations between treatment assignment
and school characteristics. Of the 50 iterations, we chose a randomization with p = 0.66 for
the first balance test and p = 0.78, 0.96, and 0.86 for the second balance tests. Coefficients
from the latter three regression models are reported in Table A.4. The only explanatory
variable that has a statistically significant association with treatment assignment is pilot
study participation, which is expected given that pilot schools were purposefully assigned to
a treatment. Results are similar, with p-values of 0.70, 0.99, and 0.82, when the pilot study
indicator was omitted from the regressions.
Table A.5 reports the mean characteristics of schools in our study’s treatment and control groups. Three additional schools volunteered to participate in our study, and the two
recruited academically selective schools that were originally dropped were added back as
control schools, increasing the number of participating schools to 170. However, these five
schools (2 control, 2 FF1 and 1 FF3) are not included in Tables A.4-A.5 since they were not
part of the original block randomization. Only students from the 165 schools in the original
blocked random assignment are used in the main results of this paper.

B

Production of intervention materials

Study schools were randomized into three treatment arms and a control group. Schools in the
first treatment arm (FF1) received a “Fast Facts” list of proximate high schools. Schools in
the second treatment arm received Fast Facts and a supplementary list of academically nonselective “limited unscreened” schools that give priority admission to students who attend an
open house. This group was also invited to receive text message reminders about these open
houses. Schools in the third treatment arm received Fast Facts and a supplementary list of
high school programs organized by academic interest area. All treatment schools received
a one-page insert of “screened language” programs citywide that exclusively serve recent
immigrants new to the English language.
The procedure we used to generate Fast Facts and supplementary lists drew from three
primary data sources:

61
• The 2015-16 NYC High School Directory, which includes (among other things) graduation rates, program interest areas, and admissions methods. The graduation rate
pertained to the cohort graduating in 2013-14, the most recent available at the time
of printing.
• Imputed graduation rates for high schools that had not yet had a graduating cohort.35
• Travel time by walking or public transit from every middle school to every high school
in NYC, calculated using the Google Maps API during August 2015.
Our starting point for creating Fast Facts was a list of all middle-high school combinations
with their travel time by public transit (N=256,082). We dropped high schools that primarily
served continuing 8th graders, reducing the list to 234,986 cases. For each high school we
retained information about its graduation rate (using the imputed version where necessary),
admissions methods, interest areas, and directory page number.
Importantly, we produced these three lists for all study schools, regardless of their actual
treatment assignment. Doing so provided a “counterfactual” Fast Facts list for schools that
were not selected to receive one (or were assigned to receive a different version).

B.1

Fast Facts

Fast Facts sheets were provided to students in every treatment arm (FF1, FF2, and FF3).
Each consisted of a list of 30 high schools. Our procedure for creating Fast Facts was as
follows. For every middle school we identified all high schools with a graduation rate of 70%
or higher that were within a 45-minute commute from that middle school.36 This list was
sorted by travel time (ascending), graduation rate (descending), and school name (ascending,
to break ties and to ensure replicability). The first 10 high schools in this ordered list were
immediately flagged for inclusion on Fast Facts. We then successively added schools as long
as the cumulative number of screened schools was ≤ 10, the number of new schools was
≤ 10, and (in select cases) the number of schools located in a different borough was ≤ 10.37
Schools that would put the Fast Facts list over these limits were skipped. Once 30 schools
was reached, the list was finalized. In cases where 30 schools could not be identified with this
35

We predicted graduation rates for these high schools using a quadratic function of their 9th grade “on
track” indicator (the percent completing 10 or more credits in 9th grade). The prediction model used all
high schools with non-missing graduation rates and 9th grade “on track” indicators from 2014-15. The
upper limit of the 95% prediction interval was used as the imputed graduation rate for schools lacking this
information. High schools that were so new that they lacked both performance measures were omitted from
the list.
36
For schools in the Rockaways section of Queens we relaxed the commuting time requirement to 60
minutes.
37
This restriction was imposed for 27 middle schools where we observed students very rarely applying to
high schools outside of their own borough.

62
procedure, we relaxed the graduation rate and commuting time restrictions.38 High schools
were listed on Fast Facts in descending order by graduation rate and (in the case of ties)
alphabetically by school name. The imputed graduation rate was used in the sorting order
for new schools, although the imputed rate was not displayed on the sheet. (Rather, the
graduation rate reads “*new school”).
To summarize, Fast Facts was a list of the closest 30 high schools within a given commute
(45 minutes) that are above a graduation rate floor (70%). The list capped the number of
new, screened, and (in some cases) out-of-borough schools that appeared. If necessary for
producing a list of 30 schools, the maximum commuting time and/or minimum graduation
rate was relaxed. A sample Fast Facts is pictured in Figure A.1.

B.2

Academically non-selective school supplement

Schools in the FF2 treatment arm were given Fast Facts and a supplementary list of academically non-selective high schools that give priority admission to students who attend an
open house. The 18-25 high school programs featured on this supplement use the “limited
unscreened” admissions method, which means they do not screen students using grades or
other academic criteria. They do, however, give priority admission to students who attend
an open house or information session. Schools on the supplement were drawn from Fast
Facts or were added when Fast Facts did not generate at least 18 non-selective programs.
Our procedure for creating this list was as follows. For each middle school we counted the
number of limited unscreened programs offered by schools on Fast Facts. (We counted programs rather than schools, as some schools offered multiple programs). When there were
>25 limited unscreened programs on Fast Facts, we identified 20 with the highest graduation
rates and used these as the non-selective school supplement. When there were 18 ≤ x ≤ 25
limited unscreened programs on Fast Facts, we retained them all for the non-selective school
supplement. When there were <18 limited unscreened programs on Fast Facts, we retained
these and drew additional programs until there were 20. (Schools were drawn using the same
minimum criteria and sort order used for Fast Facts).
For presentation on the academically non-selective school supplement, programs were
sorted in descending order by their school’s graduation rate, and (in the case of ties) alphabetically by program name. Schools that already appeared on Fast Facts were introduced
with the text, “These are some of the limited unscreened schools from your Fast Facts list.”
Any added schools not on Fast Facts were introduced with the text, “Here are a few more
limited unscreened programs to consider.” Unlike Fast Facts, the non-selective school supplement provided the 4-character program code and program (rather than school) name. A
sample non-selective school supplement is pictured in Figure A.2.
38

In the Rockaways, the relaxed criteria were a graduation rate of 65% and a maximum commuting time
of 75 minutes. For all other schools the relaxed criteria were a graduation rate of 65% and a maximum
commuting time of 60 minutes.

63

B.3

Schools by academic interest area

Schools in the FF3 treatment arm were given Fast Facts and a supplementary list of high
schools grouped by academic theme or interest area. The 49 high school programs featured on
this list were drawn from Fast Facts or were added when Facts Facts did not generate enough
programs in each category. Our procedure for creating this list was as follows. For each
middle school we identified seven programs in each of these categories: Academically Selective
(all screened programs); Business & Communications; Health Professions; Humanities; Law,
Government, Civics & History; Performing and Visual Arts; and STEM.39 In each interest
area we took the first seven programs that appeared after applying the same minimum criteria
and sort order used for Fast Facts.40 By using the original sort order, schools featured on
Fast Facts were the first to be listed in their respective interest area. Fast Facts was often not
sufficient to populate seven programs in each category. In these cases, we drew additional
programs until each interest area was filled.
For presentation on the academic interest area supplement, programs were sorted in
descending order by their school’s graduation rate. (Again, listing first programs in schools
that appeared on Fast Facts, and then added programs.) Unlike Fast Facts, the interest
area supplement provided the 4-character program code, admissions method, and program
name. (For example: “PPA HS: Musical Theatre,” “PPA HS: Dance,” and “Union Square
Academy for Health: Dental”). A sample academic interest area supplement is pictured in
Figure A.3.

B.4

Screened language insert

All treatment schools received a one-page insert identifying 42 higher-performing schools
citywide that offered “screened language” programs for English language learners and recent
immigrants. This insert was the same for all treatment schools, with schools listed separately
by borough. School names were listed, along with program names (e.g., Bilingual Haitian
Creole Institute), 4-character program code, language of instruction, and directory page
number. All of these schools had a 6-year graduation rate of 70% or higher. The front of
the insert was printed in English, while the back was printed in Spanish. A sample screened
language insert is pictured in Figure A.4.
39

The categories were consolidated from a larger number of interest areas used by the NYCDOE in its
High School Directory. “Academically Selective” is not an interest area per se, but a way to distinguish
schools that screen on the basis of grades, test scores, or other criteria.
40
For the academic interest area supplement we relaxed the maximum commute time to 80 minutes, or 90
minutes in the Rockaways. This was done to ensure a minimum number of schools in each interest area. We
also modified the sort order so that programs that screened for English language learners were listed last in
the case of ties.

64

B.5

Fast Facts and supplementary list descriptives

Tables B.1-B.3 report descriptive statistics for the high schools appearing on our intervention materials. Table B.1 summarizes the Fast Facts lists given to all treatment schools in
the study. Table B.2 summarizes the (pooled) Fast Facts list and academically non-selective
school supplement; FF2 was the only group of schools that actually received both of these
lists. Table B.3 summarizes the (pooled) Fast Facts list and academic interest area supplement; FF3 was the only group of schools that actually received both of these lists. Again,
we generated Fast Facts—and the two supplementary lists—for all study schools, regardless of treatment assignment. Doing so provided “counterfactual” lists that characterize
information a school would have received, had they been in a particular treatment group.
Table B.1 shows that the typical Fast Facts list consisted of 30 high schools with an
average graduation rate of 81.5% and average commuting time (middle school to high school)
of 25.3 minutes. An average of 57.4% of schools on Fast Facts offered a limited unscreened
program, 25.1% offered a screened program, and 23.3% offered only screened programs.41
An average of 26.3% were new schools that as of 2015-16 had not had a published graduation
rate, and 78.9% of listed high schools were located in the same borough as the middle school.
Tables B.2 and B.3 show how the materials produced for the FF2 and FF3 schools
compare to the typical Fast Facts lists. The combined Fast Facts and academically nonselective school supplement included an average of 32.4 unique schools (versus 30 on Fast
Facts alone), while the combined Fast Facts and academic interest area supplement included
an average of 42.9 schools. The average graduation rate of schools on the former (81.2%)
was comparable to Fast Facts alone, while the latter (82.6%) was higher. (The interest
area supplement required drawing more schools onto the list, including a minimum of seven
screened programs, which tend to have higher graduation rates). As expected, the combined
Fast Facts and academically non-selective school supplement included a higher share of
schools offering limited unscreened programs than Fast Facts alone (61.2% vs. 57.4%).
The average travel time on the two set of materials was higher (26.1 and 31.6 minutes,
respectively) and a smaller share of schools was located in the same borough as the middle
school (76.7% and 65.3%). (These differences reflect the need to draw additional schools
onto the supplementary lists).
As a test for whether the intervention materials produced were balanced across treatment and control groups, the rightmost column in Tables B.1-B.3 report the p-value from
a regression of the listed high school characteristic on a set of treatment group indicators
and randomization block fixed effects. In only one case is the p-value less than 0.05, providing confidence that the schools appearing on the intervention materials are comparable, on
average, across middle schools in the experiment.
41

Admissions methods used by a school are not mutually exclusive. A school can offer, for example, a
screened program and a limited unscreened program.

65

B.6

Open house data and text message reminders

Our master list of open houses was compiled from the 2015-16 High School Directory, the
NYCDOE online calendar, visits to tables at the city and borough-wide school fairs, and
weekly calls by our research team to limited unscreened high schools. Because open house
dates were regularly added, canceled, and re-scheduled, this data collection continued until
the last batch of text messages were sent. By that time we had assembled a list of 762 open
house dates. The number of open houses varied by high school; some offered as few as one
open house during the fall semester, for example, while others held weekly or bi-weekly open
houses.
We scheduled 11 weeks of text messaging, with information about two high schools sent
to participants every Sunday evening. The first batch of messages was sent on September
20, 2015, and the last on November 29, 2015 (Table B.4). The content of the messages
changed weekly and was customized to each receiving middle school. Our weekly procedure
for selecting high schools for inclusion in the text message reminders was as follows.
For each middle school we identified all limited unscreened high schools that met our
original criteria for inclusion on Fast Facts.42 From this set we flagged schools with scheduled
open house dates as of that week. Based on these dates we allocated open house reminders
to 22 available slots (over 11 weeks), prioritizing high schools with fewer total open house
opportunities and with higher graduation rates. For example, if a high school had a total of
one scheduled open house, we assigned a text message reminder for it on the Sunday before
the open house. Up to two of these could be scheduled in one week. If more than two such
open houses were identified in a single week, we prioritized school(s) with higher graduation
rates. When high schools had two or more scheduled open houses, we attempted to assign a
text message reminder for the first of these. If that week was full, we attempted to schedule
a message for the week of the second open house, and so on. Finally, after all schools with
scheduled open houses were assigned a text message slot (subject to the limit of 2 per week),
we filled unassigned slots with a general message with information about a limited unscreened
high school not already covered above (again prioritizing higher graduation rates).
Because the open house calendar was dynamic, this weekly routine sometimes led to
repeat messages. To see this, suppose high school K123 had one open house scheduled
as of October 25. Given its limited open house opportunities at the time, we would have
prioritized a text message reminder for that week. If K123 later scheduled more open houses,
it would re-appear on our list (with regularity if it is a high graduation rate school). We
therefore monitored the results of our algorithm to minimize duplication. When we observed
a middle school was scheduled to receive a repeat text message reminder for the same high
42

For most middle schools this included high schools with a graduation rate of 70% or higher and a
maximum commuting time of 45 minutes. For schools in the Rockaways, we included high schools with a
graduation rate of 70% or higher and a maximum commuting time of 70 minutes. The latter is relaxed
somewhat from the Fast Facts criteria to ensure a sufficient number of schools.

66
school, we often manually forced them to receive a different reminder (for the next school in
their text message priority list). We were less likely to do this in the first few weeks of text
messaging, since most users had not yet signed up for the service.
Table B.4 reports the number of open house and general text message reminders sent in
each week of the study. In the early weeks (1-3), the two messages tended to include one
open house reminder and one general school message. In later weeks—during the peak open
house period—both weekly text messages were open house reminders.
Examples of the open house reminder and general text messages are shown below. (These
were sent in English or Spanish, depending on user preferences). When recipients wanted
more information about a school, they were given the opportunity to text back “1” for
information about the first school and “2” for information about the second school. The
examples below include the responses to these requests.

Open House this week @ Urban Assembly School for Law & Justice on Sat 12/12
@ 11am txt 1 for more info
UALaw&Just is @ 283 Adams St, Brooklyn, 718-858-1160; bus: B103 B25 B26
B38 B41 B45 B54 B57 B61 B62 B63 B65 B67 B69; train: G, 2 3 4 5 R, M, A C
F, B Q

Interested in Bronx River HS? Call 718-904-4210 to schedule a visit txt 1
for more info
Bx River is @ 3000 East Tremont Ave, Bronx, 718-904-4210; bus:
Bx31 Bx4 Bx40 Bx42 Bx4A Bx8; train: 6

Bx21 Bx24

When a school offered multiple open houses in one week, our text message accommodated
this. For example:

Open House this week @ Murray Hill Academy on Thur 11/12, Sat 11/14 @ Thur
4-5:30pm; Sat 9:30-11am & 11:30am-1:00pm txt 2 for more info

As we did with the Fast Facts and supplementary school lists, we generated “counterfactual” text messages for middle schools that were not assigned to the non-selective school
supplement treatment group (FF2). These were generated using the same rules as those
used to produce the actual text messages sent to participating families in the FF2 treatment
arm.

Figure A.1: Sample Fast Facts (front and back)
67

Figure A.2: Sample academically non-selective school supplement
68

Figure A.3: Sample academic interest area supplement
69

70

Figure A.4: Screened language insert

71

Table A.1: Mean school characteristics, 2014-15
(1)

(2)
Baseline
All
sampling
schools
frame
N
Charter school
Brooklyn
Manhattan
Queens
Bronx
Staten Island
High-poverty recruitment pool
Mid-poverty recruitment pool
Pilot study participant
% Female
% Male
% Asian
% Black
% Hispanic
% Other race
% White
% SWD
% EL
% FRPL
Census tract residential poverty
Mean 8th grade math scale score
Mean 8th grade ELA scale score
Enrollment
Grade 8 enrollment
Grade 9 enrollment

(3)
High-pov.
recruit.
pool

(4)
(5)
Mid-pov.
recruit.
Study
pool
schools

592

438

217

108

165

0.147
0.331
0.215
0.184
0.243
0.027
0.341
0.182
0.039
49.5
50.5
9.4
37.2
41.1
1.5
10.8
20.2
11.0
80.3
38.2
291.7
294.4
591.2
123.5
19.0

0.105
0.340
0.199
0.199
0.263
–
0.461
0.247
0.052
49.2
50.8
10.2
35.9
42.4
1.4
10.1
20.5
12.3
82.1
38.3
291.6
293.5
576.7
134.6
0.0

0.124
0.341
0.258
0.028
0.373
–
0.931
–
0.101
49.1
50.9
4.3
36.8
55.3
0.9
2.6
23.1
16.2
89.7
49.1
284.1
284.6
426.6
98.8
0.0

0.093
0.481
0.157
0.204
0.157
–
–
1.000
0.000
48.6
51.4
13.1
40.5
34.5
1.5
10.3
19.7
11.2
84.3
34.6
293.8
295.5
647.0
153.0
0.0

0.079
0.358
0.176
0.097
0.370
–
0.630
0.327
0.139
48.7
51.3
5.0
37.4
51.6
1.1
4.8
22.9
14.8
88.9
45.0
284.7
286.8
473.2
116.0
0.0

Notes: authors’ calculations using data from the NYCDOE and American Community Survey (for Census
tract poverty rates). School enrollment and demographic data come from the 2014-15 NYCDOE Demographic Snapshot.

72

Table A.2: Mean high school admissions process outcomes, 2013-14
(1)

(2)
Baseline
All
sampling
schools
frame

(3)
High-pov.
recruit.
pool

(4)
(5)
Mid-pov.
recruit.
Study
pool
schools

N

530

382

189

98

147

Graduation rates:
1st choice
1st-3rd choices
All choices
Final matched school
9th grade enrolled school
Variability in gradrate (range)

83.3
82.2
81.0
76.5
76.9
22.4

82.8
81.6
80.4
75.5
75.7
24.3

80.0
79.1
78.0
72.2
72.3
27.5

83.5
82.2
80.8
76.2
76.4
23.3

80.7
79.7
78.5
72.9
73.0
26.5

Graduation rates <70%:
1st choice
1st-3rd choices
All choices
Final matched school
9th grade enrolled school

14.1
16.3
18.9
30.6
30.2

15.5
17.7
20.6
34.0
33.8

20.1
22.5
25.7
41.3
41.3

13.9
16.2
18.9
31.3
31.0

19.5
21.7
24.8
39.7
39.9

Number of main round choices
Matched to 1st choice
Matched to 1st-3rd choice
Participation in R2 after main round match
9th grade enrollment in matched school
Enrolled in a charter high school

7.0
48.3
75.1
9.7
88.2
0.1

7.7
44.6
73.6
10.3
89.9
0.0

8.4
46.2
75.6
10.7
88.9
0.1

7.3
43.6
72.4
11.3
91.5
0.0

8.1
45.6
75.3
10.9
89.4
0.1

Percent in same boro, choices 1-3
Limited unscreened, choices 1-3
Screened, choices 1-3

79.1
34.8
38.4

79.3
35.8
35.8

75.0
45.6
29.2

81.2
31.3
38.2

76.3
44.1
30.4

Notes: authors’ calculations using 2013-14 high school admissions data from the NYCDOE (the most recent
available at the time of randomization to treatment assignment).

73

Table A.3: Counts of schools by treatment group, borough, and blocking group
Treatment groups:
FF1 FF2 FF3

Control

Total

Borough totals:
Bronx
Brooklyn
Manhattan
Queens

14
14
7
4

14
14
7
4

14
14
7
4

19
16
8
4

61
58
29
16

Total

39

39

39

47

164

Blocking group totals:
Bronx
Brooklyn
Manhattan
Queens
Queens (Rockaways)
Bronx (pilot)
Brooklyn (pilot)
Manhattan (pilot)

10
11
6
2
2
4
3
1

10
11
6
2
2
4
3
1

10
11
6
2
2
4
3
1

15
13
7
2
2
4
3
1

45
46
25
8
8
16
12
4

Total

39

39

39

47

164

Notes: This table shows our planned assignment of 164 recruited schools to treatment and control groups.
Schools were randomly assigned to treatments within matched blocks of similar schools. Blocks were formed
within the eight strata of schools listed in the bottom panel. 23 pilot study schools were blocked separately
within borough, and all pilot schools were assigned to one of three treatments (none to control). Nearest
neighbor (non-pilot) matches from the same borough were selected as controls for the pilot study blocks.
One additional non-pilot school in Brooklyn was added to the Brooklyn (pilot) group to balance one of the
blocks. After treatment groups were assigned, the 165th school (which shared a guidance counselor with
another participating school) was forced into the same treatment group.

74

Table A.4: Balance test: predicting treatment assignment using school characteristics

Percent with no R1 match
Graduation rate of top 3 choices
Percent of top 3 choices limited unscreened
Mean 8th grade math score
Mean 8th grade ELA score
Grade 8 enrollment
% Free or reduced price lunch
% EL
% SWD
% Female
% Black
% White
% Hispanic
Charter school
Percent ELA level 1
Percent Math level 1
Pilot study
Constant

N
Joint p-value

(1)
FF1 vs C

(2)
FF2 vs C

(3)
FF3 vs C

-1.602
(-0.482)
0.068
(1.186)
0.018
(1.054)
0.053
(1.362)
-0.015
(-0.355)
0.003
(1.783)
0.008
(0.487)
-0.015
(-0.540)
0.006
(0.235)
0.003
(0.111)
0.024
(1.198)
0.045
(1.358)
0.021
(1.162)
0.360
(0.604)
0.010
(0.355)
0.032
(1.122)
0.962*
(2.496)
-21.997
(-1.500)

1.958
(0.624)
-0.012
(-0.225)
0.016
(1.058)
-0.015
(-0.420)
0.019
(0.390)
-0.002
(-1.077)
-0.006
(-0.473)
-0.002
(-0.068)
-0.003
(-0.105)
-0.022
(-0.611)
-0.017
(-0.866)
-0.014
(-0.493)
-0.021
(-1.163)
0.225
(0.508)
0.015
(0.420)
-0.011
(-0.402)
1.046**
(2.940)
3.008
(0.148)

1.644
(0.574)
-0.074
(-1.459)
-0.012
(-0.780)
0.019
(0.516)
0.039
(1.005)
-0.001
(-0.741)
0.003
(0.238)
0.014
(0.675)
0.034
(1.527)
0.022
(1.029)
-0.015
(-0.634)
-0.044
(-1.287)
-0.020
(-0.874)
0.402
(0.709)
0.007
(0.263)
0.015
(0.495)
0.910*
(2.378)
-11.469
(-0.660)

86
0.780

86
0.964

87
0.863

Notes: t-statistics in parentheses. ∗ = p < 0.05 ∗∗ = p < 0.01. All regressions include randomization block
fixed effects.

75

Table A.5: Mean school characteristics by treatment group, 2014-15
Treatment groups:
FF1 FF2 FF3
N
Charter school
Brooklyn
Manhattan
Queens
Bronx
In high poverty sampling frame
In mid poverty sampling frame
Pilot study participant
% Female
% Male
% Asian
% Black
% Hispanic
% Other race
% White
% SWD
% EL
% FRPL
Census residential poverty
Mean 8th grade math scale score
% Level 1 math
% Level 4 math
Mean 8th grade ELA scale score
% Level 1 ELA
% Level 4 ELA
Enrollment
Grade 8 enrollment
Grade 9 enrollment
Mean graduation rate - all choices
Mean graduation rate - top 3 choices
Mean graduation rate - 1st choice
Percent of all choices limited unscreened
Percent of top 3 choices limited unscreened
Percent of 1st choices limited unscreened
Percent with SPHS offer
Percent with LGA offer
Percent with no R1 match

Control

39
0.077
0.359
0.179
0.103
0.359
0.667
0.308
0.205
48.7
51.3
4.3
37.1
52.0
1.2
5.4
23.5
13.9
89.7
45.0
283.7
51.9
2.2
285.6
42.5
2.7
498.0
132.4
0.0

39
0.103
0.359
0.179
0.103
0.359
0.513
0.410
0.205
48.6
51.4
4.9
40.1
49.1
0.9
4.9
22.3
13.7
87.1
42.8
284.1
50.2
2.8
287.0
39.5
2.7
462.5
99.6
0.0

40
0.075
0.375
0.175
0.100
0.350
0.700
0.275
0.175
48.6
51.4
5.8
38.3
50.8
1.1
3.9
23.6
15.6
90.3
46.3
285.3
48.6
3.4
287.4
39.1
3.2
414.9
112.8
0.0

47
0.064
0.340
0.170
0.085
0.404
0.638
0.319
0.000
48.7
51.3
5.0
34.7
54.1
1.2
4.9
22.2
15.7
88.7
45.6
285.4
48.3
2.9
287.1
39.1
3.5
511.1
118.6
0.0

79.4
80.6
81.3
46.0
45.5
45.3
0.0
0.0
0.1

79.5
80.5
81.1
45.2
44.4
43.6
0.0
0.0
0.1

79.0
80.2
81.1
41.6
39.5
38.4
0.0
0.0
0.1

79.7
80.7
81.7
42.5
42.0
41.7
0.0
0.0
0.1

Notes: One recruited school that shared a guidance counselor with a second recruited school was omitted
from the original block randomization and later added back to FF3 (the group to which its companion school
was randomly assigned). This explains why FF3 includes 40 schools instead of the original 39 from Table
A.3. High school choice outcomes in the bottom section of the table are from 2013-14.

76

Table B.1: Mean characteristics of schools on Fast Facts
All study
schools
N
Number of schools on FF1
Total # of seats
Graduation rate
Imputed gradrate
Graduation rate ≥70%
Apps per seat
Same borough
Travel time (mins.)
Audition
Ed Option
Limited Unscreened
Screened
Screened: Language
Zoned
Screened pgms only
Bronx
Brooklyn
Manhattan
Queens
New school
SD gradrate (with imp)

165

Treatment groups:
FF1
FF2
FF3
39

39

Control

40

47

30
30
30
30
4036.3 4146.8 4002.1 4066.0
81.5
81.6
81.4
81.4
0.176 0.185 0.180 0.163
0.985 0.979 0.977 0.989
9.4
9.6
9.4
9.1
0.789 0.812 0.789 0.805
25.3
24.7
26.7
25.7
0.077 0.083 0.068 0.078
0.152 0.148 0.148 0.163
0.574 0.573 0.599 0.572
0.251 0.248 0.246 0.254
0.096 0.093 0.088 0.091
0.014 0.016 0.018 0.015
0.233 0.237 0.216 0.234
0.355 0.352 0.376 0.336
0.330 0.332 0.323 0.353
0.254 0.259 0.233 0.242
0.061 0.056 0.068 0.069
0.263 0.256 0.265 0.257
9.0
9.0
9.0
9.0

30
3947.9
81.7
0.176
0.994
9.4
0.757
24.2
0.077
0.151
0.557
0.255
0.108
0.009
0.243
0.357
0.313
0.279
0.052
0.272
8.9

p-value

0.639
0.423
0.244
0.322
0.529
0.124
0.077
0.519
0.499
0.162
0.738
0.170
0.465
0.192
0.063
0.910
0.248
0.380
0.589
0.996

Notes: for this table we first calculated a mean for each middle school characterizing the 30 high schools
on its Fast Facts list. This table reports the means of those quantities, over all study schools (N=165)
and separately by treatment group. Recall that Fast Facts lists were generated for all schools in the study,
regardless of treatment group. The p-value reported in the rightmost column is from a regression of the
listed high school characteristic on a set of treatment group indicators and randomization block fixed effects.
The null hypothesis tested is that the coefficients on the three treatment indicators are jointly zero. The
graduation rate and graduation rate ≥70% outcomes are conditional on being non-missing. Total seat counts
do not include zoned guarantee programs, which do not have a maximum seat count.

77

Table B.2: Mean characteristics of high schools listed on combined Fast Facts and academically non-selective school supplement
All study
schools
N
Number of schools on FF2
Total # of seats
Graduation rate
Imputed gradrate
Graduation rate ≥70%
Apps per seat
Same borough
Travel time (mins.)
Audition
Ed Option
Limited Unscreened
Screened
Screened: Language
Zoned
Screened pgms only
Bronx
Brooklyn
Manhattan
Queens
New school
SD gradrate (with imp)

165

Treatment groups:
FF1
FF2
FF3
39

39

Control

40

47

32.4
32.5
32.1
32.3
4310.9 4441.3 4237.2 4325.9
81.2
81.3
81.1
81.1
0.190 0.200 0.196 0.172
0.981 0.975 0.971 0.987
9.3
9.5
9.3
9.1
0.767 0.781 0.765 0.789
26.1
25.6
27.2
26.5
0.069 0.073 0.062 0.070
0.140 0.135 0.136 0.151
0.612 0.612 0.631 0.607
0.230 0.227 0.228 0.235
0.089 0.086 0.082 0.085
0.013 0.015 0.017 0.015
0.212 0.214 0.199 0.213
0.363 0.360 0.388 0.344
0.325 0.332 0.315 0.349
0.251 0.255 0.228 0.238
0.061 0.053 0.069 0.069
0.271 0.267 0.275 0.261
8.9
9.0
9.0
8.9

32.8
4251.1
81.4
0.191
0.989
9.3
0.737
25.3
0.069
0.137
0.601
0.231
0.099
0.008
0.220
0.360
0.308
0.279
0.053
0.281
8.9

p-value

0.347
0.607
0.418
0.093
0.299
0.675
0.158
0.242
0.623
0.409
0.232
0.866
0.270
0.459
0.335
0.026*
0.813
0.183
0.279
0.487
0.922

Notes: for this table, we first calculated a mean for each middle school characterizing the 30+ high schools
on its combined Fast Facts and non-selective school supplement. This table reports the means of those
quantities, over all study schools (N=165) and separately by treatment group. Recall that these lists were
generated for all schools in the study, regardless of treatment group. The p-value reported in the rightmost
column is from a regression of the reported school characteristics on a set of treatment group indicators and
randomization block fixed effects. The null hypothesis tested is that the coefficients on the three treatment
indicators are jointly zero. The graduation rate and graduation rate ≥70% outcomes are conditional on being
non-missing. Total seat counts do not include zoned guarantee programs, which do not have a maximum
seat count.

78

Table B.3: Mean characteristics of high schools listed on combined Fast Facts and academic
interest area supplement
All study
schools
N
Number of schools on FF3
Total # of seats
Graduation rate
Imputed gradrate
Graduation rate ≥70%
Apps per seat
Same borough
Travel time (mins.)
Audition
Ed Option
Limited Unscreened
Screened
Screened: Language
Zoned
Screened pgms only
Bronx
Brooklyn
Manhattan
Queens
New school
SD gradrate (with imp)

165

Treatment groups:
FF1
FF2
FF3
39

39

Control

40

47

42.9
43.0
43.2
42.3
6278.3 6473.2 6230.4 6208.1
82.6
82.7
82.6
82.3
0.162 0.168 0.161 0.153
0.989 0.987 0.984 0.988
9.4
9.6
9.5
9.2
0.653 0.669 0.648 0.674
31.6
31.4
33.1
31.7
0.069 0.077 0.065 0.070
0.223 0.215 0.221 0.231
0.570 0.572 0.586 0.567
0.252 0.250 0.250 0.251
0.092 0.093 0.086 0.091
0.019 0.021 0.021 0.020
0.177 0.181 0.168 0.177
0.280 0.274 0.287 0.271
0.310 0.314 0.304 0.332
0.316 0.322 0.303 0.307
0.093 0.090 0.106 0.090
0.224 0.219 0.222 0.221
8.804 8.846 8.859 8.792

43.0
6216.0
82.7
0.163
0.997
9.4
0.625
30.5
0.067
0.225
0.560
0.254
0.099
0.014
0.180
0.286
0.294
0.331
0.088
0.231
8.733

p-value

0.512
0.206
0.448
0.472
0.318
0.438
0.113
0.096
0.161
0.191
0.211
0.883
0.161
0.510
0.335
0.366
0.877
0.485
0.330
0.696
0.782

Notes: for this table, we first calculated a mean for each middle school characterizing the 30+ high schools
on its combined Fast Facts and academic interest area supplement. This table reports the means of those
quantities, over all study schools (N=165) and separately by treatment group. Recall that these lists were
generated for all schools in the study, regardless of treatment group. The p-value reported in the rightmost
column is from a regression of the reported school characteristics on a set of treatment group indicators and
randomization block fixed effects. The null hypothesis tested is that the coefficients on the three treatment
indicators are jointly zero. The graduation rate and graduation rate ≥70% outcomes are conditional on being
non-missing. Total seat counts do not include zoned guarantee programs, which do not have a maximum
seat count.

79

Table B.4: Text message reminders and participants by week
Week Date of message
Text message 1:
number
(Sunday)
General Openhse
1
2
3
4
5
6
7
8
9
10
11

Text message 2:
General Openhse

20-Sep-15
27-Sep-15
4-Oct-15
11-Oct-15
18-Oct-15
25-Oct-15
1-Nov-15
8-Nov-15
15-Nov-15
22-Nov-15
29-Nov-15

9
3
2
0
0
0
0
1
0
0
1

30
36
37
39
39
39
39
38
39
39
38

39
22
10
1
0
1
0
10
2
14
22

0
17
29
38
39
38
39
29
37
25
17

Total

16

413

121

308

Notes: authors’ calculations.

Cumulative
Treatment 2
School visits
12
17
24
33
34
36
37
38
39
39
39

Number of Number of
unique text unique text
participants
schools
93
339
591
868
1194
1585
1665
1729
1787
1881
1881

19
27
32
38
38
38
38
39
39
39
39

80

Table C.1: Percent of students with information session priority, 2014-15
1st choice

1st-5th
choices

All LUS
choices

All students

40.8

36

34.8

Free lunch
Reduced price lunch
Not free or reduced

37.9
49.3
53.7

34.3
41.5
45.4

33.4
39
43

EL
Not EL

33.3
41.9

30.4
36.9

29.7
35.6

Special education
Not special education

35.6
42.4

31.7
37.4

30.2
36.1

Black
Hispanic
Not black or Hispanic

40.3
37.1
54.1

37
32.4
46.4

36
31.2
44.5

Female
Male

42.3
39.5

37.1
35.1

36
33.7

Bottom two ELA quartiles
Top two ELA quartiles

36.2
50.3

32.5
43.3

31.5
41.4

18,379

87,446

149,038

N

Notes: authors’ analysis using data from the 2014-15 high school admissions process. Only public school
applicants to limited unscreened (LUS) programs that gave open house or information session priority are
included. Students given priority for other reasons—such as returning 8th graders—are excluded from these
calculations. Column (1) includes the 18,379 students who ranked a LUS program as their 1st choice. In
columns (2) and (3), the unit of observation is a student-choice. For example, if a student ranked three
LUS programs and received information session priority for two, they would be counted twice among those
with priority and once among those without priority. These columns can be interpreted as the probability a
student with a given characteristic—having ranked a LUS school—received information session priority for
that school. “Not free or reduced” also excludes students enrolled in a universal free meals school.

81

Table C.2: Impact of informational interventions on graduation rate of choices and matches,
with missings imputed
FF1

Treatment groups
FF2
FF3

Pooled

Control group
Mean
SD

Graduation rate:
1st-3rd choices (mean)
(with imputed)

0.219
(0.451)

-0.376
(0.606)

-1.026+
(0.534)

-0.384
(0.424)

80.9

10.6

Final matched school
(with imputed)

1.633**
(0.537)

0.565
(0.618)

-0.0775
(0.567)

0.743
(0.455)

73.6

13.2

9th grade enrolled school
(with imputed)

1.056+
(0.538)

0.396
(0.615)

-0.156
(0.585)

0.450
(0.459)

74.4

13.7

-3.186*
(1.592)

-1.116
(2.004)

0.474
(1.977)

-1.330
(1.576)

21.9

29.5

Final matched school
(with imputed)

-7.235**
(2.284)

-5.522*
(2.781)

-3.113
(2.771)

-5.311*
(2.185)

40.3

49.0

9th grade enrolled school
(with imputed)

-5.869**
(2.238)

-4.319
(2.677)

-2.827
(2.735)

-4.376*
(2.143)

38.4

48.6

Graduation rate below 70%:
1st-3rd choices (mean)
(with imputed)

Notes: each row reports estimates from two regressions. The first includes indicator variables for the
separate treatment groups (FF1-FF3). The second pools the three treatment groups into one indicator
variable. Graduation rates were imputed for high schools that had not yet had a graduating cohort (see
Appendix B for details). Sample sizes vary from 18,058 (9th grade enrolled school) to 19,107 (1st-3rd choices).
All models include the following controls: school randomization block, student race/ethnicity, female, free
lunch eligible, reduced-price lunch eligible, special education, EL, foreign born, quadratic in 7th grade ELA
and mathematics z-scores, missing indicators for z-scores and other covariates, and indicator for students in
schools that received a treatment in our 2014-15 pilot study. School-level controls include a charter indicator,
8th grade enrollment, percent female, percent by race/ethnicity, percent with disabilities, percent EL, and
mean 8th grade math and ELA scores. All school controls are measured in the year prior to treatment.
Standard errors in parentheses, adjusted for clustering at the school level. + p < 0.10 * p < 0.05 ** p < 0.01
*** p < 0.001.

82

Table C.3: Impact of informational interventions: excluding pilot study schools
Treatment groups
FF1
FF2
FF3
% of 1st-3rd choices from
intervention-specific list
Matched to 1st choice

Graduation rate:
1st-3rd choices (mean)

Final matched school

Graduation rate <70%:
1st-3rd choices (mean)

Final matched school

Control group
Mean
SD

9.619***
(2.239)

5.479*
(2.254)

6.714**
(2.005)

37.2

32.6

2.378
(1.615)

2.572
(1.844)

2.625
(1.603)

44.6

49.7

0.444
(0.487)

-0.149
(0.702)

-0.578
(0.552)

80.9

11.2

1.633**
(0.590)

0.342
(0.718)

0.366
(0.616)

73.4

13.7

-3.140+
(1.828)

-2.032
(2.310)

-0.631
(2.116)

23.1

31.6

-6.702**
(2.474)

-5.261+
(3.093)

-4.806
(2.940)

42.9

49.5

Notes: each row reports estimates from two regressions. The first includes indicator variables for the
separate treatment groups (FF1-FF3). The second pools the three treatment groups into one indicator
variable. Sample sizes vary from 14,705 (graduation rate at final matched school) to 17,083 (matched to
1st choices). All models include the following controls: school randomization block, student race/ethnicity,
female, free lunch eligible, reduced-price lunch eligible, special education, EL, foreign born, quadratic in
7th grade ELA and mathematics z-scores, missing indicators for z-scores and other covariates. School-level
controls include a charter indicator, 8th grade enrollment, percent female, percent by race/ethnicity, percent
with disabilities, percent EL, and mean 8th grade math and ELA scores. All school controls are measured
in the year prior to treatment. Standard errors in parentheses, adjusted for clustering at the school level. +
p < 0.10 * p < 0.05 ** p < 0.01 *** p < 0.001.

83

Table C.4: Impact of informational interventions: excluding charter schools
Treatment groups
FF1
FF2
FF3
% of 1st-3rd choices from
intervention-specific list
Matched to 1st choice

Graduation rate:
1st-3rd choices (mean)

Final matched school

Graduation rate <70%:
1st-3rd choices (mean)

Final matched school

10.66*** 5.130*
(2.163) (2.148)

Control group
Mean
SD

5.630**
(2.047)

37.5

32.6

3.090+
(1.785)

3.037
(1.922)

3.248+
(1.720)

44.9

49.7

0.397
(0.509)

-0.237
(0.711)

-1.054+
(0.562)

80.8

11.2

1.545**
(0.583)

0.204
(0.708)

-0.147
(0.627)

73.4

13.7

-3.112+
(1.845)

-0.957
(2.404)

0.560
(2.169)

23.3

31.7

-6.387*
(2.554)

-4.578
(3.204)

-2.963
(3.020)

42.8

49.5

Notes: each row reports estimates from two regressions. The first includes indicator variables for the
separate treatment groups (FF1-FF3). The second pools the three treatment groups into one indicator
variable. Sample sizes vary from 15,766 (graduation rate at final matched school) to 18,301 (matched to
1st choices). All models include the following controls: school randomization block, student race/ethnicity,
female, free lunch eligible, reduced-price lunch eligible, special education, EL, foreign born, quadratic in 7th
grade ELA and mathematics z-scores, missing indicators for z-scores and other covariates, and indicator for
students in schools that received a treatment in our 2014-15 pilot study. School-level controls include 8th
grade enrollment, percent female, percent by race/ethnicity, percent with disabilities, percent EL, and mean
8th grade math and ELA scores. All school controls are measured in the year prior to treatment. Standard
errors in parentheses, adjusted for clustering at the school level. + p < 0.10 * p < 0.05 ** p < 0.01 ***
p < 0.001.

84

Table C.5: Impact of informational interventions on other measures of HS quality
Treatment groups
FF2
FF3

Pooled

-0.0840
(0.320)

-0.386
(0.414)

-1.176**
(0.353)

-0.557+
(0.296)

85.6

7.4

0.752+
(0.382)

0.204
(0.443)

-0.738+
(0.407)

0.0750
(0.314)

81.3

10.2

0.196
(0.607)

-0.902
(0.831)

-1.596*
(0.758)

-0.734
(0.554)

63.1

14.9

1.649*
(0.645)

-0.239
(0.803)

-1.148+
(0.655)

0.152
(0.545)

53.9

16.4

-0.504
(0.337)

-0.835*
(0.396)

-0.918**
(0.332)

-0.739*
(0.288)

83.4

6.8

-0.259
(0.362)

-0.544
(0.421)

-0.737+
(0.410)

-0.505
(0.318)

80.0

9.5

FF1
HS 9th grade % on track:
1st-3rd choices (mean)

Final matched school

College readiness %:
1st-3rd choices (mean)

Final matched school

% of students who feel safe:
1st-3rd choices (mean)

Final matched school

Control group
Mean
SD

Notes: each row reports estimates from two regressions. The first includes indicator variables for the separate
treatment groups (FF1-FF3). The second pools the three treatment groups into one indicator variable.
Sample sizes vary from 15,961 (college readiness at final matched school) to 19,107 (on-track percent at 1st3rd choices). All models include the following controls: school randomization block, student race/ethnicity,
female, free lunch eligible, reduced-price lunch eligible, special education, EL, foreign born, quadratic in 7th
grade ELA and mathematics z-scores, missing indicators for z-scores and other covariates, and indicator
for students in schools that received a treatment in our 2014-15 pilot study. School-level controls include a
charter indicator, 8th grade enrollment, percent female, percent by race/ethnicity, percent with disabilities,
percent EL, and mean 8th grade math and ELA scores. All school controls are measured in the year prior to
treatment. Standard errors in parentheses, adjusted for clustering at the school level. + p < 0.10 * p < 0.05
** p < 0.01 *** p < 0.001.

2.905*
(1.454)
2.225+
(1.264)
-0.205
(0.463)
0.832
(0.521)
-1.240
(1.756)
-5.040*
(2.432)

Matched to
1st choice

Matched to
1st-3rd choice

Graduation rate:
1st-3rd choices

Graduation rate:
matched school

% below 70%
1st-3rd choices

Graduation rate
below 70% (match)

-5.063+
(2.599)

-0.388
(1.783)

0.652
(0.562)

-0.881+
(0.528)

6.124***
(1.754)

5.286**
(1.770)

7.638***
(2.004)

Not FRPL

-4.688*
(2.226)

-1.839
(1.775)

0.453
(0.568)

-0.0863
(0.547)

3.328*
(1.571)

1.297
(1.823)

9.622***
(1.601)

Spanish

-7.535+
(3.924)

-5.315+
(2.739)

0.193
(0.934)

0.387
(0.877)

-2.965
(2.901)

1.287
(3.355)

11.34***
(2.652)

Other lang

-3.393
(2.186)

0.322
(1.564)

0.686
(0.556)

-0.568
(0.490)

2.888*
(1.286)

3.558*
(1.472)

4.211**
(1.570)

English

-4.552*
(2.092)

-0.101
(1.832)

0.779
(0.593)

-0.692
(0.539)

4.712**
(1.451)

3.255+
(1.829)

6.154***
(1.727)

Math Q1

-9.962*
(4.521)

-2.852
(1.981)

1.338
(1.147)

-0.581
(0.603)

3.692
(2.553)

5.445+
(3.161)

10.80***
(2.677)

Math Q4

-7.807
(5.791)

-1.827
(3.439)

3.141+
(1.679)

-0.774
(1.156)

6.246
(4.152)

9.504*
(4.501)

6.256+
(3.203)

New to dist

Notes: Student and school covariates and block effects included (as in earlier tables). Standard errors in parentheses, adjusted for
clustering at the school level. + p < 0.10 * p < 0.05 ** p < 0.01 *** p < 0.001.

7.314***
(1.747)

% of 1st-3rd
choices from FF1

FRPL

Table C.6: Pooled impact estimates by subgroup, part 1

85

5.307***
(1.532)
4.375**
(1.497)
-0.420
(0.445)
0.731
(0.470)
-0.621
(1.521)
-4.634+
(2.348)

Matched to
1st choice

Matched to
1st-3rd choice

Graduation rate:
1st-3rd choices

Graduation rate:
matched school

% below 70%
1st-3rd choices

Graduation rate
below 70% (match)

-14.40*
(5.608)

-14.79***
(3.531)

0.722
(1.403)

2.075+
(1.131)

-11.22***
(3.257)

6.800+
(4.068)

15.60***
(3.018)

White

-2.244
(2.267)

1.813
(1.671)

0.414
(0.671)

-0.992+
(0.590)

5.240**
(1.602)

4.575*
(1.848)

2.707+
(1.469)

Black

-5.597**
(2.035)

-1.354
(1.570)

0.974*
(0.459)

-0.127
(0.481)

3.029*
(1.431)

0.895
(1.595)

8.581***
(1.597)

Hispanic

-15.10*
(5.894)

-5.896+
(3.454)

1.795
(1.688)

0.364
(1.273)

2.403
(3.101)

7.115+
(4.070)

12.48***
(3.288)

Asian

-5.604+
(3.125)

-0.457
(2.408)

-0.007
(0.769)

-0.636
(0.712)

3.972+
(2.241)

3.821
(2.462)

10.54***
(1.943)

Immigrant

-4.717*
(2.284)

-1.275
(1.676)

0.843+
(0.473)

-0.293
(0.453)

2.476*
(1.201)

3.223*
(1.354)

7.025***
(1.760)

Born in US

Notes: Student and school covariates and block effects included (as in earlier tables). Standard errors in parentheses, adjusted for
clustering at the school level. + p < 0.10 * p < 0.05 ** p < 0.01 *** p < 0.001.

-4.696+
(2.511)

-1.565
(1.969)

0.610
(0.579)

-0.322
(0.511)

1.081
(1.294)

1.104
(1.640)

6.835*** 7.825***
(1.812)
(1.825)

Boys

% of 1st-3rd
choices from FF1

Girls

Table C.7: Pooled impact estimates by subgroup, part 2

86

87

Table C.8: Additional subgroup estimates: usage and match rates
Usage: % of 1st-3rd choices
from intervention-specific list
FF1
FF2
FF3

Matched to 1st choice
FF2
FF3
FF1

N

Full study sample

10.43***
(2.112)

5.503**
(2.051)

5.482**
(1.957)

3.104+
(1.651)

3.530+
(1.794)

3.539*
(1.655)

19109

Girls

10.07***
(2.122)

5.275*
(2.192)

4.509*
(2.068)

5.985**
(1.864)

4.449*
(2.053)

5.200**
(1.939)

9371

Boys

10.71***
(2.308)

5.655**
(2.135)

5.915**
(2.041)

-0.0630
(1.963)

2.203
(2.223)

1.580
(1.942)

9738

Foreign born

14.30***
(2.503)

9.663***
(2.815)

7.917***
(2.198)

3.386
(3.062)

4.187
(3.379)

4.020
(3.068)

3042

Born in US

9.921***
(2.116)

5.030*
(2.042)

5.173*
(2.010)

3.066+
(1.627)

3.279+
(1.823)

3.353*
(1.631)

16067

EL

13.11***
(2.795)

6.169*
(3.041)

6.837*
(2.878)

1.022
(2.277)

-0.131
(3.423)

6.241*
(3.026)

3064

Not EL

9.788***
(2.166)

5.192*
(2.059)

4.974*
(1.962)

3.397*
(1.720)

3.538*
(1.755)

2.511
(1.673)

16045

Special education

8.779***
(2.498)

4.388+
(2.299)

5.744*
(2.315)

0.324
(2.572)

-0.114
(2.600)

3.478
(2.446)

4141

Not special education

10.84***
(2.118)

5.888**
(2.159)

5.527**
(2.004)

3.706*
(1.681)

4.545*
(1.832)

3.289+
(1.686)

14968

Girls - Q1 math

8.491***
(2.076)

6.760**
(2.020)

7.755***
(1.970)

3.949
(2.851)

0.00185
(3.214)

5.366+
(3.048)

2821

Girls - Q4 math

13.15***
(3.719)

7.616+
(4.077)

1.046
(4.657)

7.288
(4.668)

-6.345
(5.343)

10.31*
(5.050)

1098

Boys - Q1 math

5.702*
(2.562)

3.808
(2.655)

4.334*
(2.186)

-1.310
(2.766)

3.548
(3.124)

4.554
(2.791)

3197

Boys - Q4 math

19.77***
(3.895)

7.553*
(3.724)

12.86***
(3.270)

7.885
(5.703)

5.591
(5.696)

8.042
(5.225)

1030

Notes: Each row and column set (FF1-FF3) represents estimates from a separate regression for the indicated
subgroup. Student and school covariates and block effects included (as in earlier tables). Standard errors in
parentheses, adjusted for clustering at the school level. + p < 0.10 * p < 0.05 ** p < 0.01 *** p < 0.001.

88

Table C.9: Additional subgroup estimates: graduation rates of choices and matches
Graduation rate
matched school
FF1
FF2
FF3

Graduation rate: below
70% matched school
FF2
FF3
FF1

N

Full study sample

1.664**
(0.571)

0.526
(0.662)

-0.066
(0.596)

-6.274*
(2.418)

-5.147+
(2.959)

-3.346
(2.865)

16657

Girls

1.439**
(0.546)

0.677
(0.690)

0.0382
(0.589)

-5.795*
(2.450)

-5.597+
(3.104)

-2.820
(2.945)

8272

Boys

1.754*
(0.679)

0.290
(0.755)

-0.372
(0.709)

-6.280*
(2.726)

-4.291
(3.216)

-3.245
(3.043)

8385

Foreign born

0.316
(0.960)

0.283
(1.007)

-0.442
(0.952)

-4.967
(3.699)

-8.233*
(4.062)

-4.825
(3.833)

2651

1.850*** 0.579
(0.533) (0.644)

-0.0417
(0.574)

-6.410**
(2.310)

-4.747
(2.908)

-2.896
(2.840)

14006

Born in US

EL

2.151*
(1.049)

0.0174
(1.086)

-2.495*
(1.137)

-12.75***
(3.435)

-5.345
(3.590)

-0.399
(3.704)

2707

Not EL

1.570**
(0.569)

0.606
(0.681)

0.341
(0.591)

-4.949*
(2.476)

-5.053
(3.117)

-3.558
(2.907)

13950

Special education

0.969
(0.760)

-0.420
(0.870)

-1.228+
(0.698)

-0.875
(2.943)

-1.510
(3.583)

1.913
(3.215)

3662

Not special education

1.741**
(0.600)

0.631
(0.688)

0.0661
(0.637)

-7.390**
(2.580)

-5.749+
(3.068)

-4.322
(3.018)

12995

Girls - Q1 math

1.636*
(0.754)

1.601
(0.990)

-0.429
(0.806)

-6.346*
(3.079)

-11.02**
(3.903)

1.245
(3.397)

2505

Girls - Q4 math

0.418
(1.381)

-0.267
(1.500)

1.563
(1.678)

-6.815
(4.956)

-6.491
(5.213)

-11.40*
(5.455)

908

Boys - Q1 math

1.633+
(0.868)

0.605
(0.838)

-0.552
(0.854)

-5.613+
(2.999)

-5.693+
(3.342)

-2.206
(3.155)

2808

Boys - Q4 math

3.822*
(1.599)

0.570
(2.069)

0.275
(1.731)

-14.58*
(6.220)

-2.764
(7.835)

-9.329
(6.433)

785

Each row and column set (FF1-FF3) represents estimates from a separate regression for the indicated subgroup. Student and school covariates and block effects included (as in earlier tables). Standard errors in
parentheses, adjusted for clustering at the school level. + p < 0.10 * p < 0.05 ** p < 0.01 *** p < 0.001.

89

Table C.10: Impact of informational interventions on other choice outcomes
FF1

Treatment groups
FF2
FF3

Pooled

Control group
Mean
SD

Nonselective and screened
language supplement:
Percent from nonselective
supplement, 1st-3rd choices

3.263*
(1.455)

6.748***
(1.588)

3.049+
(1.570)

4.077**
(1.235)

14.5

23.3

On screened language
supplement, % of all choices

0.485
(0.439)

-0.309
(0.386)

0.167
(0.427)

0.166
(0.359)

3.4

11.6

Any choice from screened
language supplement

-0.740
(1.351)

-0.551
(1.529)

-0.957
(1.280)

-0.770
(1.119)

15.3

36.0

Characteristics of choices:
Percent new schools,
1st-3rd choices

-0.0982
(0.735)

1.082
(0.870)

-1.056
(0.760)

-0.143
(0.628)

9.0

17.9

All choices in the
same borough

9.009**
(2.817)

3.551
(3.474)

3.982
(2.771)

5.792*
(2.308)

51.8

–

Top 3 choices in the
same borough

9.370***
(2.564)

2.346
(2.965)

3.950
(2.526)

5.609**
(2.063)

64.9

–

Graduation rate of choices
1-3 in descending order

2.075*
(1.010)

2.995**
(0.953)

1.362
(0.997)

2.052*
(0.791)

34.2

47.4

Percent of all choices
within 45 minutes

-1.103
(2.254)

-3.850+
(2.132)

-3.141+
(1.836)

-2.544
(1.661)

80.0

22.6

0.519
(1.601)

-2.347
(1.903)

-1.109
(1.789)

-0.804
(1.498)

27.3

44.5

-0.0594
(0.243)

0.157
(0.287)

-0.311
(0.236)

-0.0950
(0.212)

2.1

14.3

Other outcomes:
Took SPHS exam

Offered a SPHS seat

Notes: each row represents estimates from a separate regression. Sample sizes vary from 19,013 (graduation rates in descending order) to 19,109 (all others). All models include the following controls: school
randomization block, student race/ethnicity, female, free lunch eligible, reduced-price lunch eligible, special
education, EL, foreign born, quadratic in 7th grade ELA and mathematics z-scores, missing indicators for
z-scores and other covariates, and indicator for students in schools that received a treatment in our 2014-15
pilot study. School-level controls include a charter indicator, 8th grade enrollment, percent female, percent
by race/ethnicity, percent with disabilities, percent EL, and mean 8th grade math and ELA scores. All
school controls are measured in the year prior to treatment. Standard errors in parentheses, adjusted for
clustering at the school level. + p < 0.10 * p < 0.05 ** p < 0.01 *** p < 0.001.

