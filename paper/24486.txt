NBER WORKING PAPER SERIES

MULTIMARKET CONTACT IN HEALTH INSURANCE:
EVIDENCE FROM MEDICARE ADVANTAGE
Haizhen Lin
Ian M. McCarthy
Working Paper 24486
http://www.nber.org/papers/w24486

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
April 2018, Revised July 2019

We thank Liran Einav, Leemore Dafny, Jeff Prince, Matthew Schmitt, and Fiona Scott Morton
for useful comments. We also thank seminar participants at Stanford University, Indiana
University, University of Illinois Urbana-Champagne, and University of Tennessee, as well as
conference audience at the Georgia Health Economics Research Day, the American Economic
Association Meetings, the International Health Economics Association Meetings, and the
International Industrial Organization Conference. The views expressed herein are those of the
authors and do not necessarily reflect the views of the National Bureau of Economic Research.
NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.
© 2018 by Haizhen Lin and Ian M. McCarthy. All rights reserved. Short sections of text, not to
exceed two paragraphs, may be quoted without explicit permission provided that full credit,
including © notice, is given to the source.

Multimarket Contact in Health Insurance: Evidence from Medicare Advantage
Haizhen Lin and Ian M. McCarthy
NBER Working Paper No. 24486
April 2018, Revised July 2019
JEL No. I11,L11
ABSTRACT
Many industries, including health insurance, are characterized by a handful of large firms
competing against each other in multiple markets. Such overlap across markets, defined as
multimarket contact (MMC), may facilitate tacit collusion and thus reduce the intensity of
competition. We examine the effects of MMC on health insurance prices and quality using
comprehensive data on the Medicare Advantage (MA) market from 2008 through 2015. Our
identification strategy exploits two plausibly exogenous changes to MMC: 1) out-of-market
consolidations, which affect MMC but are not likely driven by local market heterogeneity; and 2)
reimbursement policy changes in a subset of markets, which encourage additional entry and
therefore affect MMC even in markets otherwise unaffected by the policy itself. Across a range
of estimates and alternative measures of MMC, our results consistently support the mutual
forbearance hypothesis, where we find that prices are significantly higher and hiqh-quality plans
become less pervasive as MMC increases. These results suggest MMC as one potential channel
through which cross-market consolidations and regulatory policies could alter competitiveness in
local markets otherwise unaffected by the merger or policy.

Haizhen Lin
Department of Business Economics and Public Policy
Kelley School of Business
Indiana University
1309 East Tenth Street
Bloomington, IN 47405
and NBER
hzlin@indiana.edu
Ian M. McCarthy
Department of Economics
Emory University
Rich Memorial Building, Room 319
Atlanta, GA 30322
and NBER
immccar@emory.edu

An online appendix is available at http://www.nber.org/data-appendix/w24486

1

Introduction

A large literature in management and economics suggests that competition between firms may
be softened as a result of multimarket contact (MMC) (Karnani & Wernerfelt, 1985; Bernheim &
Whinston, 1990; Evans & Kessides, 1994; Prince & Simon, 2009; Ciliberto & Williams, 2014). The
possibility that MMC could promote anticompetitive outcomes was first articulated by Edwards
(1955): “The multiplicity of firm contacts may blunt the edge of their competition.” Bernheim
& Whinston (1990) offered one of the first theoretical models of MMC. They showed that under
the assumption of asymmetry, tacit collusion is sustainable due to the threat of retaliation in
overlapped markets. The intuition is that MMC serves to pool firms’ incentive constraints across
markets, and asymmetry allows firms to transfer incentive constraints across markets.1 Collusive
outcomes are therefore easier to sustain in markets with higher levels of MMC. This potential
softening of competition due to MMC is referred to as the mutual forbearance hypothesis.
Given the natural concerns surrounding collusion and its effects on market outcomes, understanding the empirical effects of MMC is critical in designing appropriate antitrust and regulatory
policy. Subsequently, there has been strong interest among strategy researchers and industrial
economists in testing the mutual forbearance hypothesis.2 In this paper, we extend the mutual
forbearance hypothesis to studying both product prices and quality in health insurance, specifically
the Medicare Advantage (MA) market. To the best of our knowledge, we are the first in studying
MMC in the U.S. health insurance market.
Our focus on the MA market is highly policy-relevant. First, this market is a large and growing
component of the U.S. healthcare system, with over 24 million individuals (34% of the Medicare
population) currently enrolled in an MA plan for their health insurance benefits.3 MA is also
a prime example of managed competition in which insurers’ behaviors are highly influenced by
federal policy. Empirical evidence of MMC in the MA market therefore has the opportunity to
1

Other works have identified additional mechanisms by which MMC could enhance collusion, such as concavity
of the profit function (Spagnolo, 1999) and imperfect monitoring (Matsushima, 2001; Kobayashi & Ohta, 2012).
2
The presence of MMC and mutual forbearance has been examined empirically across several industries, including
airlines (Evans & Kessides, 1994; Prince & Simon, 2009; Ciliberto & Williams, 2014), cement (Jans & Rosenbaum,
1997), banking (Molnar et al., 2013), movies (Feinberg, 2015), and radio (Waldfogel & Wulf, 2006), among others.
More recently, Schmitt (2018) examines the role of MMC in hospital markets, and Wilson (2019) examines MMC
in the internet service provider market.
3
This reflects nearly a four-fold increase since the Medicare Modernization Act of 2003. Kaiser Family Foundation
2019 MA Spotlight, available at https://www.kff.org/medicare/issue-brief/medicare-advantage-2019-spotlight-firstlook/.

2

directly inform policy in MA and other settings relying heavily on managed competition, including
Medicaid HMOs and the health insurance exchanges created under the Affordable Care Act. More
generally, there has been little regulatory activity regarding mergers and acquisitions that do not
affect local market concentration but actually lead to changes in multimarket contact. Our study
therefore has potential policy implications for such out-of-market mergers and acquisitions, which
have become increasingly common in the health care setting.
In addition to policy relevance, the MA market offers a textbook environment for the examination of the mutual forbearance hypothesis for two reasons. First, a critical condition for mutual
forbearance is a firm’s ability to detect deviations from collusion (Thomas & Willig, 2006). Failing to meet this condition might cause researchers either to underestimate the effect of MMC or
(incorrectly) fail to detect mutual forbearance. Our setting has a compelling advantage over existing studies in that price and quality information are publicly available, transparent to competing
firms once information is posted during open enrollment, and constant within a calendar year. This
transparency intuitively allows for sustained collusion and offers a clearer opportunity to study the
effects of MMC. Second, the existing empirical and theoretical research on MMC prioritizes price
as the main outcome of interest.4 The richness in available data on the MA market allows us to
extend the mutual forbearance hypothesis to product quality, which is critical when considering
firms’ non-price behavior and the broader implications for consumer welfare.
To briefly explain our empirical strategy, we follow the literature in calculating MMC as the
average number of pairwise market overlaps among all competing firms in a given market. We
also consider several alternative measures of MMC in our sensitivity analyses, including measuring
MMC at the firm-market level. Note that MA plan “prices” derive from a competitive bidding
process, which we discuss in more detail in Section 2.1. We measure prices using both bids and
monthly premiums. The plan bid captures the total payment to insure a single individual, and
the premium represents the portion of the total payment that is paid directly by the enrollee. We
measure quality using the star rating system introduced by the Centers for Medicare and Medicaid
Services (CMS) in 2009, following Curto et al. (2015), Duggan et al. (2016), and others.
For both prices and quality, MMC is arguably endogenous. We therefore pursue an instrumental
variable strategy by taking advantage of two plausibly exogenous changes in MMC. The first
4

Prince & Simon (2009) provide an important exception in studying quality of service in the US airline industry,
as does Wilson (2019) in his analysis of MMC and internet service providers.

3

source exploits out-of-market merger activities. Specifically, we form an instrumental variable
that measures the merger-induced change in pairwise overlaps in markets that are otherwise not
directly affected by the merger. The second source of exogenous variation derives from changes in
MA reimbursement policies that increased CMS payments to MA plans in selected markets. These
policy changes incentivize additional entry into affected markets (Layton & Ryan, 2015; Duggan
et al., 2016) and therefore affect MMC even in markets otherwise unaffected by the policy itself.
Our results largely support the mutual forbearance hypothesis. From our preferred specifications, we find that a one standard deviation increase in MMC (4.5) leads to between a $16 and
$18 (2.2% and 2.5%) increase in Part C bids, which is the component of Medicare Advantage that
covers inpatient and outpatient care. Similarly, when moving from the 25th to 75th percentile in
MMC (5.7), we estimate an increase in Part C bids of 3.2%. These magnitudes are comparable
to those found in other studies. For example, Ciliberto & Williams (2014) find that moving from
the 25th to 75th percentile in MMC leads to a 2% increase in pricing, and Evans & Kessides
(1994) estimate a slightly larger effect of 5%. We also find some evidence of an increase in Part D
(prescription drug coverage) bids.5
With regard to quality, we find evidence that increasing MMC reduces the prevalence of highquality (four-star rated and above) contracts. Within a contract, we find an increase in MMC of
one standard deviation leads to approximately a 12 percentage point reduction in the probability
that a contract receives a high overall rating. We also consider quality adjustment through insurers’
selection of plan offerings across markets, where we find an even larger effect. For example, a one
standard deviation increase in MMC leads to one fewer high-rated contract available in an average
market, reflecting a 30% decrease in high-quality plans. These results are large compared to the
existing evidence from the airline industry, where Prince & Simon (2009) find that an increase
in MMC from the 25th to the 75th percentile leads to quality decreases of between 5% and 15%,
depending on the quality measure used. Our findings therefore suggest quality provision as an
important channel through which firms respond to changes in MMC.
Our paper contributes to the existing literature on MMC in three important ways. First, we
offer one of the first studies of MMC in health insurance where overlap across markets appears to
be an important characteristic. Our results suggest MMC as one potential channel through which
MA policy and cross-market consolidation could alter competitiveness in local markets otherwise
5

More details regarding institutional differences between Part C and Part D are discussed in Section 2.1.

4

unaffected by the policy or merger.
Second, with the exception of Prince & Simon (2009) and Wilson (2019), the majority of studies of MMC focus on prices. We extend our understanding of the impact of MMC by examining
both pricing and product quality. While the magnitude of our estimated price effects is similar
to the prior literature, the estimated reduction in quality is relatively large. This could be due to
differences in the transparency of our quality measures versus those in Prince & Simon (2009). Regardless, our findings suggest that ignoring non-price attributes is likely to underestimate consumer
welfare loss due to MMC.
Third, while the standard approach of identification relies on market fixed effects, our identification further exploits out-of-market consolidations and exogenous MA policies, which helps to
remove variation in MMC driven by time-varying unobservables also correlated with prices and
quality. Similar identification strategies have been used in the hospital setting, including Dafny
et al. (2012, 2017) and Schmitt (2018). In this way, our paper is closest to Schmitt (2018) who
examines the impact of MMC on estimated hospital prices; however, Schmitt (2018) adopts an
event study approach measuring how prices respond to out-of-market mergers, with the assumption that out-of-market mergers capture exogenous changes in hospital MMC. Our identification
strategy instead exploits changes in local pairwise overlaps due to out-of-market mergers as an
instrument, adapting the simulated change in local market concentration employed in Dafny et al.
(2012). This allows us to directly quantify the impact of MMC on market outcomes and offers a
direct comparison to existing studies such as Evans & Kessides (1994), Prince & Simon (2009), and
Ciliberto & Williams (2014), although we also consider the reduced-form effects of out-of-market
mergers as a supplemental analysis in Section 6.

2

Institutional Background

The Balanced Budget Act of 1997 (BBA) introduced private health insurance options known
as Medicare + Choice plans (M+C, or Medicare Part C). Medicare Part C, including Medicare
Part A for inpatient care and Medicare Part B for outpatient care, was then revised as part of
the 2003 Medicare Modernization Act and renamed Medicare Advantage (MA), which allowed
additional plan types such as Regional PPOs and Special Needs Plans as well as Part D coverage
(prescription drug). MA plans, like the preceding Medicare Part C plans, are provided by private
5

insurers who contract with CMS annually. Insurers generally operate multiple contracts across
(and perhaps within) markets, and there is typically more than one individual plan offered under a
single contract, which differ in plan characteristics such as premiums, copayments, and deductibles.
By choosing an MA plan, beneficiaries no longer receive the traditional benefits of Medicare Feefor-Service (FFS) but must still enroll in Medicare Parts A and B and pay the Part B premium.
CMS requires that MA plans offer at least what the beneficiary could receive from Medicare FFS.

2.1

Medicare Advantage Bidding

Premiums for MA plans are determined by a competitive bidding process. For Part C services
(under most plan types), MA insurers submit bids to CMS intended to reflect the anticipated cost
of the plan to cover Medicare Parts A and B benefits. These bids, which we denote by bc(j)t for plan
j under contract c at time t, are then compared to a local benchmark payment rate, denoted Bmt
for market m. For bc(j)t < Bmt , CMS pays the insurer the risk-adjusted bid for enrollee i, αi ×bc(j)t .
CMS also pays these insurers a percentage of the difference between the bid and benchmark in the
form of a rebate, denoted γc(j)t ;6 however, rebates must be transferred to beneficiaries in the form
of added benefits. Therefore, in the case of bc(j)t < Bmt , the insurer’s effective price received for
enrollee i is simply αi × bc(j)t . Conversely, if insurers submit bids in excess of the benchmark, CMS

pays the plan αi × bc(j)t − bc(j)t − Bmt , and enrollees pay the bid-benchmark differential in the
form of monthly premiums (in addition to the usual Medicare Part B premiums and any Part D
premiums). The additional monthly premium offsets the reduction in per-enrollee payments made
by CMS, such that the insurer again receives an effective price of αi × bc(j)t for enrollee i. The
price ultimately received by the insurer for Part C services is therefore the plan’s risk-adjusted bid
amount, regardless of whether this bid amount is paid fully by CMS or in-part by the enrollee.
MA plans that also offer prescription drug coverage (MA-PD plans) undergo a similar bidding
process for Part D benefits but with at least two important differences. First, since traditional
Medicare does not cover prescription drugs, CMS relies on the national average bid as a benchmark
6

Since 2012, the benchmark rates were adjusted based on the contract’s star rating, with contracts of 4 stars or
more receiving a 5% increase in their benchmark rates. New contracts also received a 3.5% increase in benchmark
rates. In addition, for the years 2012-2014, the percentage received as a rebate was a function of the contract’s star
rating, with contracts of 4.5 or 5 stars receiving a 70% rebate, contracts of 3.5 or 4 stars receiving a 65% rebate, and
contracts of 3 stars or below receiving a 50% rebate. Contracts deemed “too new” for a star rating were assigned a
default rating of 3.5-4 stars for rebate calculations (65% of the difference between the bid and benchmark). In all
other years, plans receive a set rebate of 75%.

6

comparison for a given plan’s bid, and this comparison dictates the final monthly premium for
a given plan. Second, the Part D program includes a handful of subsidies paid by CMS to the
insurer, including subsidies for low-income enrollees and additional payments for high cost enrollees.
Insurers can also self-subsidize their Part D premiums using their Part C rebates. Due to the
differences in the bidding process between Part C and Part D components of MA, we examine the
impact of MMC on Part C and Part D pricing separately.

2.2

Medicare Advantage Quality Ratings

In 2007, CMS launched a star rating program by which contracts were rated from 1 to 5 stars in
each of five different domains.7 Beginning in 2009, CMS began assigning an overall star rating to
each MA contract, ranging from 1 to 5 stars in half-star increments. This overall star rating is
clearly presented to potential enrollees in official CMS documentation and is designed to reflect
the quality of each plan.
Both the overall and the domain-specific star ratings are calculated based on dozens of individual measures.8 Over our time period, 55 different measures were used at some point in calculating
a contract’s star rating, and among those, 9 measures arguably reflect an objective assessment of
plan quality and are available in every year from at least 2009 through 2015.9 These 9 measures
correspond to one of three domains defined by CMS: 1) staying healthy, which captures the percentage of enrollees receiving specific tests and screenings; 2) managing chronic conditions, which
captures the percentage of enrollees with appropriate “management” of their chronic condition
(e.g., osteoporosis, diabetes, high blood pressure, or rheumatoid arthritis); and 3) handling of
7
These domains initially were: 1) “helping you stay healthy”; 2) “getting care from your doctors and specialists”;
3) “getting timely information and care from your health plan”; 4) “managing chronic conditions”; and 5) “your
rights to appeal.” Since 2007, the individual measures and domains have changed nearly every year. For example,
CMS expanded the “rights to appeal” domain in 2010 to include measures on complaints and the number of
beneficiaries leaving the plan, among others. Also in 2010, the “timely information” domain was replaced by
“customer service”.
8
The data underlying the star ratings for each individual metric are collected one or two years prior to each
given open enrollment and based on a variety of data sources, including the Healthcare Effectiveness Data and
Information Set (HEDIS), the Consumer Assessment of Healthcare Providers and Systems (CAHPS), the Health
Outcomes Survey (HOS), the Independent Review Entity (IRE), the Complaints Tracking Module (CTM), and
CMS administrative data.
9
A total of 16 individual measures are available from 2009 through 2015. We drop 7 of those measures, 2
belonging to the “staying healthy” domain and the remainder belonging to the domain of “ratings of health plan
responsiveness.” We drop these 7 measures because they rely on beneficiaries’ self-reported assessments of their
change in health or of the quality of service and care received. For example, one of these measures asks, “using
any number from 0 to 10, what number would you use to rate all your health care in the last 6 months?” We drop
these variables due to the subjective nature of these measures, but results are largely consistent if including them.

7

appeals, which measures the timeliness with which plans reviewed any appeals following denial of
a claim as well as the “fairness” of those decisions as determined by CMS review. We employ the
overall star rating as well as these domain-specific measures in our analysis of quality. These 9
individual measures and associated domains used in our analysis of quality are discussed in more
detail in the supplemental appendix.

2.3

Definition of Market and Product

We define the market as a county because competition and an enrollee’s choice set differ at the
county level. The appropriate definition of a product, however, may vary depending on the outcome
of interest. For example, since bids and premiums differ at the plan level, a natural delineation of
products is by unique plan ID; however, approval by CMS to provide Medicare benefits applies at
the contract level. For this latter reason, authors sometimes adopt the contract as the definition of
a unique product (Town & Liu, 2003; Dafny & Dranove, 2008; Curto et al., 2015). Star ratings are
also calculated at the contract level. A case can therefore be made for defining a unique product
either at the plan level or at the contract level. For completeness, we present pricing results for
both.

2.4

Medicare Advantage Data

We collect data on MA market shares, contract/plan characteristics, and market area characteristics from several publicly available sources from 2008 through 2015. The set of available plans in
each county is constructed from the Medicare Service Area files, which list all approved MA contracts within a county/month/year.10 To these records, we merge enrollment and plan information
at the contract/plan level from the MA enrollment files as well as county-level MA penetration
information.11 We exclude plans with missing or fewer than 11 enrollees as all such enrollments are
masked in the data. Next, we merge the contract’s overall summary star measure, plan premium
and rebate information at the contract/plan/county/year level, and county-level census demographic and socioeconomic information from the American Community Survey (ACS). Finally,
10

We begin with the Service Area files because the CMS enrollment files include enrollees that move and keep
their MA coverage despite the fact that a particular MA contract may not be approved in the new market area.
11
Plan-level enrollments are available monthly, but there is little variation in enrollments across months due to
the nature of the open enrollment process. We therefore measure plan enrollments as the average enrollment across
months in a given year.

8

we incorporate county-level hospital discharge data from the annual Healthcare Cost Reporting
Information System (HCRIS) database as well as Part C benchmark rates and average FFS costs
by county. Additional details of our data construction are available in the supplemental appendix.
We present summary statistics for our plan/contract-level independent variables as well as our
county-level variables in Tables 1 and 2, respectively. Note that we observe from the MA payment
files the average Part C payments made by CMS to a given plan as well as any rebates paid for
Part C bids below the relevant benchmarks. Along with the observed Part C premium, we can
estimate each plan’s risk-adjusted Part C bid as either: 1) the observed Part C payment for plans
with a positive rebate (i.e., bids below the benchmark); or 2) the sum of the Part C payment and
any observed premium for plans with $0 rebates.12 For Part D bids, we observe the CMS “direct
subsidy” payment as well as the Part D premium for basic prescription drug coverage (net of any
reduction from Part C rebates). Since we do not observe how much of a Part C rebate is used to
pay down the Part D basic premium, we cannot directly estimate the Part D bid. We nonetheless
consider the net Part D bid (net of any reduction from Part C rebates), estimated as the sum
of the CMS direct subsidy payment and the Part D basic premium. Summary statistics of the
estimated plan bids are also included in Table 1.

Tables 1 and 2

At least four salient features of the MA market emerge from these summary statistics. First,
the MA market has become increasingly concentrated in recent years, with a spike in the total
number of plan/county observations in 2009 and dropping by more than 33% by 2015, with similar
trends in the total number of plans per county. Consistent with these trends, average plan market
share increased from 5.7% in 2009 to over 8% in 2011 though 2015. Enrollment per plan similarly
increased from 215 enrollees per month in 2009 to nearly 500 beneficiaries per plan per county in
2015. Second, the types of plans available have become more homogeneous in many respects. For
12

The Part C premium observed in the data includes both a “basic” Part C premium, which would cover the cost
of traditional Medicare FFS benefits and would only be positive if the plan’s bid exceeded the benchmark, as well
as any premium for “mandatory supplemental benefits,” which are benefits not covered under traditional Medicare
FFS. When the Part C bid exceeds the benchmark, the differential would be passed on to enrollees as the “basic”
Part C premium, which we do not observe separately from any premium for mandatory supplemental benefits. Our
calculation of bids as the sum of the Part C premium and the Part C payment is therefore an upper bound of the
bid; however, note that this calculation only applies to around 15% of plans with $0 rebates (i.e., plans that we
observe to have bid above the benchmark).

9

example, in 2008, approximately 35% of plans were managed care (HMO or PPO) and around
62% offered prescription drugs. In 2015, over 90% of plans were managed care and 81% of plans
offered prescription drug coverage. Third, plan prices have been relatively stable since 2010.
Monthly consolidated premiums, for example, increased less than 6% from $48 per month in 2010
to $51 per month in 2015. Decomposing these premium changes between Part C and Part D, the
observed increase in premiums has been driven by an increase in Part D premiums while Part
C premiums have remained around $28 per month since 2010.13 Finally, there has also been an
increase in average contract quality (as measured by CMS star ratings), with the majority of
contracts receiving less than a 3-star rating in 2009 through 2011, over 60% of contracts receiving
a 3 to 3.5-star rating in 2012-2014, and 56% of contracts receiving a rating of 4 to 5 stars in 2015
(compared to just 31% in 2014 and 18% in 2013).14 These movements are consistent with CMS’
increased efforts to discourage beneficiaries from choosing plans with ratings below 3 stars.15

3

Conceptual Framework

The theory of multimarket contact (MMC) has mainly focused on identifying conditions and circumstances under which interdependencies across markets could promote collusive outcomes. In
their seminal work, Bernheim & Whinston (1990) showed that perfect observability and asymmetry are necessary for mutual forbearance. In our setting of the Medicare Advantage market, both
conditions are satisfied due to CMS’ annual publication of price and quality information and the
observed asymmetry across markets (such as differences in local market structure). Although subsequent theoretical studies have relaxed these assumptions and identified additional circumstances
under which multimarket contact facilitates tacit collusion (Spagnolo, 1999; Matsushima, 2001;
Kobayashi & Ohta, 2012), we abstain from testing these competing theories.
Of our particular interest is whether MMC promotes collusive outcomes. From the literature,
the impact of MMC on prices is intuitively straightforward. Since MMC tends to soften competition, we expect price to increase following increases in MMC. The majority of empirical studies
support this prediction. For example, Evans & Kessides (1994) offer one of the first empirical
13

These average premiums are based on all plans and therefore include many $0 premium plans.
Note that thes average star ratings in Table 1 are at the contract/county level rather than just the contract
level, reflecting an average star rating weighted by prevalence across counties.
15
For example, contracts receiving a rating of below 3 stars are listed with a large warning box online which asks
potential enrollees to double-check whether they want to enroll in that plan.
14

10

studies of MMC using data from the U.S. airline industry. They find that airlines charge higher
prices on routes with a higher level of MMC. Ciliberto & Williams (2014) also examine the airline
industry. They identify underlying conduct parameters using variation in MMC, therefore directly
linking MMC to the degree of coordination. More recently, Schmitt (2018) studies MMC in the
hospital setting and finds that hospitals exposed to out-of-market mergers (thus with increased
MMC) charge higher prices.
In our setting of the Medicare Advantage market, we expect a higher level of MMC would
lead to higher prices in terms of both firms’ bids and premiums, which are adjusted annually via a
competitive bidding process. We consider bids as our main price measure for the following reasons.
First, a plan’s bid captures revenue per enrollee from an insurer’s point of view, and it also reflects
the total health insurance payment for an individual of baseline risk paid by both CMS and the
individual enrollee. Second, most plans (about 85%) charge zero “basic” Part C premiums. As
we discussed in Section 2.1, premiums will be $0 whenever the Part C bid falls below the market
benchmark, but increases in bids still reflect an increase in the cost of health insurance from CMS’
perspective as well as a reduction in benefit generosity for enrollees in terms of rebates. Examining
plan bids therefore allows us to explore variation in pricing which is not captured by premiums.
We also study premiums because they represent the part of the payment directly paid out by the
enrollee.16
More importantly, we extend our analysis of MMC to consider its effect on quality. Given the
literature’s focus on prices, we derive our intuition for the likely effect of MMC on quality from
the broad literature on market power and firms’ strategic behavior. Such literature applies given
that MMC could confer market power via mutual forbearance. However, theoretical research in
this area is largely inconclusive regarding the effect of market power on quality, especially in a
setting where firms choose both price and quality (Dorfman & Steiner, 1954; Spence, 1975; Mussa
& Rosen, 1978; Dana Jr & Fong, 2011). For example, if competition changes the elasticity of
demand with respect to quality more (less) than the elasticity with respect to price, we should
expect quality to fall (increase) with softened competition. Mirroring this theoretical ambiguity,
existing empirical studies of the effects of market power on quality offer mixed results (Berry &
16

We study premiums rather than other cost-sharing provisions such as copayments and co-insurance rates because
those financial features a relatively stable over time within the same plan and because consumers primarily respond
to premiums (Stockley et al., 2014; Curto et al., 2015). Moreover, other cost-sharing provisions such as copayments
or co-insurance rates will tend to differ across health care services for the same plan.

11

Waldfogel, 2001; Sweeting, 2010; Fan, 2013; Crawford et al., 2018). Those mixed results have also
been found in a health care setting, primarily in the hospital market, as in Kessler & McClellan
(2000), Gowrisankaran & Town (2003), and Kessler & Geppert (2005).17
Given its theoretical ambiguity, empirical investigation on the relationship between MMC and
quality is particularly important; however, existing evidence is scarce. Prince & Simon (2009)
measure quality using airline on-time performance, finding that MMC increases airline delays (i.e.,
decreases quality), but delays are one of many dimensions of quality in this market and may not
be fully transparent or predictable in a given purchasing decision. More recently, Wilson (2019)
finds that MMC decreases download speeds among internet service providers. In our setting, we
highlight two possible channels through which insurers could adjust quality provision in response to
changes in MMC. First, quality adjustment could occur within a contract. For example, insurers
could offer a more comprehensive provider network to increase quality. They can also process
appeals of their beneficiaries in a more timely manner. Second, quality adjustment could occur
through an insurer’s selection of which contracts to offer in which counties. Indeed, we observe a
large amount of entry and exit of contracts in the data, suggesting that insurers might adjust the
quality of their offerings through strategically limiting or expanding contracts across markets.

4

Empirical Strategy

We discuss first our construction of the MMC measure before turning to our model specification
and identification strategy.

4.1

Multimarket Contact

Quantifying MMC is a key step toward studying its empirical effects. In any given market, there
exists some variation in pairwise overlaps of participating firms with their competitors, and all
such pairwise comparisons collectively determine the level of coordination and thus affect the
prevalence of any collusive behavior. To offer a simple example, consider extending the standard
Bertrand-Nash framework to incorporate MMC and tacit collusion. An increase in pair-specific
17

These empirical investigations have largely examined how clinical outcomes vary with market HerfindahlHirschman Index. More recent studies, such as Cutler et al. (2010), Gaynor et al. (2013), and Bloom et al.
(2015), tend to find that increased hospital competition leads to higher quality. See Gaynor (2006) for an extensive
review of this literature.

12

MMC would tend to enhance the degree of coordination not only for the affected firms but also for
other incumbent firms in the same market due to interdependence among rival firms. As a result,
a firm’s aggressiveness towards its competitors depends on the pairwise overlaps of each firm-pair
in a given market. It is therefore natural to take into account all of the pairs of participants in a
market environment and average the MMC across these pairs. Indeed, this is a common approach
to measuring MMC in the empirical literature (Evans & Kessides, 1994; Jans & Rosenbaum, 1997;
Ciliberto & Williams, 2014; Schmitt, 2018).18 Following this literature, we calculate MMC as the
average number of pairwise market overlaps among all firms in a given market:

M M Cmt

Nmt X
Nmt
X
1
=
1 [i, j ∈ Nmt ] (mmcijt − 1)
Nmt (Nmt − 1) i=1 j=1,j6=i

=

Nmt
Nmt
X
1
1 X
1 [i, j ∈ Nmt ] (mmcijt − 1)
Nmt i=1 Nmt − 1 j=1,j6=i

Nmt
1 X
=
M M Cimt ,
Nmt i=1

(1)

where mmcijt denotes the total number of markets in which firms i and j overlap in year t. With a
slight abuse of notation, Nmt denotes the set of all firms operating in market m at time t as well as
the total number of firms in a market. The indicator function, 1 [i, j ∈ Nmt ], is set to 1 if both firm
i and j operate in market m at time t and 0 otherwise.19 Note that an equivalent expression for
M M Cmt is averaging insurer-level MMC measures (M M Cimt ) in a given market and year. This
alternative expression in terms of insurer-level MMC is useful when we exploit exogenous variation
at the insurer and market level in order to identify the effects of MMC, as discussed in detail in
Section 4.3.
To better understand the construction of our M M Cmt variable, Table 3 presents the count of
pairwise market overlaps among the top 10 insurers in MA in 2015. We see from the diagonal
that Humana is the largest insurer (in terms of markets served), with a presence in over 2,400
markets. UnitedHealth, Blue Cross Blue Shield (BCBS), Aetna, and Wellcare round out the top
18

Some existing studies have taken a different approach by measuring MMC at the firm-market level, including
Fernandez & Marin (1998) and Prince & Simon (2009). We show in the supplemental appendix that our results
are consistent if using this approach to define multimarket contact.
19
There are 3,102 market/year observations with just one insurer in our data. These markets are relatively small
on average, with just 165 enrollees per market compared to an average of over 800 MA enrollees in other markets.
We drop these markets in our analysis in Section 5.

13

5 insurers in MA as of 2015. Note that we treat all Blue Cross Blue Shield plans and affiliates as
BCBS following Dafny (2015).20 Table 3 reflects a substantial amount of market overlap across
insurers. For example, out of the 1,222 markets in which BCBS operated in 2015, the insurer
overlapped with Humana in 1,080 of those markets (88%). Similarly, of the 1,370 markets in
which UnitedHealth operated, the insurer overlapped with BCBS in 531 of those markets (39%).

Table 3

To examine variation in MMC across markets and over time, we present box plots of MMC by
year in Figure 1 as well as a kernel density estimate of the change in MMC from 2008 to 2015 in
Figure 2. In 2008, the mean MMC across all markets is just over 880, which means that insurers
overlapped in over 880 counties on average. This number is large but is reflective of the dominance
of a few large insurers in the MA market. For example, a market with one of the larger MMC values
in 2008 was Hardy County, West Virginia. In that year, 4 insurers (Humana, Coventry, Universal,
and BCBS) operated in Hardy County. Universal (the smallest insurer in that market) overlapped
with BCBS in 1,110 markets, with Humana in 1,535 markets, and Coventry in 1,189. With Harden
County as the reference market, Universal therefore overlapped with some other insurer in 1,278
markets on average. Accounting for the remaining overlaps between other insurers, the resulting
average MMC for this market was 1,371 in 2008.
Note that our measure of MMC in the MA market is significantly larger than that of the
U.S. hospital market (Schmitt, 2018), but compares to other settings such as the airline industry
(Evans & Kessides, 1994; Ciliberto & Williams, 2014). As is evident from Figure 1, mean MMC
first increases from 2008 to 2009 and then falls gradually through 2011 before leveling off after 2012.
From Figure 2, we also observe strong heterogeneities in changes in MMC over time. In particular,
among nearly 2,200 counties with a sufficient MA market in both 2008 and 2015, MMC decreased
by over 1,000 in the lowest 5% of markets and increased by over 380 in the top 5% of markets.
The observed decrease in average MMC over time is therefore characterized by differential changes
across markets rather than an overall shift in the distribution of MMC, which offers additional
variation with which to identify the effects of MMC on MA prices and quality.
20

We also include Anthem in our BCBS designation; however, results are qualitatively unchanged when treating
Anthem separately.

14

Figures 1 and 2

In addition to measuring MMC based on Equation 1, we also consider several alternative
measures. Specifically, we consider a weighted measure of M M C with weights given by the relative
market size of each overlapped market, and similarly a weighted measure where weights are given
by each market’s HHI (Jans & Rosenbaum, 1997; Fernandez & Marin, 1998; Prince & Simon,
2009). We also consider MMC measured at the insurer-market level (i.e., M M Cimt in Equation
1). Finally, we consider MMC calculations in which we focus only on the top 5 insurers. Results
from these alternative measures are presented in the supplemental appendix.

4.2

Empirical Specification

We estimate effects of MMC on prices with a series of linear regressions of the form
yc(j)mt = βxc(j)mt + νm + τt + γc + αM M Cmt + εc(j)mt ,

(2)

where xc(j)mt denotes a vector of time-varying product/market characteristics for plan j operating
under contract c, νm denotes county fixed effects, τt denotes year fixed effects, γc denotes contract fixed effects, and M M Cmt denotes multimarket contact. We include in xc(j)mt the following
variables: 1) county demographics such as total population, the percent of the population ages
18 to 34, 35 to 64, and 65 or above, the percent of the population classified as Caucasian and
percent African American, the percent of the population with household incomes between $50,000
and $75,000, between $75,000 and $100,000, between $100,000 and $150,000, and above $150,000,
the percent of the population with a high school degree and percent with a bachelor’s degree,
and the percent of the population that is employed full time; 2) hospital variables including the
total number of discharges in the county, total number of hospitals, and the hospital HHI; 3) an
indicator for prescription drug coverage; and 4) MA variables including average FFS costs and the
MA benchmark rate. Many other plan characteristics, such as whether the plan is HMO or PPO,
do not vary within a contract over time and are therefore absorbed in the contract fixed effect.
Coefficient estimates are derived from the generalized within-estimator as described in Correia
(2016) and implemented in Correia (2017), which is a refinement of the techniques in Guimaraes
et al. (2010) and Gaure (2013).
15

4.3

Addressing Endogeneity of MMC

MMC is likely to be correlated with unobservables that affect market structure and prices. For
example, a market that is experiencing increased demand for MA plans may attract more entry,
therefore generating increased overlap among competing firms. Such a market might simultaneously experience an increase in premium growth. Ignoring such endogeneity would lead to erroneous conclusions regarding how MMC affects market prices. To address this concern, we pursue
an instrumental variables analysis in which we exploit two plausibly exogenous changes thought to
influence MMC: 1) “simulated” increase in pairwise overlaps due to out-of-market mergers; and 2)
exposure to changes in reimbursement policies including the introduction of the urban floor policy
in 2001 and double-bonus policy in 2012. We discuss these instruments in more detail below.
Simulated Merger Effects
Our simulated merger instrument derives from changes in pairwise overlaps due to out-of-market
mergers. To form this instrument, we exploit 8 relatively large mergers/acquisitions over our study
time frame. We refer to all mergers and acquisitions simply as mergers for brevity. These mergers
were first identified by changes to the parent organization observed in the data, and then confirmed
through various sources, including Irving Levin’s annual health care acquisition reports from 2005
through 2015, press releases, and coverage in the news media.21 A list of all such mergers along
with supporting documentation is presented in Table 4.

Table 4

For each merger, we form the instrument by taking the count (before the merger is finalized) of
all market overlaps between a non-merging insurer and a merging insurer. For example, consider
the merger between Bravo and HealthSpring finalized in November 2010. This merger event would
cause changes in the pairwise overlap for all markets where either Bravo or HealthSpring operate.
In markets where Bravo operates prior to the merger, our IV measure for insurer i is the count of
all markets in which insurer i overlaps with HealthSpring (in the year prior to the merger) but not
21

To make sure that we have captured all the large merger and acquisition events, we rely on the annual report from
the Irving Levin’s health care acquisition reports, which offers detailed information regarding all the announcement
of proposed merger events. This data source has been used in other studies identifying merger events such as
Schmitt (2018).

16

Bravo. This is because insurer i’s overlap with HealthSpring is caused by the merger, while insurer
i’s overlap with Bravo is not. In this way, our merger-based instrument is intuitively similar to the
simulated change in HHI used in Dafny et al. (2012). The instrument is calculated based on each
insurer’s market presence prior to the merger but takes its value in the years after the merger was
finalized. For example, in the case of the merger between Bravo and HealthSpring, the instrument
is based on market presence in 2010 but takes its value in 2011-2015, which we also interact with
year dummy variables.
To better describe our strategy, consider an industry with four insurers (A, B, C, and D) and
four markets. Assume that insurer C acquires D. Before the merger, Market 1 (the reference
market) consists of insurers {A,B,D}; Market 2 consists also of {A,B,D}; Market 3 consists of
{A,B,C}; and Market 4 consists of {A,B,C,D}. For the reference market prior to the merger,
insurer A overlaps with insurer B in 3 markets and overlaps with insurer D in 2 markets, for a
total pairwise overlap of 5. The merger generates an increase in insurer A’s overlap, resulting
from A’s overlap with C in Market 3 prior to the merger. Our merger-induced change in pairwise
overlaps for insurer A in the reference market therefore takes a value of 1 beginning in the first
full year after the merger was finalized. Extending this example to Market 3, the instrument for
insurer C takes the value of the sum of all merger-induced pairwise overlaps for insurer A and B.
Effectively, by acquiring insurer D, insurer C introduces additional overlaps with insurers A and
B (from Markets 1 and 2).22
It is important to note that our identification relies on out-of-market mergers (i.e., mergers
between insurers that do not perfectly overlap across all markets). Had all the merger events
occurred within markets, our merger-induced instruments would all be zero. We instead see in the
data that there is substantial opportunity for our identified merger events to affect local market
MMCs. For example, out of a total of 20,190 market-year pairs in the data, 40% were exposed to
an out-of-market merger at some point during our time frame.
22

It is not immediately clear how to treat markets in which both merging insurers operated prior to the merger
(Market 4 in our example) since prices might be directly affected in such markets. Including these markets may call
into question the standard exclusion restriction, although the exclusion restrictions for our other policy instruments
likely still hold. We include such markets in our initial analysis and set the merger-related instrument to 0. We
also consider an alternative analysis in the supplemental appendix where we drop all these markets (about 7% of
the main sample), with little change in our results.

17

Exposure to Urban Floor and Bonus Counties
As discussed in detail in Zarabozo & Harrison (2009) and examined in Duggan et al. (2016), the
“urban floor” policy was introduced in 2001 as part of the State Children’s Health Insurance
Program (SCHIP) Benefits Improvement and Protection Act (BIPA). This policy placed a lower
bound on the reimbursement paid to MA plans in urban counties, defined as counties in MSAs
with at least 250,000 people. Since, at the time, reimbursement was otherwise based on average
FFS costs, counties exposed to the urban floor had relatively low FFS costs and were relatively
large in terms of population. Beginning in 2004, the Medicare Modernization Act again adjusted
MA payment rates by instituting a universal payment floor of 100% of Medicare FFS costs in the
county. In counties with higher FFS costs, MA benchmarks were set at the prior year’s benchmark
plus the average national growth rate for FFS costs (or 2% if the growth rate was less than 2%).
Therefore, although a separate payment formula did not apply formally to urban floor counties
beyond 2004, the effects of the urban floor policy persisted beyond 2004 (Duggan et al., 2016).
In our analysis, we identify urban floor counties based on FFS costs and population size as of
2004. This was the last year that the policy was officially in place and the largest set of counties
directly impacted by the policies. An indicator for these urban floor counties is directly observed
from publicly available data on CMS payments to MA plans. We then create an insurer-county
measure of urban floor exposure as the count of all other counties in which an insurer operated
prior to the urban floor program (in year 2000) that were ultimately treated by the urban floor
policy by 2004.23 We also interact this exposure measure with year dummies to allow effects to
dissipate over time.
We similarly exploit the introduction of “double-bonus” counties in 2012 as an additional source
of exogenous variation. This policy was intended as a reward system in which the standard bonus
paid to high-quality MA contracts (above 3-stars) was doubled for selected counties. Importantly,
Layton & Ryan (2015) find that the double-bonus program generated an influx of plans in affected
markets. Counties were selected for the double bonus program based on: 1) urban floor county
as of 2004; 2) at least 25 percent of eligible beneficiaries were enrolled in an MA plan as of 2009;
23

Our MA data include information on the effective date of each contract. We can therefore identify an insurer’s
presence in a market in 2000 based on the effective date of all contracts offered in 2008 (the earliest year for which
we have complete data on enrollments and approved MA service areas). Since we define exposure at the insurer
level (rather than the contract level), our measure of baseline exposure will capture all counties for which the insurer
maintained at least one contract in 2000 and 2008, even if some specific contracts or plans were ultimately dropped
in those counties.

18

and 3) Medicare FFS costs in that area were lower than the national average. The double-bonus
counties are therefore a subset of the urban floor counties. We also observe in the CMS payment
data whether a given county qualified for the double-bonus payment. Similar to our calculation of
exposure to the urban floor policy, we calculate exposure to the double-bonus policy as the count
of other markets in which a given insurer operated prior to the policy (in year 2011) that were
ultimately selected by CMS to receive double-bonus payments.24 By construction, our measure of
exposure to the double-bonus policy is set to 0 prior to 2011 and maintains the same value for the
same insurer over time, which we again interact with year dummies.
Generated IV Approach
With the above-mentioned instruments, we account for endogeneity of M M Cmt with a preliminary
prediction of M M Cimt , from which we derive an estimate of M M Cmt as the simple average across
insurers in market m and year t based on Equation 1. We then employ the estimated MMC,
\
M
M C mt , as an instrument in a standard fixed effects instrumental variables (FE-IV) estimator.
Specifically, we denote our set of instruments by Zimt , which consists of all variables created from
out-of-market mergers as well as the introduction of the urban floor and bonus county policies.
Our generated instrument regression model is then
M M Cimt = δZimt + ωimt .

(3)

This approach allows us to incorporate insurer- and market-level instruments and therefore
exploits all of the available variation in our instrument set. We estimate Equation 3 with ordinary
\
least squares (OLS), from which we obtain predicted values M
M C imt and, subsequently,
Nmt
1 X
\
\
M
M C imt .
M M C mt =
Nmt i=1

\
Finally, we use M
M C mt as a generated instrument for M M Cmt in estimating Equation 2. Our
generated instrument exploits the available information at the appropriate “level” of the data and
24
We also included indicators for double-bonus counties, interacted with time dummies, directly in Equation 2
since those markets are directly affected by the double-bonus policy. Controlling for the double-bonus policy in this
way does not change our results.

19

acts simply as linear combination of exogenous instruments, Zimt .25 Results for our generated
instrument regression in Equation 3 are presented in the supplemental appendix.

4.4

Additional Specifications

We also consider additional specifications in order to address specific concerns regarding the effect
of MMC on prices and quality. First, contract pricing and quality will naturally depend on the
competitiveness of any given market. We have excluded such measures from our main specification
due to endogeneity concerns regarding market-level measures of competitiveness. Note that our
instruments are arguably exogenous to local market competitiveness, in which case excluding
measures of local market competitiveness should not contaminate our identification of the effect of
MMC. Nonetheless, we consider a specification where we include the county-level HHI among MA
insurers as an additional covariate. Second, larger insurers may be able to raise prices directly,
regardless of MMC, but will also tend to overlap with more firms in other markets. Failing
to account for insurer prevalence across markets may therefore incorrectly attribute these direct
pricing effects to MMC. We account for this with a specification in which we also control for
the number of other markets in which the insurer operates. Finally, we have excluded from the
pricing specification any measure of contract quality since quality may also be an outcome related
to MMC, but we recognize that higher quality contracts are also higher priced on average. We
therefore consider a final specification where we include a set of indicator variables capturing the
plan’s overall star rating.

5
5.1

Results
Multimarket Contact and Prices

We focus first on the plan-level results, in which a product is defined as a unique plan ID. In this
analysis, the effect of MMC on price is identified from within-contract variation across plans as
well as variation over time for the same plan. Plan-level regression results are summarized in Table
25

A similar approach in which authors estimate a preliminary regression at a different level of the data and employ
predicted values as instruments has been used in the trade and labor literatures. See, for example, Wolf (2000),
Friedberg (2001), Frankel & Rose (2005), and Chintrakarn & Millimet (2006). As discussed in Wooldridge (2010),
“we can ignore the fact that the instruments were estimated in using 2SLS for inference.”

20

5, with effects for different outcomes presented across the rows and with different specifications
along the columns. Panel 1 presents the fixed effects (FE) estimates based on Equation 2, and
panel 2 presents the fixed effects instrumental variable (FE-IV) estimates when using predicted
MMC as an instrument. All standard errors are clustered at the county level.

Table 5

The results are consistent with the mutual forbearance hypothesis, where higher values of MMC
lead to higher bids and premiums. Specifically, the estimated effect on Part C bids of 3.568 in
Panel 2 implies that an increase of one standard deviation (4.5) in MMC leads to an increase
in Part C bids of about $16 on average (or 2.2%). Note that we measure MMC in 100s in the
estimation. We also estimate an increase of at least $2 (or 7%) in Part C Premiums from a one
standard deviation increase in MMC. Finally, we estimate very small (and insignificant) effects on
Part D bids and premiums.
Table 6 presents results at the contract level. Here, premiums and bids are averaged across
plans under the same contract in a given market. The structure of the table is otherwise analogous
to the plan-level results in Table 5, with effects for different outcomes presented along the rows
and with different specifications along the columns. The results again provide empirical evidence
in support of the mutual forbearance hypothesis. Based on the FE-IV estimates in Panel 2 of
Table 6, a one standard deviation increase in M M C leads to an $18 (or 2.5%) increase in Part C
bids and just under a $3 (or 10%) increase in Part C premiums (from specification 1 in column
1). Different from the plan-level results, we find a larger effect on Part D bids. For example, a
one standard deviation increase in M M C leads to an $1.20 (or 1.8%) increase in Part D bids.
Consistent with the results on Part C and Part D bids, we also find that MMC leads to higher
premiums.

Table 6

The results in Tables 5 and 6 are largely consistent if we control for local market competitiveness
(column 2), insurer prevalence (column 3), and quality star ratings (column 4). It is also interesting
to note that we find stronger results if we control for underlying star rating for each contract. This

21

is intuitive if increased MMC also depresses product quality, which we specifically examine in the
next section.
Taken together, we find consistent evidence that MMC tends to increase Part C bids and
premiums. To put our estimates in perspective, we consider a scenario of moving from the 25th to
75th percentile in MMC and estimate an increase in Part C bids of 3.2%. These magnitudes are
comparable to those found in other studies. For example, Ciliberto & Williams (2014) find that
an increase of MMC from the 25th to the 75th percentile leads to a 2% increase in airline pricing,
and Evans & Kessides (1994) estimated a slightly larger effect of 5%. As a back-of-the-envelope
calculation, our estimated effects on Part C bids suggest a reduction in annual consumer welfare
of $5 billion from a one standard deviation increase in MMC.26 We also find some evidence that
MMC increases Part D bids, although not much for Part D premiums. Finally, although results
are excluded for brevity, we note that our estimates are unchanged when weighting plans by the
number of enrollees.

5.2

Multimarket Contact and Quality

We measure quality with a series of indicator variables for whether a contract is 4-star rated or
higher. We form this indicator separately for the overall rating as well as the 9 individual measures.
We then combine the 9 individual measures into their respective 3 domains, as indicated in the
supplemental appendix. Collectively, we therefore consider 4 measures of quality for each contract:
an indicator for whether the contract received a high rating (4-stars or higher) and indicators in
each of our domains set to 1 if at least half of the underlying metrics in that domain received a
high rating.
Analogous to our analysis of contract-level prices, we first consider within-contract variation in
quality ratings over time. This analysis estimates Equation 2 for each of our contract-level quality
outcomes, and we again consider different specifications designed to assess the sensitivity of our
results to the market-level HHI as well as the insurer’s prevalence across other markets. Results
are summarized in Table 7.
26

This calculation assumes a total of 20 million MA beneficiaries with an increase of $16 in Part C bids, which
suggests a welfare loss of $3.84 billion in terms of increased prices (20 million*$16*12), and reduced benefits of
$1152 million (10million*0.6*$16 assuming 50% purchased contracts with zero Part C premiums and CMS pays
60% of the bid-benchmark differential as rebates).

22

Table 7

The FE-IV estimates in panel 2 of Table 7 suggest that a one standard deviation increase in
MMC leads to approximately a 12 percentage point reduction in the probability that a contract
receives a high overall rating. Among the measures for which we have data available throughout our
panel, this reduction is concentrated in the domains of “keeping patients healthy” and “appeals”,
and offset somewhat by increases in the “managing chronic disease” domain. Our contract-level
results are therefore somewhat mixed, with a decrease in overall quality but an increase in quality
among some specific measures. This finding is perhaps unsurprising. Note that a typical contract
operates in multiple markets but receives the same quality rating across all operated markets.
This suggests within-contract adjustment might need to take into account changes in MMC in all
affected markets. As a result, firms might be constrained in manipulating their star rating for a
given contract in the wake of changes in MMC to a particular local market.
In addition to within-contract quality adjustment, an insurer could also manipulate quality
provision through selecting contracts into local markets. To capture this mechanism, we examine
quality at the market level.27 We aggregate our quality measures to the county level by taking
the count of the high-quality contracts where high-quality is defined analogously to the contractlevel analysis. We then use these count measures as outcomes in estimating Equation 2 at the
market level. As before, we present the standard FE results as well as our preferred FE-IV results
using predicted MMC as our instrument. Note that, due to the timing of CMS approvals, it is
not possible for insurers to know which contracts will be offered in their market at the time they
submit their initial applications.28 We therefore use lagged MMC in our market level analysis, and
lagged predicted MMC as our instrument. These results are presented in Table 8.

Table 8
27

For completeness, we also present market-level pricing results in the supplemental appendix, along with additional discussion of the entry and exit of contracts over our panel.
28
For more details on the timing of insurer bids and approvals, see the Medicare Advantage Applications available
at https://www.cms.gov/Medicare/Medicare-Advantage/MedicareAdvantageApps/index.html. In general, insurers
seeking changes to existing products or seeking to expand into new markets must first submit applications to CMS
for approval. It is recommended that they submit a notice of intent to apply at the end of the prior calendar year
but no later than mid-January, with final applications due in February. Conditionally approved contracts must then
prepare plan bids and cost-sharing details of all plan benefit packages, which are reviewed by CMS and ultimately
approved or denied in August of a given calendar year. Final contracts are executed in September, just prior to the
beginning of the open enrollment period.

23

Panel 1 presents results based on the FE within-estimator, and panel 2 presents the FEIV results. Effects on different quality measures are presented along the rows, with alternative
specifications presented along the columns. The estimated effects on the number of high-rated
contracts (based on the overall star rating) are presented in row 1 of both panels, where we
estimate an economically meaningful decrease in the prevalence of high-rated contracts as MMC
increases. Specifically, the estimated coefficient of -0.242 on M M Ct−1 from the FE-IV estimator
suggests that a one standard deviation increase in MMC in year t − 1 leads to one fewer high-rated
contract in year t. To put this estimate in context, we observe 2.7 high-rated contracts per market
in 2015. Our estimated reductions therefore reflect around a 30% reduction in the prevalence of
high-rated contracts in an average market.
Rows 2-5 in each panel of Table 8 present the results on the counts of high-rated contracts in
the specific quality domains. Here, we continue to estimate large negative effects of MMC on the
prevalence of high-rated contracts. The largest effects are in the “keeping patients healthy” and
the “managing chronic diseases” domains, with smaller (albeit still negative) effects in “appeals.”
Altogether, our results generally suggest that quality decreases in response to an increase in MMC,
at both the individual contract level and aggregated market level. Our estimated magnitude of
effects is also large compared to the existing literature. For example, Prince & Simon (2009)
find that an increase in MMC from the 25th to the 75th percentile leads to quality decrease by
5% to 15%, depending on the quality measure used; however, our measures of quality are more
transparent and arguably more manipulable by insurers, especially through contract entry and
exit from local markets.

6

Robustness

In this section, we gauge the sensitivity of our results to various concerns regarding our identification strategy and measurement of MMC. We also discuss a series of additional sensitivity analyses,
the results of which are presented in the supplemental appendix.

24

6.1

Estimates based on Out-of-market Mergers

We first propose an alternative identification strategy where we directly exploit out-of-market
mergers in which a given insurer is exposed to additional market overlaps due a competitor merging
with another insurer outside of the reference market. Revisiting our example from Section 4,
consider an industry with four insurers (A, B, C, and D) and four markets, and assume that
insurer C acquires D. Before the merger, Market 1 (the reference market) consists of insurers
{A,B,D}; Market 2 consists also of {A,B,D}; Market 3 consists of {A,B,C}; and Market 4 consists
of {A,B,C,D}. When C acquires D, insurers A and B in the reference market are each exposed to
one additional overlap due to pre-existing overlap with insurer C in Market 3. Since only one of
the merging parties operates in the reference market, this is an out-of-market merger in which the
average pairwise overlaps changed due to the merger.
Similar to Schmitt (2018), we adopt the following specification
yc(j)mt = βxc(j)mt + νm + τt + γc + α × 1 (t > τim ) + εc(j)mt ,

(4)

where 1 (t > τim ) is a post-treatment indicator variable set to one in the years after an insurer i
was exposed to a change in MMC in market m due to an out-of-market merger.29 The rest of the
variables in Equation 4 are as defined previously. We also consider a simplified specification in
which we exclude xc(j)mt from the regression.
To separate our estimates from any direct effects due to the merger itself, we exclude all
observations associated with insurers that were ultimately part of a merger (e.g., in the context of
our example above, insurers C and D would be dropped from our analysis in all years). We also
exclude all markets in which both merging insurers existed prior to the merger.30 The estimates
therefore reflect the change in prices or quality from a plausibly exogenous increase in MMC driven
by an out-of-market merger. We again present results at both the plan and contract levels.31
29

Since we define τim as an out-of-market merger that changes an insurer’s count of pairwise overlaps, we set
the indicator to 0 if there was no change in MMC due to the merger. For example, if a fifth insurer (insurer E)
operated only in the reference market in our example above, the indicator would be 0 since insurer E’s overlap with
other insurers is unchanged, even though they compete in the reference market with an insurer that was part of
the acquisition. Results are unchanged if we instead exclude these insurers from the analysis.
30
We further exclude observations in which an insurer first enters market m in the year a merger was finalized,
since we do not have pre-merger prices for such observations.
31
The specification in Equation 4 does not directly extend to the market level. If we instead re-define the
treatment variable as the average of insurer-level indicators in the county, and estimate results are the market level,
we find results similar to those in Section 5.2.

25

Results are summarized in Table 9.

Table 9

Our results are largely consistent with our main findings in Section 5. Across all specifications,
we find Part C bids increase due to MMC.32 We also estimate relatively smaller but significant
increases in Part D bids, consolidated premiums, and Part D premiums. With regard to quality,
we again estimate significant reductions in the prevalence of high-rated contracts.
Note that the sample of contracts underlying the estimates in Table 9 differs from our prior
results – in particular, three of the largest insurers in Medicare Advantage (Humana, UnitedHealth,
and Wellcare) are part of a merger during our time period and therefore excluded from this analysis.
Nonetheless, the results generally yield similar conclusions to our original analysis, with changes
in MMC from out-of-market mergers leading to an increase in prices and a reduction in quality.

6.2

Additional Robustness Checks

We also examine the sensitivity of our estimates to variation in samples across outcomes and
specifications. One large source of variation is missing premium and payment information in
the raw data. In the supplemental appendix, we address this concern by restricting the sample
only to contract/county observations (or plans operating under such contracts) for which all price
variables are non-missing in all available years and re-estimating our preferred specification for
all outcomes. We also consider the sensitivity of our main results to the presence of markets in
which both merging insurers operated prior to a merger. We do this by excluding all observations
for counties in which both merging insurers existed together in any year prior to the merge. This
restriction reduces the plan-level sample size by just under 10,000 plan/county/year observations,
or about 7%. Finally, we consider alternative measures of MMC as discussed in Section 4.
Results for these additional analyses are provided in the supplemental appendix. Across all
sensitivity analyses, our results are generally consistent with those presented in Section 5. We
conclude from these additional analyses that the positive effect of MMC on Part C bids and
32
In our main specification, we do not differentiate between insurers exposed to one or many out-of-market mergers
over time. We nonetheless re-estimated Equation 4 after excluding all insurers/markets exposed to multiple out-ofmarket mergers. The results are almost identical to those in Table 9.

26

premiums is significant and persistent, as is the negative effect of MMC on the prevalence of highquality contracts. Collectively, our results therefore offer strong evidence in support of the mutual
forbearance hypothesis in the Medicare Advantage market.

7

Discussion

Tacit collusion driven by contact with the same competitors across markets has been examined
across several industries, often with a focus on prices. In this paper, we extend the literature on
MMC to the study of health insurance markets. We also consider another important dimension
by which MMC may influence firm behavior – namely, product quality. Our results consistently
support the mutual forbearance hypothesis, where we find that existing insurers tend to place
higher bids and are less likely to offer high-quality contracts when competing against the same
insurers across multiple markets. Our results also suggest that ignoring the effect of MMC on
product quality might lead researchers to underestimate the loss in consumer welfare driven by
increases in MMC.
Note that we do not interpret increases in MMC as an increase in collusion for the same
market. Rather, we interpret increases in MMC as an increase in the probability of collusion.
For example, if markets have some latent and heterogeneous threshold beyond which MMC may
facilitate collusive behavior, an increase in the continuous MMC measure reflects an increase in
the number of markets for which tacit collusion may now occur.
Our findings offer several central takeaways. First, a firm’s ability to detect deviations from
collusion seems critical in assessing mutual forbearance and MMC. In our setting, both perfect
observability and asymmetry conditions are satisfied, allowing us to find strong evidence in support of the mutual forbearance hypothesis. Our findings also suggest tacit collusion as a potential
unintended consequence of price transparency. Second, the effect of MMC in Medicare Advantage
appears to also reduce plan benefits and quality, in addition to directly affecting prices. This interpretation in terms of “plan benefits” follows from the institutional details of the bidding process,
wherein the rebated percentage of the bid-benchmark differential (for bids below the benchmark)
must go to enrollees in the form of expanded benefits. Since this differential is decreasing due to
MMC, this suggests a reduction in plan benefits, although we do not observe the precise dimensions
by which benefits are changed. Third, in addition to within-plan or within-contract changes over
27

time, we estimate large effects of MMC via selection of contracts offered across markets. These
effects clearly emerge in our analysis of market-level quality.
We conclude with two policy implications. First, as the Medicare Advantage market becomes
increasingly characterized by relatively few national insurers, our results suggest that the incentives
to collude due to MMC may play an increasing role. This further informs future MA policy in
that expanded “choice” may have less effect on competitiveness when such expansion derives from
large, national insurers. MA policy may instead attempt to counter these forces by encouraging
entry from smaller or regional insurers for which MMC is less prevalent. Such a strategy would
not only maintain choice but also minimize the incentives to collude due to MMC.
Second, existing antitrust enforcement procedures tend to overlook anti-competitive effects of
increased MMC (or pro-competitive effects of reduced MMC). However, mergers that have no
impact on local market concentration (e.g., cross-market mergers) could potentially lead to large
changes in MMC and, through this mechanism, affect the overall intensity of competition. Our
results support this hypothesis and suggest that MMC should be given more careful consideration
when assessing changes in competition from mergers/acquisitions, especially in settings where
national players tend to overlap in multiple markets.

28

References
Bernheim, B Douglas, & Whinston, Michael D. 1990. Multimarket contact and collusive behavior.
The RAND Journal of Economics, 21, 1–26.
Berry, Steven T, & Waldfogel, Joel. 2001. Do mergers increase product variety? Evidence from
radio broadcasting. The Quarterly Journal of Economics, 116(3), 1009–1025.
Bloom, Nicholas, Propper, Carol, Seiler, Stephan, & Van Reenen, John. 2015. The impact of
competition on management quality: evidence from public hospitals. The Review of Economic
Studies, 82(2), 457–489.
Chintrakarn, Pandej, & Millimet, Daniel L. 2006. The environmental consequences of trade:
Evidence from subnational trade flows. Journal of Environmental Economics and Management,
52(1), 430–453.
Ciliberto, Federico, & Williams, Jonathan W. 2014. Does multimarket contact facilitate tacit
collusion? Inference on conduct parameters in the airline industry. The RAND Journal of
Economics, 45(4), 764–791.
Correia, Sergio. 2016. A Feasible Estimator for Linear Models with Multi-Way Fixed Effects.
Working Paper. Duke University.
Correia, Sergio. 2017. reghdfe: Stata module for linear and instrumental-variable/GMM regression absorbing multiple levels of fixed effects. Statistical Software Components S457874. Boston
College Department of Economics.
Crawford, Gregory S, Shcherbakov, Oleksandr, & Shum, Matthew. 2018. Quality Overprovision
in Cable Television Markets. Working Paper. SSRN.
Curto, Vilso, Einav, Liran, Levin, Jonathan, & Bhattacharya, Jay. 2015. Can Health Insurance
Competition Work? Evidence from Medicare Advantage. Working Paper. Department of Economics, Stanford University.
Cutler, David M, Huckman, Robert S, & Kolstad, Jonathan T. 2010. Input constraints and the
efficiency of entry: Lessons from cardiac surgery. American Economic Journal: Economic Policy,
2(1), 51–76.
29

Dafny, L., & Dranove, D. 2008. Do report cards tell consumers anything they don’t already know?
The case of Medicare HMOs. The Rand journal of economics, 39(3), 790–821.
Dafny, Leemore. 2015. Evaluating the Impact of Health Insurance Industry Consolidation: Learning
from Experience. Issue Brief. The Commonwealth Fund.
Dafny, Leemore, Duggan, Mark, & Ramanarayanan, Subramaniam. 2012. Paying a Premium
on Your Premium? Consolidation in the US Health Insurance Industry. American Economic
Review, 102(2), 1161–1185.
Dafny, Leemore, Ho, Kate, & Lee, Robin S. 2017. The Price Effects of Cross-Market Mergers:
Theory and Evidence from the Hospital Industry. Working Paper w22106. Nationa Bureau of
Economic Research.
Dana Jr, James D, & Fong, Yuk-Fai. 2011. Product quality, reputation, and market structure.
International Economic Review, 52(4), 1059–1076.
Dorfman, Robert, & Steiner, Peter O. 1954. Optimal advertising and optimal quality. American
Economic Review, 826–836.
Duggan, Mark, Starc, Amanda, & Vabson, Boris. 2016. Who benefits when the government pays
more? Pass-through in the Medicare Advantage program. Journal of Public Economics, 141,
50–67.
Edwards, Corwin D. 1955. Conglomerate bigness as a source of power. Pages 331–359 of: Business
concentration and price policy. Princeton University Press.
Evans, William N, & Kessides, Ioannis N. 1994. Living by the golden rule: Multimarket contact
in the US airline industry. Quarterly Journal of Economics, 109(2), 341–366.
Fan, Ying. 2013. Ownership consolidation and product characteristics: A study of the US daily
newspaper market. American Economic Review, 103(5), 1598–1628.
Feinberg, Robert M. 2015. Pricing of First-Run Movies in Small US Metropolitan Areas: Multimarket Contact and Chain Effects. The BE Journal of Economic Analysis & Policy, 15(1),
285–297.

30

Fernandez, Nerea, & Marin, Pedro L. 1998. Market power and multimarket contact: Some evidence
from the Spanish hotel industry. The Journal of Industrial Economics, 46(3), 301–315.
Frankel, Jeffrey A, & Rose, Andrew K. 2005. Is trade good or bad for the environment? Sorting
out the causality. The Review of economics and statistics, 87(1), 85–91.
Friedberg, Rachel M. 2001. The impact of mass migration on the Israeli labor market. Quarterly
Journal of Economics, 116(4), 1373–1408.
Gaure, Simen. 2013. OLS with multiple high dimensional category variables. Computational
Statistics & Data Analysis, 66, 8–18.
Gaynor, Martin. 2006. Is vertical integration anticompetitive?: Definitely maybe (but that’s not
final). Journal of Health Economics, 25(1), 175–180.
Gaynor, Martin, Moreno-Serra, Rodrigo, & Propper, Carol. 2013. Death by market power: reform,
competition, and patient outcomes in the National Health Service. American Economic Journal:
Economic Policy, 5(4), 134–66.
Gowrisankaran, Gautam, & Town, Robert J. 2003. Competition, payers, and hospital quality1.
Health services research, 38(6p1), 1403–1422.
Guimaraes, Paulo, Portugal, Pedro, et al. 2010. A simple feasible procedure to fit models with
high-dimensional fixed effects. Stata Journal, 10(4), 628.
Jans, Ivette, & Rosenbaum, David I. 1997. Multimarket contact and pricing: Evidence from the
US cement industry. International Journal of Industrial Organization, 15(3), 391–412.
Karnani, Aneel, & Wernerfelt, Birger. 1985. Multiple point competition. Strategic Management
Journal, 6(1), 87–96.
Kessler, Daniel, & McClellan, Mark. 2000. Is hospital competition socially wasteful? Quarterly
Journal of Economics, 2(115), 577–615.
Kessler, Daniel P, & Geppert, Jeffrey J. 2005. The effects of competition on variation in the quality
and cost of medical care. Journal of Economics & Management Strategy, 14(3), 575–589.

31

Kobayashi, Hajime, & Ohta, Katsunori. 2012. Optimal collusion under imperfect monitoring in
multimarket contact. Games and Economic Behavior, 76(2), 636–647.
Layton, Timothy J, & Ryan, Andrew M. 2015. Higher incentive payments in Medicare Advantage’s
pay-for-performance program did not improve quality but did increase plan offerings. Health
services research, 50(6), 1810–1828.
Matsushima, Hitoshi. 2001. Multimarket contact, imperfect monitoring, and implicit collusion.
Journal of Economic Theory, 98(1), 158–178.
Molnar, Jozsef, Violi, Roberto, & Zhou, Xiaolan. 2013. Multimarket contact in Italian retail
banking: Competition and welfare. International Journal of Industrial Organization, 31(5),
368–381.
Mussa, Michael, & Rosen, Sherwin. 1978. Monopoly and product quality. Journal of Economic
theory, 18(2), 301–317.
Prince, Jeffrey T, & Simon, Daniel H. 2009. Multimarket contact and service quality: Evidence
from on-time performance in the US airline industry. Academy of Management Journal, 52(2),
336–354.
Schmitt, Matt. 2018. Multimarket Contact in the Hospital Industry. American Economic Journal:
Economic Policy, 10(3), 361–87.
Spagnolo, Giancarlo. 1999. On Interdependent Supergames: Multimarket Contact, Concavity, and
Collusion. Journal of Economic Theory, 89(1), 127–139.
Spence, A. 1975. Monopoly, Quality, and Regulation. Bell Journal of Economics, 6(2), 417–429.
Stockley, Karen, McGuire, Thomas, Afendulis, Christopher, & Chernew, Michael E. 2014. Premium Transparency in the Medicare Advantage Market: Implications for Premiums, Benefits,
and Efficiency. Working Paper. National Bureau of Economic Research.
Sweeting, Andrew. 2010. The effects of mergers on product positioning: evidence from the music
radio industry. The RAND Journal of Economics, 41(2), 372–397.

32

Thomas, Charles J, & Willig, Robert D. 2006. The risk of contagion from multimarket contact.
International Journal of Industrial Organization, 24(6), 1157–1184.
Town, Robert, & Liu, Su. 2003. The welfare impact of Medicare HMOs. RAND Journal of
Economics, 719–736.
Waldfogel, Joel, & Wulf, Julie. 2006. Measuring the effect of multimarket contact on competition:
Evidence from mergers following radio broadcast ownership deregulation. The BE Journal of
Economic Analysis & Policy, 5(1).
Wilson, Kyle. 2019. Local competition, multimarket contact, and product quality: Evidence from
internet service providers. Working Paper. Pomona College.
Wolf, Holger C. 2000. Intranational home bias in trade. The Review of Economics and Statistics,
82(4), 555–563.
Wooldridge, Jeffrey M. 2010. Econometric analysis of cross section and panel data. MIT press.
Zarabozo, Carlos, & Harrison, Scott. 2009. Payment policy and the growth of Medicare Advantage.
Health Affairs, 28(1), w55–w67.

33

Tables and Figures
Figure 1: Range of MMC by Year

34

Figure 2: Kernel Density of MMC Change from 2008 to 2015

35

Table 1: Plan- and Contract-level Summary Statistics
2008

2009

2010

2011

2012

2013

2014

2015

Overall

219.1
(1151.8)
MA Shareb
0.0618
(0.101)
Part C Bid
697.5
(57.99)
Part D Bid
64.58
(12.90)
Premiumc
35.96
(42.07)
Part C Premiumd
24.14
(33.09)
19.56
Part D Premiume
(17.24)
Drug Coveragef
0.615
HMOg
0.206
PPOh
0.152
Observations
28,988
Contract/County Data
Star Rating 3 to 3.5
Star Rating 4 to 5
Plans Offeredi
1.791
(1.064)
Observations
16,185

214.6
(1152.1)
0.0568
(0.0913)
733.6
(68.96)
69.53
(15.00)
38.08
(45.11)
24.16
(35.36)
20.98
(18.13)
0.669
0.212
0.180
33,224

258.1
(1210.7)
0.0697
(0.106)
756.5
(79.64)
71.31
(14.55)
48.51
(48.84)
34.44
(38.73)
19.25
(17.37)
0.738
0.249
0.274
29,212

354.5
(1482.6)
0.0865
(0.124)
741.8
(79.28)
69.96
(15.04)
45.47
(49.82)
29.49
(37.30)
20.07
(18.34)
0.772
0.328
0.412
22,447

392.9
(1562.7)
0.0866
(0.126)
738.4
(73.16)
69.01
(16.08)
44.12
(49.06)
27.99
(35.71)
20.70
(19.26)
0.786
0.342
0.450
22,337

415.3
(1632.4)
0.0824
(0.123)
742.6
(83.87)
64.46
(16.76)
45.49
(51.23)
28.12
(37.00)
21.93
(19.98)
0.798
0.361
0.471
23,029

462.4
(1748.1)
0.0808
(0.121)
763.0
(83.42)
61.87
(18.68)
48.07
(54.14)
27.45
(36.90)
26.02
(22.64)
0.800
0.373
0.505
22,000

498.2
(1852.9)
0.0815
(0.119)
716.8
(78.70)
60.95
(19.39)
51.14
(54.44)
27.16
(36.67)
28.19
(23.35)
0.811
0.389
0.515
21,430

336.3
(1462.7)
0.0741
(0.113)
735.0
(77.56)
66.75
(16.48)
44.08
(49.27)
27.79
(36.45)
21.90
(19.73)
0.739
0.297
0.349
202,667

0.161
0.028
1.766
(1.051)
18,815

0.206
0.057
1.801
(1.063)
16,224

0.462
0.100
1.745
(1.003)
12,865

0.621
0.115
1.742
(0.991)
12,822

0.652
0.182
1.723
(1.000)
13,363

0.612
0.312
1.710
(0.994)
12,869

0.325
0.557
1.673
(0.955)
12,812

0.354
0.154
1.748
(1.021)
115,955

Plan/County Data
Enrollmenta

a

Defined as the average monthly enrollment for a plan.
Defined as a plan’s share of the MA market.
c
Denotes the consolidated Part C and Part D premium, including an $0 premium plans.
d
Reflects the premium only for Part C benefits (basic benefits and any mandatory supplemental
benefits), including $0 premium plans.
e
Defined as the total Part D premium (sum of the basic and supplemental premiums), net of any
rebates from Part C.
f
An indicator for whether the plan offers Part D benefits.
g
An indicator for whether the contract is a Health Maintenance Organization.
h
An indicator for whether the contract is a Preferred Provider Organization.
i
Defined as the number of plans offered under a given contract.
b

36

Table 2: County-level Summary Statistics
MA Penetrationa
Number of Plansb
Insurersc
Benchmark Rated
Mean FFS Costs
Population (1000s)
% Age ≥ 65
% Employed
% White
% Black
College Graduate
Observations

2008
0.146
(0.105)
10.03
(9.241)
4.382
(2.470)
766.3
(70.01)
7992.7
(1294.8)
158.6
(395.5)
0.139
(0.0339)
0.387
(0.0537)
0.828
(0.143)
0.0930
(0.125)
0.134
(0.0561)
2,890

2009
0.159
(0.109)
11.39
(9.976)
4.638
(2.497)
792.8
(71.50)
7950.0
(1281.2)
102.9
(319.9)
0.152
(0.0407)
0.376
(0.0579)
0.840
(0.160)
0.0920
(0.145)
0.123
(0.0526)
2,918

2010
0.160
(0.113)
9.919
(8.528)
3.952
(2.128)
789.5
(71.83)
8185.6
(1354.4)
102.7
(317.8)
0.154
(0.0403)
0.375
(0.0585)
0.841
(0.161)
0.0925
(0.147)
0.125
(0.0536)
2,945

2011
0.170
(0.119)
7.630
(6.546)
3.112
(1.726)
789.9
(72.15)
8363.6
(1252.0)
103.7
(320.4)
0.157
(0.0405)
0.375
(0.0593)
0.839
(0.161)
0.0938
(0.147)
0.126
(0.0526)
2,942

a

2012
0.183
(0.123)
7.577
(6.532)
2.944
(1.640)
794.7
(69.97)
8340.9
(1224.1)
104.3
(323.0)
0.160
(0.0408)
0.376
(0.0607)
0.839
(0.162)
0.0947
(0.148)
0.127
(0.0527)
2,948

2013
0.201
(0.126)
7.906
(6.594)
2.965
(1.672)
805.6
(67.01)
8272.0
(1280.9)
106.2
(327.6)
0.163
(0.0411)
0.370
(0.0610)
0.838
(0.161)
0.0957
(0.148)
0.128
(0.0532)
2,913

Defined as the overall share of MA relative to the total Medicare market
Denotes the total number of plans in a county
c
Denotes the number of unique insurers in a county
d
Reflects the average Part C benchmark payment for each county
b

37

2014
0.221
(0.128)
7.727
(6.493)
2.942
(1.796)
831.5
(60.11)
8334.9
(1148.7)
109.2
(334.7)
0.166
(0.0413)
0.369
(0.0611)
0.834
(0.162)
0.0979
(0.149)
0.130
(0.0538)
2,847

2015
0.233
(0.131)
7.559
(6.270)
2.890
(1.795)
774.8
(53.20)
8580.0
(1134.6)
110.3
(338.6)
0.170
(0.0419)
0.371
(0.0620)
0.833
(0.162)
0.0981
(0.149)
0.132
(0.0544)
2,835

Overall
0.184
(0.123)
8.721
(7.781)
3.480
(2.106)
793.1
(69.77)
8251.5
(1263.6)
109.9
(332.5)
0.158
(0.0412)
0.375
(0.0598)
0.837
(0.160)
0.0948
(0.146)
0.128
(0.0536)
23,238

38

Aetna
BlueCross
Cigna
HealthNet
Humana
Kaiser
UCare MN
UnitedHealth
Universal
WellCare
1,222
197
64
1,080
37
0
531
57
187

BlueCross

298
9
287
9
0
190
15
86

Cigna

67
54
25
0
51
5
15

HealthNet

2,490
58
99
1,182
65
284

Humana

76
0
58
5
23

Kaiser

108
0
0
0

UCare MN

1,370
85
207

UnitedHealth

95
24

Universal

Numbers reflect the total count of market overlaps between each insurer in 2015. The values are
denoted by mmcijt in Equation 1. “BlueCross” reflects all Blue Cross and Blue Shield plans and
affiliates.

a

Aetna
614
283
80
31
544
25
0
378
35
95

Table 3: Pairwise Overlaps Among Top 10 Insurers in 2015a

304

WellCare

Table 4: Identified Mergers/Acquisitions
Acquired
Acquiring
Date Finalized Year in Dataa
Bravo
HealthSpring
November 2010 2011
Sisters of Mercy
Coventry
2010
2011
HealthSpring
Cigna
January 2012
2012
XLHealth
United Healthcare February 2012 2012
Arcadian
Humana
April 2012
2012
Munich American Windsor
2011
2012
Coventry
Aetna
May 2013
2013
Windsor Health
WellCare
January 2014
2014
a

Sourceb
Modern Healthcare
St. Louis Business Journal
Cigna Press Release
UHC Press Release
Humana Press Release
Munich Press Release
Aetna Press Release
Yahoo Finance Article

Based on first observed change in “parent organization” or “organization marketing name” in
the MA data, which appears to occur before some acquisitions are completely finalized.
b
Please refer to Section 4.3 for more details regarding additional data source.

39

Table 5: Effects of MMC on Pricing at Plan-levela
FE Regression Results
Part C Bids
(n=142,780)
Part D Bids
(n=118,745)
Premium
(n=163,008)
Part C Premium
(n=161,817)
Part D Premium
(n=118,759)
FE-IV Regression Results
Part C Bids
(n=142,780)
Part D Bids
(n=118,745)
Premium
(n=163,008)
Part C Premium
(n=161,817)
Part D Premium
(n=118,759)
Specification
Contract, County, Year FE
HHI
Insurer Prevalence
Star Ratings

(1)

(2)

(3)

(4)

0.265**
(0.108)
-0.141***
(0.019)
-0.057
(0.049)
0.051
(0.040)
-0.139***
(0.023)

0.242**
(0.108)
-0.146***
(0.019)
-0.066
(0.049)
0.043
(0.040)
-0.143***
(0.023)

0.396***
(0.112)
-0.045**
(0.020)
0.084*
(0.050)
0.120***
(0.040)
-0.047**
(0.024)

0.440***
(0.116)
-0.151***
(0.022)
-0.145***
(0.049)
-0.028
(0.039)
-0.155***
(0.026)

3.568***
(0.732)
[170.61]
0.086
(0.128)
[202.57]
0.339
(0.261)
[214.47]
0.466**
(0.198)
[209.40]
-0.058
(0.150)
[202.61]

3.499***
(0.734)
[170.13]
0.075
(0.128)
[202.32]
0.309
(0.262)
[214.18]
0.443**
(0.198)
[208.97]
-0.065
(0.150)
[202.36]

3.694***
(0.735)
[174.82]
0.158
(0.128)
[206.56]
0.437*
(0.261)
[218.18]
0.517***
(0.199)
[213.15]
0.009
(0.151)
[206.60]

4.322***
(0.750)
[208.53]
0.233*
(0.128)
[234.22]
1.012***
(0.252)
[258.93]
1.002***
(0.202)
[251.07]
0.022
(0.143)
[234.28]

X

X
X

X

X

X
X

a
Plan-level regression results, with standard errors in parenthesis clustered at the county level.
Sample sizes vary due to missing values for dependent variables. See the supplemental appendix
for results on a balanced panel with non-missing values over time. First-stage F-statistics for our
generated instrument are presented in brackets. Additional independent variables not in the table
include contract fixed effects, county and year fixed effects, county-level demographic variables, an
indicator for prescription drug coverage, average FFS costs in the county, the MA benchmark rate,
and measures of the local (county) hospital market including HHI, total discharges, and number of
hospitals. * p<0.1, ** p<0.05, *** p<0.01

40

Table 6: Effects of MMC on Pricing at Contract-levela
FE Regression Results
Part C Bids
(n=77,114)
Part D Bids
(n=82,611)
Premium
(n=92,217)
Part C Premium
(n=91,628)
Part D Premium
(n=82,616)
FE-IV Regression Results
Part C Bids
(n=77,114)
Part D Bids
(n=82,611)
Premium
(n=92,217)
Part C Premium
(n=91,628)
Part D Premium
(n=82,616)
Specification
Contract, County, Year FE
HHI
Insurer Prevalence
Star Ratings

(1)

(2)

(3)

(4)

0.532***
(0.107)
-0.136***
(0.017)
-0.051
(0.047)
0.050
(0.039)
-0.126***
(0.019)

0.505***
(0.107)
-0.140***
(0.017)
-0.058
(0.047)
0.044
(0.039)
-0.130***
(0.019)

0.672***
(0.108)
-0.039**
(0.018)
0.090*
(0.047)
0.120***
(0.039)
-0.046**
(0.020)

0.512***
(0.110)
-0.155***
(0.020)
-0.184***
(0.048)
-0.063*
(0.038)
-0.153***
(0.021)

4.100***
(0.719)
[163.12]
0.267**
(0.110)
[202.73]
0.647**
(0.257)
[203.11]
0.597***
(0.199)
[198.87]
0.134
(0.122)
[202.73]

4.037***
(0.721)
[162.80]
0.256**
(0.110)
[202.45]
0.629**
(0.257)
[202.99]
0.584***
(0.200)
[198.65]
0.127
(0.122)
[202.45]

4.122***
(0.712)
[172.24]
0.320***
(0.109)
[210.74]
0.708***
(0.257)
[211.83]
0.629***
(0.200)
[207.59]
0.177
(0.122)
[210.74]

5.011***
(0.717)
[213.17]
0.322***
(0.107)
[250.67]
1.105***
(0.243)
[258.26]
1.020***
(0.192)
[251.57]
0.140
(0.111)
[250.67]

X

X
X

X

X

X
X

a
Contract-level regression results, with standard errors in parenthesis clustered at the county
level. Sample sizes vary due to missing values for dependent variables. See the supplemental appendix for results on a balanced panel with non-missing values over time. First-stage F-statistics
for our generated instrument are presented in brackets. Additional independent variables not in the
table include contract fixed effects, county and year fixed effects, county-level demographic variables,
the percentage of plans offering prescription drug coverage, average FFS costs in the county, the MA
benchmark rate, and measures of the local (county) hospital market including HHI, total discharges,
and number of hospitals. * p<0.1, ** p<0.05, *** p<0.01

41

Table 7: Effects of MMC on Contract Qualitya
FE Regression Results
Overall Rating
(n=64,717)
Keeping Patients Healthy
(n=53,289)
Managing Chronic Disease
(n=40,604)
Appeals
(n=54,528)
FE-IV Regression Results
Overall Rating
(n=64,717)
Keeping Patients Healthy
(n=53,289)
Managing Chronic Disease
(n=40,604)
Appeals
(n=54,528)

(1)

(2)

(3)

-0.002***
(0.001)
-0.002**
(0.001)
0.004***
(0.001)
-0.002***
(0.001)

-0.002***
(0.001)
-0.002**
(0.001)
0.004***
(0.001)
-0.002***
(0.001)

-0.003***
(0.001)
-0.000
(0.001)
0.004***
(0.001)
-0.003***
(0.001)

-0.028***
(0.003)
[259.59]
-0.016***
(0.004)
[262.01]
0.012***
(0.004)
[272.25]
-0.007**
(0.003)
[277.72]

-0.028***
(0.003)
[259.96]
-0.016***
(0.004)
[262.98]
0.012***
(0.004)
[272.72]
-0.007**
(0.003)
[277.62]

-0.028***
(0.003)
[271.04]
-0.016***
(0.004)
[272.22]
0.012***
(0.004)
[280.75]
-0.007**
(0.003)
[279.80]

X

X
X

X

Specification
County, Year FE
HHI
Insurer Prevalence

X

a

Contract-level regression results with standard errors in parenthesis clustered at the county
level. Sample sizes vary due to missing values for dependent variables. Additional independent
variables not in the table include county-level demographic variables, the percentage of plans offering
prescription drug coverage, average FFS costs in the county, the MA benchmark rate, and measures
of the local (county) hospital market including HHI, total discharges, and number of hospitals. *
p<0.1, ** p<0.05, *** p<0.01

42

Table 8: Effects of MMC on Market Qualitya
FE Regression Results
Overall Rating
Keeping Patients Healthy
Managing Chronic Disease
Appeals
FE-IV Regression Results
Overall Rating
Keeping Patients Healthy
Managing Chronic Disease
Appeals
First-stage F -stat
Specification
County, Year FE
HHI
Count of Contracts

(1)

(2)

(3)

-0.025***
(0.003)
0.009**
(0.004)
0.006*
(0.003)
0.002
(0.003)

-0.025***
(0.003)
0.009**
(0.004)
0.006*
(0.003)
0.001
(0.003)

-0.026***
(0.003)
0.008**
(0.004)
0.006*
(0.003)
0.008**
(0.003)

-0.242***
(0.030)
-0.313***
(0.038)
-0.131***
(0.028)
-0.007
(0.023)
170.37

-0.244***
(0.030)
-0.315***
(0.038)
-0.133***
(0.028)
-0.009
(0.023)
169.88

-0.236***
(0.029)
-0.303***
(0.037)
-0.126***
(0.028)
-0.052**
(0.022)
178.18

X

X
X

X
X

a

County-level regression results (N = 14, 345) with standard errors in parenthesis clustered at the
county level. Additional independent variables not in the table include county-level demographic
variables, the percentage of plans offering prescription drug coverage, average FFS costs in the
county, the MA benchmark rate, and measures of the local (county) hospital market including HHI,
total discharges, and number of hospitals. * p<0.1, ** p<0.05, *** p<0.01

43

Table 9: Effects of Out-of-market Mergersa

Part C Bids

Part D Bids

Consolidated Premiums

Part C Premiums

Part D Premiums

Plan
(1)
8.485***
(1.589)
[41,440]
3.507***
(0.372)
[34,442]
2.763**
(1.090)
[42,871]
-0.240
(0.904)
[42,429]
2.885***
(0.495)
[34,445]

Level
(2)
9.804***
(1.633)
[37,212]
3.684***
(0.386)
[30,664]
3.710***
(1.166)
[38,324]
-0.340
(0.967)
[37,949]
3.495***
(0.516)
[30,667]

Overall Rating

Keeping Patients Healthy

Managing Chronic Disease

Appeals

Contract FE
County, Year FE
Additional controlsb

X
X

X
X
X

Contract Level
(3)
(4)
7.749*** 9.521***
(1.658)
(1.793)
[16,237]
[14,337]
3.698*** 3.858***
(0.430)
(0.458)
[17,834]
[15,696]
3.699*** 4.120***
(1.179)
(1.275)
[18,394]
[16,160]
1.385
0.919
(0.964)
(1.042)
[18,228]
[16,024]
2.527*** 3.189***
(0.530)
(0.564)
[17,835]
[15,697]
-0.077*** -0.066***
(0.013)
(0.014)
[14,330]
[12,724]
-0.022
-0.036**
(0.015)
(0.016)
[13,101]
[11,624]
-0.172*** -0.159***
(0.016)
(0.018)
[10,578]
[9,344]
-0.034*** -0.036***
(0.012)
(0.014)
[11,854]
[10,477]
X
X
X
X
X

Estimates presented for coefficient on 1 (t > τim ) in Equation 4, with standard errors in parenthesis clustered at the county level. Columns 1-2 present plan-level results and columns 3-4 present
contract-level results. Markets in which both merging insurers operated prior to a merger, as well
as all observations associated with a merging firm, are excluded from the analysis. Sample sizes
presented in brackets. * p<0.1, ** p<0.05, *** p<0.01
b
Additional controls consist of county-level demographic variables, prescription drug coverage,
average FFS costs in the county, the MA benchmark rate, and measures of the local (county) hospital
market including HHI, total discharges, and number of hospitals.
a

44

