NBER WORKING PAPER SERIES

PROBING FOR INFORMAL WORK ACTIVITY
Katharine G. Abraham
Ashley Amaya
Working Paper 24880
http://www.nber.org/papers/w24880

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
August 2018, Revised June 2019

The authors are grateful to Frederick G. Conrad, Monica Dashen, Susan Houseman, Frauke
Kreuter, and James R. Spletzer for helpful comments and suggestions on an earlier draft of the
paper. Support for collection of the data analyzed in the paper was provided by the U.S. Census
Bureau under Contract YA132312CN0037 with the University of Maryland, which provided
support for the Joint Program in Survey Methodology (JPSM) generally and the 2016 JPSM
Survey Practicum specifically. The views expressed herein are those of the authors and do not
necessarily reflect the views of the National Bureau of Economic Research.
NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.
© 2018 by Katharine G. Abraham and Ashley Amaya. All rights reserved. Short sections of text,
not to exceed two paragraphs, may be quoted without explicit permission provided that full
credit, including © notice, is given to the source.

Probing for Informal Work Activity
Katharine G. Abraham and Ashley Amaya
NBER Working Paper No. 24880
August 2018, Revised June 2019
JEL No. J21,J46
ABSTRACT
The Current Population Survey (CPS) is the source of official U.S. labor force statistics. The
wording of the CPS employment questions may not always cue respondents to include informal
work in their responses, especially when providing proxy reports about other household
members. In a survey experiment conducted using a sample of Mechanical Turk respondents,
additional probing identified a substantial amount of informal work activity not captured by the
CPS employment questions, both among those with no employment and among those categorized
as employed based on answers to the CPS questions. Among respondents providing a proxy
report for another household member, the share identifying additional work was systematically
greater among those receiving a detailed probe that offered examples of types of informal work
than among those receiving a simpler global probe. Similar differences between the effects of the
detailed and the global probe were observed when respondents answered for themselves only
among those who had already reported multiple jobs. The findings suggest that additional probing
could improve estimates of employment and multiple job holding in the CPS and other household
surveys, but that how the probe is worded is likely to be important.

Katharine G. Abraham
Department of Economics and
Joint Program in Survey Methodology
University of Maryland
1218 LeFrak Hall
College Park, MD 20742
and NBER
kabraham@umd.edu
Ashley Amaya
RTI International
701 13th Street NW
Suite 750
Washington, DC 20005
aamaya@rti.org

Introduction
Information on employment and hours of work is critical to policy makers and other
decision makers for assessing the state of the labor market and the economy more broadly. In the
United States, much of this information comes from the Current Population Survey (CPS), a
monthly survey of approximately 60,000 households carried out by the U.S. Census Bureau on
behalf of the Bureau of Labor Statistics (BLS). In the CPS, an individual is considered to be
employed if he or she “did any work at all for pay or profit during the survey reference week.
This includes all part-time and temporary work, as well as regular full-time, year-round
employment” (Bureau of Labor Statistics, undated).
One potential concern about the CPS data is that the wording of the survey’s employment
questions may not adequately cue respondents to report work activity outside of a conventional
job or business. The CPS employment questions are asked for each household member age 16
and older. The initial employment question asks whether the household member did any work
during the survey reference week for ‘pay’ (or, if applicable, for ‘pay or profit’). Later questions
in the sequence ask about having more than one ‘job’(or, if applicable, more than one ‘job or
business’). 1 It is not clear, however, that respondents necessarily will think of money earned
through informal work activity as either ‘pay’ or ‘profit’ or consider such activity to be a ‘job’
or ‘business.’ The consequence may be that the reporting of informal work activity is
incomplete.
The use of proxy respondents is a second potential challenge to accurate reporting.
Although CPS interviewers attempt to collect employment information from each household

1

The “pay or profit” and “job or business” formulations are used in cases in which the CPS respondent has indicated
that someone in the household has a business.

1|Page

member age 16 years or older, time and availability constraints often lead to the use of a proxy
reporter, a household member who answers the survey questions on behalf of other household
members. Responses for roughly half of CPS sample persons are collected from proxy reporters
(U.S. Census Bureau 2006). Even if the respondent understands that all work to earn money
should be reported, irregular or casual work performed by other household members may be less
salient to the proxy respondent than similar work performed by the respondent herself and thus
less likely to be reported. In some cases, the respondent simply may not know about informal
work performed during the survey reference period by other household members.
This paper seeks to understand the nature of potential biases in the reporting of work
activity in the CPS and similar surveys. Our first research question can be stated:

1) Is there informal work for pay or profit done during the survey reference week that is
not captured by the standard Current Population Survey (CPS) employment
questions?

To answer this research question, we examine whether asking questions focused specifically on
informal work as a follow-up to the standard CPS employment questions identifies additional
work activity. We also are interested in whether different ways of asking such added questions
are more or less effective and in whether this varies according to whether a respondent is
reporting for themselves versus another household member or, in the latter case, according to the
relationship of the respondent to the other household member:

2|Page

2) Does the way in which questions that probe for informal work are asked affect the
number of additional jobs identified?
3) Does the relative effectiveness of different ways of probing for informal work vary by
whether the survey respondent is answering for herself (self-report) or for another
household member (proxy report)? If answering for another household member, does
the relative effectiveness of different ways of probing vary by the closeness of the
survey respondent to the other household member?

Finally, we are interested in the potential effects of under-reporting of informal work during the
survey reference week on key labor force measures:

4) How does any under-reporting of informal work in answering the standard CPS
questions affect estimates of the employment rate (the share of the sample that is
categorized as employed) and the multiple job holding rate (the share of employed
persons in the sample who hold more than one job)?

Background
To understand how question wording might affect reports of work activity, we must first
identify how respondents formulate responses. The most common model of the response process
suggests four steps: (1) understanding the question, (2) recall, (3) inference and estimation, and
(4) mapping the answer onto the response format and editing the response (Sudman, Bradburn
and Schwarz, 1996; Tourangeau, Rips, and Rasinski, 2000). We limit our discussion to the first
two of these steps because they are the most relevant to our research questions and experimental
conditions.
3|Page

Before a respondent can provide a response to a survey question, she must first
understand what information is being requested. Even questions that appear to be clear can be
interpreted in different ways. For example, in one study, respondents were asked: “Have you
smoked at least 100 cigarettes in your entire life?” Respondents disagreed on whether to include
puffs where they did not inhale, whether to count cigarettes they had only partially smoked, and
what constituted a cigarette (Schober, Suessbrick, and Conrad 2018). This sort of disconnect is
due, in part, to the difference between literal interpretation and pragmatic interpretation.
Individuals want to be responsive to what they think the researcher wants to know (pragmatic
interpretation), regardless of exactly what was asked (literal interpretation) (Schwarz 1999). A
respondent answering the CPS employment questions might decide that informal or irregular
work activity that occurred during the survey reference week is not part of what the interviewer
is asking about. . For example, someone who performed as a magician at weekend children’s
parties or maintained a blog that generated ad revenue might think of this activity as a ‘hobby’
and not as ‘work’, and fail to report it when asked the standard CPS questions. While any
misconstruing of a question on the part of a respondent is problematic for achieving accurate
estimates, there is no reason to think that the severity of this problem should differ between self
and proxy reports. In either case, a probe asking specifically about informal work may change
the respondent’s understanding of what they should be reporting and thus uncover previously
unreported work activity.
In the second step of the response process, the respondent must recall information
relevant to formulating a response. She will use cues such as ‘work’, ‘pay or profit’, ‘job or
business,’ and the reference week from the question wording and survey context to search her
memory. Poor cues will increase the chance of retrieval failure (Tourangeau 2000). Because

4|Page

richer information is stored about the self than about others (Kuiper and Rogers 1979), strong
cues may be especially important for proxy reporting. To the extent that individuals store more
information about events that involve them directly, even a weak cue may spur retrieval of a
given event, whereas stronger cues may be required to activate the retrieval of information about
other individuals’ activities. In the context of collecting information about informal work
activity, we would expect a question that provides specific examples of the types of work that
may have been performed (e.g., doing yard work or driving for a ridesharing service) to activate
a respondent’s memory more successfully than a question that asks in more general terms about
informal work activity. We would expect this to be more the case for proxy reports than for selfreports and, among proxy reports, perhaps more so for individuals with whom the respondent has
weaker ties (e.g., a roommate or other unrelated household member) as opposed to those with
whom the respondent has stronger ties (e.g., a spouse).
The use of dispositional knowledge also may lead to failure in the recall process.
Individuals may have two distinct types of knowledge about others: situational and dispositional
(Schwarz and Wellens 1997). Situational knowledge includes details about specific events
whereas dispositional knowledge is information that can be inferred about an individual based on
her typical behavior. In a study of consumer expenditures, for example, respondents used a
combination of situational and dispositional knowledge to report their own spending behavior
but relied primarily on dispositional knowledge when reporting on behalf of their spouse
(Dashen 2000). When individuals use dispositional knowledge to answer questions about
employment, they may be less likely to report sporadic or casual work activity because it is not a
‘usual’ behavior (Sudman, Bradburn, and Schwarz 1996; Schwarz and Wellens 1997). This
reasoning suggests that, to the extent that probing encourages the respondent to tap into

5|Page

situational knowledge, it may be differentially effective for uncovering added informal work
among proxy reports compared to self-reports.
Individuals also may fail to retrieve the necessary information if it was not encoded in the
first place. While this should be relatively rare for self-reports of employment, it could be more
of an issue for proxy reporting. If another household member did work during the reference week
but did not tell the respondent, the respondent would not know to report it. More generally, it
may be difficult for a proxy respondent to estimate the extent of another household member’s
participation in an irregular behavior over a particular interval of time (Phillips, Bickart and
Menon 2006). The closeness of proxy reporters to the subject of their reporting has been found to
be correlated with the accuracy of the proxy report, perhaps because individuals who are closer
to one another are more likely to share information about their activities (Bower and Gilligan
1979; Phillips, Bickart and Menon 2006). As an example, Kojetin and Miller (1993) found
stronger agreement between spouses’ reports about their partners’ spending and the partners’
own reports than between parents’ reports about their children’s spending and the children’s own
reports. In general, making spending decisions jointly with another household member,
discussing spending with the other household member, or observing items that the other
household member may have purchased all contributed to stronger agreement between reports
made by the proxy respondent and those made by the person doing the spending. If lack of
encoding is problematic in the context of reporting about work activity, we might expect the
effects of probing to differ depending on the relationship between the respondent and the person
about whom she is reporting. In this case, probing could be more effective when used to elicit
information about individuals such as a spouse who are closer to the respondent, since the

6|Page

information is more likely to have been encoded in the first place, and less effective when used
to elicit information about other household members.
Three primary methods have been tested to improve accuracy of reports about behavior.
First, definitions have been used to clarify questions, thus improving comprehension. In an
experiment described by Fowler (1992), definitions intended to ensure that respondents’
interpretations of a set of questions related to health behaviors were consistent with the
researcher’s intent were provided to half of the participants but not to the others. While no
information was collected on respondent interpretation, the distribution of responses differed
significantly between the two conditions. Inclusion of definitions or instructions can be more
important in complex situations. For example, in one experiment, subjects asked a series of
questions about employment status, housing, and household purchases based on complex
fictional scenarios answered accurately about 87% of the time when interviewers had the
flexibility to clarify definitions, but just 28% of the time when no definitions were provided.
Answers to the same questions based on simpler scenarios were accurate 97% or more of the
time regardless of whether the interviewer had the opportunity to provide clarification (Schober
and Conrad 1997).
Second, adding examples to questions offers additional cues that the respondent may be
able to use to recall more complete information. The choice of examples provided may affect the
responses that are given. In a study of food consumption, Tourangeau et al. (2014) varied the
examples for different food categories by the frequency of consumption (e.g., bread vs. barley
for grains) and by whether the item would be considered a typical example (e.g., milk vs. sour
cream for dairy). Overall, individuals reported more consumption when any examples were
provided. Further, when asked to list what they ate, they were more likely to mention

7|Page

consumption of the example items. This suggests that individuals retrieve enough information to
make a judgement but do not try to recall everything.
Finally, and perhaps most relevant for this study, researchers have tested the use of
decomposed questions to offer additional cues and enhance recall. Menon (1997) conducted a
diary experiment in which individuals were asked either open-ended questions about the number
of times they had done each of six behaviors or a set of questions that explicitly cued the
respondent to think about the different circumstances under which each of the same things might
have been done. The second, decomposed condition improved the accuracy of recall for the three
irregular behaviors studied (making unplanned stops to talk to friends, snacking, and drinking
from a water fountain), but not for the regular behaviors (washing hair, having dinner, and
attending class).
Other research has identified circumstances under which decomposed questions may
perform less well. In a survey experiment reported by Belli et al. (2000), respondents either were
asked a simple question about the total number of local or long-distance phone calls they had
made during a specified period or were asked decomposed questions about the same behavior
that cued the respondent to think separately about calls at different times or to different
destinations. Subjects who received the decomposed question had a greater tendency to overreport the number of phone calls they had made than subjects who received the simple question.
Members of the study population in the Belli et al. (2000) study made a sufficiently large number
of phone calls that they most likely used an estimation strategy to formulate their answers rather
than enumerating each call individually (Blair and Burton 1987). We would expect respondents
reporting on informal work activities during the prior week to enumerate rather than estimate,

8|Page

meaning that the findings reported by Menon (1997) are likely to be more applicable to our
context than the findings reported by Belli et al. (2000).
Additional research has suggested that probing or decomposed questions also may result
in overreporting due to forward telescoping, that is, the inclusion of activities that in fact had
occurred prior to the specified reference period (telescoping) (Sudman and Bradburn 1973).
Forward telescoping is more likely to occur when events are highly salient. Events that are less
salient are more likely to suffer from backward telescoping, i.e., the exclusion of events that
occurred within the reference period because individuals think they occurred longer ago. To the
extent that work identified through the additional questions is work that is less salient, the results
will be more likely to suffer from backwards than forward telescoping, trending the additional
work identified toward zero (Brown, Rips, and Shevell 1985). Moreover, telescoping (of any
kind) is more likely to occur the further back the period for which the respondent is asked to
recall (Martin 2006). Given that our survey asks about events that occurred over the most recent
calendar week, we would not expect telescoping to be a large problem in our context. On
balance, the existing literature leads us to expect that adding questions to the CPS questionnaire
to identify previously unreported work should improve the accuracy of the information collected.
The material importance of any potential underreporting of informal work activity for our
understanding of the labor market will depend in part on the prevalence of such activity among
the CPS target population. This is something that several recent surveys have attempted to
measure. Robles and McGee (2016) analyze data from the Enterprising and Informal Work
Activities (EIWA) survey fielded by the Federal Reserve Board in October and November of
2015. Based on their sample, during the six months prior to the survey, 36% of the adult
population had participated in informal work that involved either selling or renting property or

9|Page

providing services. The estimate from the 2016 Survey of Household Economics and
Decisionmaking (SHED), which included similar questions, is that 28% of adults earned money
from informal work during the month prior to the survey (Board of Governors of the Federal
Reserve Board 2017). The two waves of the Survey of Informal Work Participation (SIWP)
carried out during 2015 asked whether respondents were “currently engaged” in informal paid
activity or side jobs, exclusive of selling property, renting property or responding to surveys
(Bracha and Burke 2019). This was found to be the case for 21% of adults age 21 and older
categorized as employed, 25% percent of those categorized as unemployed and 12% of those
categorized as out of the labor force based on the CPS employment questions. An important
caveat is that all three of these estimates are based on online panel surveys. One might be
concerned that engagement in other sorts of informal work is higher among those willing to
participate in an online panel than among the general population. While this may be the case, at
least in the SHED, even after excluding all informal work done by anyone who reported any
online work, the estimated prevalence of informal work activity falls but remains substantial
(Abraham and Houseman 2018).
Existing research provides some insights regarding the set of questions about the
measurement of informal work that motivate our research. In an early study based on data
collected during the early 1990s, Martin and Polivka (1995) explored the effect of probing for
informal work activity on measured employment rates. In one portion of their study, household
survey respondents were asked questions very similar to the current CPS employment sequence.
Then, in cases in which there was at least one adult member of the respondent’s household with
no reported employment, a question about informal work activity was asked regarding the first
such person listed on the household roster. Additional work activity identified through this

10 | P a g e

probing raised the estimated employment rate by 2.3 percentage points, with proportionally
larger effects for household members under age 20 and age 65 and older. Martin and Polivka did
not attempt to learn about underreporting of informal work as a secondary work activity (i.e.,
about multiple job holding) or about differences in the effects of probing for self versus proxy
reporters, nor did they experiment with alternative wordings for their probe.
More recently, analyzing data from the two waves of the SIWP fielded in 2015, Bracha
and Burke (2019) estimated that accounting for informal work activity identified through probing
would raise the overall employment rate by 4.5 percentage points above that estimated based on
responses to the CPS employment questions and raise the multiple job holding rate by more than
11 percentage points. In contrast to Martin and Polivka (1995), Bracha and Burke asked first
about informal work and then administered the CPS employment questions. This question
ordering could have affected the responses to the CPS questions and thus their conclusions. The
wording of their question about informal work—which asks whether a respondent is “currently
engaged” in such work rather than about whether the respondent did any such work during the
survey reference period—is also potentially problematic. Bracha and Burke (2019) do not
provide evidence on possible differences in the reporting behavior of self-reporters versus proxy
reporters, nor was their study designed to learn about the effectiveness of different ways of
asking about respondents’ participation in informal work.
Another relevant study is Katz and Krueger (2019a), which reports on a 2015 survey of
respondents recruited via the Mechanical Turk website, Amazon’s crowdsourcing platform, that
was designed primarily to learn whether people answering the CPS employment questions underreport multiple job holding. They first asked the CPS employment questions and then asked “Did
you work on any gigs, HITS or other small paid jobs last week that you did not include in your

11 | P a g e

answer to the previous question?” Taking the additional small jobs mentioned by respondents
into account raised the share of workers in the Katz and Krueger sample who are multiple job
holders from 39 percent to 77 percent. Similar to the other studies we have discussed, the Katz
and Krueger study was not designed to shed light on possible differences between the reporting
behavior of self-reporters versus proxy reporters nor to assess the relative effectiveness of
different ways of probing to learn about informal work activity.
Finally, in a novel analysis, Allard and Polivka (2018) use data from the American Time
Use Survey (ATUS) to gauge the effects of accounting for informal work on the employment
and multiple job holding rates. The ATUS, which uses the CPS as a sampling frame, includes
CPS-style questions about individuals’ labor force status and also collects information on each
respondent’s allocation of time during one 24-hour period. Allard and Polivka focus on time
devoted to labor-intensive income-generating activities such as hobbies, crafts, food,
performances or services that are not part of a job or business. They estimate that, in the ATUS
over the 2012-2016 period, accounting for such activities would have raised the employment rate
by between 0.4 and 3.0 percent and raised the multiple job-holding rate by between 3.0 and 20.7
percent. In both cases, the range reflects uncertainty about the extent to which average daily
participation in such activities reflects the same people engaging in the activity on multiple days
as opposed to different people engaging in the activity on different days. These estimates suggest
that the standard CPS questions miss relatively little informal work activity, but depend both on
the definition of income-generating activities adopted and, perhaps more importantly, on the
ATUS doing a good job of capturing time devoted to those activities.

12 | P a g e

Methods
To answer our research questions, we use data from the 2016 Joint Program in Survey
Methodology (JPSM) practicum project. For this project, a task visible only to U.S. residents was
posted to the Mechanical Turk website, asking for individuals to complete a survey about
employment referred to in the posting as the Current Employment Survey. Individuals who
clicked on the task were told that they would receive $2.50 for completion of a survey about the
employment status of themselves and other household members. A total of 4,991 people
completed the survey on August 16 and 17, 2016, taking an average of 13.55 minutes to answer
the questions asked. Given the non-probabilistic nature of the survey, response rates were not
calculated. We excluded 52 cases due to item non-response, and analysis was conducted on the
remaining 4,939 completed interviews.
The first section of the survey collected information on the characteristics of all members
of a respondent’s household. It included questions concerning age, sex, education, race and
ethnicity, marital status and relationship to the household respondent (opposite sex spouse,
opposite sex unmarried partner, same-sex spouse, same-sex unmarried partner, child, grandchild,
parent, brother/sister, other relative, foster child, housemate/roommate, roomer/boarder or other
non-relative). The second section of the survey asked questions to identify each household
member’s employment status; for those who were employed, whether they held more than one
job; and, as applicable, the hours worked on the main and other jobs. With the exception of some
experimental questions concerning sexual orientation and gender identity, all of the questions
about household members’ characteristics and work activity were taken directly from the Current
Population Survey (CPS) questionnaire. The use of the CPS employment questions on the JPSM
practicum survey means that the responses can be used to construct CPS-like measures of both
13 | P a g e

employment and multiple job holding during the survey reference week (“last week,” defined as
the most recent completed week beginning on a Sunday and ending on a Saturday).
For the respondent (in single person households) or for one randomly-selected member of
the household (in multiple person households), the CPS employment questions were followed by
additional questions probing for activity to earn money outside of a regular job. This is the
sample of people on which the analysis reported here is based. As can be seen in Table 1, the
analysis subjects are younger and considerably more educated than the population as a whole.
The specific questions asked about informal work activity were varied experimentally. In
one treatment condition, randomly assigned to half the cases, respondents were asked a global
yes/no question about whether any such activity had occurred during the survey reference week
(the global question). If no work activity had been reported for the subject household member in
response to the standard CPS questions, the global question was:

Sometimes people who don’t have a job do other things to earn money. Did
[you/[NAME]] do other things to earn money last week?

For those with work activity reported in answer to the CPS questions, the global question was:

Sometimes, in addition to working at a job [or business] where there is a definite
arrangement for regular work on a continuing basis, people do other things to earn
money. Outside of a job [or business], did [you/[NAME]] do other things to earn money
last week?

14 | P a g e

In these questions, as applicable, the text filled based on the person selected (e.g., if the
respondent is answering about another household member, NAME refers to that person’s name)
and whether or not the respondent had reported work by the individual in a family business.
In the second treatment condition, survey respondents were asked essentially the same
question, but with potential informal work activity decomposed into seven different categories
(the detailed question). The seven categories of work activity outside of a regular job that a
respondent might report were (1) provided services to other people, (2) provided services to a
self-employed individual or business, (3) performed as an actor, musician or entertainer, (4)
drove for a ridesharing service, (5) assisted with medical, marketing or other research, (6) posted
videos, blog posts or other content online, or (7) did other informal work or side job. Examples
were provided for all but the ‘other’ category.
For anyone categorized as CPS employed for whom informal work was reported, the
respondent was asked to indicate whether the informal work mentioned in response to additional
probing had been included in the CPS job count. Both among those who received the global
probe and among those who received the detailed probe, only about half of the informal work
mentioned when we probed had been included when answering the CPS employment questions.
Respondents also were asked to report the number of hours devoted to the informal work
reported in response to the probing question. The full survey questionnaire is reproduced in
online Appendix A. Online Appendix B provides information on the age, sex, education,
ethnicity and race of self-reports and proxy reports by assignment to the global versus the
detailed question treatment. The question treatment groups are well balanced with respect to
these characteristics. The only statistically significant differences between the characteristics of
the global and detailed question treatment groups are among other household members, with

15 | P a g e

those assigned the global question somewhat less likely than those assigned the detailed question
to have some college or an Associate degree (30.6% versus 36.7%) and somewhat more likely to
have a Bachelors degree or higher (40.5% versus 36.1%).
To answer our first research question—whether there is informal work for pay or profit
done during the survey reference week that the CPS employment questions do not capture—we
look at the proportion of individuals for whom additional probing identified work that was not
included in the answers to the CPS questions. We use a one-tailed one sample t-test to determine
whether this proportion is significantly greater than zero.
To address our second research question on whether the method used to probe for
informal work affects the answers obtained, we compare the share of people for whom additional
work is identified by the global versus the detailed question. We use a two-tailed two-sample ttest to determine whether the two probes—the global question and the detailed question—elicit
different amounts of additional work activity. To address our third research question, we carry
out these same comparisons separately for respondents reporting for themselves (self-reporters)
versus respondents reporting for other household members (proxy reporters) and then, within the
latter group, separately for respondents reporting about a spouse or unmarried partner (which we
will refer to simply as a spouse) versus respondents reporting about another household member.
We are most interested in the effects that probing for informal work activity has on the
estimated employment rate (the percent of people in the sample who were employed) and the
multiple job holding rate (the percent of employed persons with two or more jobs). Additional
work activity identified among those initially classified as not employed could raise the
employment rate; additional work activity identified among those with a single CPS job could

16 | P a g e

raise the multiple job holding rate. 2 We look first at how asking one or the other of the probing
questions (either the global question or the detailed question) affects the statistics of interest (the
employment rate and the multiple job holding rate). We use one-tailed paired t-tests to determine
whether these effects pass the threshold of statistical significance. The differences in the effects
of interest then are compared across the two treatments—the detailed question treatment versus
the global question treatment—using a two-tailed two-sample t-test. These analyses related to
our final research question are carried out first for the full sample and then separately by
household member status (self-report or proxy report), with the latter also broken out according
to whether the report is for a spouse or other household member.
All analyses are unweighted. The implications of the sample design and lack of weights
are considered in the concluding discussion.

Results
Our first research question asks whether individuals engage in informal work during the
reference week that is not captured by the standard CPS employment questions. We begin by
looking at the patterns of employment for the sample as a whole. As shown in Table 2, based on
their employment status as determined using the responses to the standard CPS questions, 16.6%
of sample members are categorized as not employed, 63.6% as employed with one job, and
19.8% as employed with more than one job. 3 When respondents are prompted with follow-up

2

The identification of multiple jobs for someone initially classified as not employed also in principle could raise the
multiple job holding rate. For the purpose of comparing the effects of the detailed and global questions on the
multiple job holding rate, however, we do not want to allow for an outcome that is possible for those receiving the
detailed question but not for those receiving the global question. In contrast to the detailed question, the global
question allows us to determine only that an individual had done some work that was not initially reported, not
whether they had more than one unreported job.
3
In CPS data for August 2016, 38.7% of individuals 18 and older were not employed, 58.3% were employed with
one job, and 3.0% were employed with two or more jobs. This distribution was similar for those reporting for

17 | P a g e

questions about work activity outside of a regular job, additional work not reflected in the
answers to the standard CPS employment questions is reported for 21.9% of the sample.
Additional work is identified for members of all three employment-status groups—among those
the CPS questions identified as not employed, as employed with a single job and as employed
with two or more jobs.
Because our sample was recruited through Amazon’s Mechanical Turk, we know that all
of our respondents have been involved in gig work at least to some extent. This means that the
incidence of additional work we uncovered by probing likely is higher than in the general
population. We do not have good information on the types of informal work done by those who
received the global probe, but we do have that information for those who received the detailed
probe. About a third of those receiving the detailed probe who did any added informal work
reported work in the research category, which is where Mechanical Turk activities should be
listed. 4 As a sensitivity check, using the portion of our sample that received the detailed probe,
we reran the tabulations reported in Table 2 excluding all additional informal research work.
Without this exclusion, 25.8% of those receiving the detailed probe reported additional work
activity; excluding research work, this share was smaller but remained substantial at 19.7%. As
shown in online Appendix Table C1, even with research work excluded, probing identified
substantial added work activity in all three employment status groups as determined based on the
answers to the CPS employment questions.

themselves compared to those for whom a proxy report was obtained, as well as for reference persons, spouses, and
other household members.
4
Looking across the remaining categories, among those receiving the detailed probe for whom we identified added
work, 17% performed services for others, 12% performed services for a business or self-employed person, 7%
earned money by posting content online, 3% drove for a ride-sharing service, 3% performed as an entertainer, and
31% did other types of informal work not captured in the more specific categories. These numbers add up to
slightly more than 100 percent because there were some people who reported more than one type of added work.

18 | P a g e

Another natural question to ask about the added work activity identified through probing
is whether it involved more than a minimal amount of individuals’ time. We collected
information on hours for informal work identified through probing both for those receiving the
global probe and for those receiving the detailed probe. Among those responding to the global
probe, after asking the hours question, we then asked whether any reported informal work
activity had been included when answering the CPS employment questions. Some subjects
receiving the global probe could have done more than one type of informal work during the
survey reference week and it is not entirely clear how they would have answered this question.
For those responding to the detailed probe, we asked separately about hours and their inclusion
in answering the CPS employment questions for each type of reported informal activity. As a
check on whether our conclusions would have been different had we excluded informal work
activity identified through probing that involved only a minimal amount of time, we recomputed
the numbers reported in Table 2 but counting added informal work only for those with at least
four hours of such work identified through probing. As can be seen in online Appendix Table
C3, the share of respondents with added work is about 40 percent lower—13.0% rather than
21.9% —but the general trends in the estimates are otherwise unaffected.
Among the full set of people reporting additional work during the survey reference week
after probing, including those with very low hours, some 17.6% said that they spent an estimated
15 or more hours on that additional activity (15.2% for those receiving the global probe and
19.3% for those receiving the detailed probe). Added work activity during the reference week
identified through probing occupied an average of 8.2 hours during the survey reference week
(7.0 hours for those receiving the global probe and 9.1 hours for those receiving the detailed
probe), roughly equivalent to a full normal work day. Those with no CPS employment for whom

19 | P a g e

unreported work activity was identified by probing are somewhat more likely than those with
one or more CPS jobs to have spent 15 or more hours on that activity during the reference week
(24.7% versus 16.0% overall, 17.1% versus 14.9% for those the receiving the global probe, and
29.2% versus 16.9% for those receiving the detailed probe). Among those for whom added work
activity was identified, the group with no CPS employment also spent more hours than those
with one or more CPS jobs (9.9 versus 7.9 hours overall, attributable entirely to the difference of
11.8 versus 8.5 hours for those receiving the detailed probe). Our second research question asks
whether the form of the follow-up question about informal work affects the number of people for
whom additional work activity is identified. The first two rows of Table 3 report estimates of the
distribution of the sample by CPS employment status and the distribution of additional
employment identified by probing across the three employment status groups. Here these
estimates are shown separately for the cases receiving the global prompt and those receiving the
detailed prompt. As anticipated given that the assignment to the global versus the detailed probe
was random, the shares of the sample cases in each of the three CPS employment status groups
do not differ significantly between the two treatments. The share of cases for which added
employment was identified through probing, however, is significantly greater under the detailed
question treatment than under the global question treatment (25.8% versus 18.0%, a statistically
significant difference of 7.8 percentage points). This overall difference is spread across
individuals with no CPS employment, one CPS job and more than one CPS job; in each of the
three groups, the detailed question identifies significantly more added employment than does the
global question.
The third research question we posed was whether the effects of prompts to uncover work
activity outside of a regular job differ depending on whether they apply to the individual herself

20 | P a g e

(self-report) or to another household member (proxy report) and, in the latter case, whether the
effects differ according to the relationship between the respondent and the other household
member. The next two panels of Table 3 report estimates separately for the self-report and proxy
report cases in our sample. The prevalence of work activity reported in response to the CPS
questions is much higher for the people for whom we obtained self-reports than for the people
for whom we obtained proxy reports. Those in the self-report group are much less likely to have
no CPS employment, equally likely to have a single CPS job and much more likely to have two
or more CPS jobs. Consistent with the random assignment of respondents to treatments, within
each of these two groups (self-reports and proxy reports), there are no significant differences in
the prevalence of work activity elicited by the standard CPS questions between those receiving
the global prompt and those receiving the detailed prompt.
The self-report cases in our sample differ from those for whom we have proxy reports not
only in their level of work activity as captured by the CPS questions but potentially also with
respect to the prevalence and nature of any work activity not captured by those questions.
Differences in the amount of additional work activity identified by prompting for the self-report
cases versus the proxy report cases could be due to differences in how people report about
themselves as compared to how they report about others They also could be due, however, to real
differences in the labor force activity of the self-reports versus the proxy reports. Given that
respondents were assigned randomly to be asked the detailed question versus the global question,
however, we can attribute differences across question treatments within either the self-report or
the proxy report group to the type of probe each treatment group received.
Asking the detailed question rather than the global question raises the share of proxy
report cases for which additional work activity is identified by 10.2 percentage points, from 6.0%

21 | P a g e

of cases with added work activity using the global prompt to 16.3% of cases using the detailed
prompt. In contrast, the difference for the self-report cases is just 5.7 percentage points, with
27.9% reporting added work activity under the global prompt versus 33.7% under the detailed
prompt. Putting these results somewhat differently, the number of proxy report cases with
additional work identified by probing increases by 172% when the detailed question is asked
instead of the global question, compared to an increase of just 21% for the self-report cases.
Asking the detailed rather than the global question also has a larger effect on the number of
hours devoted to additional work for proxy report cases for whom additional work is identified
(11.1 hours versus 6.5 hours, a 4.6 hour difference) than for self-report cases with additional
work (8.3 hours versus 7.1 hours, a 1.2 hour difference). Among the proxy reports, there are
significant differences in the amount of additional work activity identified by the detailed prompt
versus the global prompt for all three employment status groups—those without CPS
employment, those with one CPS job and those with more than one CPS job. Among the selfreport cases, however, the only statistically significant difference arises for the subgroup who
already had reported more than one job in response to the standard CPS questions.
The bottom two panels of Table 3 further break out how asking the global versus the
detailed question affects the additional work activity reported when a proxy is answering for a
spouse or unmarried partner (referred to for convenience as a spouse) versus some other
household member. The rationale for making this comparison is that we expect a respondent
generally to be closer to her spouse than to other household members and to communicate more
with her spouse about daily activities. If this is correct, we might expect the amount of additional
work activity identified by the global compared to the detailed questions be more similar when
the proxy subject is a spouse than when the proxy subject is some other household member.

22 | P a g e

Among reports for spouses, the global and the detailed questions perform very similarly
with respect to identifying previously unreported work activity for those with no CPS job,
though a second or third job is more likely to be reported when the detailed question is asked.
Among reports for other household members, the detailed question elicits significantly more
reports of additional employment than the global question for all three CPS employment status
groups (no CPS employment, one CPS job, or two or more CPS jobs). This is consistent with
stronger cues being more important for activating respondents’ memories or encouraging
respondents to make use of situational knowledge when they are reporting for household
members other than their spouse. Both for spouses and for other household members, among
those with additional work identified, the detailed probe has a larger effect than thon the number
of hours reported (11.0 versus 6.1 hours for spouses and 11.2 versus 6.9 hours for other
household members).
Because we have good information about the type of informal work performed only for
respondents asked the detailed question, we cannot repeat this analysis with research work
excluded. We have replicated the Table 3 tabulations excluding added work that involved less
than four hours during the reference week. These results are shown in online Appendix Table
C4. As in our baseline results, the detailed probe elicits more unreported work activity than the
global probe. This is especially true for proxy reports and, among the proxy reports, for other
household members rather than a spouse.
Table 4 examines how taking into account the additional work activity identified by
probing affects the estimated employment rate, defined as the share of the sample employed
during the survey reference week, and the estimated multiple job holding rate, defined as the
share of CPS employed persons holding more than one job during the reference week. The table

23 | P a g e

reports estimated rates based on the responses to the CPS questions; augmented rates that add the
additional work activity identified by probing to the numerator used to calculate the rate in
question; and differences between each pair of estimated rates. In the full sample, as shown by
the numbers in the first two rows of the table, probing to identify additional work activity
consistently raises both the employment rate and the estimated multiple job holding rate. The
increase in the employment rate is larger for those who received the detailed probe than for those
who received the global probe. The difference in the effects of the detailed versus the global
probe on the estimated employment rate in the full sample is a statistically significant 2.0
percentage points. Both the global and the detailed probe produce substantially larger effects on
the multiple job holding rate. Again, in the full sample, the effect is larger with the detailed
probe, which raised the multiple job holding rate by a statistically significant 3.6 percentage
points more than the global probe. 5
Disaggregating by whether the respondent is reporting for herself or for another
household member makes clear that the differences in the effects on the employment rate we
observe in the full sample for the detailed question versus the global question arise primarily
among the proxy report cases. For proxy reports, the effect on the employment rate of
incorporating additional work activity identified by probing is a statistically significant 3.0
percentage points larger based on asking the detailed question as opposed to the global question.
For the self-report cases, the corresponding difference in employment rate effects is smaller (1.2
percentage points) and not statistically significant.
The same general pattern holds for the multiple job holding rate. For proxy reports,
incorporating additional work identified by probing raises the multiple job holding rate by a

5

In CPS data for August 2016, among those age 18 and older, the employment rate was 61.3% and the multiple job
holding rate was 5.0%.

24 | P a g e

statistically significant 8.4 percentage points more when the detailed question is asked than when
the global question is asked. For self-reports, in contrast, although both the detailed and the
global question questions identify a sizable number of second jobs not reported in response to the
CPS questions, the difference between the two effects is small and statistically indistinguishable
from zero.
As with the results reported in Table 3, there is heterogeneity within the proxy report
cases. Results are shown separately for spouses and other household members in the bottom two
panels of Table 4. Recall that, among those reporting about themselves, the global and the
detailed questions have statistically indistinguishable effects on both the employment rate and
the multiple job holding rate. In the reports for spouses, the effect on the employment rate of
asking the detailed question is statistically indistinguishable from the effect of asking the global
question, but asking the detailed question has a notably larger effect on the multiple job holding
rate. Adding work activity identified by probing raises the multiple job holding rate for a spouse
by a statistically significant 6.7 percentage points more when the detailed question is asked than
when the global question is asked. Finally, among reports for other household members, asking
the detailed question rather than the global question has a larger effect on both the employment
rate and the multiple job holding rate.
To assess the sensitivity of these findings, we have replicated the Table 4 tabulations for
respondents who received the detailed prompt but with added research work excluded (results
reported in online Appendix Table C2). We also have replicated the full Table 4 analysis but
with added work involving less than four hours during the reference week excluded (results
reported in online Appendix Table C5). Even with these exclusions, incorporating the added
work identified by probing produces a statistically significant increase in the estimated

25 | P a g e

employment rate and has an even larger effect on the estimated multiple job holding rate. In the
tabulations that exclude added work involving less than four hours, we can examine the effects
of asking the detailed versus the global question about informal work. All of the qualitative
findings from our Table 4 analysis are robust to the exclusion of very-low-hours added work.

Discussion and Conclusion
The results that we have reported suggest that there may be a substantial number of
people involved in informal work that is not captured by the standard CPS questions. In our
sample, additional probing using either a global question or a decomposed question identified a
sizeable number of reports of additional work activity. This was true whether a respondent was
reporting for themselves or for another household member, and also whether the other household
member was a spouse or someone else. Accounting for this additional work activity raised both
the employment rate and the multiple job holding rate, defined in each case in the same way as in
the monthly labor force statistics published by the BLS.
Further, our results suggest that different ways of probing for additional work activity
may produce different results depending on the person about whom a respondent is reporting.
For those in our sample reporting about themselves, the effects of a global probe are not very
different from the effects of a more detailed probe that decomposes various possible types of
work activity a person might have carried out and provides examples. Among these self-reports,
the detailed probe elicits a significantly greater number of reports of additional work activity
only for those who already had mentioned two or more jobs in response to the standard CPS
questions. In contrast, for proxy reports, the detailed probe more consistently elicits a greater

26 | P a g e

number of such reports. This is especially true when a respondent is reporting for a household
member other than her spouse.
For a self-report, asking the detailed question rather than the global question has
essentially the same effect as asking the global question on both the employment rate and the
multiple job holding rate. For reports about a spouse, asking the detailed question produces a
larger effect on the multiple job holding rate but not the employment rate. Finally, for reports
about other household members, asking the detailed question has a larger effect on both the
employment rate and the multiple job holding rate.
The added work activity identified through probing in our survey most likely is
attributable either to respondents not having understood that this activity should have been
reported in answering the CPS employment questions or to the cue offered by the probe
activating their memories of the activity. The fact that, for self-reports, the detailed probe
generally does not produce larger effects than the global probe may suggest that memories about
own recent work activity tend to be relatively accessible. In contrast, for proxy reports—and
especially proxy reports pertaining to household members other than the spouse—the detailed
probe more consistently produces more reports of added work activity, suggesting that strong
cues are likely to be useful when seeking information from household survey respondents about
work done by others in their households.
An important limitation of our study is that the sample for which we collected data is not
representative of the population as a whole. All of our respondents are individuals who are active
on Mechanical Turk and thus likely (though not certain) to have been involved at least in that
form of informal work activity during the survey reference week. We would not expect the same
necessarily to be true of other members of respondents’ households, but even that group is

27 | P a g e

younger and more educated than the population as a whole and may be atypical in other respects.
For these reasons, even if we were to reweight the data we have collected to match the
observable demographic characteristics of the broader population, the estimates derived from our
survey responses could not be generalized to that universe. Another caution about drawing
conclusions from our study about biases in the responses to the CPS employment questions is
that our survey was conducted online, whereas the CPS responses are collected via telephone or
face-to-face interviews. The survey findings nonetheless provide important evidence about the
sensitivity of survey estimates to asking more probing questions and structuring the probes in
different ways.
To the extent that irregular or informal work has become more common, under-reporting
of work activity in response to the standard CPS questions could have become more prevalent
over time. The fact that the share of people reporting self-employment income on their tax
returns has been rising while the share reporting self-employment income in household survey
data has been flat or declining is consistent with this possibility (Katz and Krueger 2019b;
Abraham et al. 2018). On the other hand, surveys designed specifically to capture informal work
activity do not show continued overall growth in the rate of participation in such activity in
recent years, though participation in online platform work appears to have become more
prevalent and cyclical effects could have masked a continuation of an underlying positive trend
(Bracha and Burke 2018). It is important in any case to understand clearly what the CPS
employment questions are and are not capturing, and to think about whether and how they could
be improved or supplemented.
As the agency responsible for producing official U.S. labor force statistics, the Bureau of
Labor Statistics has a strong interest in producing the best possible information about

28 | P a g e

individuals’ work arrangements and how they are evolving. The Contingent Work Supplement
(CWS) to the CPS, administered on five occasions between 1995 and 2005 and again in 2017,
provides valuable information on this topic (see, e.g., Polivka 1996, Cohany 1996, and Bureau of
Labor Statistics 2018). Because the CWS takes as its starting point the employment reported in
response to the standard CPS questions, asking additional questions only about the main job
reported for each person, it provides no information about any work not reported in answer to the
standard CPS questions or work that is secondary to a main job. There is a need, we would
argue, for efforts to design questions that can be used to obtain information about informal work
more broadly. That said, if the types of informal work that people are doing change over time,
the questions that are most appropriate to ask may change as well, something that could make it
more difficult to produce estimates of informal work activity that are consistent over time.
In future research, it would be of value to examine whether our findings can be replicated
in samples that have different characteristics and, ideally, are more representative of the general
population. There also would be value in replicating our analysis using the survey modes that are
employed in the CPS (telephone and face-to-face interviews) rather than collecting responses to
an online instrument. In this study, we have compared the effects of asking a global question to
the effects of asking a particular decomposed question for learning about informal work not
reported in response to the standard CPS questions. The categories and examples included in our
decomposed question focused on activities in which compensation is received mainly for a
person’s labor, as opposed to being provided in connection with selling a product (e.g., selling
crafts on e-Bay) or providing temporary use of a capital asset (e.g., renting out a room in a house
through Airbnb). It is not yet clear, however, which categories and examples of activities should
be mentioned to obtain the most complete accounting of work done for pay or profit. Further

29 | P a g e

research on how best to ask about such activity would be desirable. Additional testing also might
incorporate follow-up questions about when any added activities were performed (to determine
whether and to what extent activities that occurred prior to the survey reference period may have
been reported), how much was earned from any missed activities (as a means of gauging their
importance), and why the activities were not reported initially.

30 | P a g e

References

Abraham, Katharine G., John C. Haltiwanger, Kristin Sandusky and James R. Spletzer. 2018.
“Measuring the Gig Economy: Current Knowledge and Open Issues,” National Bureau of
Economic Research Working Paper No. 24950. August. DOI 10.3386/w24950.
Abraham, Katharine G. and Susan N. Houseman. 2018. “Making Ends Meet: The Role of
Informal Work in Supplementing Americans’ Income,” Upjohn Institute, unpublished
working paper. December.
Allard, Mary Dorinda and Anne E. Polivka. 2018. “Measuring Labor Market Activity Today:
Are the Words Work and Job Too Limiting for Surveys?” Monthly Labor Review.
November. Accessed at https://www.bls.gov/opub/mlr/2018/article/pdf/measuring-labormarket-activity-today.htm April 16, 2019.
Belli, Robert F., Norbert Schwarz, Eleanor Singer and Jennifer Talarico. 2000. “Decomposition
Can Harm the Accuracy of Behavioural Frequency Reports,” Applied Cognitive
Psychology, 14: 295-308. DOI http://dx.doi.org/10.1002/10990720(200007/08)14:4<295::AID-ACP646>3.0.CO;2-1
Blair, Edward and Scot Burton. 1987. “Cognitive Processes Used by Survey Respondents to
Answer Behavioral Frequency Questions,” Journal of Consumer Research, 14(2): 280288. DOI https://doi.org/10.1086/209112.
Board of Governors of the Federal Reserve System. 2017. Report on the Economic Well-Being
of U.S. Households in 2016. Washington, D.C.: Board of Governors of the Federal
Reserve System. Accessed at https://www.federalreserve.gov/publications/files/2016report-economic-well-being-us-households-201705.pdf May 10, 2019.
Bower, Gordon H. and Stephen G. Gilligan. 1979. “Remembering Information Related to One’s
Self,” Journal of Research in Personality, 13: 420-432. DOI
https://doi.org/10.1016/0092-6566(79)90005-9
Bracha, Anat, and Mary A. Burke. 2018. “The Ups and Downs of the Gig Economy, 20152017,” Federal Reserve Bank of Boston Working Paper 18-12. October. Accessed at
https://www.bostonfed.org/publications/research-department-working-paper/2018/theups-and-downs-of-the-gig-economy-2015-2017.aspx May 10, 2019.
____________. 2019. “How Big is the Gig?” Federal Reserve Bank of Boston, unpublished
working paper. January.
Brown, N.R., L.J. Rips, and S.K. Shevell. 1985. “The Subjective Dates of Natural Events in
Very-Long-Term Memory,” Cognitive Psychology, 17(2): 139-177. DOI
https://doi.org/10.1016/0010-0285(85)90006-4

31 | P a g e

Bureau of Labor Statistics. Undated. “Labor Force Statistics from the Current Population Survey:
Frequently Asked Questions.” Accessed at https://www.bls.gov/cps/faq.htm June 8, 2018.
____________. 2018. “Contingent and Alternative Employment Arrangements, May 2017.”
Accessed at https://www.bls.gov/news.release/pdf/conemp.pdf June 18, 2018.
Cohany, Sharon R. 1996. “Workers in Alternative Employment Arrangements.” Monthly Labor
Review October: 31–45. Accessed at https://www.bls.gov/mlr/1996/10/art4full.pdf May
10, 2019.
Dashen, Monica. 2000. “The Effects of Retention Intervals on Self- and Proxy Reports of
Purchases,” Memory, 8 (3): 129–143. DOI https://doi.org/10.1080/096582100387560
Fowler, Floyd Jackson, Jr. 1992. “How Unclear Terms Affect Survey Data,” Public Opinion
Quarterly, 56(2): 218-231. DOI https://doi.org/10.1086/269312
Katz, Lawrence F. and Alan B. Krueger. 2019a. “Understanding Trends in Alternative Work
Arrangements in the United States.” NBER Working Paper No. 25425. Cambridge, MA:
National Bureau of Economic Research. DOI 10.3386/w25425
____________. 2019b “The Rise and Nature of Alternative Work Arrangements in the United
States, 1995-2015.” ILR Review, 72(2): 382–416. DOI
https://doi.org/10.1177%2F0019793918820008
Kojetin, Brian A. and Leslie A. Miller. 1993. “The Intrahousehold Communications Study:
Estimating the Accuracy of Proxy Responses at the Dyadic Level,” paper presented at the
48th Annual Conference of the American Association for Public Opinion Research, St.
Charles, Illinois. May. Accessed at
http://www.asasrms.org/Proceedings/papers/1993_188.pdf May 10, 2019.
Kuiper, N.A. and T.B. Rogers. 1979. “Encoding of Personal Information: Self-Other
Differences,” Journal of Personality and Social Psychology, 37(4): 499-514. DOI
http://dx.doi.org/10.1037/0022-3514.37.4.499
Martin, Elizabeth. 2006. “Survey Questionnaire Construction,” U.S. Census Bureau Research
Report Series, Survey Methodology #2006-13. Accessed at
https://www.census.gov/srd/papers/pdf/rsm2006-13.pdf May 10, 2019.
Martin, Elizabeth and Anne Polivka. 1995. “Diagnostics for Redesigning Survey Questionnaires:
Measuring Work in the Current Population Survey,” Public Opinion Quarterly, 59(4):
547-567. DOI https://doi.org/10.1086/269493
Menon, Geeta. 1997. “Are the Parts Better than the Whole? The Effects of Decompositional
Questions on Judgments of Frequent Behaviors,” Journal of Marketing Research, 34(3):
335-346. DOI https://doi.org/10.1177%2F002224379703400303

32 | P a g e

Phillips, Joan M. and Barbara A. Bickart and Geeta Menon. 2006. “Reporting About Others'
Behavior: The Role of Judgment Strategy, Knowledge, and Regularity.” September.
Accessed at https://ssrn.com/abstract=946247 April 16, 2019.
Polivka, Anne E. 1996b. “A Profile of Contingent Workers.” Monthly Labor Review. October:
10–21. Accessed at https://www.bls.gov/opub/mlr/1996/article/profile-of-contingentworkers.htm May 10, 2019.
Robles, Barbara and Marysol McGee. 2016. Exploring Online and Offline Informal Work:
Findings from the Enterprising and Informal Work Activities (EIWA) Survey,
Washington: Board of Governors of the Federal Reserve System. DOI
https://doi.org/10.17016/FEDS.2016.089
Schober, Michael F., and Frederick G. Conrad. 1997. “Does Conversational Interviewing Reduce
Survey Measurement Error?,” Public Opinion Quarterly, 61(4): 576-602. DOI
https://doi.org/10.1086/297818
Schober, Michael F., Anna L. Suessbrick, and Frederick G. Conrad. 2018.“When Do
Misunderstandings Matter? Evidence from Survey Interviews about Smoking,” Topics in
Cognitive Science, 10(2): 452-484. DOI 10.1111/tops.12330
Schwarz, Norbert. 1999. “Self-Reports: How the Questions Shape the Answers,” American
Psychologist, 54(2): 93-105. DOI http://dx.doi.org/10.1037/0003-066X.54.2.93
Schwarz, Norbert and Tracy Wellens. 1997. “Cognitive Dynamics of Proxy Responding: The
Diverging Perspectives of Actors and Observers,” Journal of Official Statistics, 13(2):
159-179.
Sudman, Seymour and Norman M. Bradburn. 1973. “Effects of Time and Memory Factors on
Response in Surveys,” Journal of the American Statistical Association, 68: 805-815.
DOI: 10.2307/2284504.
Sudman, Seymour, Norman M. Bradburn and Norbert Schwarz. 1996. Thinking About Answers:
The Application of Cognitive Processes to Survey Methodology, San Francisco: JosseyBass.
Tourangeau, Roger. 2000. “Remembering What Happened: Memory Errors and Survey
Reports,” in Arthur A. Stone, Christine A. Bachrach, Jared B. Jobe, Howard S. Kurtzman
and Virginia S. Cain, eds., The Science of Self-Report: Implications for Research and
Practice, Mahwah, NJ: Lawrence Erlbaum Associates Inc., 29-47.
Tourangeau, Roger, Frederick G. Conrad, Mick P. Couper and Cong Ye. 2014. “The Effects of
Providing Examples in Survey Questions,” Public Opinion Quarterly, 78(1): 100-125.
U.S. Census Bureau. 2006. DOI https://doi.org/10.1093/poq/nft083

33 | P a g e

Tourangeau, Roger, Lance J. Rips and Kenneth Rasinski. 2000. The Psychology of Survey
Response, Cambridge University Press: New York.
U.S. Census Bureau. 2006. Design and Methodology: Current Population Survey, Technical
Paper No. 66. Washington DC.

34 | P a g e

Table 1: Characteristics of Analysis Sample versus American Community Survey
Estimates (percent distributions)

Respondent

Other
Household
Members

ACS
(2016)***

18-24/16-24*

11.7

18.7

12.8

25-34
35-44
45-54
55-64
65 and over

45.8
23.9
11.1
5.7
1.7

31.7
17.5
14.1
11.4
6.6

17.7
16.6
17.7
16.4
18.9

50.6

47.3

51.4

0.3
8.7
36.2
54.7

6.7
21.3
33.6
38.3

12.6
27.7
31.0
28.7

Hispanic
Non-Hispanic White
Non-Hispanic African American
Non-Hispanic other race
Non-Hispanic multiracial

7.3
73.8
7.0
8.0
3.9

10.7
70.9
6.9
8.9
2.6

16.0
65.5
12.3
4.8
1.5

Sample size

2,704

2,235

--

Age

Female**
Education

Less than high school
High school
Some college or Associate degree
Bachelors degree or higher
Race/Ethnicity

*All

survey respondents were age 18 or older, but respondents were asked to report for other household members
age 16 and older. The survey sample includes N=93 other household members age 16 or 17. The ACS numbers show
the age distribution of the population age 18 and older.
**The survey sample includes N=22 respondents and N=19 other household members reported as transgender or
not identifying as either male or female, or for whom no report on gender identity was provided. They are included
in the denominator when calculating the percent female in our sample.
***All

sample distributions are significantly different from the corresponding ACS distributions at p<0.001.

Table 2: Additional Work Activity Identified by Probing, Full Sample
Employment
Status Based on
CPS Questions,
Percent of Full
Sample

Additional Work
Activity Identified
by Probing,
Percent of Full
Sample*

Additional Work
Activity Identified
by Probing, Percent
of Row Category

4,939

100.0

21.9

21.9

820

16.6

3.9

23.5

3,142

63.6

14.8

23.3

977

19.8

3.1

15.9

Sample
Size
Total
CPS not employed
CPS employed, 1 job
CPS employed, 2 plus jobs

*All reported values for percent in full sample with additional work activity identified by probing significantly different from zero at p< 0.001.

Full Sample
Global prompt
Detailed prompt
Detailed minus global
(p-value)
Self Reports
Global prompt
Detailed prompt
Detailed minus global
(p-value)
Proxy Reports
Global prompt
Detailed prompt
Detailed minus global
(p-value)
Spouse
Global prompt
Detailed prompt
Detailed minus global
(p-value)
Other Household Member
Global prompt
Detailed prompt
Detailed minus global
(p-value)
100.0
100.0
--

100.0
100.0
--

100.0
100.0
--

100.0
100.0
--

100.0
100.0
--

1,364
1,340
--

1,128
1,107
--

583
542
--

545
565
--

Total

2,492
2,447
--

Sample
Size

44.0
41.6
-2.4
(0.411)

17.3
18.5
1.1
(0.623)

30.2
30.3
0.0
(0.987)

5.4
5.3
-0.1
(0.862)

16.6
16.6
0.0
(0.980)

Employed

50.8
54.7
3.9
(0.198)

73.2
71.2
-2.0
(0.449)

62.4
62.8
0.4
(0.856)

64.4
64.6
0.2
(0.921)

63.5
63.8
0.3
(0.845)

1 Job

5.1
3.7
-1.4
(0.250)

9.4
10.3
0.9
(0.614)

7.4
7.0
-0.4
(0.386)

30.3
30.2
-0.1
(0.965)

19.9
19.7
-0.2
(0.828)

2+ Jobs

Employment Status Based on CPS Questions
(percent of sample)
Not

Table 3: Additional Work Activity Identified by Probing, Global versus Detailed Probe

5.9
18.6
12.7
(<0.001)

6.2
13.8
7.7
(<0.001)

6.0
16.3
10.2
(<0.001)

27.9
33.7
5.7
(0.001)

18.0
25.8
7.8
(<0.001)

Total

4.8
10.1
5.3
(0.001)

2.7
3.1
0.4
(0.697)

3.7
6.7
3.0
(0.002)

2.3
3.4
1.2
(0.070)

2.9
4.9
2.0
(<0.001)

Employed

1.1
7.4
6.3
(<0.001)

2.9
8.3
5.4
(<0.001)

2.0
7.9
5.8
(<0.001)

22.7
23.4
0.7
(0.664)

13.3
16.4
3.0
(<0.001)

1 Job

0.0
1.1
1.1
(0.014)

0.5
2.4
1.9
(<0.001)

0.3
1.7
1.5
(0.001)

3.0
6.9
3.9
(<0.001)

1.8
4.5
2.8
(<0.001)

2+ Jobs

Additional Work Activity Identified by Probing
(percent of sample)
CPS, Not
CPS,
CPS,

Detailed prompt
Detailed minus global
(p-value)
Self Reports
Global prompt
Detailed prompt
Detailed minus global
(p-value)
Proxy Reports
Global prompt
Detailed prompt
Detailed minus global
(p-value)
Spouse
Global prompt
Detailed prompt
Detailed minus global
(p-value)
Other Household Member
Global prompt
Detailed prompt
Detailed minus global
(p-value)

Full Sample
Global prompt
83.4
0.0
(0.984)
94.7
94.7
0.1
(0.951)
69.8
69.7
0.0
(0.987)
82.7
81.6
-1.1
(0.623)
56.0
58.4
2.4
(0.411)

1,364
1,340
--1,128
1,107
--583
542
--545
565
---

83.4

2,447
---

2,492

Sample
Size

60.7
68.5
7.8
(0.007)

85.4
84.7
-0.7
(0.730)

73.5
76.4
2.9
(0.110)

96.9
98.1
1.2
(0.042)

88.3
2.0
(0.035)

86.3

4.8
10.1
5.3
(0.001)

2.7
3.1
0.4
(0.697)

3.7
6.7
3.0
(0.002)

2.3
3.4
1.2
(0.070)

4.9
2.0
(<0.001)

2.9

Employment Rates
CPS
Augmented Difference
Questions by Probing

(<0.001)
(<0.001)
---

(<0.001)
(<0.001)
---

(<0.001)
(<0.001)
---

(<0.001)
(<0.001)
---

(<0.001)
---

(<0.001)

(pvalue)

305
330
---

482
442
---

787
772
---

1,291
1,269
---

2,041
---

2,078

Sample
Size

9.2
6.4
-2.8
(0.184)

11.4
12.7
1.3
(0.557)

10.6
10.0
-0.6
(0.710)

32.0
31.8
-0.2
(0.933)

23.6
0.3
(0.820)

23.9

11.1
19.1
7.9
(0.005)

14.9
22.9
7.9
(0.002)

13.5
21.2
7.8
(<0.001)

55.9
56.5
0.6
(0.769)

43.2
3.3
(0.031)

39.9

2.0
12.7
10.8
(<0.001)

3.5
10.2
6.7
(<0.001)

2.9
11.3
8.4
(<0.001)

23.9
24.7
0.7
(0.667)

19.6
3.6
(0.002)

16.0

Multiple Job Holding Rates
CPS
Augmented Difference
Questions by Probing

Table 4: Effect of Additional Work Activity Identified by Probing on Employment and Multiple Job Holding Rates, Global versus
Detailed Probe

(0.007)
(<0.001)
---

(<0.001)
(<0.001)
---

(<0.001)
(<0.001)
---

(<0.001)
(<0.001)
---

(<0.001)
---

(<0.001)

(pvalue)

Appendix A: JPSM 2016 Survey Practicum Questionnaire
Current Employment Survey
8/1/2016 V12
INTRODUCTION
Welcome to the Current Employment Survey. We are seeking to gather information about the
employment status and personal characteristics of survey respondents and the people they live
with.
This study is being conducted by Katharine G. Abraham at the University of Maryland College
Park and should take approximately 10 minutes to complete. We suggest that you find
someplace quiet and away from distractions to take the survey.
Your responses are voluntary and will remain completely confidential. Only researchers and
staff who work on this project will have access to your responses. There are no known risks of
participation.
If you are not comfortable answering a question, you may skip it and move on to the next
question. This will not affect your Mechanical Turk payment.
Please check the box below, to indicate that you have read this statement in its entirety; that
you are at least 18 years of age; that your questions about the research study have been
answered to your satisfaction; and that you voluntarily agree to participate in the study. You may
print a copy of this consent form if you wish.
□

I have read this statement in its entirety and affirm the stated conditions

ROSTERING
Q1.

We want to know a little bit about the people in your household who are old enough to
work before we ask you some questions about their employment status.
Including yourself, how many people ages 16 or older live in your household?
DROP DOWN MENU 1-10, 11 or more
IF Q1 IN (.,1), GO TO Q4_1. ELSE GO TO Q2.

1

Q2.

Please list the first names, nicknames or initials of the people ages 16 and older in
your household starting with yourself.
We don’t need actual names, just something that in later questions will tell you who we
are asking about.
[We will only collect information for 10 of the people in your household. Please list
yourself first, then include the 9 oldest people age 16 and older among the remaining
members of your household.]
DISPLAY THE CORRECT NUMBER OF TEXT BOXES

Q3_X. How is [NAME] related to you?
1. Opposite-sex Spouse (Husband/Wife)
2. Opposite-sex Unmarried Partner
3. Same-sex Spouse (Husband/Wife)
4. Same-sex Unmarried Partner
5. Child
6. Grandchild
7. Parent (Mother/Father)
8. Brother/Sister
9. Other relative (Aunt, Cousin, Nephew, Mother-in-law, etc.)
10. Foster child
11. Housemate/Roommate
12. Roomer/Boarder
13. Other nonrelative
REPEAT Q3_X FOR EACH HH MEMBER BEFORE GOING TO Q4_1.
DEMOGRAPHICS
ASK Q4_1-Q13_1 BEFORE LOOPING BACK FOR OTHER HOUSEHOLD MEMBERS.
Q4_X. In what year [were you/was [NAME]] born?
If you don’t know the answer, leave this box blank.
ENTER YEAR 1896-2000
IF Q4_X=BLANK, CONTINUE TO Q5_X. ELSE GO TO Q6_X.

2

Q5_X. Even though you may not know [your/[NAME]’s] exact birth year, what is your best
guess as to how old [you were/NAME was] on [your/his or her] last birthday?
ENTER AGE 16-120
Q6_X-Q7_X EXPERIMENT: HALF THE SAMPLE GETS Q6_X-Q8_X. THE OTHER HALF OF
THE SAMPLE GETS Q6A_X-Q7A_X.]
Q6_X. [Was your/To the best of your knowledge, was [NAME]’s] sex assigned as male or
female at birth?
1.
2.
8.
9.

Male
Female
I don't know the answer
I prefer not to answer

Q7_X. [Do you/To the best of your knowledge, does [NAME]] currently describe
[yourself/themselves] as male, female, or transgender?
1.
2.
3.
4.
8.
9.

Male
Female
Transgender
[Do not/Does not] identify as male, female or transgender
I don't know the answer
I prefer not to answer

IF INCONSISTENT ([Q6=1 & Q7=2] OR [Q6=2 & Q7=1]), GO TO Q8_X. (ONLY GO TO
Q8_X ONCE PER PERSON.) ELSE GO TO Q9_X.
Q8_X. Just to confirm, [you were/[NAME] was] assigned [IF Q6_X=1: male/IF Q6_X=2: female]
at birth and now [describe yourself/describes themselves] as [IF Q7_X=1: male/IF
Q7_X=2: female]. Is that correct?
1. Yes, that is correct
2. No, that is not correct
IF Q8_X=2, RETURN TO Q6_X. ELSE GO TO Q9_X.

3

Q6A_X. [Do you/To the best of your knowledge, does [NAME]] currently consider
[yourself/themselves] male or female?
1.
2.
3.
8.
9.

Male
Female
[Do not/Does not] identify as male or female
I don't know the answer
I prefer not to answer

Q7A_X. Sex is what a person is born. Gender is how a person feels. When a person’s sex and
gender do not match, they might think of themselves as transgender.
[Are you/To the best of your knowledge, is [NAME]] transgender?
1.
2.
8.
9.

Yes
No
I don't know the answer
I prefer not to answer

IF Q6A_X IN (3,8,9) GO TO Q8A_X. ELSE GO TO Q9_X.
Q8A_X. [Was your/To the best of your knowledge, was [NAME]’s] sex assigned as male or
female at birth?
1.
2.
8.
9.

Male
Female
I don't know the answer
I prefer not to answer

Q9_X. [Which/To the best of your knowledge, which] of the following best represents how [you
think of yourself/[NAME] thinks of themselves]?
1. [IF (Q6_X=1 AND Q7_X=1) OR (Q6A_X=1 AND Q7A_X=2): Gay, ELSE: Gay or
lesbian]
2. Straight, that is, not [IF (Q6_X=1 AND Q7_X=1) OR (Q6A_X=1 AND Q7A_X=2): gay,
ELSE: gay or lesbian]
3. Bisexual
4. Something else
8. I don't know the answer
9. I prefer not to answer

4

Q10_X. [Are you/Is [NAME]] now…
1.
2.
3.
4.
5.
6.

Married
Living with partner
Widowed
Divorced
Separated
Never married

Q11_X. What is the highest level of school [you have/[NAME] has] completed or the highest
degree [you have/[NAME] has] received?
1.
2.
3.
4.
5.
6.
7.
8.

Less than a high school degree, no diploma
High school graduate or the equivalent (for example: GED)
Some college but no degree
Associate degree (for example: AA, AAS, ABA)
Bachelor's degree (for example: BA, AB, BS)
Master's degree (for example: MA, MS, MEng, MEd, MSW, MBA)
Professional school degree (for example: MD, DDS, DVM, LLB, JD)
Doctorate degree (for example: PhD, EdD)

Q13_X. [Are you/Is [NAME]]...
Please select all that apply.
1.
2.
3.
4.
5.
6.
7.

White
Black or African American
Hispanic, Latino, or Spanish origin
American Indian or Alaska Native
Asian
Native Hawaiian or Other Pacific Islander
Other (please specify)

IF Q1>X, LOOP BACK TO Q4_X-Q13_X. ELSE GO TO Q14

5

EMPLOYMENT
Q14.

Now we are going to ask you some questions about work-related activities.
[IF Q1=1: Do you/IF Q1>1: Does anyone in this household] have a business or a farm?
1. Yes
2. No
ASK Q15_1-Q29_Y FOR RESPONDENT BEFORE LOOPING BACK FOR EACH
HOUSEHOLD MEMBER.

Q15_X. [The rest of our questions relate to work you [or others in your household] may have
done last week. By last week, we mean the week beginning on Sunday and ending on
Saturday.]
Last week, did [you/[NAME]] do any work for [either] pay [or profit]?
1. Yes
2. No
IF Q15_X=1, GO TO Q18_X. ELSE IF Q14=1 AND Q15_X IN (BLANK,2), GO TO
Q16_X, ELSE GO TO Q17_X.
Q16_X. Last week, did [you/[NAME]] do any unpaid work in the family business or farm?
1. Yes
2. No
IF Q16_X=(BLANK,2), GO TO Q17_X. ELSE GO TO Q18_X.
Q17_X. Last week, [in addition to the business] did [you/[NAME]] have a job, either full- or parttime?
Include any job from which [you were/[NAME] was] temporarily absent.
1. Yes
2. No
IF Q17_X=1, GO TO Q18_X. ELSE GO TO Q24_X.

6

Q18_X. Last week, did [you/[NAME]] have more than one [job/job or business], including parttime, evening or weekend work?
Include any jobs from which [you were/[NAME] was] temporarily absent.
1. Yes
2. No
IF Q18_X=1, GO TO Q19_X. ELSE GO TO Q20_X.
Q19_X. Altogether, how many [jobs/jobs or businesses] did [you/[NAME]] have last week?
1. 1 job
2. 2-3 jobs
3. 4 or more jobs
DISPLAY Q20_X AND Q20A_X ON THE SAME SCREEN.
Q20_X. [How/To the best of your knowledge, how] many hours did [you/[NAME]] work at
[your/his/her/his or her/their] [main] [job/job or business] last week?
ENTER NUMBER 0-100
Q20A_X. Is this more, less, or about the same amount of time [you/[NAME]] would work at
[your/his/her/his or her/their] [main] [job/job or business] in a typical week?
1. More
2. About the same
3. Less
IF Q19_X IN (2,3,.), GO TO Q21_X. ELSE GO TO Q22_X.
DISPLAY Q21_X AND Q21A_X ON THE SAME SCREEN.
Q21_X. [How/To the best of your knowledge, how] many hours did [you/ [NAME]] work at
[your/his/her/his or her/their] other jobs last week?
ENTER NUMBER 0-100
Q21A_X. Is this more, less, or about the same amount of time [you/[NAME]] would work at
[your/his/her/his or her/their] other jobs in a typical week?
1. More
2. About the same
3. Less

7

Q22_X. How much [do you/does [NAME]] usually earn per week at [your/his/her/his or
her/their] [main] job before any taxes or deductions?
Include any overtime pay, commissions, or tips usually received.
Report in whole numbers. Do not include “$” or “,”.
ENTER NUMBER 0-20,000
IF GIGSELECT 1=X, GO TO Q24_X EXPERIMENT. ELSE LOOP BACK TO Q14_X FOR NEXT
PERSON. IF NO MORE PEOPLE IN HOUSEHOLD, GO TO Q30.

Q24-Q29_Y are randomly assigned to one person per household. GIGSELECT references the person
about whom the questions are asked.
1

8

“GIG” QUESTIONS
[Q24 EXPERIMENT: HALF OF THE SAMPLE WILL RECEIVE Q24a AND HALF WILL
RECEIVE Q24b.]
Q24a. [Sometimes people who don’t have a job do other things to earn money. Did/Sometimes,
in addition to working at a job [or business] where there is a definite arrangement for regular
work on a continuing basis, people do other things to earn money. Outside of a job [or
business], did] [you/[NAME]] do any of the things listed below to earn money last week?
[This might include work you’ve already told us about.]
If you’re not sure where to put work [you/[NAME]] did, choose the category that seems to fit best
Choose more than one category only if you are reporting more than one type of work.
Yes (1)

No (2)

a. Provided services to other people (for example, babysitting, house sitting, dog
walking, yard care, housecleaning, tutoring, picking up dry cleaning, running errands,
assembling furniture, or providing other personal assistance)

b. Provided services to a self-employed individual or business (for

example, consulting on a project, editing, setting up or maintaining a computer system, building
maintenance or repairs)

c. Performed as an actor, musician or entertainer (for example, singing at a

wedding, entertaining at a children’s party or juggling at a street fair)

d. Drove for a ride sharing service (for example, Uber, Lyft, Sidecar, or a local
limousine company)

e. Assisted with medical, marketing or other research (for example,
participating in a medical study, responding to a survey, or being part of a focus group)

f. Posted videos, blog posts, or other content online (for example, running a
travel blog or You Tube channel that generate ad revenues or commissions)

g. Did other informal work or side job (please specify)
IF ANY Q24_A-Q24_G=1, GO TO Q24C. ELSE LOOP BACK TO Q14_X FOR NEXT
PERSON. IF NO MORE PEOPLE IN HOUSEHOLD, GO TO Q30.

9

Q24b. [Sometimes people who don’t have a job do other things to earn money. Did/Sometimes,
in addition to working at a job [or business] where there is a definite arrangement for
regular work on a continuing basis, people do other things to earn money. Outside of a
job [or business], did] [you/[NAME]] do other things to earn money last week?
[This might include work you’ve already told us about.]
1. Yes
2. No
IF Q24b=1, GO TO Q24c. ELSE LOOP BACK TO Q14_X FOR NEXT PERSON. IF NO
MORE PEOPLE IN HOUSEHOLD, GO TO Q30.
Q24c. Please describe the other work that wasn’t part of a regular job that [you/[NAME]] did last
week to earn money.
DISPLAY OPEN-ENDED TEXT BOX
Q24d. Some workers find short, in-person jobs or tasks through companies that connect them
directly with customers using a website or mobile app. These companies also coordinate
payment for the service through the app.
Other workers select short, paid tasks through companies that maintain online lists of
tasks. These tasks typically take between a few minutes and a few hours to complete
and are done entirely online.
Do either of these describe any of the other work that [you/[NAME]] did last week?
Yes (1)

No (2)

[INCLUDE ONE ROW FOR EACH ITEM REPORTED YES IN
Q24a_X OR JUST DISPLAY YES/NO IF ANSWERED Q24b]
IF Q15_X=1 OR Q16_X=1 OR Q17_X=1, GO TO Q25. ELSE GO TO Q26_Y AND ASK
Q26_Y-Q27_Y FOR ALL JOBS MARKED YES IN Q24A OR Q24B.

10

Q25. Earlier you reported [you/[NAME]] had [a/2-3/4 or more] [job[s]/job[s] or business[es]] last
week. Did you include [the following things/the other work you just reported] in that
count?
Yes (1)

No (2)

[INCLUDE ONE ROW FOR EACH ITEM REPORTED YES IN Q24a
OR JUST DISPLAY YES/NO IF ANSWERED Q24b]

GO TO Q26_Y AND ASK Q26_Y-Q27_Y FOR ALL JOBS MARKED YES IN Q24A OR Q24B.
DISPLAY Q26_Y AND Q27_Y ON THE SAME PAGE.
Q26_Y. [Please answer the following questions about the work you did [RESPONSE TO
Q24_Y].]
[How/To the best of your knowledge, how] many hours did [you/[NAME]] spend
[Q24_Y/on [your/his/her/his or her/their] work outside of a regular job] last week?
If less than one hour, report one.
ENTER HOURS 1-100
Q27_Y. Is this more, less, or about the same amount of time [you/[NAME]] would spend on this
activity in a typical week?
1. More
2. About the same
3. Less

11

HOUSEHOLD INCOME
Q30.

[Which/Now thinking about all members of your household, which] category represents
[your/your household’s] total combined income before taxes during the past 12
months?
This includes money from jobs, net income from business, farm or rent, pensions,
dividends, interest, social security payments and any other money income received.
1. Less than $5,000
2. $5,000 to $7,499
3. $7,500 to $9,999
4. $10,000 to $12,499
5. $12,500 to $14,999
6. $15,000 to $19,999
7. $20,000 to $24,999
8. $25,000 to $29,999
9. $30,000 to $34,999
10. $35,000 to $39,999
11. $40,000 to $49,999
12. $50,000 to $59,999
13. $60,000 to $74,999
14. $75,000 to $99,999
15. $100,000 to $149,999
16. $150,000 or more
17. I don't know the answer
18. I prefer not to answer

12

CONCLUSION
Thank you very much for completing our survey!
We will combine your answers with those provided by other Turkers to answer the following
research questions:
1) Are people willing and able to report information about the people they live with, including
their sexual orientation and gender identity, other personal characteristics, work arrangements
and income?
2) Do people think of work outside of a regular job as employment?
The names, nicknames or initials you have provided to identify the members of your household
will be removed from your responses before anyone looks at them. All of the survey responses
we have received will be stored on a secure computer at the University of Maryland for analysis
by our research team. If requested, researchers at the Census Bureau who are studying the
collection of information about sexual orientation and gender identity will be given access to the
survey data under similarly secure conditions. Statistical tabulations of the responses to the
questions about employment and earnings, but no individual responses, may be provided to
researchers at the Bureau of Labor Statistics.
We did not inform you at the beginning of this survey that we would be asking about sexual
orientation and gender identity. One of the key goals of our study is to learn about how people
respond to questions on this topic when they are asked in the context of a series of more
standard questions about household members’ age, race, education, and so on. Stating up
front that we would be asking about sexual orientation and gender identity could have affected
whether some people chose to attempt the survey and biased our findings.
Now that we have informed you more fully about our research goals, if you would like to have
your survey responses deleted, please send an email to [contact information] with your
Mechanical Turk ID number and we will delete the information you have supplied. This will not
affect your Mechanical Turk payment.

13

Appendix B: Characteristics of Analysis Sample, Global versus Detailed Probe, by Respondents
versus Other Household Members (percent distributions)
Other Household Members

Respondents
Global
Prompt

Detailed
Prompt

Difference

Global
Prompt

Detailed
Prompt

Difference

10.9
45.8
24.8
10.8
5.8
2.1

12.5
45.8
23.1
11.6
5.7
1.3

1.6ns
0.0ns
-1.7ns
1.0ns
-0.1ns
-0.8ns

17.6
32.9
18.2
12.9
11.6
6.7

19.8
30.4
16.8
15.3
11.2
6.5

2.1ns
-2.5ns
-1.4ns
2.3ns
-0.4ns
-0.2ns

49.3

51.7

2.4ns

46.5

47.9

1.4ns

0.2
8.9

0.5
8.6

0.4ns
-0.3ns

7.0
21.9

6.4
20.8

-0.6ns
-1.1ns

35.9

36.6

0.8ns

30.6

36.7

6.1**

55.1

54.3

-0.9ns

40.5

36.1

-4.4*

Hispanic
Non-Hispanic White
Non-Hispanic African American
Non-Hispanic other race
Non-Hispanic multiracial

7.8
72.9
7.5
8.1
3.8

6.8
74.8
6.5
7.9
4.0

-1.0ns
1.9ns
-1.0ns
-0.2ns
0.2ns

10.6
71.8
6.5
8.8
2.4

10.8
70.0
7.2
9.0
2.9

0.3ns
-1.8ns
0.8ns
0.3ns
0.5ns

Sample size

1,364

1,340

--

1,128

1,107

--

Age
18-24/16-24*
25-34
35-44
45-54
55-64
65 and over
Female**
Education

Less than high school
High school
Some college or Associate
degree
Bachelors degree or higher
Race/Ethnicity

All survey respondents were age 18 or older, but respondents were asked to report for other household
members age 16 and older. The survey sample includes N=93 other household members age 16 or 17.
*

The survey sample includes N=22 respondents and N=19 other household members reported as
transgender or not identifying as either male or female, or for whom no report on gender identity was
provided. They are included in the denominator when calculating the percent female.
**

Online Appendix Table C1: Additional Work Activity Identified by Probing, Detailed Probe Sample,
Excluding Additional Work in the Research Category

Total
CPS not employed
CPS employed, 1 job
CPS employed, 2 plus jobs

Excluding Additional Work in the
Research Category
Additional Work
Activity Identified
Additional Work
by Probing,
Activity Identified
Percent of
by Probing, Percent
Detailed Sample*
of Row Category

Sample
Size

Employment
Status Based on
CPS Questions,
Percent of
Detailed Sample

2,447

100.0

19.7

19.7

406

16.6

4.2

25.4

1,560

63.8

12.0

18.8

481

19.7

3.6

18.1

*All reported values for percent in detailed sample with additional work activity identified by probing significantly different from zero at p<
0.001.

2,447
1,340
1,107
542
565

Full Sample

Self Reports

Proxy Reports

Spouse

Other Household
Member

Sample
Size

58.4

81.6

69.7

94.7

83.4

68.1

84.5

76.2

97.1

87.6

9.7

3.0

6.4

2.4

4.2

Employment Rates
CPS
Augmented Difference
Questions by Probing

(<0.001)

(<0.001)

(<0.001)

(<0.001)

(<0.001)

(pvalue)

330

442

772

1,269

2,041

Sample
Size

6.4

12.7

10.0

31.8

23.6

18.2

21.3

20.0

48.9

37.9

11.8

8.6

10.0

17.0

14.4

Multiple Job Holding Rates
CPS
Augmented Difference
Questions by Probing

Online Appendix Table C2: Effect of Additional Work Activity Identified by Probing on Employment and Multiple Job Holding
Rates, Detailed Probe Sample, Excluding Additional Work in the Research Category

(<0.001)

(<0.001)

(<0.001)

(<0.001)

(<0.001)

(pvalue)

Online Appendix Table C3: Additional Work Activity Identified by Probing, Full Sample, Excluding
Additional Work that Totaled Less than Four Hours

Total
CPS not employed
CPS employed, 1 job
CPS employed, 2 plus jobs

Excluding Individuals Who Completed
Less Than Four Hours of Gig Work

Sample
Size

Employment
Status Based on
CPS Questions,
Percent of Full
Sample

Additional Work
Activity Identified
by Probing, Percent
of Full Sample*

Additional Work
Activity Identified
by Probing, Percent
of Row Category

4,933

100.0

13.0

13.0

814

16.6

2.5

15.1

3,142

63.6

8.9

14.0

977

19.8

1.6

8.1

*All reported values for percent in full sample with additional work activity identified by probing significantly different from zero at p< 0.001.
Note: Six cases dropped from sample due to missing hours information.

100.0
100.0
--

100.0
100.0
--

100.0
100.0
--

100.0
100.0
--

100.0
100.0
--

2,487
2,446
--

1,363
1,340
--

1,124
1,106
--

582
542
--

542
564
--

Total

43.7
41.5
-2.2
(0.452)

17.2
18.5
1.3
(0.579)

30.0
30.2
0.2
(0.911)

5.3
5.3
0.0
(0.985)

16.6
16.5
0.1
(0.916)

Employed

Note: Six cases dropped from sample due to missing hours information.

Full Sample
Global prompt
Detailed prompt
Detailed minus global
(p-value)
Self Reports
Global prompt
Detailed prompt
Detailed minus global
(p-value)
Proxy Reports
Global prompt
Detailed prompt
Detailed minus global
(p-value)
Spouse
Global prompt
Detailed prompt
Detailed minus global
(p-value)
Other Household Member
Global prompt
Detailed prompt
Detailed minus global
(p-value)

Sample
Size

51.1
54.8
3.7
(0.221)

73.4
71.2
-2.2
(0.421)

62.6
62.8
0.2
(0.920)

64.4
64.5
0.1
(0.941)

63.6
63.8
0.2
(0.903)

1 Job

5.2
3.7
-1.4
(0.246)

9.5
10.3
0.9
(0.621)

7.4
7.0
-0.4
(0.699)

30.3
30.2
-0.2
(0.932)

19.9
19.7
-0.3
(0.806)

2+ Jobs

Employment Status Based on CPS Questions
(percent of sample)
Not

2.8
11.9
19.1
(<0.001)

3.1
8.5
5.4
(<0.001)

2.9
10.2
7.3
(<0.001)

18.1
18.7
0.5
(0.720)

11.3
14.8
3.6
(<0.001)

Total

2.0
6.9
4.9
(<0.001)

1.2
2.6
1.4
(0.092)

1.6
4.8
3.2
(<0.001)

1.3
2.6
1.4
(0.010)

1.4
3.6
2.2
(<0.001)

Employed

0.7
4.4
3.7
(<0.001)

1.5
5.7
4.2
(0.002)

1.2
4.6
3.5
(<0.001)

14.8
13.0
-1.8
(0.185)

8.6
9.2
0.6
(0.464)

1 Job

N/A
N/A
N/A
N/A

0.3
1.1
0.7
(0.136)

0.2
0.8
0.6
(0.033)

2.1
3.1
0.9
(0.128)

1.2
2.0
0.8
(0.029)

2+ Jobs

Additional Work Activity Identified by Probing
(percent of sample)
CPS, Not
CPS,
CPS,

Online Appendix Table C4: Additional Work Activity Identified by Probing, Global versus Detailed Probe, Excluding Additional Work
that Totaled Less than Four Hours

83.4
0.0
(0.984)
94.7
94.7
0.1
(0.951)
69.8
69.7
0.0
(0.987)
82.7
81.6
-1.1
(0.623)
56.0
58.4
2.4
(0.411)

1,363
1,340
--1,124
1,106
--582
542
--542
564
---

83.4

2,446
---

2,487

58.0
65.3
7.3
(0.012)

83.9
84.1
0.3
(0.907)

71.4
74.5
3.2
(0.093)

95.9
97.3
1.4
(<0.001)

87.0
2.2
(0.025)

84.8

Note: Six cases dropped from sample due to missing hours information.

Detailed prompt
Detailed minus global
(p-value)
Self Reports
Global prompt
Detailed prompt
Detailed minus global
(p-value)
Proxy Reports
Global prompt
Detailed prompt
Detailed minus global
(p-value)
Spouse
Global prompt
Detailed prompt
Detailed minus global
(p-value)
Other Household Member
Global prompt
Detailed prompt
Detailed minus global
(p-value)

Full Sample
Global prompt

Sample
Size

2.0
6.9
4.9
(<0.001)

1.2
2.6
1.4
(0.091)

1.6
4.8
3.2
(<0.001)

1.3
2.6
1.4
(0.010)

3.6
2.2
(<0.001)

1.4

Employment Rates
CPS
Augmented Difference
Questions by Probing

(<0.001)
(<0.001)
---

(0.008)
(<0.001)
---

(<0.001)
(<0.001)
---

(<0.001)
(<0.001)
---

(<0.001)
---

(<0.001)

(pvalue)

305
330
---

482
442
---

787
772
---

1,291
1,269
---

2,041
---

2,078

Sample
Size

9.2
6.4
-2.8
(0.184)

11.4
12.7
1.3
(0.557)

10.6
10.0
-0.6
(0.710)

32.0
31.8
-0.2
(0.933)

23.6
0.3
(0.820)

23.9

10.5
14.9
4.4
(0.099)

13.3
19.7
6.4
(0.009)

12.2
17.6
5.4
(0.003)

47.6
47.0
0.5
(0.984)

35.9
1.8
(0.240)

34.2

1.3
8.5
7.2
(<0.001)

1.9
7.0
5.1
(0.081)

1.7
7.6
5.9
(<0.001)

15.6
15.2
0.3
(<0.001)

12.4
2.2
(<0.001)

10.3

Multiple Job Holding Rates
CPS
Augmented Difference
Questions by Probing

Online Appendix Table C5: Effect of Additional Work Activity Identified by Probing on Employment and Multiple Job Holding
Rates, Global versus Detailed Probe, Excluding Work that Totaled Less than Four Hours

(0.045)
(<0.001)
---

(0.003)
(<0.001)
---

(<0.001)
(<0.001)
---

(<0.001)
(<0.001)
---

(<0.001)
---

(<0.001)

(pvalue)

