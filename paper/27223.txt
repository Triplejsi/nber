NBER WORKING PAPER SERIES

VOLUNTARY REGULATION:
EVIDENCE FROM MEDICARE PAYMENT REFORM
Liran Einav
Amy Finkelstein
Yunan Ji
Neale Mahoney
Working Paper 27223
http://www.nber.org/papers/w27223

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
May 2020

We thank Parag Pathak, Jonathan Skinner, and participants in many seminars for helpful
comments, and Sophia Mo and Xuyang Xia for outstanding research assistance. We gratefully
acknowledge support from J-PAL North America’s Health Care Delivery Initiative (Finkelstein
and Mahoney), the National Institute of Aging grant P01AG019783-15, the Laura and John
Arnold Foundation (Einav, Finkelstein and Mahoney), the Becker Friedman Institute at the
University of Chicago (Mahoney) and the National Science Foundation SES-1730466
(Mahoney). The views expressed herein are those of the authors and do not necessarily reflect the
views of the National Bureau of Economic Research.
At least one co-author has disclosed a financial relationship of potential relevance for this
research. Further information is available online at http://www.nber.org/papers/w27223.ack
NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.
© 2020 by Liran Einav, Amy Finkelstein, Yunan Ji, and Neale Mahoney. All rights reserved.
Short sections of text, not to exceed two paragraphs, may be quoted without explicit permission
provided that full credit, including © notice, is given to the source.

Voluntary Regulation: Evidence from Medicare Payment Reform
Liran Einav, Amy Finkelstein, Yunan Ji, and Neale Mahoney
NBER Working Paper No. 27223
May 2020
JEL No. H51,I13,I18
ABSTRACT
Government programs are often offered on an optional basis to market participants. We explore
the economics of such voluntary regulation in the context of a Medicare payment reform, in
which one medical provider receives a single, predetermined payment for a sequence of related
healthcare services, instead of separate service-specific payments. This ``bundled payment''
program was originally implemented as a 5-year randomized trial, with mandatory participation
by hospitals assigned to the new payment model, but after two years participation was
unexpectedly made voluntary for half of these hospitals. Using detailed claim-level data, we
document that voluntary participation is more likely for hospitals who can increase revenue
without changing behavior (“selection on levels”) and for hospitals that had large changes in
behavior when participation was mandatory (“selection on slopes”). To assess outcomes under
counterfactual regimes, we estimate a simple model of responsiveness to and selection into the
program. We find that the current voluntary regime generates inefficient transfers to hospitals and
reduces social welfare compared to the status quo, but that alternative (feasible) designs could
substantially reduce these inefficient transfers. Our analysis highlights key design elements to
consider under voluntary regulation.
Liran Einav
Stanford University
Department of Economics
579 Serra Mall
Stanford, CA 94305-6072
and NBER
leinav@stanford.edu
Amy Finkelstein
Department of Economics, E52-442
MIT
50 Memorial Drive
Cambridge, MA 02142
and NBER
afink@mit.edu

Yunan Ji
Harvard University
ji@g.harvard.edu
Neale Mahoney
Booth School of Business
University of Chicago
5807 South Woodlawn Avenue
Chicago, IL 60637
and NBER
Neale.Mahoney@chicagobooth.edu

1

Introduction

Government intervention is designed to move market actors away from market equilibrium. Yet
some government programs allow these actors to voluntarily decide whether they would like to
participate in the program. There are a number of reasons why voluntary programs are popular. From a political perspective, voluntary programs may face less opposition from industry or
consumer lobbies, since their members need only sign up if they benefit. Voluntary programs
may also be more palatable to those with an ideological aversion to government mandates and a
preference for regulatory “nudges” (Thaler and Sunstein, 2003).
The key economic benefit of voluntary programs – i.e., “choose your own incentives” – is that
they might generate favorable selection. If actors have private information about their net benefits
from changing behavior, then the resulting “selection on slopes” – also known as selection on gains
or Roy selection (Heckman and Honore, 1990) – might result in selection into the program by those
with the highest net social benefits. However, if voluntary programs attract participants who,
without changing their behavior, can simply receive a higher government transfer, the resulting
“selection on levels” could lead to higher government spending without the desired behavior
change. Thus, the extent to which a voluntary program is more or less socially desirable depends
critically on the nature and extent of selection into the program.
We explore these tradeoffs in the context of the U.S. Medicare program, the public health
insurance program for the elderly and the disabled. Over the last decade, Medicare has rapidly
expanded the use of alternative models for reimbursing healthcare providers, such as Accountable
Care Organizations, bundled payments, and primary care coordination models. By 2016, over
30% of Traditional Medicare spending was based on alternative payments models (Shatto, 2016).
With the partial exception of the payment model we study, provider participation in all of these
payment models has been voluntary (GAO, 2018). However, there is an ongoing and active debate
over whether these programs should be made mandatory (e.g., Gronniger et al., 2017; King, 2019;
Frakt, 2019b; Levy, Bagley and Rajkumar, 2018; Liao, Pauly and Navathe, 2020).
We analyze the Medicare bundled payments program for hip and knee replacement, known
as Comprehensive Care for Joint Replacement (CJR). Hip and knee replacement is a large category, with almost half a million procedures and $10.7 billion in Medicare spending in 2014. Under

1

bundled payments, Medicare makes a single payment (known as the target price) to the hospital
for all services related to the episode of care, including the initial hospital stay and physician fees,
as well as any subsequent care by other medical providers during the recovery period. By contrast, under the status quo Fee-for-Service (FFS) system, Medicare makes separate payments to
different providers based on the care provided. The idea behind the bundled payments reform is
that by making the hospital the residual claimant on the costs related to the entire episode of care,
it will internalize the incentives to provide care efficiently, including coordination with downstream providers. In practice, this was implemented by providing financial bonuses or penalties
– known as “reconciliation payments” – to hospitals when the submitted Medicare FFS claims for
the episode deviated from the target price.
CJR was initially designed by Medicare administrators as a mandatory participation, 5-year
randomized trial. Randomization was conducted at the Metropolitan Statistical Area (MSA) level.
In the 67 treatment MSAs, hospitals were paid under the bundled payments program. In the
104 control MSAs, hospitals were paid under the status quo FFS system. The program was implemented as designed in April 2016. However, toward the end of the second year of the program, Medicare unexpectedly announced that participation would be made voluntary in half the
treated MSAs (CMS, 2017), and about three-quarters of the affected hospitals subsequently opted
out. This unusual set of circumstances provides a rare opportunity to assess a voluntary program
while observing behavior under the program even for participants who eventually choose not to
participate.
We begin by providing descriptive evidence on the mandatory and voluntary regimes. In
the mandatory regime, we closely follow prior analyses and find that bundled payments caused,
on average, a modest reduction in submitted Medicare claims, driven predominantly by reduced
discharges to post-acute care (PAC) facilities (Finkelstein et al., 2018; Dummit et al., 2018; Barnett
et al., 2019; Haas et al., 2019). Once reconciliation payments were taken into account, however, the
mandatory bundled payment regime had no effective impact on government expenditures. We
then examine the nature of selection into the program once it became voluntary. Consistent with
selection on levels, we find that hospitals with lower claims under FFS – who, holding behavior
constant, would benefit more from bundled payments – are more likely to opt in. Consistent with
selection on slopes, we also find that hospitals that achieved larger reductions in claims under
2

mandatory bundled payments are more likely to opt in when it becomes voluntary.
Motivated by these patterns, we specify and estimate a stylized model of responsiveness to
and selection into the bundled payment program. In the model, hospitals are characterized by a
hospital-specific “level” (average claims per episode under FFS incentives) and a hospital-specific
“slope” (the reduction in claims under bundled payments). Under a voluntary regime, the selection decision depends on the hospital-specific “target price” – the bundled payment the hospital
receives from the government under the program – as well as on the hospital’s level and slope
parameters. The random assignment in years 1-2 of the program, when participation was mandatory, identifies the levels and slopes, and the voluntary decision in year 3 identifies the selection
equation.
We estimate that average episode claims under the status quo FFS incentives would be about
$24,000 and that bundled payments reduced claims, on average, by about $400 per episode. These
averages, however, mask substantial heterogeneity across hospitals in both levels and slopes. Heterogeneity is particularly large in levels, where the standard deviation across hospitals in claims
under FFS incentives is about $4,000. Observed target prices do not come close to capturing this
heterogeneity, thus making selection on levels the key driver of the participation decision, once
participation becomes voluntary.
We use the estimated model to compare outcomes and social welfare under the observed
voluntary and mandatory programs, as well as to assess behavior and social welfare under alternative bundled payments designs. We define social welfare as the sum of consumer surplus and
producer (hospital) profits, minus the social cost of public spending. We assume that consumer
surplus is not affected by the payment regime; this is consistent with evidence from the randomized trial that healthcare quality, patient mix, and patient volume did not change with bundled
payments (Finkelstein et al., 2018; Dummit et al., 2018; Barnett et al., 2019; Haas et al., 2019). We
define the social cost of public spending as government (i.e., Medicare) spending multiplied by
the shadow cost of public funds, which we assume (conservatively) to be 0.15. This “cost of public funds” generates the key tradeoff in designing a voluntary bundled payment model: higher
target prices will induce more hospitals to participate and increase productive efficiency, but will
involve higher government spending, which is socially costly. Producer surplus and government
spending can be calculated directly from the data and estimated model parameters.
3

The model estimates, like the reduced form descriptive work, indicate substantial selection on
levels: hospitals that opt into the voluntary bundled payment regime would have had (counterfactual) average claims per episode under the FFS status quo that were substantially lower than
hospitals which do not opt in. Moreover, the magnitude of the favorable selection (on “slopes”) is
too small to offset it. As a result, we estimate that the voluntary bundled payments regime lowers
social surplus relative to the FFS status quo, due to inefficient transfers from the government to
hospitals.
We also show that better targeting could improve the net social welfare impact of the voluntary regime, by reducing the transfers and aligning better participation incentives. For example,
we estimate that a perfectly targeted voluntary bundled payments regime would raise social surplus relative to the status quo. While perfect targeting may be difficult to achieve in practice, we
show that compared to the observed targeting, other feasible designs – based on better exploiting
existing information or defining the bundle more narrowly – can come close to generating the
social gains from perfect targeting, generating up to three-fifths of the social welfare gains from
perfect targeting.
Our paper relates to several distinct literatures. Most narrowly, it contributes to the literature
on the impact of Medicare bundled payment programs. This includes several recent evaluations
of the first two years of the program we study, when participation was randomly assigned and
mandatory (Finkelstein et al., 2018; Dummit et al., 2018; Barnett et al., 2019; Haas et al., 2019). It
also includes evaluations of the much larger number of voluntary participation bundled payment
programs for a host of conditions, including coronary bypass, prenatal care, cancer, and hip and
knee replacement.1 It is well understood that non-random selection into voluntary models can
bias the evaluation of these program (e.g., Gronniger et al., 2017; Levy, Bagley and Rajkumar,
2018). Our focus here is on how voluntary participation affects the actual impact of the program,
rather than the estimated impact.
Within health economics more generally, our work contributes to the growing literature on
the impact and optimal design of financial incentives for healthcare providers (e.g., Cutler, 1995;
Clemens and Gottlieb, 2014; Ho and Pakes, 2014; Einav, Finkelstein and Mahoney, 2018; Eliason
1 See Cromwell, Dayhoff and Thoumaian (1997), Carroll et al. (2018), Newcomer et al. (2014), Doran and Zabinski
(2015), Dummit et al. (2016), Froemke et al. (2015), Navathe et al. (2017).

4

et al., 2018). It also relates to work on so-called “selection on moral hazard” – i.e., consumer
selection of health insurance plans based not only on levels but on slopes (Einav et al., 2013, 2016;
Shepard, 2016; Marone and Sabety, 2019); here, we examine selection on moral hazard from the
provider side rather than the consumer side.
More broadly, our emphasis of the potential for selection not only on levels but also on slopes
relates to work in labor economics on selection on gains (Heckman and Honore, 1990), as well
as to work on selection into voluntary regulation in other sectors. For example, recent work has
analyzed selection by landowners into voluntary incentive programs for providing environmental services (Jack and Jayachandran, 2019), by polluting firms into whether to pay taxes based on
their disclosed and verifiable emissions or the average emission rate among non-disclosers (Cicala, Hémous and Olsen, 2020), by private schools into whether or not to accept public vouchers
(DeAngelis, Burke and Wolf, 2019), and by residential electricity consumers into whether to face a
constant or time-varying regulated electricity price schedule (Ida, Ito and Tanaka, 2020).
The rest of the paper proceeds as follows. Section 2 provides background on our setting.
Section 3 describes the data and presents reduced form, descriptive evidence of the impact of
bundled payments under mandatory participation as well as the nature of hospital selection once
the program became voluntary. Section 4 presents a stylized model of selection into a voluntary
bundled payment program. Section 5 presents the econometric specification of the model and
describes its identification and estimation. Section 6 presents our main results. The last section
concludes.

2
2.1

Setting
Medicare Bundled Payment Programs

Medicare is the public health insurance program for the elderly and the disabled in the United
States. We focus on the Traditional Medicare program, which provides coverage to about twothirds of enrollees. In 2017, Traditional Medicare (hereafter "Medicare") had 38.7 million enrollees
and annual expenditures of $377 billion (CMS, 2019).
Throughout most of its history, Medicare has paid providers on a cost-plus basis referred to as
Fee-for-Service (FFS), in which providers are reimbursed based on claims submitted for services.

5

For instance, for a patient undergoing hip replacement, Medicare might make separate payments
to the hospital for the initial hospital stay, the surgeon for performing the procedure, and the
skilled nursing facility for post-acute care, as well as additional payments for each post-operative
visit by the surgeon, or for renting a wheelchair during the recovery period. Moreover, within
most of these categories, the payment would depend on the specific services provided.2
Over the last decade, Medicare has responded to concerns that the FFS system may encourage excessive healthcare use by attempting to shift providers towards alternative payment models,
such as Accountable Care Organizations (ACOs), bundled payments, and primary care coordination models. By 2016, over 30% of Traditional Medicare spending was based on these alternative
models (Shatto, 2016).
Our focus is on bundled payments, which represent a middle ground between FFS and fully
capitated models, such as ACOs, in which providers are paid a fixed per capita amount per
annum. Under bundled payments, Medicare makes a predetermined, single payment to one
provider for all services related to a clearly-defined episode of care. Episodes typically start with
an acute-care hospital stay (e.g., for hip replacement surgery) and include most subsequent care
during the recovery period. The payments are sometimes adjusted to reflect predictable variation
in patient health or in costs in the local medical market. The contracts may also be structured to
limit risk exposure for the hospital.
Proponents of bundled payments argue that by providing a single, fixed reimbursement, bundled payments will improve coordination of care and reduce unnecessary healthcare utilization.
Yet, some are concerned that because providers do not receive marginal payments, they may cut
back on necessary care or cherry-pick patients who have a lower cost of provision (Cutler and
Ghosh, 2012; Fisher, 2016).
Most prior studies of bundled payments have been observational, focusing on the experience of a small number of hospitals that voluntarily participated. Many of these studies have
found large government savings associated with bundled payments (e.g., Cromwell, Dayhoff and
Thoumaian, 1997; Carroll et al., 2018; Newcomer et al., 2014; Doran and Zabinski, 2015; Dummit et al., 2016; Froemke et al., 2015; Navathe et al., 2017). However, voluntary participation
2 One exception to this system is hospital reimbursements. Starting in 1982, Medicare adopted the Prospective Payment System (PPS) in which it makes a fixed payment for the hospital stay based on the patient’s diagnosis-related
group (DRG) (Cutler, 1995).

6

makes separating treatment from selection difficult, and the small number of participating hospitals raises concerns about generalizability (e.g., Gronniger et al., 2017; King, 2019).

2.2

Comprehensive Care for Joint Replacement (CJR)

We focus on the Medicare bundled payment program for hip and knee replacement, known as
Comprehensive Care for Joint Replacement (CJR). Hip and knee replacement (also referred in the
medical literature as lower extremity joint replacement, or LEJR) is a large Medicare category; in
2014, the year before CJR was announced, Medicare had almost half a million LEJR procedures,
accounting for about 5% of Medicare admissions and inpatient spending (Finkelstein et al., 2018).
Under CJR, an episode begins with a hospital stay in a qualifying diagnosis-related group
(DRG) and ends 90 days after hospital discharge. Medicare pays the hospital a predetermined
target price for the episode. The hospital is then financially responsible for medical claims over
the entire episode (except for care that is deemed as obviously unrelated). By contrast, under
the status quo FFS regime, Medicare pays the hospital a fixed amount for the hospital stay, and
reimburses the surgical procedure and post-discharge care separately based on those providers’
submitted claims.
The level and targeting of the target price are key design elements in a bundled payment program. Let th denote the average per episode target price at hospital h in a given year, and let yh
denote average per-episode claims submitted that year. Under FFS, Medicare pays yh on average.
Under bundled payments, Medicare pays th on average. More specifically, under bundled payments, providers continue to submit claims and receive reimbursement of yh on average as if they
were under FFS, allowing us to observe yh even under bundled payments. At the end of the year,
hospitals under bundled payments receive a “reconciliation payment” of th − yh per episode, so
that the gross Medicare payment is th .
Under CJR, Medicare tried to set the target price before each program year to be slightly lower
than expected per-episode claims under FFS.3 To do so, the target price included a small discount
off a weighted average of historical hospital and regional (defined by the 9 census divisions) perepisode claims from three prior reference years, with the weight on the regional component increased over time from one-third in the first two years of the program to 100% in the last two
3 In

particular, Medicare set hospital-specific target prices for four severity groups determined by the 2-by-2 interaction of the patient’s DRG (469 or 470) and whether the patient had a hip fracture.

7

years.4 The ‘’discount factor” was designed to reflect Medicare’s portion of expected savings
from CJR.5
We abstract in our analyses from two other features of CJR. First, to mitigate concerns that
bundled payments would create incentives to shirk on quality, hospitals were only eligible for
positive reconciliation payments if they met a minimum quality standard.6 However, in practice
the quality standard was not binding for the vast majority of the hospitals.7 In addition, prior
research has not detected effects on either incentivized or non-incentivized measures of quality
(Finkelstein et al., 2018).
Second, like most bundled payment programs, CJR is not a “pure" bundled payment model
that exposes hospitals and Medicare to unbounded risk. Rather, to limit risk exposure by both
hospitals and Medicare, the reconciliation payment was subject to stop-loss and stop-gain provisions. In particular, if th − yh was less than (the negative of) the stop-loss amount, the hospital
“only” has to pay Medicare the stop-loss amount. Similarly, if th − yh is greater than the stopgain amount, Medicare “only” has to pay the hospital the stop-gain amount. The stop-loss and
stop-gain amounts increased over time.8 These provisions complicate the model and its estimation presented later, but do not affect the qualitative economic analysis and do not seem to be
quantitatively important (see Appendix C and Appendix Table A3), so we abstract from them
throughout the main text.
4 The three reference years of historical claims are updated every other year. In 2016 and 2017 (the first two years
of the program) historical claims from 2012 to 2014 were used, in 2018 and 2019 (the third and fourth program years),
historical claims from 2014-2016 were used, and the final year of the program uses claims from 2016-2018 (CMS, 2015b).
5 The discount factor ranged from 1.5% to 3% depending on hospital quality (based on a composite quality score
defined below), with smaller discounts for higher quality hospitals (CMS, 2015b). This “discount factor” was intended
to ensure that if claims remained at past levels, Medicare expenditures would decrease under mandatory participation.
In practice, however, there was a steady secular decline in per-episode claims, which offset the built-in “discount.”
6 The quality standard is based on a composite quality score, which ranges from 0 to 20 points, and hospitals must
score at least 5 points to be eligible for bonus payments. Up to 10 points are given based on a hospital’s quality performance percentile on a complication measure for total hip arthroplasty and total knee arthroplasty; up to 8 points are
given based on a standardized national patient experience survey; up to 2 points are given for submitting the patientreported outcomes and risk variable data. Finally, up to 1.8 points can be added to the final score for improvement in
either of the first two measures relative to the previous performance year, as long as the final score does not exceed 20.
See https://innovation.cms.gov/Files/x/cjr-qualsup.pdf for details
7 For example, based on our calculation from the CJR reconciliation data, in the first year of the program fewer than
9% of treatment hospitals failed to meet the minimum quality standard for receiving a bonus.
8 In the first year, the stop-gain amount was set as 5% of t and the stop-loss was zero (meaning that hospitals would
h
never need to make payments to Medicare). By years 4 and 5, the stop-gain and stop-loss amounts were each scheduled
to be set at 20% of th .

8

2.3

Experimental Design

CJR was initially designed by CMS as a 5-year, mandatory participation, randomized trial. Year 1
was defined as April 1 to December 31 of 2016, and years 2-5 were defined as the 2017-2020 calendar years. CMS randomized 196 eligible MSAs into treatment (bundled payments) or control
(status quo FFS). Specifically, MSAs were divided into 8 strata based on the interaction of historical LEJR spending quartile and above- versus below-median MSA population. MSA treatment
probabilities varied by strata (ranging from 30% to 45%), with higher treatment probabilities for
strata with higher historical LEJR payments. CMS announced assignment to treatment and control in the July 2015 Federal Register (CMS, 2015b). Treatment and control MSAs are balanced on
outcome variables and MSA characteristics (Finkelstein et al., 2018). After exclusions, the program
covered 67 treatment MSAs and 104 control MSAs.9 Within the 171 MSAs assigned to treatment or
control, a small number of hospital types and episode types were further excluded from eligibility
(see Section 3 for more details).
Participation was mandatory in treatment MSAs: eligible hospitals had no choice but to be
reimbursed under the new bundled payment model. This mandatory participation feature was
immediately controversial, with then-US representative Tom Price spearheading a letter in 2016,
signed by 179 members of Congress, complaining that mandatory participation was unethical
and unauthorized.10 Subsequently, as the new Secretary of Health and Human Services – the
federal agency charged with overseeing Medicare – Price lead the effort to roll back mandatory
participation bundled payment models. As a result, in a rule finalized in December 2017, Medicare
unexpectedly decided to cancel two previously scheduled mandatory bundled payment models
(Advancing Care Coordination Through Episode Payment and Cardiac Rehabilitation Incentive
Payment Models) and modified CJR to be voluntary in half of the treated MSAs for the remaining
three program years (CMS, 2017).
Specifically, hospital participation in CJR was made voluntary in 33 of the 67 treatment MSAs
9 After

the initial assignment, Medicare realized that they did not exclude some hospitals that were already (prior
to assignment) signed up for BPCI (a different Medicare program), and subsequently excluded an additional 8 MSAs
from the treatment group. Medicare later identified the 17 MSAs in the control group that would have been excluded
based on these criteria. Since these exclusions were based on hospital decisions made prior to assignment we simply
drop these 25 MSAs from the study.
10 See https://thehill.com/policy/healthcare/298769-lawmakers-call-for-end-to-medicareexperiments.

9

with the lowest historical episode claims under FFS.11 In these “voluntary treatment” MSAs, hospitals had to make a one-time decision at the beginning of program-year 3 of whether to opt in,
and continue to be paid under bundled payments for the remaining 3 program years. If they
did not opt in, reimbursement would revert to FFS for the remaining 3 years. Slightly more than
one-quarter of the hospitals in the voluntary bundled payment MSAs (73 out of 279) chose to remain under bundled payments. In the 34 mandatory bundled payment MSAs, hospitals did not
face a choice and continued to be paid under bundled payments. Control group hospitals were
unaffected by this change, and continued to be paid under FFS.
In the analysis that follows, we define three time periods. Period 1 is the period prior to
bundled payments, when all providers were reimbursed under FFS. Period 2 covers the approximately two years when the mandatory participation regime was in effect and expected to remain
so. Period 3 is defined as the final 3 years of the program, when the program was voluntary for
some hospitals.
Figure 1 shows a flow chart of the experimental design. The top part of the figure shows the
initial assignment to treatment and control for period 2, when the program was mandatory, and
the bottom part shows period 3, where treatment MSAs were further divided into mandatory and
voluntary treatment groups. Because this division was based on predetermined historical MSA
spending, we can analogously divide the control MSAs into mandatory and voluntary control
MSAs based on this variable. For some of the subsequent analysis, we will compare mandatory
treatment to mandatory control, and voluntary treatment to voluntary control.

3

Data and Descriptive Evidence

In this section, we describe the data and sample, and reproduce prior findings of the average
impacts of bundled payments during the mandatory participation period. We then present evidence on selection on levels and slopes during the voluntary period. These patterns motivate our
subsequent modeling decisions.
11 Specifically,

this determination was made using spending over July 1, 2011 through June 30, 2014, which was the
same period used to determine MSA eligibility in CJR, and occurred entirely before random assignment was announced
(CMS, 2017).

10

3.1

Data and Sample

Our main data are the 100% Medicare enrollment and claims files. These contain basic demographic information (age, race, sex, and Medicaid enrollment) and claims for inpatient, outpatient, and post-acute care.12 The claims data include information on Medicare payments made to
providers and out-of-pocket payments owed, dates of admission and discharge, diagnoses, and
discharge destinations.
We supplement these data with several additional data sources. First, we obtained data from
the CJR website on the eligibility and treatment status of each hospital in each year, the hospital’s
annual target price (for 2016 and 2017), annual reconciliation payment (for 2016 and 2017), and
whether the hospital opted into bundled payments when it became voluntary in 2018.13 Second,
we use data from the 2016 American Hospital Association (AHA) annual survey on the number
of beds, ownership type (for-profit, non-profit, or government-owned), and the teaching status of
the hospital. Third, we obtained data from Hospital Compare on each hospital’s official quality
measures (for 2016 and 2017).
We limit our analysis sample to the 171 eligible MSAs and, within these MSAs, to hospitals
and episodes that were eligible for CJR. MSAs were excluded primarily due to a low volume of hip
and knee replacements. Within both treatment and control MSAs, hospitals were excluded from
CJR if they were already participating in a pre-existing Medicare voluntary bundled payment
model for LEJR.14 Episodes were excluded if the patient did not have Medicare as the primary
payer, was readmitted during the episode for LEJR, or died during the episode.15,16
We define period 2 (the period of mandatory participation bundled payments) to include all
episodes with an index admission between April 1, 2016 and September 15, 2017. The start date
corresponds to the program start date, and the end date was chosen so that nearly all 90-day
12 Specifically, we use the following claims files: Inpatient, Outpatient, Carrier, Skilled Nursing Facility, Home Health
Agency, Durable Medical Equipment, and Hospice.
13 Source: https://innovation.cms.gov/initiatives/CJR. Target prices and reconciliation payments for
2018 were not available at the time of writing.
14 Model 1 or Phase 2 (Models 2 or 4) of the Bundled Payments for Care Improvement Initiative (BPCI).
15 In Table 1, we conduct analysis that expands the sample to include readmitted patients and show there is no effect
on readmissions.
16 Finkelstein et al. (2018) provides more detail on these eligibility criteria. They estimate that the eligible MSAs
represented about 70 % of all Medicare LEJR patients, and that within eligible MSAs, about 70 % of LEJR patients
were eligible for CJR. About 20 % of LEJR patients within eligible MSAs were excluded because their hospital was not
eligible, and another approximately 10 % due to patient eligibility.

11

episodes would finish by December 31, 2017, the close of the second year.17 The end date also
ensures that all admissions (and most discharges) occurred prior to the December 2017 announcement that participation would become voluntary for some MSAs starting on January 1, 2018 (CMS,
2017). Following prior work (Finkelstein et al., 2018), we define period 1 (the period when all hospitals are under FFS) to include all episodes admitted between April 1, 2013 and September 15,
2014, and omit 2015 from the analysis to avoid contamination from potential anticipatory effects;
treatment and control MSAs were announced in July 2015 (CMS, 2015a).
To construct our baseline sample, we start with the universe of 1,570 hospitals in the 171
treatment and control MSAs that had a CJR episode during period 2; these hospitals had a total of
395,938 CJR episodes during period 2. So that we can observe outcomes in the years prior to the
intervention, we restrict the sample to the 1,455 hospitals that have at least one episode in both
years of period 1. These 1,455 hospitals constitute our baseline sample, out of which 664 hospitals
are located in a treatment MSA and 791 hospitals are in a control MSA. A total of 379,843 CJR
episodes in period 2 fall into these 1,455 hospitals.

3.2

Average Treatment Effects

Average effects of CJR in the two-year mandatory participation period (period 2) have been wellstudied (Finkelstein et al., 2018; Dummit et al., 2018; Barnett et al., 2019; Haas et al., 2019); we
reproduce some key results here. Since the program was mandatory and assignment was random
at the MSA level, we follow Finkelstein et al. (2018) and estimate:

outcome j2 = β 0 + β 1 BPj + β 2 outcome j,2014 + β 3 outcome j,2013 + δs( j) + ǫ j

(1)

where outcome j2 is the average per-episode outcome in MSA j and period 2, BPj is an indicator for
being randomly assigned to bundled payments, and β 1 is the average treatment effect of bundled
payments. We include lagged outcomes from 2013 and 2014 (i.e., period 1) as controls to improve
statistical power. Because the probability of random assignment to treatment varied across strata,
we include strata fixed effects, δs( j) , to isolate the experimental variation. In all tables, we report
heteroskedasticity robust standard errors.
17 Recall that the episode of care ends 90 days after hospital discharge.

The mean length of stay for an LEJR admission
is 3.1 days for DRG 470 and 7 days for DRG 469, so truncating the sample on September 15, 2017 guarantees that
virtually all claims associated with the episode would be included in the 2017 claim files (CMS, 2016).

12

Table 1 shows the average treatment effects. To provide a baseline, the first two columns
show the mean and the standard deviation of the outcome from the control group in period 2. The
remaining columns show the average treatment effect, standard error, and p-value of the estimate.
Healthcare Claims, Use and Government Spending. Panel A of Table 1 examines effects on
healthcare claims, healthcare use, and government spending per episode. “Claims” consist of
Medicare claims paid and patient cost sharing owed over the entire episode of care, but do not
account for any reconciliation payment associated with a bundled payment; they thus correspond
to yh in the notation from Section 2.2, and are measured as average per episode claims. Average
per-episode claims in the control group were about $25,300, with roughly half of this spending
on the index admission, which is already reimbursed with a DRG-based, prospective payment
under the status quo. Of the remaining $11,800, about $4,100 comes from post-discharge claims for
institutional Post Acute Care (PAC) – predominantly skilled nursing facilities – $1,800 represents
post-discharge claims for Home Health Care, and the remaining $5,800 includes categories such as
claims for the surgeon and other physicians (both inpatient and outpatient), hospice, and durable
medical equipment, such as wheelchair rental.
We estimate that bundled payments reduced average episode claims by about $800, or about
3 %, a statistically significant but economically modest result. This reduction is primarily driven
by a statistically significant $500 decline in claims for institutional PAC (12 % of the control mean),
with no statistically or economically significant effects on other categories of claims. The impacts
on claims are reflected in the impacts on utilization. Bundled payments did not impact average
length of stay for the index admission, but decreased the unconditional average number of days
spent in institutional PAC by about 0.6 days (8 % of the control mean).
The decline in use of institutional PAC in turn reflects at least in part an extensive margin response in where patients are discharged to following their index admission. In the control group,
patients are discharged to institutional PACs, home with home health care, and home without
home health care in equal proportion. Bundled payments reduced discharges to institutional PAC
by a statistically significant 3.4 percentage points (11 %). The decline in discharges to institutional
PAC is accompanied by a similarly sized increase in discharges to home without home health.18
18 This

can be either because the patients who would have been sent to institutional PAC are being sent home without

13

These experimental estimates are consistent with qualitative evidence on how hospitals respond
to CJR. In a survey of hospital executives and administers, Zhu et al. (2018) find that hospitals report responding by reducing SNF discharges using risk-stratification and home care support, and
by forming networks of preferred SNFs to influence quality and costs, conditional on discharge.
Although bundled payments reduced episode claims as they would be paid under FFS, actual
government spending (claims, yh , under FFS and the target price, th , under bundled payments)
does not change. The point estimate indicates a statistically insignificant increase in average government spending per episode of $33 (standard error of $208). The lack of a reduction in government spending – despite modest reductions in submitted claims – reflects the design feature
of bundled payments, according to which target prices were set to approximate counterfactual
claims under FFS.
(Lack of) Quality Shirking and Cream Skimming. The primary concern with bundled payments is that because providers are no longer paid on the margin, they will cut back on medically
necessary care, cherry-pick patients who have lower costs of provision, or both. The quality incentives provided by the program, as well as physician ethics, reputational concerns, and the threat
of malpractice lawsuits may limit any quality response. Indeed, to the extent that low quality care
increases downstream costs, hospitals may have incentives to improve quality.
Consistent with prior work on CJR, the bottom two panels of Table 1 show no evidence of
an impact of CJR on quality of care or patient composition. Panel B examines three measures of
quality: a clinically-defined complication rate, whether the patient had an emergency room visit
during the episode, and 90-day all-cause readmission. We estimate a fairly precise zero effect on
all of these measures. Panel C examines patient volume and composition. We estimate a precise zero effect on the number of LEJR admissions per 1,000 Medicare enrollees and the number
of CJR-eligible admissions.19 We examine patient composition by estimating effects on the Elixhauser Comorbidity Index of the patient pool, which is constructed as the sum of indicators for 31
home health, or because there is a cascading effect where the patients who would have been sent to institutional PAC
are being sent home with home health, and patients who would have been sent home with home health are now being
sent home without home health supports. A cascading effect seems more likely (to us), but we cannot differentiate
between these two mechanisms.
19 Specifically, while our analysis of LEJR admissions includes non-CJR eligible admissions in the sample of 171 eligibles MSAs, our analysis of CJR-eligible admissions excludes hospitals and episodes in these MSAs that are not eligible
for CJR.

14

comorbidities (Elixhauser et al., 1998; Quan et al., 2005). We estimate a precise zero effect on this
measure as well.
The lack of a patient volume response is consistent with LEJR as a non-discretionary procedure, or at least a procedure where the change in financial incentives from bundled payments is
small relative to other determining factors. The lack of cream skimming may also reflect the fact
that assignment to bundled payments in period 2 is determined at the MSA level, so that the closest substitutes for a given hospital are likely to be paid under the same regime. Cream skimming
responses could potentially be different in period 3 once participation is voluntary, as there may
now be hospitals paid under bundled payments and under FFS in the same MSA. Indeed, in a different voluntary payment model, Alexander (2017) documents that physicians strategically direct
patients across hospitals within a local area to maximize revenue.
Since our paper focuses on selection – which is a hospital-level choice – all of our remaining
analyses are conducted at the hospital level, with hospitals weighted by the number of episodes
in period 2 so that the results are representative for the average episode. Appendix Table A1 shows
that the main results from Table 1 are largely similar when estimated at the MSA level weighted
by the number of episodes, or at the hospital level weighted by the number of episodes, although
some of the point estimates shrink in magnitude. In addition, one of our three quality measures
(the complication rate) shows a statistically significant increase of 0.2 percentage points (off a base
of 1.1 %) in one of the three specifications in Appendix Table A1.
In interpreting this evidence, it is important to point out that the quality measures are limited.
We cannot, for example, measure outcomes such as morbidity, mobility, or activities of daily living
consistently across locations. We therefore cannot definitively rule out any impact of bundled
payments on quality of care. However, given the lack of compelling evidence of a quality response
on the margins we can observe, in our subsequent model and counterfactual exercises we will
assume that quality remains fixed and that patients’ utility is unaffected by the hospital’s response
to incentives.

3.3

Selection on Levels and Slopes

As we formalize in the next section, hospitals have incentives to select into CJR on both levels
and slopes. By selection on levels, we mean that hospitals have a larger incentive to select in if

15

their average claims, holding behavior fixed at what it would be under FFS, would be below their
target price. By selection on slopes, we mean that hospitals have a larger incentive to select in if
they can more easily reduce their average claims below the target price. We present descriptive
evidence on both margins, examining how the decision among voluntary treatment hospitals to
select in or out of bundled payments in period 3 correlates with episode claim levels in period 1
and behavioral responses to bundled payments in period 2. Table 2 presents the results.
Selection on Levels. In principle, we would want to examine selection on slopes by estimating
the correlation between the selection decision and period 3 spending in the absence of the incentives from bundled payments. Because treated hospitals change behavior in response to bundled
payments (see Table 1), we do not observe unaffected spending levels. The model developed in the
following sections will allow us to formally recover these counterfactual spending levels. To provide model free evidence, for now we simply look at how selection correlates with the hospital’s
average episode claims in period 1, when all hospitals were paid under FFS. Since spending levels
are strongly auto-correlated within hospitals over time, we expect hospitals with lower average
episode claims in period 1 to be more likely to select in (on levels) in period 3.20
Panel A of Table 2 shows how the selection decision varies with period 1 levels. Specifically,
we show mean outcomes and their standard deviation for three groups of hospitals. Column
1 shows hospitals in the voluntary control group, which we define as control group hospitals
that would have been assigned to voluntary based on their prior spending levels (see Figure 1).
Columns 2 and 3 show period 1 outcomes for hospitals in the voluntary treatment group, split by
those who in period 3 selected into bundled payments (column 2) or out of bundled payments
(column 3). The first three rows report results for the three outcomes where we observed a statistically significant impact of bundled payments in Table 1: episode claims, claims for institutional
PAC, and share of patients discharged to institutional PAC.
The results are consistent with selection on levels. Column 1 shows substantial heterogeneity
across hospitals in the voluntary control group, indicating potential scope for selection. For example, average episode claims are $26,523, with a standard deviation of $5,368. Columns 2 and
3 show that, as expected, hospitals who select into bundled payments have, on average, about
20 Specifically,

for control group hospitals, the correlation coefficient between period 1 and period 2 is 0.77 for total
episode claims, 0.65 for institutional PAC claims, and 0.71 for the share discharged to institutional PACs.

16

$1,600 lower average episode claims than those who select out, a statistically significant difference that is about 6 % of the control mean. The patterns are similar for claims at and the share
discharged to institutional PAC.
Selection on Slopes. To assess selection on slopes, we estimate hospital-specific slopes (i.e., behavioral changes in response to bundled payments in period 2) and then examine how selection
into bundled payments in period 3 varies with this measure. Letting outcomeh2 denote the average episode outcome for hospital h in period 2, we estimate a modified version of Equation 1 that
allows the treatment effect of bundled payments to vary by hospital. Specifically, we estimate:

outcomeh2 = β 0 + β 1h BPh + β 2 outcomeh,2014 + β 3 outcomeh,2013 + δs(h) + ǫh ,

(2)

where BPh is an indicator for being randomly assigned to bundled payments and β 1h is the hospitalspecific treatment effect. As in Equation 1, we include lagged outcomes as covariates to improve
statistical power, although in this specification the lags are defined at the hospital level. As before, we also include strata fixed effects because randomization was conducted within strata. We
estimate this specification on the set of voluntary treatment and control hospitals (see Figure 1).
Panel B of Table 2 shows the results. Specifically, we show the average estimated hospitalspecific treatment effects (β 1h ) and their standard deviation separately across hospitals that select
into bundled payments (column 2) and those that select out (column 3). The results once again
show selection in the expected direction: for hospitals that selected into bundled payments in period 3, bundled payments in period 2 reduces average claims per episode by $796, compared to
a lower reduction ($669) for hospitals that revert to FFS in period 3. However, these differences
in average slopes are not statistically distinguishable (column 4). Selection is also in the expected
direction for the other two outcomes in Panel B: hospitals that experienced greater declines in institutional PAC claims and in the share of patients discharged to institutional PAC due to bundled
payments are more likely to remain under bundled payments. The differences in the impact on
institutional PAC claims in period 2 between those who remain in bundled payments ($519) and
those who select out ($177) in period 3 is statistically distinguishable (p=0.05).
The random assignment of payment regime in period 2 is not particularly important when

17

estimating heterogeneity in treatment effects across hospitals (i.e., the β 1h ’s from Equation 2); the
control hospitals simply identify the secular time trend β 0 . Rather, estimation requires the (admittedly strong) identifying assumption that, conditional on the covariates, there are no hospitalspecific time trends. Any heterogeneity in the change in outcomes across hospitals is interpreted
as reflecting heterogeneous treatment effects. To probe the sensitivity to this assumption, we estimate an alternative specification in which we include hospital-specific linear time trends as controls. Theses time trends are identified off the hospital specific outcomes in 2013 and 2014. In this
specification, the (weaker) identifying assumption is that, conditional on covariates, there are no
hospital specific deviations from the time trend. Appendix Table A2 shows that the qualitative
pattern is robust to this alternative specification: hospitals that select into bundled payments in
period 3 experienced larger changes in outcomes in period 2 than those who opt out, although
none of these differences are statistically distinguishable.
Selection on Hospital Characteristics. Panel C of Table 2 briefly examines other characteristics
of hospitals that select in and select out of bundled payments. Hospitals that select into bundled
payments in period 3 have a somewhat higher volume of CJR episodes in period 1, suggesting
there may be fixed costs to remaining in the program, a point we return to with our model specification in Section 5.21 Hospitals that select in are less likely to be teaching hospitals, more likely
to be for-profit, and less likely to be government-owned; they are also associated with higher
measured quality.

4

Model of Voluntary Selection

4.1

Setting

We consider a pool of CJR episodes, indexed by i, which are admitted to hospital h. We assume
throughout that this pool is taken as given, and is known to the hospital.
Under FFS, providers are reimbursed based on claims. Let λi denote the claims generated
under FFS incentives by a given episode. The preceding sections’ description of the institutional
environment and the estimates of the average effects of bundled payments suggest that it is useful
to decompose λi = f iHOSP + f iOTH , where f iHOSP are the fixed, DRG-based claims submitted for the
21 We

use period 1 volume since it is necessarily unaffected by period 2 treatment assignment.

18

index hospitalization and f iOTH are the claims submitted by post-acute care and other downstream
providers. Let ciHOSP denote the costs incurred by the hospital and cOTH
the costs incurred by the
i
other providers . For tractability, we assume that other providers are reimbursed at cost, so that
f iOTH = cOTH
.22 In what follows, for each variable xi , we focus on hospital-level averages, defined
i
as xh =

1
nh

nh
∑n=
1 xi , where n h is the number of episodes at the hospital.

Hospital Profits and Participation Incentive. Under FFS, average government spending (i.e.,
Medicare reimbursement) per episode is λh = f hHOSP + f hOTH . Hospitals only incur costs and
receive Medicare payment for costs within the hospital, so they earn profits πhFFS = f hHOSP −
chHOSP . Under bundled payment, Medicare reimburses the admitting hospital the fixed target
price th for the entire episode, so average government spending per episode is th . Hospitals are,
effectively, required to incur not only hospital costs chHOSP but also downstream providers’ claims
f hOTH , which would have been reimbursed by Medicare under FFS. We assume that the hospital
can reduce claims outside of the hospital by e through the exertion of “effort” φh (e), where φh (0) =
0, φh′ > 0, and φh′′ > 0.23 Hospitals, thus, choose effort to maximize

h
i

πhBP = max th − (chHOSP + f hOTH ) − e − φh (e) ,

(3)

e

and optimal effort is pinned down by φh′ (eh∗ ) = 1. Since the hospital internalizes both the social
marginal cost and benefit of effort, bundled payments results in the first-best level of effort.
For tractability, we assume that the cost of effort is quadratic of the form φh (e) =

e2
2ωh ,

where

ωh > 0 is a hospital specific parameter. With this assumption, under bundled payments the
hospital’s optimal choice of effort is eh∗ = ωh , average claims are f hHOSP + f hOTH − ωh = λh − ωh ,
and hospital profits are πhBP = th − (chHOSP + f hOTH −

ωh
2 ).

Hospitals select into a voluntary bundled payment program, denoted by the indicator BPh =
22 This

assumption is primarily made to simplify notation. It is straightforward in the context of the model to allow other providers to obtain a fixed markup, but reasonable levels of such markups would only slightly affect the
quantitative results and would have no impact on the qualitative conclusions.
23 For simplicity, we assume that c HOSP remains the same under bundled payments and is not affected by e. This is
h
not essential, and can be viewed as a normalization, although it is a natural assumption. If the effort to reduce hospital
cost and the effort to reduce post-acute care cost are separable, the hospital cost level was already optimized under FFS
given that hospitals were already paid (under FFS) a fixed amount for the hospital portion of the episode.

19

1, if and only if πhBP > πhFFS . Substituting in yields the criteria
BPh = 1 ⇔ (th − λh ) +

ωh
> 0,
2

(4)

where the right hand side is the sum of a “level” effect (th − λh ) and a “slope” effect ( ω2h ). The
level effect (th − λh ) represents the transfer payment hospitals would receive from the government
under bundled payments relative to under FFS if they did not change their behavior from what it
was under FFS. The slope effect ( ω2h ) denotes the net savings that hospitals get from any change in
behavior under bundled payments, which is the reduced provider costs eh∗ = ωh net of the effort
cost that reduction entails ( ω2h ). These incentives are well understood by the hospital industry. For
example, Arbormetrix, a healthcare consulting firm, advises their client hospitals to consider the
following questions when deciding whether to participate in a bundled payments program: “One:
‘How good is my target price?’ Two ‘What has changed [since the target prices were set]?’ And
three: What is my opportunity to improve?”.24
Social Welfare. The distinction between selection on levels and slopes has important implications for the social welfare consequences of voluntary programs. We define social welfare W as the
sum of consumer surplus (S) and producer profits (π), minus government spending (G) weighted
by the marginal cost of public funds Λ > 0:

W = S + π − (1 + Λ) G.

(5)

The multiplier Λ > 0 captures the deadweight loss associated with raising government revenue
through distortionary taxation. Alternatively, it can be thought of as capturing a societal preference for money in the hands of government (or consumers) rather than in the hands of hospitals.25
Consistent with the descriptive results in Section 3, we assume that the hospital’s effort does not
affect patient welfare (S).
24 See

https://www.arbormetrix.com/press-releases/new-report-significant-variation-inexpected-savings-per-hospital-in-bpci-advanced.
25 Recall that y in practice measures claims paid by Medicare or owed out of pocket by consumers. Under this
h
interpretation, it would be natural to multiply S by (1 + Λ), so that Λ represents the wedge between hospitals on the
one hand and consumers and government on the other. Since we net S out of the calculations below, this can be done
without loss of generality.

20

Government spending per episode (G) is th under bundled payments and λh under FFS. Plugging in for these and for hospital profits implies that hospital participation in the bundled payments improves social welfare if and only if

WBP > WFFS ⇔ −Λ(th − λh ) +

ωh
> 0.
2

(6)

Equation 6 illustrates the key social welfare tradeoff. On one hand, bundled payments incentivizes hospitals to exert the first best level of effort eh∗ = ωh , which increases social welfare by

ωh
2 .

On the other hand, enticing hospitals to participate in bundled payments increases government
spending by th − λh . Selection on levels (th − λh ) is thus socially costly: it creates a transfer from
the government to hospitals that is associated with a social cost of Λ. By contrast, selection on
slopes increases social welfare due to the reduction in real resource utilization net of effort costs
( ω2h ). In other words, because of the cost of public funds Λ, and the need to ensure that hospitals
are willing to participate in bundled payments, hospital participation is not always social-welfare
enhancing.

4.2

Graphical Intuition

We illustrate the setting graphically in Figure 2, which depicts the participation incentives for hospitals and the corresponding social welfare implications. Hospitals are represented by a {λh , ωh }
pair. If one could mandate participation without any additional government costs, the social welfare maximizing outcome would be to mandate that all hospitals join the BP program (given that
ωh is positive, by design, for all hospitals). However, if participation is voluntary and Medicare’s
ability to encourage participation rests on the financial incentive, th , the tradeoff is represented in
Figure 2.
To draw the figure, we hold the target price t fixed across hospitals. At this payment, the solid
line represents the set of hospitals that are indifferent between participation in bundled payments
and FFS. Hospitals to the left prefer bundled payments, because the sum of the transfer holding
their behavior constant (t − λ) and the savings they get under bundled payments ( ω2 ) is positive.
Hospitals to the right of the solid line prefer to remain under FFS. Thus, hospitals have both a
simple “level” incentive to participate (if th − λh > 0), as well as an additional “slope” incentive,

21

which explains why the solid line slopes up. All else equal, a higher ωh provides an additional
incentive for the hospital to join the bundled payment program as it captures some of the savings
it can generate.
The dashed line in Figure 2 represents the set of hospitals for which social welfare is the same
whether they participate in bundled payments or FFS. While the “slope” effect ( ω2 ) enters identically (and positively) into the private participation condition (Equation 4) and the social welfare
condition (Equation 6), the “level” effect t − λ enters positively into the hospital’s participation
decision (Equation 4) but negatively in the social welfare calculus (Equation 6). This explains why
the dashed line is downward sloping, and illustrates the central social welfare tension in designing
a voluntary regime: enticing providers to participate can be socially costly.
Taken together, Figure 2 partitions hospitals to three groups: hospitals that choose the FFS
regime, hospitals that efficiently select into bundled payments, and hospitals that select into bundled payments inefficiently because they get paid much more than they “should” but do not generate significant efficiency gains (due to low ωh ).

4.3

Targeting

The bundled payment program aligns effort incentives. If Medicare could generate participation
without any additional public expenditure, it would be social-welfare improving to do so (since
we assume ωh > 0). However, in a voluntary regime Medicare must respect the hospitals’ participation constraint. If Medicare has perfect information about {λh , ωh }, it could maximize social
welfare by setting th = λh −

ωh
2

for each hospital. Under these target prices, all hospitals would

voluntarily participate and government spending would be lower.
Once information about the joint distribution of {λh , ωh } is incomplete, setting the payment
amount involves a tradeoff, similar to the one in the classic optimal regulation design problem
of Laffont and Tirole (1993). Figure 3 illustrates this tradeoff in our setting. In Panel A we start
with Figure 2 and super-impose on it the participation and social welfare indifference sets that are
associated with a higher target price t′ > t. The black (solid and dashed) indifference lines that
correspond to t′ are analogous to the gray lines, which correspond to t. Naturally, the higher payment amount increases the share of hospitals that select into bundled payments. For many of the
marginal hospitals that opt in, participation increases social welfare. At the same time, however,

22

the greater payment increases the social welfare cost associated with infra-marginal participants,
by a fixed amount of Λ(t′ − t), and in doing so makes participation social-welfare reducing for
some of these hospitals (those that lie in between the two dashed lines).
The ability to effectively target depends on the underlying joint distribution of {λh , ωh } as well
as any information about this joint distribution that the social planner can condition on in setting
target prices. This is shown in the remaining panels of Figure 3, which use ovals to illustrate three
examples of underlying joint distributions, conditional on (priced) observables.
Comparing Panels B and C shows the importance of the overall level of ωh . When ωh is high
(i.e., the cost of effort associated with reducing claims is lower and therefore optimal effort under
bundled payments is higher), as in Panel B, the participation incentives of the hospital and the
social planner are more closely aligned. In this case, even if λh is heterogenous after conditioning
on available information, it is easier to generate social welfare enhancing participation in bundled payments. However, when ωh is low (i.e., the cost of effort is higher and optimal effort is
lower), as in Panel C, selection is primarily driven by levels, and it is difficult to generate social
welfare enhancing participation by hospitals. In this case, it requires much less heterogeneity in
λh , or more precise information, to be able to generate social welfare gains through the voluntary
bundled payment program.
Comparing Panels C and D shows the importance of the relative heterogeneity in λh and ωh .
Because the primary policy instrument is a fixed payment, large heterogeneity in λh , as in Panel
C, leads to more inefficient selection into bundled payments. In contrast, if the primary source of
heterogeneity is the “slope” ωh , as in Panel D, voluntary participation is more likely to generate
social welfare gains.
The joint distribution of λh and ωh , conditional on (priced) observables, is therefore key in
assessing the potential social welfare gains from alternative payment models. It is therefore the
key object of interest in our econometric exercise in the next section.

23

5

Specification and Results

5.1 Econometric Specification
We now turn to econometrically estimating the economic model presented in the last section.
Recall the way we defined the “periods” associated with the experimental setting. In period 1,
all hospitals are still under FFS, and assignment to bundled payments has not been announced.
In period 2, a subset of the hospitals are randomly assigned to bundled payments. In period 3,
a subset of these latter hospitals endogenously choose to remain under bundled payments while
the rest switch back to FFS.
For each hospital in the sample, we observe two periods of claims data (yh1 , yh2 ) and three
periods of bundled payments participation indicators (BPh1 , BPh2 , BPh3 ). For hospitals randomly
assigned to bundled payments in period 2, we also observe the hospital-specific target price, th , in
period 2 (even if they select out of the program).
As discussed in the end of Section 4, our key object of interest is the joint distribution of

{λh , ωh }, where λh is the average per-episode claims under FFS and ωh is the reduction in claims
that is caused by bundled payments. The model implies the following relationships between the
latent objects of interest and the variables we observe. First, the claims equation (for t = 1, 2) is
given by
yht = λh − BPht ωh

for

t = 1, 2,

and second, the hospital’s participation equation (which is relevant only for period 3, when participation in bundled payments is voluntary) is given by

BPh3 = 1 ⇐⇒ (th − λh3 ) +

ωh
> 0.
2

To help fit the model to the data, we introduce two additional econometric components. First,
we allow λh to vary over time according to
ln λht = ln λh + g(t) + ǫht

for

t = 1, 2, 3.

where g(t) = γ (t − 2) is a linear time trend, normalized to be zero in period 2, and ǫht is drawn
24

(iid) from N (0, σǫ2 ).26
Second, we introduce a hospital-level choice shifter into the participation equation. Survey
evidence on how hospitals respond to bundled payments suggest that participation may be influenced by both hospital-level fixed costs and marginal per-episode costs (Zhu et al., 2018). To allow
ν
nκh

for both of these forces, we add the term νh =

to the hospital-level selection equation, where

nh is the number of episodes at the hospital, and ν and κ ∈ [0, 1] are parameters to be estimated.
For κ = 1, the hospital-level choice shifter becomes

ν
nh ,

which is equivalent to a choice shifter of

ν in an episode-level specification. For κ = 0, the hospital-level choice shifter becomes ν, implying no episode-level component. Intermediate values of κ capture intermediate cases. For now,
we remain agnostic as to what these additional forces represent and, in particular, whether they
only affect hospital choice or are also relevant for social welfare. In our counterfactual analyses in
Section 6 we will consider both possibilities.
Putting everything together, the econometric model is given by the following relationships:

yh1 = λh1 ,
yh2 = λh2 − BPh2 ωh ,
BPh3 = 1 ⇐⇒ (th − λh3 ) +

ν
ωh
+ κ > 0,
2
nh

ln λht = ln λh + γ (t − 2) + ǫht

for

t = 1, 2, 3.

Finally, we assume that ln ωh and ln λh are joint normally distributed, so that




 

2
ln
λ
µ
σ
ρ
σ
σ
λω λ ω  
h 

 λ,s  
λ

 ∼ N 
,
 .
ln ωh
µω
ρλω σλ σω
σω2
where the s subscript on µλ,s indicates that we allow the mean of ln λh to vary across strata.27
Because the DRG portion of spending is fixed, we restrict ωh from being infeasibly large by truncating it from above at 0.71 λh .28
26 Our use of the term “linear” is slightly imprecise, because the trend is in periods, which do not perfectly correspond

to calendar time (e.g., we exclude 2015 due to potential anticipatory effects).
27 Since assignment to bundled payments in period 2 was random conditional on strata, allowing the mean to vary
by strata isolates the experimental variation and is the analogue to controlling for strata fixed effects in Equation 1.
28 The institutions and empirical evidence indicate that virtually all of the savings from bundled payments arise from

25

5.2

Identification

The conceptual identification of the model is fairly straightforward given random assignment to
bundled payments in period 2. The model has a set of parameters that correspond to the “level”
of claims under FFS incentives and its evolution over time: µλs , σλ , γ, σǫ ; a set of parameters that
correspond to the reduction in claims under bundled payments: µω , σω ; a correlation parameter
that relates the levels and slopes: ρλω ; and choice shifter parameters: ν, κ. The intuition for the
identification argument follows in three steps.
First, using data from the control group alone, in which we observe λh1 and λh2 for the same
set of hospitals, we can identify µλs , γ, σλ , and σǫ . Intuitively, these would be identified from a
random effects model estimated on the control group. We can use the control group alone to estimate these parameters because random assignment guarantees that parameters estimated from
the control group are valid for the entire sample.
Second, using data from the treatment group as well as the control group, we can identify µω ,
σω , and ρλω . We observe λh1 and λh2 for all hospitals in the control group, and λh1 and λh2 − ωh
for all hospitals in the treatment group. The average change between λh1 and λh2 for control
hospitals identifies γ, the time trend in λht . Again, because of random assignment we know that
γ estimated from the control group is valid for the whole sample. For treatment hospitals, the
average difference in λh1 and λh2 − ωh in excess of γ identifies µω .
The dispersion within the treatment hospitals in the change in episode claims between period
1 and period 2 is driven by a combination of the stochastic evolution of λht and the dispersion
in ωh . Since the stochastic evolution of λht is already identified from the control group, we can
(loosely) net it out, and the residual dispersion for treatment hospitals identifies σω . The intuition
for identifying ρλω is similar: we observe the reduction in claims for each hospital in the treatment
group, and can correlate it with the hospital’s period-1 claims, and adjust it appropriately for the
additional independent noise that is driven by the stochastic evolution of λht , which is already
identified by the control group.
Finally, the bundled payment participation equation identifies the distribution of the remain“other” claims that are not associated with fixed, DRG-based payment for the index admission. The value of 0.71
represents the 99th percentile in the data for the ratio of these other claims to total episode claims. By truncating the
distribution of ωh at the 99th percentile of other claims, we are essentially making the assumption that savings cannot
exceed the 99th percentile of “other” spending.

26

ing choice shifter parameters ν and κ. This equation resembles a probit equation, but the error
term has an economic interpretation as reflecting hospitals’ profit maximizing choices. The joint
distribution of λh3 and ωh , which is identified from the previous two steps, together with our
model, generates predictions for the overall participation rate in a voluntary bundled payment
program. Any deviation from this “predicted” participation rate identifies ν, with κ identified by
the extent to which hospitals with greater numbers of episodes are, all else equal, more likely to
select into bundled payments.

5.3

Estimation

We estimate the model in two steps using maximum likelihood, following the identification argument quite closely. We summarize the estimation procedure here, and provide more details in
Appendix A.
In the first step we follow the first part of the identification argument, by estimating µλs , γ,
σλ , and σǫ using data from the control group alone. An observation is a pair of average episode
claims for a control group hospital in period 1 and period 2 {yh1 , yh2 }.
We could continue along the identification argument, and estimate the remaining parameters
in two additional steps, but in order to increase efficiency we combine them into one. Specifically,
we now use observations on the treatment group hospitals, where each independent observation
is given by {yh1 , yh2 , BPh3 }. The likelihood is given by
Lh = Pr ( BPh3 = 1) · f (yh1 , yh2 | BPh3 = 1) + Pr ( BPh3 = 0) · f (yh1 , yh2 | BPh3 = 0),
and can be evaluated numerically. As a way to speed up computation (with some small loss
in efficiency), we can use the parameters estimated in the first step and the observed value of
yh1 to generate a “posterior distribution” for ln λh2 and (identically) ln λh3 for each hospital. This
simplifies the second step of the estimation. When we estimate the model, we weight each hospital
by the number of episodes in period 2, so that the resulting parameters are representative at the
episode level.
Standard errors are calculated using the bootstrap method. Specifically, we construct bootstrap samples by drawing the observed number of hospitals with replacement from cells defined

27

by the full interaction of treatment assignment and strata. When estimate the parameters of the
model on each bootstrap sample and calculate the standard errors as the standard deviation of
these bootstrap parameter estimates.

5.4

Results

Table 3 presents the estimation results. Panel A reports the parameter estimates and Panel B
presents some of the key summary statistics that are implied by these estimates, first for all hospitals (Panel B.1) and then, in Panel B.2, limited to the hospitals in the voluntary treatment group
only (see Figure 1).
Panel A indicates a negative time trend in episode spending (γ = −0.07), which is consistent
with the time series pattern in the control group, and a relatively small standard deviation for
the idiosyncratic disturbances in λht (σǫ = 0.07 versus σλ = 0.17), which yields a λh3 with an
expected value of $24,200. We estimate that ωh has an expected value of $386, which is smaller
than the average effect estimated in Table 1 (and closer to the hospital-level estimates in Appendix
Table A1). The distributions of λh and ωh have a modest positive correlation (ρλ,ω = 0.30). The
estimate of κ is 0.40, implying that the choice shifter scales up with the number of episodes but
less than proportionally, and can thought of as representing some combination of hospital-level
and episode-level costs. With the exception of the choice-shifter parameter ν, the parameters are
precisely estimated.
The model emphasizes the importance of heterogeneity in levels and heterogeneity in slopes
in determining the nature of selection, government spending, and social welfare under a voluntary bundled payments regime. The results in Panel B.1 indicate that the heterogeneity in levels is
substantially greater than either the level or the heterogeneity in the slopes – the standard deviation of λh3 is $4,400 compared to a standard deviation of ωh of $1,100, and an even lower average
of ωh . This raises concerns that the voluntary system may primarily produce inefficient transfers
to hospitals through selection on levels. However, the potential for selection on levels may be
limited by the design of target prices. We explore this in Panel B.2, which is restricted to the subsample of hospitals in the voluntary treatment regime, where we can also observe target prices
and which will be the focus of our counterfactuals in the next section. Panel B.2 indicates that
netting out target prices does not noticeably reduce heterogeneity in levels: the $4,900 standard

28

deviation of λh3 − th for voluntary treatment hospitals is only slightly less than the $5,700 standard
deviation of λh3 for these hospitals.29
To further examine the role of target prices, Figure 4 produces empirical analogues of the
selection figures we used to illustrate the model in Section 4, incrementally accounting for target
prices and the choice-shifter νh . Once again we restrict analysis to the subsample of hospitals in the
voluntary treatment group. To provide a baseline, Panel (a) of Figure 4 plots simulated hospitals
from the joint distribution of ωh (vertical axis) and λh3 (horizontal axis), without netting out the
target price. As would be expected from the results in Panel B.2 of Table 3, the plot suggests
that selection on levels is a primary concern, with a large mass of hospitals selecting bundled
payments inefficiently or selecting FFS. In Panel (b) of Figure 4 we examine the role of targeting by
plotting λh3 − th on the horizontal axis, instead of λh3 . Netting out target prices does not noticeably
shrink the heterogeneity along the horizontal axis, with large masses of hospitals continuing to
select bundled payments inefficiently. In Panel (c), we further add the choice-shifter by plotting
λh3 − th + νh on the horizontal axis, thus capturing all the components of the selection decision.

6 Counterfactuals
We use the estimated model to perform a set of counterfactual exercises. Throughout, we focus
on the sample of hospitals in the voluntary treatment group – i.e., treatment group hospitals that
were given a choice in period 3 of whether to remain under bundled payments or revert back to
FFS (see Figure 1). We perform two main sets of exercises. First, we compare social welfare under
mandatory FFS, mandatory bundled payment, and voluntary bundled payment. Second, within
the voluntary bundled payment regime, we consider how alternative target prices affect social
welfare.30
29 From a mathematical perspective, this should not be surprising. Since Var ( λ − t ) = Var ( λ ) + Var ( t ) −
h3
h
h3
h
2Cov(λh3 , th ), the distributions of λh3 and th can have a modest positive covariance and still yield a case where
Var (λh3 − th ) ≈ Var (λh3 ).
30 The current bundled payment option offers the choice of only one target price, paired with incentives that make
the hospital the full residual claimant on effort. It would be natural to explore social welfare under menus of contracts
which trade off higher target prices in return for shallower incentives, as in the classic optimal regulation problem
in Laffont and Tirole (1993). However, given that, as shown in Figure 4, selection on levels rather than slopes is the
primary concern, and that the average slope is relatively modest, better targeting of the price level rather than better
design of the screening contracts seems a more fruitful avenue to explore.

29

6.1

Voluntary vs. Mandatory

We first compare outcomes under the observed period 3 voluntary bundled payment program to
two period 3 counterfactuals: all hospitals mandated to be under the status quo FFS regime (as
they were in period 1), or all hospitals mandated to participate in the bundled payment program
(as they were in period 2). These counterfactuals can be thought of as measuring the impact of the
government’s decision to make the bundled payment program voluntary, relative to cancelling
the program entirely or keeping it mandatory.
To operationalize this counterfactual exercise, we use our model, together with the parameter
estimates in Table 3 to simulate hospital-specific values for {λh3 , ωh } in period 3 conditional on
the hospital’s period 3 selection decision BPh3 , their target price th , and number of CJR episodes
nh2 from period 2. We assume a social cost of funds of Λ = 0.15.
Panel A of Table 4 shows the results. The first row reports the results that would occur if
there were no bundled payment program and all hospitals were paid under FFS. Government
spending (i.e., G in the definition of social welfare from Equation 5) averages $24,443 per episode
in this counterfactual (which corresponds to the average λh3 reported in Panel B.2 of Table 3). The
remainder of the entries are normalized to zero; the mandatory FFS counterfactual will serve as a
benchmark to which we compare other regimes.
The second row of Panel A considers a counterfactual in which all hospitals are mandated to
enroll in bundled payments in period 3, as was intended under the initial design. Under mandatory bundled payment, hospitals receive a transfer of (th − λh ) and are residual claimants on the
ω-related savings they generate ( ω2h ). If target prices had been calibrated to equal counterfactual
claims under FFS incentives (E h th = E h λh3 ), government spending would have been unaffected
relative to the baseline. However, as seen in Panel B.2 of Table 3, target prices th were on average
$85 lower than FFS claims, so government spending is $85 lower and (multiplied by 1 + Λ = 1.15)
social costs decrease by $98 (column 3).
In columns (4) through (7) we consider two different versions of the welfare analysis, depending on whether we treat the choice shifter νh term as non-welfare relevant or welfare-relevant.
The choice shifter would be welfare-relevant if it represents a real hospital cost - such as fixed
or variable costs of changing behavior, or perhaps uncertainty about λh , which might be greater

30

for smaller hospitals. The choice shifter might not be welfare relevant, however, if it represents a
choice friction such as status quo bias. In columns (4) and (5), where we assume νh is not welfare
relevant, hospital profits relative to FFS rise by $116 (column 4). This rise reflects the difference
between the ω-related savings of $201 (half of the expected value of ωh from Panel B.2 of Table 3)
and the $85 reduction in government payments. Social surplus rises by $214 (column 5). In other
words, the incentive effects of bundled payment (which generate

ωh
2

= $201 in social savings on

average) represent most of the social gain, with the remainder coming from the reduction in government spending. Naturally, if νh is taken into account (as in columns 6 and 7), both hospital
profits and relative social surplus are lowered by its average of $1,419 (see Panel B.2 of Table 3).
The third row of Panel A considers the voluntary selection scenario that actually took place.
To be consistent with the other counterfactuals, outcomes for voluntary selection are simulated
based on the model parameters. In particular, for each hospital we simulate a binary participation
decision and the resulting government spending, hospital profits, and social surplus. We find that
38.8% of episode-weighted hospitals select into bundled payments, which is almost identical to
the actual selection percentage (37.2% in Table 2), providing assurances about the in-sample fit of
our model. As we discussed in Section 5, the much greater heterogeneity in th − λh , relative to

ωh
2 ,

suggests that selection into bundled payment is primarily on “levels.” Consequently, voluntary
participation raises government spending relative to the other counterfactuals; specifically, we
estimate that voluntary participation raises government spending per episode by $1,682 relative
to the mandatory FFS benchmark, and by $1,767 relative to the mandatory bundled payment
regime.
Since hospitals are given a choice, their profits must be weakly higher under the voluntary
regime relative to a mandatory regime. When we treat the νh term as non-welfare relevant, hospital profits rise to $1,754 above the mandatory FFS benchmark, which is $1,638 higher than under
mandatory bundled payments. Ignoring νh , social surplus under voluntary bundled payments
is lower than under either the mandatory FFS benchmark (-$179, column 5) or the mandatory
bundled payment regime (-$393); lower social surplus reflects both the larger transfers to hospitals and the smaller share of hospitals generating ω-related efficiency gains. When we treat νh
as welfare relevant, hospital profits rise by a smaller amount of $1,248 (instead of $1,754) above
the mandatory FFS benchmark, and social surplus is correspondingly lower. It is worth noting
31

however that, while negative, social surplus in the voluntary bundled payment counterfactual is
less negative than under the mandatory bundled payment counterfactual (see column 7). Intuitively, if we think that the νh -related costs are real, it is important to let hospitals avoid them if the
offsetting ω-related benefits are not large enough.
Whether or not we treat the νh term as welfare relevant, the results indicate that the voluntary bundled payment model reduces social surplus relative to the mandatory FFS status quo.
However, the results do not imply that a voluntary program is necessarily ineffective. Voluntary
bundled payments generates positive ω-related efficiency gains. The reason overall social welfare
is reduced is because these ω-related gains are small relative to the social welfare losses associated with “overpaying” participating hospitals relative to their counterfactual FFS claims. We
therefore turn now to exploring whether and how the voluntary program performance could improve if Medicare were able to set target prices to better reflect underlying hospital-specific costs
and thus capture more of the potential $100 million dollars of potential annual ω-related gains in
social surplus (from approximately 500,000 CJR episodes per year, with an average

ωh
2

of about

200).

6.2

Targeting

In order to explore price targeting under voluntary participation in a systematic fashion, we approximate the observed target prices using a parametric distribution, and then examine the impacts of shifting its parameters. Specifically, we assume that hospital-level target prices, th , are
log-normally distributed and are correlated with hospital costs. We then explore voluntary participation under different parameter values. Appendix B provides more details.
Figure 5 summarizes the outcomes from this exercise, plotting social surplus relative to the
mandatory FFS benchmark (y-axis) against government spending (x-axis) for different target price
counterfactuals. In the plot, we focus on the social surplus values that do not consider νh (column 5
of Table 4). Panel B of Table 4 reports additional outcomes associated with each exercise, including
analyses where νh is considered welfare-relevant. The black dot in Figure 5 corresponds to the
observed distribution of th , and serves as a baseline. The observed target prices are parameterized
by means µts that vary by strata, a standard deviation of σt = 0.17, and a correlation of ρλ3 ,t = 0.81

32

with claims under FFS (λh3 ).31 Because of the log-normal parameterization, the outcomes for
observed targeting in Panel B of Table 4 are slightly different to those in the voluntary bundled
payments row of Panel A.
We consider three counterfactual targeting policies. The first, indicated by the point labeled
“perfect targeting,” sets target prices exactly equal to realized claims under FFS (th = λh3 ). Under
this contract, there is no transfer to hospitals (no selection on levels) and hospitals are the full
residual claimants on the ω-related savings they generate. Because there are no transfers to offset
the νh , only 19.9% of hospitals select into bundled payments. These 19.9% generate non-trivial ωrelated surplus gains, but because there are few of them, average total surplus only increases by
$39 per episode (i.e. about one-fifth of the increase that would be achieved if all hospitals selected
in with no transfers).
“Perfect targeting” is a useful benchmark, but not feasible in the context of our model. To
see this, recall that we model λh3 = λh + g(t) + ǫh3 , where ǫh3 is an iid random variable that
is not predictable in advance. To gauge the benefits of a more feasible contract, we consider a
second scenario (labelled “feasible targeting”) in which Medicare sets a target price of th = λh +
g(t), which is based on the hospital’s underlying type and the time trend.32 The correlation with
realized claims under FFS is reduced to √ σ2λ

σλ +σǫ2

= 0.93, which is two-thirds of the way between the

correlation for observed target prices (ρλ3 ,t = 0.81) and perfect targeting (ρλ3 ,t = 1). We estimate
that relative to the observed targeting, feasible targeting generates approximately three-fifths of
the social welfare gains that could be achieved with perfect targeting; as a result, under feasible
targeting, social surplus is virtually identical to the FFS benchmark (-$5).
The above analysis asks how well observed targeting does compared to its potential; the
mirror-image of this is to ask how well it does relative to no targeting. We therefore undertake
a third exercise, labeled “no targeting,” which considers a case in which target prices are uniform
across hospitals at a value equal to the average of λh3 . Relative to the observed targeting, the no
targeting case leads to higher levels of participation in bundled payment, greater (inefficient) selection on levels, greater government spending and higher social costs. Relative to no targeting,
31 The

values of µt,s for the 8 strata are [10.00, 10.04, 10.04, 10.11, 10.23, 10.05, 10.14, 10.26]
q our stochastic assumptions, the mean of this contract is unchanged, and the standard deviation is reduced

32 Given

to σt =

2 − σ2 = 0.17, from σ = σ = 0.18 under perfect targeting.
σλ,3
t
ǫ
h3

33

feasible targeting has the potential to generate $189 per episode in social surplus; the observed
targeting in turn generates approximately two-thirds of these feasible gains ($128 = (-66)- (-194)
out of $189).
While improved information is a natural way for Medicare to achieve better targeting, it is not
the only way to do so. Medicare could also achieve better targeting through a narrower definition
of the bundle. To illustrate, suppose that we can decompose average per-episode claims into two
additive separable components: hospital claims and other claims, which includes post-acute care.
Because hospitals were already paid a predetermined, DRG-based amount under FFS, we do not
expect hospital claims to respond to the incentives from bundled payments. Indeed, the empirical
evidence shows that most of the ω-related savings come from other claims, and post-acute claims
in particular. However, while hospital claims are not a source of ω-related savings, they are heterogenous across hospitals, and thus a source of selection on levels. Eliminating hospital claims
from the bundle thus effectively increases the degree of targeting.
We simulate the effects of two such narrower bundles. In the first, labelled “narrow bundling,
no targeting”, we remove hospital claims from the bundle but assume that we cannot target prices
for other claims. Within our framework, this is equivalent to setting the target price as the sum of
ex post, realized hospital claims and a predetermined, fixed payment for other costs.33 This target
price has correlation coefficient of ρλ3 ,t = 0.76 and reduces social welfare relative to the observed
target prices.
In the second, called “narrow bundling, observed targeting”, we continue to assume that
hospitals are paid their ex post realized claims, however, we now assume that Medicare can obtain
the same degree of targeting for other claims as the actual target price achieved for total claims.34
Doing so increases the correlation coefficient to ρλ3 ,t = 0.87. This contract generates social gains
relative to the observed voluntary bundled payment program and brings overall social welfare
(-$39) closer to the level from feasible targeting.
Overall, our findings suggest that while the observed voluntary program is socially costly,
is, the target price is set to be f hHOSP + E h [ f hOTH ]. We calculate {µt , σt2 , ρλ3 ,t } for this target price using the
empirical distributions of th = f hHOSP + E h [ f hOTH ] and λh .
34 Specifically, the target price is set to t = f HOSP + tOTH , where tOTH is the other component of the target prices.
h
h
h
h
OTH , the standard deviation to have the same ratio with f OTH as the
equal
to
the
mean
of
f
We set the mean of tOTH
h
h
h
observed target price does with λh , and correlation of tOTH
and f hOTH equal to the correlation between the observed
h
target price and λh .
33 That

34

there are feasible improvements in targeting which could create a voluntary program that would
mostly eliminate social losses (or perhaps even generate small social gains). These could arise
through tailoring target prices better to reflect claims under FFS of each hospital, or focusing the
bundle on a narrower set of services in which cost-savings can be realized.

7

Conclusion

Government regulations are sometimes based on voluntary participation, allowing market actors to “choose their own incentives.” These voluntary regimes may be socially beneficial if they
induce selection of actors with private information about the net benefits from changing their
behavior, but they may be socially costly if they primarily attract actors who can receive higher
government payments with no behavior change. We explored this tradeoff between “selection on
slopes” and “selection on levels” in the context of Medicare payment reform.
Our analysis takes advantage of a unique setting in which Medicare introduced an alternative payment model – called bundled payments – as a randomized trial and then modified the
experimental design in midstream. Bundled payments was originally imposed as a mandatory
participation model for hospitals in 67 randomly selected markets, with hospitals in 104 other
randomly selected markets paid under the status quo. Two years into this five-year experiment,
however, hospitals in half of the 67 randomly selected markets were unexpectedly allowed to
choose whether to remain under bundled payments or revert back to the status quo payment
model. This provided a rare opportunity to observe all hospitals’ behavior under the alternative
model and then to observe which hospitals voluntarily choose to continue under it.
Both the descriptive evidence and the model estimates indicate that selection was primarily
based on levels rather than on slopes. The main driver of participation in the voluntary bundled
payment model was whether the hospital would benefit financially from the alternative regime
without any change in behavior. We also found selection on slopes – hospitals who changed their
behavior more in response to bundled payments were also more likely to opt in – but selection on
this margin was much less quantitatively important.
As a result, we estimated that the voluntary bundled payment model generated inefficient
transfers to hospitals and reduced social welfare relative to imposing the status quo fee-for-service
(FFS) payment regime on all hospitals. However, we also estimated that alternative (feasible) vol35

untary designs that targeted reimbursement more closely to hospitals’ claims level under FFS
could reduce these inefficient transfers substantially. Of course, any design with less generous reimbursements to "better-performing" actors may raise concerns about fairness, as well as concerns
about ratchet effects (Freixas, Guesnerie and Tirole, 1985).
Our quantitative results are, of course, specific to our setting. The impact of alternative payment models in Medicare have tended to be modest – “singles not home runs” in the words of
Frakt (2019a); in our setting, this limits the scope for social-welfare improving selection on slopes.
In other contexts, this scope could be greater. In addition, the design feature that is so helpful
for our empirical work – that we observe hospital behavior under the alternative regime and then
their choices of whether to continue in it – may also affect the selection dynamics relative to a more
typical setting in which actors are given a choice of opting into a new regime without any prior
experience with that regime. For example, hospitals’ prior experience under bundled payments
may have increased hospitals’ information about their levels and/or slopes, thus creating more
selection on one or both of these dimensions. In addition, the expectation that they would have
to participate in bundled payments for five years may have induced hospitals to undertake sunk
investments, which may in turn have affected their participation decisions when it unexpectedly
became optional.
Beyond the specific quantitative results, our analysis suggests the importance of considering
– and ideally estimating – selection on both slopes and levels in settings in which the regulator
is considering a voluntary regime. While there is an active and ongoing debate over the merits
of voluntary versus mandatory payment reforms, voluntary participation is currently the norm
across Medicare’s alternative payment models. With the partial exception of the program we
study, all other bundled payment models, Accountable Care Organizations, and primary care coordination models have been implemented in a voluntary manner. Moreover, as we noted in the
introduction, voluntary regulation is widespread outside of healthcare, in sectors such as education, environmental regulation, and electricity regulation. Exploring the impact and optimal
design of such voluntary programs in these other settings is an important and fruitful direction
for further work.

36

References
Alexander, Diane. 2017. “How Do Doctors Respond to Incentives? Unintended Consequences
of Paying Doctors to Reduce Costs.” Working Paper. https://www.chicagofed.org/
publications/working-papers/2017/wp2017-09.
Barnett, Michael L, Andrew Wilcock, J Michael McWilliams, Arnold M Epstein, Karen E
Joynt Maddox, E John Orav, David C Grabowski, and Ateev Mehrotra. 2019. “Two-Year Evaluation of Mandatory Bundled Payments for Joint Replacement.” New England Journal of Medicine,
380(3): 252–262.
Carroll, Caitlin, Michael Chernew, A Mark Fendrick, Joe Thompson, and Sherri Rose. 2018.
“Effects of Episode-Based Payment on Health Care Spending and Utilization: Evidence From
Perinatal Care in Arkansas.” Journal of Health Economics, 61: 47–62.
Cicala, Steve, David Hémous, and Morten Olsen. 2020. “Adverse Selection as a Policy Instrument: Unraveling Climate Change.” Working Paper. https://home.uchicago.edu/
~scicala/papers/unraveling/unraveling_climate_change_draft.pdf.
Clemens, Jeffrey, and Joshua D Gottlieb. 2014. “Do Physicians’ Financial Incentives Affect Medical Treatment and Patient Health?” American Economic Review, 104(4): 1320–49.
CMS. 2015a. “Medicare Program; Comprehensive Care for Joint Replacement Payment Model
for Acute Care Hospitals Furnishing Lower Extremity Joint Replacement Services. Final Rule.”
Federal Register, 80(226): 73273–73554.
CMS. 2015b. “Medicare Program; Hospital Inpatient Prospective Payment Systems for Acute Care
Hospitals and the Long-Term Care Hospital Prospective Payment System Policy Changes and
Fiscal Year 2016 Rates; Revisions of Quality Reporting Requirements for Specific Providers,
Including Changes Related to the Electronic Health Record Incentive Program; Extensions of
the Medicare-Dependent, Small Rural Hospital Program and the Low-Volume Payment Adjustment for Hospitals. Final Rule; Interim Final Rule with Comment Period.” Federal Register,
80(158): 49325–49886.
CMS. 2016. “Medicare Program; Hospital Inpatient Prospective Payment Systems for Acute Care
Hospitals and the Long-Term Care Hospital Prospective Payment System and Policy Changes
and Fiscal Year 2017 Rates; Quality Reporting Requirements for Specific Providers; Graduate
Medical Education; Hospital Notification Procedures Applicable to Beneficiaries Receiving Observation Services; Technical Changes Relating to Costs to Organizations and Medicare Cost
Reports; Finalization of Interim Final Rules With Comment Period on LTCH PPS Payments
for Severe Wounds, Modifications of Limitations on Redesignation by the Medicare Geographic
Classification Review Board, and Extensions of Payments to MDHs and Low-Volume Hospitals.
Final Rule.” Federal Register, 81(162): 56761–57345.
CMS. 2017. “Medicare Program; Cancellation of Advancing Care Coordination Through Episode
Payment and Cardiac Rehabilitation Incentive Payment Models; Changes to Comprehensive
Care for Joint Replacement Payment Model: Extreme and Uncontrollable Circumstances Policy
for the Comprehensive Care for Joint Replacement Payment Model.” Federal Register, 82: 57066–
57104.
CMS. 2019. “CMS Fast Facts.” Centers for Medicare & Medicaid Services.

37

Cromwell, Jerry, Debra A Dayhoff, and Armen H Thoumaian. 1997. “Cost Savings and Physician Responses to Global Bundled Payments for Medicare Heart Bypass Surgery.” Health Care
Financing Review, 19(1): 41.
Cutler, David M. 1995. “The Incidence of Adverse Medical Outcomes under Prospective Payment.” Econometrica, 63(1): 29–50.
Cutler, David M, and Kaushik Ghosh. 2012. “The Potential for Cost Savings through Bundled
Episode Payments.” New England Journal of Medicine, 366(12): 1075–1077.
DeAngelis, Corey A, Lindsey M Burke, and Patrick J Wolf. 2019. “The Effects of Regulations
on Private School Choice Program Participation: Experimental Evidence from Florida.” Social
Science Quarterly, 100(6): 2316–2336.
Doran, James P, and Stephen J Zabinski. 2015. “Bundled Payment Initiatives for Medicare and
Non-Medicare Total Joint Arthroplasty Patients at a Community Hospital: Bundles in the Real
World.” The Journal of Arthroplasty, 30(3): 353–355.
Dummit, Laura A, Daver Kahvecioglu, Grecia Marrufo, Rahul Rajkumar, Jaclyn Marshall,
Eleonora Tan, Matthew J Press, Shannon Flood, L Daniel Muldoon, Qian Gu, et al. 2016.
“Association between Hospital Participation in a Medicare Bundled Payment Initiative and
Payments and Quality Outcomes for Lower Extremity Joint Replacement Episodes.” JAMA,
316(12): 1267–1278.
Dummit, Laura A, Kimberly Smathers, OJ Bright, Rebecca Cherry, McCulloch Cline, Amy
Cowell, et al. 2018. “CMS Comprehensive Care for Joint Replacement Model: Performance Year
1 Evaluation Report.” The Lewin Group.
Einav, Liran, Amy Finkelstein, and Neale Mahoney. 2018. “Provider Incentives and Healthcare
Costs: Evidence From Long-Term Care Hospitals.” Econometrica, 86(6): 2161–2219.
Einav, Liran, Amy Finkelstein, Raymond Kluender, and Paul Schrimpf. 2016. “Beyond Statistics:
the Economic Content of Risk Scores.” American Economic Journal: Applied Economics, 8(2): 195–
224.
Einav, Liran, Amy Finkelstein, Stephen P Ryan, Paul Schrimpf, and Mark R Cullen. 2013. “Selection on Moral Hazard in Health Insurance.” American Economic Review, 103(1): 178–219.
Eliason, Paul J, Paul LE Grieco, Ryan C McDevitt, and James W Roberts. 2018. “Strategic Patient
Discharge: The Case of Long-Term Care Hospitals.” American Economic Review, 108(11): 3232–65.
Elixhauser, Anne, Claudia Steiner, D Robert Harris, and Rosanna M Coffey. 1998. “Comorbidity
Measures for Use with Administrative Data.” Medical Care, 8–27.
Finkelstein, Amy, Yunan Ji, Neale Mahoney, and Jonathan Skinner. 2018. “Mandatory Medicare
Bundled Payment Program for Lower Extremity Joint Replacement and Discharge to Institutional Postacute Care: Interim Analysis of the First Year of a 5-Year Randomized Trial.” JAMA,
320(9): 892–900.
Fisher, Elliott S. 2016. “Medicare’s Bundled Payment Program for Joint Replacement: Promise
and Peril?” JAMA, 316(12): 1262–1264.

38

Frakt, Austin. 2019a. “‘Value’ of Care Was a Big Goal. How Did It Work Out?” The New York Times,
September 23.
Frakt, Austin. 2019b. “Which Health Policies Actually Work? We Rarely Find Out.” The New York
Times, September 9.
Freixas, Xavier, Roger Guesnerie, and Jean Tirole. 1985. “Planning Under Incomplete Information and the Ratchet Effect.” The Review of Economic Studies, 52(2): 173–191.
Froemke, Cecily C, Lian Wang, Matthew L DeHart, Ronda K Williamson, Laura Matsen Ko, and
Paul J Duwelius. 2015. “Standardizing Care and Improving Quality under a Bundled Payment
Initiative for Total Joint Arthroplasty.” The Journal of Arthroplasty, 30(10): 1676–1682.
GAO. 2018. “Voluntary and Mandatory EpisodeBased Payment Models and Their Participants.”
United States Government Accountability Office GAO-19-156.
Gronniger, T, M Fiedler, K Patel, L Adler, and P Ginsberg. 2017. “How Should the Trump Administration Handle Medicare’s New Bundled Payment Programs.” Health Affairs Blog, April.
Haas, Derek A, Xiaoran Zhang, Robert S Kaplan, and Zirui Song. 2019. “Evaluation of Economic
and Clinical Outcomes Under Centers for Medicare & Medicaid Services Mandatory Bundled
Payments for Joint Replacements.” JAMA Internal Medicine, 179(7): 924–931.
Heckman, James J, and Bo E Honore. 1990. “The Empirical Content of the Roy Mode.” Econometrica, 58(5): 1121–1149.
Ho, Kate, and Ariel Pakes. 2014. “Hospital Choices, Hospital Prices, and Financial Incentives to
Physicians.” American Economic Review, 104(12): 3841–84.
Ida, Takanori, Koichiro Ito, and Makoto Tanaka. 2020. “Selection on Welfare Gains and Policy
Design: Experimental Evidence from Electricity Plan Choice.” Working Paper.
Jack, B Kelsey, and Seema Jayachandran. 2019. “Self-Selection Into Payments for Ecosystem Services Programs.” Proceedings of the National Academy of Sciences, 116(12): 5326–5333.
King, Robert. 2019. “CMS to Use Mandatory Models ‘Very Judiciously,’ Official Says.” Modern
Healthcare, April 26.
Laffont, Jean-Jacques, and Jean Tirole. 1993. A Theory of Incentives in Procurement and Regulation.
MIT press.
Levy, S, N Bagley, and R Rajkumar. 2018. “Reform at Risk-Mandating Participation in Alternative
Payment Plans.” New England Journal of Medicine, 378(18): 1663–1665.
Liao, Joshua M, Mark V Pauly, and Amol S Navathe. 2020. “When Should Medicare Mandate
Participation In Alternative Payment Models?” Health Affairs, 39(2): 305–309.
Marone, Victoria R, and Adrienne Sabety. 2019. “Should There be Vertical Choice in Health Insurance Markets?” Working Paper. https://victoriamarone.github.io/jobmarket/
Marone_JMP_Vertical_Choice.pdf.
Navathe, Amol S, Andrea B Troxel, Joshua M Liao, Nan Nan, Jingsan Zhu, Wenjun Zhong, and
Ezekiel J Emanuel. 2017. “Cost of Joint Replacement Using Bundled Payment Models.” JAMA
Internal Medicine, 177(2): 214–222.
39

Newcomer, Lee N, Bruce Gould, Ray D Page, Sheila A Donelan, and Monica Perkins. 2014.
“Changing Physician Incentives for Affordable, Quality Cancer Care: Results of an Episode
Payment Model.” Journal of Oncology Practice, 10(5): 322–326.
Quan, Hude, Vijaya Sundararajan, Patricia Halfon, Andrew Fong, Bernard Burnand, JeanChristophe Luthi, L Duncan Saunders, Cynthia A Beck, Thomas E Feasby, and William A
Ghali. 2005. “Coding Algorithms for Defining Comorbidities in ICD-9-CM and ICD-10 Administrative Data.” Medical Care, 1130–1139.
Shatto, John D. 2016. “Center for Medicare and Medicaid Innovation’s Methodology and Calculations for the 2016 Estimate of Fee-for-Service Payments to Alternative Payment Models.”
Centers for Medicare and Medicaid Services.
Shepard, Mark. 2016. “Hospital Network Competition and Adverse Selection: Evidence From
the Massachusetts Health Insurance Exchange.” Working Paper. https://www.nber.org/
papers/w22600.
Thaler, Richard H, and Cass R Sunstein. 2003. “Libertarian Paternalism.” American Economic Review, 93(2): 175–179.
Zhu, Jane M, Viren Patel, Judy A Shea, Mark D Neuman, and Rachel M Werner. 2018. “Hospitals
Using Bundled Payment Report Reducing Skilled Nursing Facility Use and Improving Care
Integration.” Health Affairs, 37(8): 1282–1289.

40

Figure 1: Experimental Design
Eligible MSAs
(MSAs=171, Hospitals=1,455,
Episodes = 100%)

Treatment
(MSAs=67, Hospitals = 664,
Episodes = 42%)

Control
(MSAs=104, Hospitals = 791,
Episodes = 58%)
Year 1-2
Year 3+

Mandatory Treatment
(MSAs=34, Hospitals =
405, Episodes = 23%)

Voluntary Treatment
(MSAs=33, Hospitals =
259, Episodes = 19%)

Mandatory* Controls
(MSAs=52, Hospitals =
460, Episodes = 33%)

Voluntary* Controls
(MSAs=52, Hospitals =
331, Episodes = 25%)

Note: Figure shows the design of the bundled payments experiment. The top half shows the initial mandatory design in
program years 1-2, and the bottom half shows the partially voluntary design in program years 3-5. Episode shares are based
on data from program years 1-2.
∗ Control

group MSAs are assigned to mandatory vs. voluntary by authors using historical spending.

41

Figure 2: Hospital Selection Into Bundled Payment and Social Welfare Implications

;

!#17"'8'9
!"#"$%&')*
:--.$.",%#/
!#17"'8'=9'>
!"#"$%&'((!
!"#"$%&')*
+,"--.$.",%#/
%

<

Note: Figure shows, for a given target price t, the hospital participation decision and social welfare implications as a
function of the hospital’s λ and ω.

42

Figure 3: Model Illustration
(a) Impact of Raising Target Prices
@

(b) Larger ω, More Variable λ
1

!#2<"'='7

!#4<"'='9

!"#"$%&')*
;--.$.",%#/

!"#"$%&')*
0--.$.",%#/

!#2<"'='>7'?

!#4<"'='>9'?
!"#"$%&'((!
!"#"$%&'((!

!"#"$%&')*
+,"--.$.",%#/

!"#"$%&')*
+,"--.$.",%#/
%

%0

%

A

(c) Smaller ω, More Variable λ
;

2

(d) More Variable ω, Less Variable λ
;

!#1="'>'6

!#1="'>'6

!"#"$%&')*
:--.$.",%#/

!"#"$%&')*
:--.$.",%#/

!#1="'>'?6'@

!#1="'>'?6'@
!"#"$%&'((!

!"#"$%&'((!

!"#"$%&')*
+,"--.$.",%#/

!"#"$%&')*
+,"--.$.",%#/
%

%

<

<

Note: Figure illustrates some of the key analytics in voluntary bundled payment design. Panel A illustrates the
tradeoffs involved in setting higher target payments t′ > t; Panels B through D consider the impact of different
primitives and targeting, with Panel B vs. C comparing outcomes with higher vs. lower ω and Panel C vs. D
comparing outcomes with more vs less unobserved heterogeneity in λ.

43

Figure 4: Model Estimates
(a) No Target Price or Choice Shifter

(b) Target Price, Ignoring Choice Shifter

(c) Target Price and Choice Shifter

Note: Figure reports the empirical analogues of Figures 2 and 3. Specifically, it reports simulated hospitals based
on our estimates for the 259 hospitals in the voluntary treatment group (see Figure 1), with circles proportional
to the number of episodes. Panel (a) reports results assuming there are no target prices and the choice shifter νh
in the hospital selection equation is not decision-relevant. Panel (b) considers the role of target prices by plotting
λh3 − th − t on the horizontal axis. In addition to adding th , we subtract the average target price t, so that the axis
remains on the same scale as in Panel (a). In Panel (c), we not only net out target prices but also allow the choice
shifter νh to be decision-relevant.

44

Figure 5: Medicare Costs and Social Surplus Under Alternative Target Prices

Note: Figure plots social surplus per episode (relative to the FFS counterfactual) against government spending, and
correspond to the values in columns (5) and (2) of Table 4. See that table note for more details.

45

Table 1: Experimental Estimates
!"#$%"&'
()*#'

!"#$%"&'+,

-.)%*/)'
0%)*$1)#$'
233)4$

+$*#5*%5'
2%%"%

67.*&8)

;<=>?@
B>=<@A
@=B;;
B=H?B
<=H><

>=A?B
;=>HC
B=>H?
DBH
<>B

7CDC
7BC<
7@DH
7HD
;A

;?@
HD
B;H
<D
<<

?E??B
?E?A
?E??B
?EB@
?EA@

;EA
CEC

?E@
;E>

7?EB
7?EA

?E?
?E;

?E;B
?E?;

,9:4J*%/)',):$9#*$9"#
F#:$9$8$9"#*&'6":$'-48$)'!*%)
I"1)'I)*&$J'-/)#4P
I"1)'QRS"'I"1)'I)*&$J'-/)#4PT
K$J)%

?E>B>
?E>>D
?E>;D
?E?;?

?EB?@
?EBDA
?E;>;
?E?>;

7?E?>@
?E??@
?E?@;
7?E??@

?E??D
?E?BH
?E?BH
?E??;

?E??B
?EHB
?E?;
?E?<

U".)%#1)#$'+V)#59#/

;<=>?@

>=A?B

>>

;?H

?EHH

?E?BB
?EBDD
?EB?;

?E??<
?E?;C
?E?B<

?E??B
?E??>
7?E??B

?E??B
?E??>
?E??;

?E;A
?E@B
?EAD

;DED
;>EA
;E@

B<EH
BBE>
?E>

7?EH
?EB
?E?

?E<
?E<
?E?

?EB?
?EHD
?EDH

!"#$%&'(&)%"*+,-&./*%*0"/*1#-&"#2&3145/&67$#2*#8&97$:&;7*,12$<
!&*91:
!&*91:'3"%'F#5)G'-519::9"#
!&*91:'3"%'F#:$9$8$9"#*&'6-!
!&*91:'3"%'I"1)'I)*&$J
K$J)%'!&*91:
L$9&9M*$9"#
N81O)%'"3',*P:'9#'F#5)G'-519::9"#
N81O)%'"3',*P:'9#'F#:$9$8$9"#*&'6-!

!"#$%&=(&>?"%*/@&A$",?:$,
!"1V&94*$9"#'W*$)
2W'X9:9$',8%9#/'2V9:"5)
D?75*P'-&&'!*8:)'W)*519::9"#'W*$)
!"#$%&)(&'2+*,,*1#,&"#2&!"/*$#/&)1+71,*/*1#
Y2ZW'-519::9"#:'QV)%'B=???')#%"&&)):T
!ZW7)&9/9O&)'Y2ZW'-519::9"#:'QV)%'B=???')#%"&&)):T
2&9GJ*8:)%'!"1"%O959$P'+4"%)

Note: Table shows results from estimating equation (1) by OLS on period 2 data; the regression includes strata fixed effects
and lagged outcomes from period 1. Standard errors are heteroskedasticity robust. Control means and standard deviations
are from period 2. “Claims” include patient cost-sharing. Complication rate is defined, as in Finkelstein et al. (2018), as the
share of CJR-eligible patients who have at least one of eight underlying complications that go into the total hip arthroplasty
/ total knee arthroplasty 90-day complication measure used in the targeted quality score.

46

Table 2: Selection

1$23,(4"546"789&'#7
1$23,(4"54?897"@,749%4A,(9"@4;
A,(-,%&4"54?897"@,749%4A,(9"@4;

!"#$%&'()
*"%&("#

!"#$%&'()
+,#,-&./%

!"#$%&'()
+,#,-&.0$&

::;
B;CBDD

<:
;EC>>E
:<GFH

;=>
FEC<=D
>FG=H

F>CBF:
JBC:>=K
EC=;F
JFCEI:K
:>GDH
J;>GIHK

F>C;E>
JEC;<>K
EC>=;
JFCIBEK
:<G:H
J;>GFHK

F<C<<<
JBCED=K
BCBBF
JFCEE=K
E;G>H
J;EGBHK

.<D>
J;CD:FK
.B;D
JD<:K
.:G:H
J<G=HK

.>>D
JFC=:;K
.;<<
J;CE<EK
.;GFH
JDGFHK

:FI
>FGIH
EG:H
F>G>H
>:GEH
;IGIH
<DGFH
BG:H
::G;H
;EGBH
E<G;H

FB;
>IG;H
;>G;H
;FGBH
>=G>H
;=GDH
BDG:H
IG>H
BFGFH
FFGEH
FEG=H

! .S'#$,4"54+,#,-&.
/%4S7G4+,#,-&.0$&4
N955,(,%-,

!"#$%&'(&)$%$*+,-#&-#&.$/$%0&1!$2,-3&4&56+*-7$0&8$2&98,0-3$:
*#'927
*#'92745"(4/%7&9&$&9"%'#4A"7&4L-$&,4*'(,
+M'(,4N97-M'(O,@4&"4/%7&9&$&9"%'#4A"7&4L-$&,4*'(,

IGI:
IGIF
IG;I

!"#$%&;(&)$%$*+,-#&-#&)%-8$0
/28'-&4"%4,897"@,4-#'927
/28'-&4"%4/%7&9&$&9"%'#4AL*4-#'927
/28'-&4"%4+M'(,4N97-M'(O,@4&"4/%7&9&$&9"%'#4AL*

IG<:
IGIB
IG;:

!"#$%&<(&)$%$*+,-#&-#&=-08,+"%&<>"2"*+$2,0+,*0
P,'%41$23,(4"54*QR4?897"@,7
L3"S,4P,@9'%4T,@7
U,'-M9%O
V"(.8("59&
1"%.8("59&
W"S,(%2,%&."X%,@
+M'(,4X9&M4L3"S,4P,@9'%4Y$'#9&)
1"(&M,'7&
P9@X,7&
+"$&M
Z,7&

:I>
>IG>H
;=G<H
;<GBH
<=GBH
EGIH
>IGIH
=GEH
::GEH
FFGEH
:BG:H

IG;E
IG=F
IGIF
IGI>
IGB<
IGFI
IGI;
IGI=
IGI:
IG:;
IGIF

Note: Table reports means (and standard deviations in parentheses). In Panel A, all outcomes are defined in period 1 (although the target price is defined in period 2). Panel B reports the average (and standard deviation) over different hospitals
of β 1,h from estimating equation (2) by OLS. In Panel C, the ‘’above median CJR episodes” comes from period 1 data, and
“Above Median Beds”, “Teaching”, “For-profit”, “Non-profit”, and “Government-owned” variables are all based on data
from the 2016 American Hospital Association annual survey; we are unable to match 3 hospitals to these survey. For these
outcomes, the number of hospitals in control, select-in, select-out are 329, 73, and 185, respectively. Finally, “Share with Above
Median Quality” is based on a modified version of the hospitals’ composite quality scores from period 2, which is based on
the first 18 points of the score (see footnote 6). p-values of differences are computed based on a simple t-test of equality of the
means.

47

Table 3: Parameter Estimates
!"#$%&'(&!")"*$+$)&,-+.*"+$!"#$%&#'
!" #
-.*-/
$"
.*-12
%&
3.*.12
$ '&
.*.11
µω
/*055
σω
-*4..
ρ λ ,ω
.*5..
ν
3-47...
!
.*/..
!"#$%&/(&0*1%.$2&3.-+).45+.6#!89:
/787&'%%&96-1.+"%λh
6470.6
λ h3
6/7-0=
ωh
501

(#)*+!,,*
.*.-0
.*../
.*../
.*..4
.*2.0
.*645
.*.26
-57112
.*-.(;89:

<4

<64

<4.

<24

<=4

/7555
/752/
-7-6/

-=75/-2726--

667250
6-7.=.
/1

647//4
6570.5
-64

607/24
617014
5//

557/22
5-7=25
-7/21

/7:7&;6-1.+"%-&.#&+9$&<6%5#+")=&>)$"+*$#+&?)651&@#%=
λh
647=20
47/-6
-07/64
λ h3
6/7//5
47146
-170.4
t h - λ h3
304
/70=4
307650
ωh
/.5
-7.00
-(t h - λ h3 ) + ω/2
--1
/70/2
327=/1
ν/n hᴷ
3-7/-=
4-5
367510

6-7=02
6.76..
367=46
/2
367254
3-7425

647521
65720=
-04
-60
500
3-76=2

6=7.2=
6271.4
672-541
67023-7-6/

547241
5/712.
27416
-7/06
27126
30/4

Note: Panel A reports parameter estimates from the model and Panel B.1 reports some key summary statistics implied by
these estimates for all 1,455 hospitals. Standard errors are calculated using the bootstrap method, based on 20 samples of
hospitals drawn with replacement from cells defined by the full interaction of treatment assignment and strata. Panel B.2
reports these implied statistics separately for the 259 hospitals in the voluntary treatment group (see Figure 1). The model is
estimated weighting each hospital by the number of episodes. The summary statistics in panels B.1 and B.2 are computed
from hospital-level simulated data, weighted by the number of episodes per hospital.
⋆

Episode-weighted average of strata-specific estimates.

48

49

EFEG
4EEFEG
7IFIG

68H887
68H79I
6:H469

365

345

796
;67
4H4K4
6HE;8
4H7I4
K97

E
JKI
4HK77

375

!"#$%&'"(
0*1&$#(S*+%+

7K4
;4I
4H46:
4HIIE
4H6;K
K48

E
44:
4H;98
7K
J9
J::
J4K8
J4E6
J7K

E
648
J4;K

RM=*.&=M(SB*&1"(0B&/%".
!"#$%&'"()*+,&%$#( !"#$%&'"(0*1&$#(
-.*/&%
02.,#2+
385
395

49:
79;
:;E
4H794
;K:
8K;

E
J4H7E6
4H68I

J4K:
J7::
J964
J;67
J9I9
J89:

E
J4H6E8
J:I9

R=1*.,*.$%&=M(SB*&1"(0B&/%".
!"#$%&'"()*+,&%$#( !"#$%&'"(0*1&$#(
-.*/&%
02.,#2+
3:5
3;5

Note: All counterfactuals are conducted on the 259 hospitals in the voluntary treatment group (See Figure 1). We weight the hospital-level simulated data by
the number of episodes per hospital, so that the statistics are representative of the average episode. In Panel A, row 1 reports results from the counterfactual
in which BP does not exist and all hospitals are paid FFS, row 2 reports results from a mandatory participation bundled payment counterfactual, and row
3 reports results from the observed voluntary participation bundled payment regime. Panel B reports results from counterfactual voluntary participation
regimes that vary in their target prices. Column 2 reports Medicare spending (G from Equation 5). All other columns report results relative to the FFS
counterfactual. Column 3 reports relative social costs (i.e. (1 + Λ)((th − λh ). Columns 4 and 5 report hospital profits and social surplus relative to the
FFS counterfactual, under the assumption that νh is not welfare relevant; therefore hospital profits relative to FFS are given by (th − λh ) + ω2h , and social
surplus relative to FFS is given by ( ω2h − Λ)(th − λh ). Columns 6 and 7 report relative hospital profits and social surplus when νh is welfare relevant and
therefore subtracted from both.

!"#$%&4(&'%+$-#"+5/$&2,%3#+"-.&6$758$0&95+:&;5<<$-$#+&="-7$+&!-5>$0
4KFKG
68H;8K
-"./"1%(%$.M"%&=M
@"$+&N#"(%$.M"%&=M
6KF8G
69HE;7
ON+".'">(%$.M"%&=M
79FIG
69H8IE
P*(%$.M"%&=M
84F8G
6:H68;
P$..*Q(N2=>#"H(=*(%$.M"%&=M
7IF:G
69H:88
P$..*Q(N2=>#"H(*N+".'">(%$.M"%&=M
77F:G
69H6;7

!"#$%&'(&)"#*"+,-.&/01&2,%3#+"-.
<$=>$%*.?(@@0((3A"=1BC$.D5
<$=>$%*.?(A2=>#">(-$?C"=%
L*#2=%$.?(A2=>#">(-$?C"=%(

T*'".=C"=%(
0,"=>&=M

0B$."(
0"#"1%&=M(R=(

Table 4: Counterfactuals

Voluntary Regulation:
Evidence from Medicare Bundled Payments
Online Appendix
Liran Einav

A

Amy Finkelstein

Yunan Ji

Neale Mahoney

Maximum Likelihood Estimation

We estimate the parameters of the model using two-step simulated maximum likelihood. For
notational convenience, let HC = { h : BPh2 = 0} be the set of control group hospitals, and let
HCs be the subset of control group hospitals in stratum s. Similarly, let HT = { h : BPh2 = 1}

be the set of treatment group hospitals. Finally, let HV be the set of treatment group hospitals
who were given the decision whether to voluntarily select into the BP program in period 3 and
HM := HT \ HV be the set of treatment group hospitals who were mandated to remain in the

program.

We weight hospitals according to the average number of CJR episodes at that hospital so
that our estimates are representative of the average episode in our sample. Let wh denote these
hospital importance weights and let WC = ∑h∈ HC wh denote the sum of control hospital weights
and WCs = ∑h∈ HCs wh be the sum of hospital weights in stratum s.
In the first step, we estimate the parameters θ1 = {µλ , σλ , γ, σǫ } that determine the evolution

of λ using data from the control group alone. The first step log likelihood is
ln L =

∑
h∈ Hc

wh ln f (yh1 , yh2 |θ1 )

(7)

where {yh1 , yh2 } are data and f is their joint density function.

Our distributional assumptions imply that ln yh1 and ln yh2 are jointly normally distributed,

allowing us to derive the maximum likelihood estimators in closed form. The first step maximum
likelihood estimators are:
b=
γ

1
WC

∑
h∈ HC

wh [ln yh2 − ln yh1 ]

(8)

1
b + ln yh2 ] for s = 1 . . . 8
wh [ln yh1 + γ
2WCs h∈∑
HCs
s
1
d
b)(ln yh2 − µ
d
σbλ =
wh (ln yh1 − µ
λ,s + γ
λ,s )
WC h∈∑
HC
v
"
#
u
u 1
2
2
d
b)2 + (ln yh2 − µ
d
wh [(ln yh1 − µ
σbǫ = t
λ,s + γ
λ,s ) ] − σbλ
2WC h∈∑
H
d
µ
λ,s =

(9)
(10)

(11)

C

In the second step, we estimate the remaining parameters θ2 = {µω , σω , ρλω , ν} of the joint
distribution of {λ, ω } and choice shifter ν, conditional on the first step estimates θb1 . Because the
50

control-group hospitals provide no information about these second-step parameters, the entire
second step relies only on the hospitals in the treatment group. The second-step log likelihood is
thus given by

∑

ln L =

h∈ HV

wh ln g1 ( BPh3 , yh2 |θb1 , θ2 , yh1 ) +

∑
h∈ HM

wh ln g2 (yh2 |θb1 , θ2 , yh1 )

(12)

where g1 is the joint distribution of { BPh3 , yh2 } and g2 is the marginal distribution of yh2 .

Operationally, we estimate the joint distribution by decomposing it into the conditional choice

probability and marginal distribution

so that

ln g1 ( BPh3 , yh2 |θb1 , θ2 , yh1 ) = ln Pr( BP = BPh3 |θb1 , θ2 , yh1 , yh2 ) + ln g2 (yh2 |θb1 , θ2 , yh1 ),
ln L =

∑
h∈ HV

wh ln Pr( BP = BPh3 |θb1 , θ2 , yh1 , yh2 ) +

∑
h ∈ HT

wh ln g2 (yh2 |θb1 , θ2 , yh1 ).

(13)

(14)

Since neither the choice probability nor the marginal distribution of yh2 has a closed-form solution
(because they depend on yh2 = λh2 − ωh , which is the difference of two log normally distributed

variables), we need to use simulation to construct the likelihood function. For a given set of parameters θ2 , we simulate many values for λh2 and ωh . We then estimate the marginal density using
a kernel estimator and multiple it by the choice probability to construct the simulated likelihood.
We tested our estimator by simulating data based on known parameters and then estimating the model on these simulated data. We found that the estimator performed well when we
draw 50,000 values for each set of candidate parameter values, and estimate the marginal density
function g2 using a Epanechnikov kernel with a bandwidth of 400. We maximize the likelihood
by conducting a grid search over θ2 , which in testing we found worked more reliably than other
methods.

B

Target Price Distribution

For the estimation of the model we use the observed target prices. However, in order to explore the
impact of better targeting in a systematic fashion in our counterfactual exercises, we approximate
the observed target prices using a parametric distribution, and then change these parameters. In
this appendix we provide more details about this exercise.
We model target prices as log normally distributed, such that they are correlated with hospitals costs λh (but only correlated with ωh via the correlation between λh and ωh ). Since target
prices are partially based on lagged hospital spending, and we allow mean hospital spending to
vary by strata, we also allow the mean of the target price distribution to vary by strata.
Following the notation in Appendix A, let HT = { h : BPh2 = 1} be the set of treatment

group hospitals. We weight hospitals according to the average number of CJR episodes at a given
hospital. Let wh denote these hospital importance weights and let WT = ∑h∈ HT wh denote the sum
51

of treatment hospital weights and WTs = ∑h∈ HTs wh be the sum of hospital weights in strata s.
We only observe target prices for treatment group hospitals in period 2. Using these data,
the maximum likelihood estimators for the mean and standard deviation of the log target price
distribution are given by:
1
wh ln th2 for s = 1 . . . 8
WTs h∈∑
HTs
s
1
wh (ln th2 − µcts )2 .
σbt =
∑
WT h∈ H
µcts =

(15)
(16)

T

We estimate ρλt using the covariance between log spending in period 1 (ln yh1 ) and the period
2 log target price (ln th2 ). The covariance is given by
Cov(ln yh1 , ln th2 ) = Cov(ln λh − γ + ǫh1 , ln th2 ) = Cov(ln λh , ln th2 ) = ρλt σλ σt

(17)

where the ǫh1 drops out because it is assumed to be independently drawn and thus Cov(ǫh1 , ln th2 ) =
0.
It follows that the maximum likelihood estimator of the correlation is
ρc
λt =

1 1
σbλ σbt WT

∑
h ∈ HT

b)(ln th2 − µcts ).
wh (ln yh1 − µc
λs + γ

(18)

b are the estimates described in Appendix A. For our counterfactuals, it will be
where σbλ , µc
λs , and γ

more natural to adjust the correlation between λh3 and ln th (than the correlation between λh and
σbλ
ρc
ln th ). This object is given by ρd
λt .
λ3 t = q
σbλ 2 + σbǫ 2
To examine the impact of better targeting, we simulate data using different parameters for the
target price distribution, and then examine how these alternative target prices impact selection,
Medicare costs, hospital profits, and social surplus. We simulate data in two steps. First we
draw values for {λh3 , ωh } conditional on the observed th and nh . To do so, we draw from the
unconditional distribution of {λh3 , ωh } and then keep the draws that imply an optimal selection
decision such that BP = BPh3 at these values.

Second, we draw target prices for a given set of parameters, conditional on the simulated
j

j

values of λh3 from step 1. Let j be a counterfactual associated with the triplet {µt , σ j , ρλ3 t } for the
j

j

j

distribution of target prices th . Since th and λh3 are jointly log normal, the conditional values of th
can be simulated as
j

j
th

=

j
µt

+

j

ρλ3 t σt
σλ3

(λh3 − µλ ) +

q

j

j

1 − (ρλ3 t )2 σt ǫh

(19)

where ǫh ∼ N (0, 1) is an independent, normally distributed random variable. Importantly, we

keep the draws of ǫh for each hospital fixed throughout the set of counterfactual exercises, so that
52

differences in outcomes across exercises are not driven by simulation variation.

C

Stop-Loss and Stop-Gain

As we discussed in Section 2, CJR was not implemented as a “pure” bundled payment program.
Instead, like most bundled payment programs, it limited risk exposure to both hospitals and Medicare. In particular, the reconciliation payments for the difference between target prices and realized FFS claims were capped on either side by stop-gain and stop-loss amounts. These amounts
increased from a stop-gain of 5 percent of th and a stop-loss of zero (meaning that hospitals would
never need to make payments to Medicare) in year 1, to stop-gain and stop-loss amounts of ± 20

percent of th in years 4 and 5 of the program.

Qualitatively, we do not see these provisions as affecting the basic economics of the environment. For instance, while some hospitals receive smaller reconciliation payments when the
stop-gain binds, because this provision targets the tail of the distribution, the affected hospitals
are unlikely to be marginal in their selection decision. The same logic holds for the cap on losses.
To quantitively assess the importance of the stop-gain and stop-loss provisions, we estimate
an alternative version of the model that caps reconciliation payments at ± 20 percent and we redo

our counterfactuals with these estimates. In testing, we found that we required a larger number of
draws for reliable estimation of the model, and this was not feasible on the computer server with
the research identifiable claims data. To estimate this alternative model, we therefore removed
hospital-level data for the 1,326 of 1,455 hospitals where we had adequate sample size to preserve
anonymity (11 or more episodes in periods 1 and 2) and estimated the model on a more powerful
computer server. The hospitals we dropped are those with the smallest number of episodes, and
we confirmed that the estimates of the baseline model (without stop-gain or stop-loss) were very

similar when they were excluded. Appendix Table A3 reproduces Table 4 using the stop-loss and
stop-gain version of the model. While the exact numbers are slightly different, the qualitative
patterns in the tables are identical and the quantitive estimates are very similar.

53

Figure A1: Selection on Hospital Characteristics
(b) Composite Quality Score

0

0

Selection Into Treatment
.02
.04
.06
.08

Selection Into Treatment
.001
.002
.003
.004

.1

.005

(a) Pre-Period CJR Episodes

0

200
400
600
Number of CJR Episodes in Pre Period
Hospital Selected In

800

0

Hospital Selected Out

5

10
Official CQS

Hospital Selected In

15

20

Hospital Selected Out

Note: Figure shows kernel densities of hospital characteristics by whether the hospital selected in or out of the
CJR program in period 3.

54

Table A1: Experimental Estimates: Alternative Specifications
(4+?X),)&;'M#S)7-K$)F
!"#$%"&'
()*#'''
3456
!"#$%&'(&)$"%*+,"-$&./$&"#0&12$#03#4
!&*7/8

9:;<=>
3<;C=D6

!&*7/8'1"%'E#F)G'+F/7887"#

D<;:>C
39;<B@6

!&*7/8'1"%'E#8$7$H$7"#*&'I+!'

>;D99
3D;<B=6

!&*7/8'1"%'J"/)'J)*&$K

D;B=D
3ADB6

L$K)%'!&*7/8

:;B<:
3:<D6

M$7&7N*$7"#'()*8H%)8
OH/P)%'"1'5*Q8'7#'E#F)G'+F/7887"#

OH/P)%'"1'5*Q8'7#'E#8$7$H$7"#*&'I+!

5782K*%-)'5)8$7#*$7"#
'E#8$7$H$7"#*&'I"8$'+2H$)'!*%)

9RC
3=R>6
@R@
39R<6

=R<D<
3=RD=>6

'J"/)'J)*&$K'+-)#2Q

=R<<A
3=RDAC6

'J"/)'3ST"'J"/)'J)*&$K'+-)#2Q6

=R<9A
3=R9<96

'L$K)%

=R=9=
3=R=<96

!"#$%&5(&67"%3*8&9$"/7-$/
!"/U&72*$7"#'V*$)

=R=DD
3=R==:6

0V'W787$'5H%7#-'0U78"F)

=RDAA
3=R=9@6

A=?F*Q'+&&'!*H8)'V)*F/7887"#'V*$)

=RD=9
3=R=D:6

!"#$%&:(&'0;3//3<#/&"#0&!"*3$#*&:<;2</3*3<#
X0YV'+F/7887"#8'3U)%'D;===')#%"&&))86

9ARA
3D:RB6

!YV?)&7-7P&)'+F/7887"#8'3U)%'D;===')#%"&&))86

9<RC
3DDR<6

0&7GK*H8)%'!"/"%P7F7$Q'42"%)

9R>
3=R<6

+,)%*-)'
.%)*$/)#$'
011)2$'
3406''
!"#$%&'
?@A@
39=>6
()((*
?D@:
3BA6
()(.
?>AB
3D9B6
()((*
?BA
3:A6
()*1
9C
3::6
().1

(4+?X),)&;'Z)7-K$)F
!"#$%"&'
()*#'''
3456

9:;BAA
3<;<>>6
D<;@:>
39;=@A6
>;DD@
3D;99=6
D;AA@
3B@96
C;=<9
3:<B6

?=RD
3=R=>6
()/*
?=RC
3=R9<6
()(/

9RC
3=R<6

?=R=<>
3=R==A6
()((*
=R==>
3=R=DB6
()-*
=R=>9
3=R=DB6
()(/
?=R==>
3=R=DB6
()(,

=R<9=
3=R=A<6

=R==D
3=R==D6
()/.
=R==<
3=R==<6
()1*
?=R==D
3=R==96
().2

=R=DD
3=R==>6

?=RB
3=R:6
()*(
=RD
3=R:6
()-2
?=R==D
3=R=9A6
()2-

9@R<
3D<RC6

@RC
3DRA6

=R<@B
3=RD@<6
=R9BA
3=R9D96
=R=D<
3=R=9<6

=RDA>
3=R=9D6
=RD=<
3=R==>6

9DRD
3AR@6
9R<
3=R96

+,)%*-)'
.%)*$/)#$'
011)2$'
3406''
!"#$%&'
?:A<
39D<6
()((+
?DD@
3AD6
()/(
?<<<
3D9D6
()((+
D@
3B@6
()-,
D=
3>>6
()-/

J"8U7$*&?X),)&;'Z)7-K$)F
!"#$%"&'
()*#'''
3456

9:;BAA
3:;D>96
D<;@:>
39;C@=6
>;DD@
39;>DD6
D;AA@
3AAC6
C;=<9
3D=>A6

?=R=D
3=R=>6
()+0
?=R<
3=R9D6
()*1

9RC
3=RC6

?=R=9D
3=R==A6
()(/(
=R=9:
3=R=DA6
()*2
=R=D<
3=R=DB6
()1,
?=R==>
3=R==96
()(-

=R<9=
3=RD:D6

=R==D
3=R===:6
()(/
=R==9
3=R==96
()1/
?=R==9
3=R==96
()//

=R=DD
3=R=D=6

?=R:
3=R<6
()*.
=RD
3=R:6
()-+
?=R==C
3=R=9B6
()-,

@RC
3>R96

=R<@B
3=R9996
=R9BA
3=R9C:6
=R=D<
3=R=<=6

=RDA>
3=R=>@6
=RD=<
3=R=<D6

@RA
3D9R>6
CR@
3AR:6
9R<
3=R>6

+,)%*-)'
.%)*$/)#$'
011)2$'
3406''
!"#$%&'
?>=@
39BC6
()*,?>@
3D<<6
()+0
?<9<
3D9<6
()(*(
9C
3BA6
()+BA
3BC6
()0(
=R=
3=R=>6
()-+
?=R>
3=R9D6
()(?=R=9D
3=R==A6
()(/(
=R=9C
3=R=DB6
()*.
=R==:
3=R=9=6
()-/
?=R==>
3=R==96
()(,
=R==9
3=R===:6
()(*
=R==9
3=R==<6
(),*
?=R==D
3=R==96
()1(
?=R:
3=R96
()(/
?=R>
3=R96
()(/
?=R===D
3=R=9@6
*

Note: Table compares regression estimates in Table 1 with estimates from two alternative specifications:
an MSA-level specification, where observations are weighted based on number of episodes in the MSA
in period 2, and a hospital-level specification where observations are weighted based on the number of
episodes at the hospital in period 2. See Table 1 note for more details.

55

Table A2: Selection on Slopes with Hospital-Specific Trends
!"#$%&%$'(%)*+

N'7#-%*#

O%(K1P)7"%('-2!"#$%&%$1Q/#*;

52,'-.#1)&1!#-#$(23*1
,)-.*('/011 ,)-.*('/01!#-#$(2
6781!#-#$(24.(1
!#-#$(23*
4.(
9%&&#/#*$#
3:"'$(1)*1#"%7);#1$-'%:7
3:"'$(1)*13*7(%(.(%)*'-15IJ1$-'%:7
3:"'$(1)*1!K'/#19%7$K'/L#;1()13*7(%(.(%)*'-15IJ

2<=>
EFG=@AH
2CF=
E=<@H
2@8@M
E<8BMH

2>>=
EAGB@FH
2F<<
EFGD<DH
2F8AM
E=8AMH

?8<@
?8?C
?8F@

,)-.*('/01111
!#-#$(23*

2@>A
EDG@@CH
2@?C
EAGB=>H
2@8?M
EF>8?MH

,)-.*('/01111
!#-#$(24.(

@BC
EF?G?FBH
D>
EDGB<>H
2?8<M
EAA8CMH

52,'-.#1)&1!#-#$(2
3*16781!#-#$(24.(1
9%&&#/#*$#
?8DA
?8D=
?8D>

Note: The panel titled “Baseline” replicates Table 2 Panel B from the paper, and reports the average (and standard
deviation) over different hospitals of b1,h from estimating equation (2) by OLS. The panel titled “With HospitalSpecific Trend” reports the analogous results from estimating and augmented version of equation (2), which additionally controls for hospital-specific linear time trends. Specifically, we report estimates of β 4,h from the regression
yh = β 0 + β 1,h + β 2,t + β 3,h × t + β 4,h × BPh + ǫh,t , where β 1,h are hospital fixed effects, β 2,t are calendar year fixed
effects, β 3,h × t are hospital fixed effects interacted with a linear time trend, and β 4,h × BPh are hospital fixed effects
interacted with an indicator for treatment hospitals in period 2 (when bundled payment was in effect); we estimate
this equation using data from 2013, 2014, 2016 and 2017. All estimates are weighted by the number of episodes in the
hospital in period 2. The p-values in columns (3) and (6) are based on robust standard errors.

56

57

79I
::7
4HE9E
4HI78
4H667
I:E

E
44;
4H;6I
L
J7;
JL:
J66L
J478
J;6

E
47E
J647

RM=*.&=M(TB*&1"(0B&/%".
!"#$%&'"()*+,&%$#(
!"#$%&'"(0*1&$#(
-.*/&%
02.,#2+
385
395

494
787
:7I
4H779
;;L
8I9

E
J4H766
4H67:

J4LI
J79;
J9EL
J;6I
J9;I
J88;

E
J4H7EI
J;E8

R=1*.,*.$%&=M(TB*&1"(0B&/%".
!"#$%&'"()*+,&%$#(
!"#$%&'"(0*1&$#(
-.*/&%
02.,#2+
3:5
3;5

Note: Table reports analogue outcomes to Table 4 based on an alternative specification of the model with stop-loss and stop-gain provisions for reconciliation payments. See Appendix Section C for more details.

78L
;EE
4H48:
6HE:6
4H79;
L76

!"#$%&4(&'%+$-#"+5/$&2,%3#+"-.&6$758$0&95+:&;5<<$-$#+&="-7$+&!-5>$0
-"./"1%(%$.M"%&=M
4LFIG
68H:;7
@"$+&N#"(%$.M"%&=M
6IFIG
68HL;I
ON+".'">(%$.M"%&=M
79FEG
69H7::
P*(%$.M"%&=M
84F4G
6:H4:7
P$..*Q(N2=>#"H(=*(%$.M"%&=M
7IF4G
69H99E
P$..*Q(N2=>#"H(*N+".'">(%$.M"%&=M
77FEG
69H4IE

375

E
J47
4HL84

EFEG
4EEFEG
7IFLG

365

!"#$%&'"(0*1&$#(
T*+%+

68H7;E
68H79I
6:HE9;

!"#$%&'(&)"#*"+,-.&/01&2,%3#+"-.
<$=>$%*.?(@@0((3A"=1BC$.D5
<$=>$%*.?(A2=>#">(-$?C"=%
K*#2=%$.?(A2=>#">(-$?C"=%(

345

0B$."(0"#"1%&=M( S*'".=C"=%(
R=(
0,"=>&=M

Table A3: Counterfactuals from Alternative Specification with Stop-Loss and Stop-Gain Provisions

