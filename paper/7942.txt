 # &  

     

  
  
   !"
#!$ %!'()*
++%,--.../!!$-%%!-.'()*
  
   
0121 34++ 54
 /!6$7  1*089
3+/! *111




                    
   !    !             
             "   #    
! $  ! #   %  & '  ( &   
        )  " *  
+,---. /   '! 0'     $   & 
&(   1(&       +
    

  
         
        
!" # $  ! %&'(
) *  (+++
,- ! ./
$%#%
           
 2 1 

   0

    *0  

3   

    

1   

0    4

    *0  *  *1    0  
 4   

 **0  1           

0 1          

 0    

    0 *  )
  1 2

  

 

2  
5  

     

  0    * 

   *0    

      

  0 2 *            
            #   

      

  0      

       
 ) 1 2    
    



  



    



"!   .



  

  0    2   

      

0 *  #



        2   0  

   26          *0



 

    2  )  1 *             1 
      6 )-7      



       

    0   26   2  1      
   

 6     



 2 


   
     
  !"#$$%&&'"
()
(*+, (,

 
    
      
  !"#$$%&&'"
*+, (,

Health economists and other empirical researchers often debate the advantages and disadvantages of various functional forms used in regression analyses. Researchers frequently use, for
example, logarithmic transformations of the dependent variable when the variable exhibits significant skewness. Often it is the level of the dependent variable that is of interest in the analysis
and retransformation of the estimated predictions is necessary. Many health outcomes are also
characterized by a signi cant point mass at zero. It has become common among health economists
to use a two-part model even though the outcome of interest is typically the unconditional outcome
that includes the zero values. Examples of health outcomes exhibiting skewness and point mass
at zero include health care expenditures, number of doctor visits, and duration of hospital stay.
Several recent papers have addressed these modeling issues from a variety of points of view (e.g.,
Mullahy, 1998; Manning, 1998; Angrist, 2000; Manning and Mullahy, 2000).
Retransformation and two-part modeling require that the researcher make distributional assumptions. For example, in order to obtain predicted values of the unconditional level outcomes
from a logarithmic transformed dependent variable, a researcher must retransform the predicted
logged dependent variable. This retransformation requires assumptions about the dependence of
the error term distribution on observable covariates. One also must specify assumptions about the
relationship between the errors of the marginal and conditional outcomes represented in two-part
models. To our knowledge there is no general empirical approach that simultaneously \makes irrelevant" the decision to transform or not and the choice of two-part versus one-part modeling while
also allowing for possibly complex interactions of explanatory variables on the outcome of interest.
Our goal in this paper is to provide such an approach.
In this paper we describe a relatively simple estimation approach that \solves" the transformation problem while incorporating explicitly the potential confounding e ects of two-part models.
Our estimation strategy uses sequences of conditional probability functions, similar to those used in
discrete time hazard rate analyses, to construct a discrete approximation to the density function of
the outcome of interest conditional on exogenous explanatory variables. Once we have constructed
the conditional density function, it is straightforward to examine expectations of arbitrary functions
of the outcome of interest and to evaluate how these expectations vary with observed exogenous
covariates. Our implementations of the approach use exible functional forms when de ning the

1

sequences of conditional probabilities. This means that we have exible representations of the conditional density functions, and consequently exible representations for regression functions such
as the expected value of the outcome conditional on exogenous covariates.
In our formulation we construct the sequences of conditional probabilities using standard
binary outcome models. In our Monte Carlo experiments and health economics application we
use a logit probability model because of its simplicity, but any binary outcome model could be
used. We allow the arguments of these conditional probability functions to be loosely-speci ed
polynomial functions of covariates. These models can then be estimated using standard computer
packages such as SAS and Stata. In fact, we used Stata for all of the Monte Carlo experiments
and real application estimates reported in this paper. It is simple for researchers to implement this
approach in practice.
The approach we use naturally admits variations in covariate e ects over particular ranges
of the variables. It might be the case, for example, that particular variables have no impacts on
an outcome of interest until the outcome exceeds some pre-speci ed cuto level. Characteristics
of one's health insurance contract (e.g., the deductible, the coinsurance rate after exceeding the
deductible, and the maximum out-of-pocket expenditure) are obvious examples in the health insurance literature where the economic impacts of these covariates vary over the range of the dependent
variable. One could, in principal, model directly how such features e ect the budget constraint and
then solve for the correct demand function to use in a least squares estimation. The resulting
functional form for the regression model would almost always be quite nonlinear, and it would
depend crucially upon arbitrary distributional and functional form assumptions. The approach we
examine here incorporates such e ects with almost no modi cation.
While the presence of unobserved individual heterogeneity could limit a researcher's ability
to translate such economic restrictions directly to restrictions in a statistical model, these types
of functional restrictions can provide key information to help identify nonparametrically both the
behavioral relationship and the heterogeneity distribution (Mroz and Weir, 1990; Hahn, Todd,
and Van der Klaauw, 2000); this is a clear case where a well-speci ed economic theory can help

2

provide identi cation without the imposition of arbitrary functional forms.1 The discrete conditional density estimation approach we use can be applied directly to a wide range of situations
where researchers have relied upon restrictive functional forms and distributional assumptions. It
is straightforward to apply the approaches we describe to: discrete time hazard rate models (Allison, 1984); ordered data models, where researchers almost always assume either an ordered logit or
an ordered probit model with covariate-invariant cuto points (Maddala, 1983); count data models, where most researchers use a Poisson model or simple, parametrically restrictive modi cations
of the Poisson such as the negative binomial model or the zero-in ated Poisson model (Cameron
and Trivedi, 1998); and multinomial models with mutually exclusive outcomes, where researchers
have relied almost exclusively on multivariate probit or logit models (Maddala, 1983). In addition
to this wide application of the conditional density estimation technique, the use of a maximum
likelihood framework provides the foundation for more complex modeling of selection, endogeneity,
and unobserved heterogeneity.
Using Monte Carlo experiments and our health economics application, we examine the performance of these discrete, conditional density approximations when the outcome of interest is a
positively-skewed continuous variable with mass at zero. We nd that the discrete approximation works quite well with these outcomes. This suggests that the approach may be useful when
a researcher is interested in estimating the expected impact of exogenous covariates on particular functions of the outcome variable, regardless of whether the outcomes of interest are discrete,
continuous, or mixed.
1 The approach we use yields estimates of how the entire distribution of health expenditures would change

in response to variations in exogenous characteristics. Conceptually it is straightforward to add unobserved
heterogeneity to the speci cations we use along the lines suggested by Heckman and Singer (1984),Mroz
(1999), and Mroz and Guilkey (1992). This would, in principal, allow one to examine how covariate e ects
vary within ranges of the outcome variable. For example, one might be interested in how increasing coinsurance rates would e ect health care expenses for those spending more than $500 per year. To do this well,
however, the researcher would need to hold constant the distribution of the \heterogeneity" applicable for
this range of the outcome and must specify precisely how the heterogeneity distribution would be identi ed.
This would require strong assumptions or additional information. In general one would need multiple observations per agent in order to identify the heterogeneity distribution separately from the distribution of
the outcome conditional on exogenous covariates and the heterogeneity (Heckman and Honore, 1990). Such
extensions are beyond the scope of this paper. Hence, the approach we detail in this paper does not address
the question of how one can obtain interesting and consistent estimates of how covariates in uence outcomes
over intervals of the support of the dependent variable conditional on the random variable falling within the
interval.

3

1 Description of Estimation Procedure
We begin by describing in detail the estimation technique. The approach requires determination of
intervals within the support of the dependent variable, approximation of the conditional expected
value, and implementation of the empirical approximation in practice. We conclude this section by
explaining how to calculate statistical derivations of interest.
The conditional density estimation approach we propose in this paper closely resembles the
approaches used by Efron (1988) and Donald, Green, and Paarsch (2000). The Efron model, like
that proposed here, approximates the distribution of a continuous outcome by a discrete distribution
function. He proposes that one estimate the statistical approximation to the distribution function
by a sequence of logit hazard rates, which is precisely the modeling approach we adopt. The
main di erence between our approach and Efron's is that we examine distributions conditional on
observed covariates, while Efron models only the unconditional distribution. An important result
from Efron's analysis concerns the fact that the eciency loss due to discretization can be quite
small. For a true underlying continous Poisson process, for example, he nds that information loss
quickly goes to zero as the number of discrete intervals gets large.
Donald, Green, and Paarsch (2000) propose an estimator quite similar to the one we describe
below. The primary di erence between their estimator and ours is that they use a continuous
distribution with discrete structural shifts to approximate the underlying distribution, as in Meyer's
(1990) approach to estimating hazard models. To allow for e ects of covariates that vary over
the support of the outcome, they rely on separate, discontinous \proportional hazard" e ects for
various ranges of the the outcome variable. Our approach, on the other hand, allows the impacts of
covariates to vary smoothly over the entire range of the support of the outcome of interest, except
possibly at particular points or regions where the researcher has an a priori notion that behavior
might be discontinuous. The complexity of the estimated distribution and its dependence upon
covariates is pre-speci ed in the Donald, Green, and Paarsch approach, while the estimator we
propose allows the data to determine the number of terms and breakpoints used to approximate
the conditional distribution function. Eastwood and Gallant (1991), for example, nd that data
dependent rules for choosing the number of terms in an expansion often yields less bias than using
xed rules. A nal advantage of our approach is that estimating the smoothed conditional density

4

function only requires one to use simple logit models. Donald, Green, and Paarsch's estimator can
be dicult to use because it requires that the reseacher provide reasonable starting values for the
parameter estimates. All of the di erences we mention are quite minor, and the choice of which of
these two apporaches would be better depends upon whether one believes that the distribution of
the outcome of interest has many interesting and important, discontinuous segments.

1.1 Discretizing the Support of the Dependent Variable
Figure 1 displays an arbitrary distribution function for a random variable Y conditional on a set
of covariates x with density f (yjx).2 Suppose we break the range of the dependent variable into K
intervals, where the kth interval is de ned by [yk;1; yk ); for yk;1  yk ; y0 = ;1 and yK = 1.
6

f (yjx)

; p [yk;1  Y < yk jx]

;
;;
;
;
@@ @@
@ @
@@ @@
@ @@
@@ @@
@ @
@@ @@ @
@ @
@@ @@ @
@ @
@ @@ @
@@ @
0

yk;1

-

yk

Y

Figure 1: Arbitrary Distribution of Y
The probability that the random variable Y falls in the rst interval is given by:
p [y0  Y < y1 jx; Y

y ]=
0

Z y1
y0

f (yjx)dy = (1; x)

(1)

2 If the random variable Y is discrete, then each partition may include one or more points in the support

of Y. For most of the following discussion, we use notation for a continuous distribution for the outcome,
but little would need to be changed to accommodate discrete or mixed outcomes.

5

where (1; x) is that function of x that gives this probability. Note that (1; x) is implicitly a
function of the choice of partition for the support of Y , but this dependence on the partition is
captured entirely though the values y0 and y1 . The probability that the random variable Y falls in
the kth interval is given by
p [yk;1  Y < yk jx] =

Z yk

yk;1

f (yjx)dy

(2)

and the conditional probability that the random variable falls in the kth interval given that it did
not fall in one of the rst (k ; 1) intervals is
(k; x) = p [yRk;1  Y < yk jx; Y
yk
yk;1 f (y jx)dy
= 1 ; R yk;1 f (yjx)dy
y0

 yk; ]
1

(3)

The functions (; ) de ne the \discrete time hazard" function representation for the chosen
partition of the support of Y . By the properties of hazard functions, the probability that the
random variable Y falls in the kth interval is given by
p [yk;1  Y < yk jx] = (k; x)

kY
;1
j =1

[1 ; (j; x)] :

(4)

The hazard rate decomposition implies, by de nition, a conditional independence between the
events fyk;1  Y < yk jx; Y  yk;1 g and fyj ;1  Y < yj jx; Y  yj ;1g 8j 6= k. If a researcher
imposes a functional form for f (yjx) or (k; x), however, the potential for unobserved heterogeneity
exists and the conditional independence can break down (Heckman and Singer, 1984). This happens
because the same unobservable, say , in uences all of the events represented in Equation (4).
This, however, is only an issue for the hazard function that is constructed by conditioning on the
unobserved heterogeneity. Suppose g (k; xj) is the discrete hazard rate under density g(yjx; )
that is conditional on the unobserved heterogeneity and that Q() is the cumulative distribution of
the unobserved heterogeneity. Conditional on the heterogeneity the independence properties hold.
The conditional distribution function is given by
p [yk;1  Y < yk jx; ] = g (k; xj)

and the unconditional distribution function is
p [yk;1  Y < yk jx] =

Z

g (k; xj)

6

kY
;1
j =1

kY
;1

[1 ; g (j; xj)]

(5)

[1 ; g (j; xj)] dQ() :

(6)

j =1

This distribution in Equation (6) must, by de nition, have an \independent" hazard rate decomposition like that described above in Equation (4).
The primary implication of unobserved individual heterogeneity is that one cannot interpret
the distribution function f (yjx) and the \hazard" function (k; x) as holding the heterogeneity
xed, as would be the case if one were able to estimate the \hazard" functions g (k; xj). Thus one
cannot give a clear structural interpretation to e ects of variations in x on the outcome y in subintervals of its support; to do this would require knowledge of the distribution of the heterogeneity
conditional on being in the speci ed sub-intervals. The point here is similar to the interpretation
of estimates of \duration dependence" of the hazard rate in waiting time models with unobserved
heterogeneity. Unless one holds constant the unobserved heterogeneity in a waiting time model,
the time shape of the hazard function does not have a structural interpretation; the time shape
depends upon changes in the distribution of the unobserved heterogeneity over the support of the
dependent variable. The decomposition we use, however, does permit one to make precise structural
statements about the impact of the covariates x on the expectation of any function of y that does
not condition on particular ranges for the random variable. It is straightforward, for example, to
calculate how the mean and the variance of the random variable Y , or the mean and variance of
functions of the random variable Y , vary with changes in the exogeneous covariates x.

1.2 Approximating Moments of the Distribution
In this discussion we focus on rst conditional moments, but the discussion could easily be modi ed
for any conditional moments. The true expecation of a function h() of a random variable Y , given
x, is
Z1
E (h(Y )jx) =
h(y)f (yjx)dy
(7)
;1

where h() is any smooth and continuous function of Y . For a partition of the support of Y with
K intervals, we approximate the expectation of a function h(Y ) conditional on covariates x by
E~ (h(Y )jx) =

K
kY
;1
X
h (kjK )(k; x) [1 ; (j; x)]
j =1

k=1

(8)

where each h (kjK ) is an approximation to h(y) in the kth interval (corresponding to interval
[yk;1 ; yk )). The approximation we use treats the h (kjK )'s as xed for all values of x within the

7

kth interval. For smooth and continuous functions h(Y ), this approximation to the expectation will

converge to the true expectation as the widths of the intervals shrink towards zero. The empirical
question, then, is how well this approximation can work in practice.

1.3 Implementing the Approximation Empirically
Before one can apply this approximation in practice, several decisions need to be made regarding
implementation. The ve decisions at the discretion of the researcher are to:
1. choose the number of intervals to use (K ),
2. specify boundaries of the intervals (i.e., the values of y1 ; y2 ; : : : ; yK ;1 ),
3. pick a set of constants h (1jK ); h (2jK ); : : : ; h (K jK ) to use in the approximation to the
integral,
4. decide how to approximate the conditional density functions, and
5. calculate derivatives of the expectation of the function of the outcome of interest.
For each of the ve decisions we use empirical analogues to guide our choices.

Choosing Widths of the Intervals
First, consider the choice of the boundaries of the intervals. Suppose that one has already chosen
to have K intervals. For the most part, in our Monte Carlo experiments and empirical example
we choose as boundary points values that place an equal number of observations in each interval
(i.e., 1=K th of the sample of Y falls within each interval). If we chose 10 intervals, for example,
then y1 is the tenth percentile of the observed outcome Y , y2 is the twentieth percentile of the
observed outcome Y , and yK ;1 is the ninetieth percentile of Y . Boundaries chosen in this fashion
are equivalent for monotonic transformations of the random variable Y . In those instances where
there are signi cant point masses in the observed distribution of Y , one can allow each mass point
to de ne a single interval. In the work we report here we examine annual health care expenses. We
allow zero expenditures to be a single interval and choose boundary points such that there are an
equal number of observed positive expenditures in each of the remaining intervals.3
3 When there are minor point masses, say heaping at $100 in health expenditures for example, we typically

do not allow for additional intervals that contain only one point of the distribution unless the number of

8

Selecting the Number of Intervals
Next, consider the question of how many intervals to use for the discrete distribution. In practice we
address this question empirically. We choose as the number of points of support that number which
maximizes the goodness of t of the model given the four additional decisions being discussed. To do
this, consider having already chosen K 0 intervals with each interval containing N=K 0 observations.
Estimate the discrete distribution function and construct the value of the log likelihood of this
choice of K 0 intervals as
2 8
91fy(i)2[yk;1 ;yk )g 3
0
K
k
;
1
<
=
Y
Y
7
L(Y jK 0) = ln 64 :(k; x(i)) [1 ; (j; x(i))];
5
i=1
j =1
k=1
N
X

(9)

Next, consider taking each of the K 0 intervals (each with an equal number of observed Y 's
per interval) and breaking each one into R sub-intervals with an equal number of observed values
of Y in each interval. Each of the new intervals contains N=(K 0 R) observations. Let the estimated
probability of an observation being in the kth of the original K 0 intervals be (k; x(i); K 0 ). Now,
allocate this probability equally among each of the R sub-intervals that comprise this kth interval. Under this allocation rule for distributing the estimated probability, the probability that an
observation falls in one of these R sub-intervals is given by
(k; x(i); K 0 )
 (r; K 0 ; x(i); R  K 0 ) =
(10)
R

This is the adjusted probability that an observation falls in the rth sub-interval of the original kth
interval. All we have done is distributed these probabilities equally over the ner partition.
Since (1=R) of the observations that originally fell in the kth interval fall in each of these R
new, smaller intervals, it is straightforward to calculate the sample log likelihood when one uses
these equal allocation probabilities. This adjusted log likelihood is given by

L(Y jK 0 ; R  K 0) = L(Y jK 0 ) ; N ln(R)

(11)

where N is the number of observations not at places of signi cant point mass. For each observation,
the log-likelihood value is reduced by ln(R). This re ects the fact that it is \harder" to predict
observations at that one value is large relative to the number of intervals. These heaped values, however,
can make it impossible to distribute the mass equally among the remaining intervals. Do note that if such
minor mass points are substantively interesting and important, for example at 26 weeks duration in an
unemployment spell or 2000 hours in an annual hours worked distribution, one can and should allow these
mass points to be separate intervals.

9

which interval an observation falls into when one allows for more intervals. This adjusted likelihood
function value re ects changes in the log likelihood value associated with expanding the number of
intervals and not re-estimating the model.
Now, consider estimating a model containing R  K 0 intervals. A reasonable criterion to
use to decide whether one should use the estimates from the model with K 0 intervals or those
from the model with R  K 0 intervals in whether or not the the new log likelihood function value,
L(Y jR  K 0), exceeds the original log likelihood function value for K 0 intervals adjusted for the
ner partition, L (Y jK 0 ; R  K 0 ). If by choosing a ner partition we t the data worse than we did
by using a model with fewer intervals (and an equal allocation of probability within each interval),
then we would choose the model with a fewer number of intervals. The usefulness of this criterion
comes from the fact that our estimators of (k; x) are smooth over regions of the support of y. If
one were more nonparametric and allowed for completely separate functions (k; x) across intervals,
then following this criterion would always select the model with the most partitions.
To implement this in practice, consider comparing each choice of R to a model with only one
partition.4 The adjusted log likelihood function value with one partition is

L(Y jR; 1) = L(Y jR) + N ln(R)

(12)

This tells us how much better a model with R intervals ts the data than a model with only one
interval and an equal allocation of probabilities across the R intervals. We choose as the number
of intervals, K , that value of R which maximizes the above adjusted log likelihood function value.
In our Monte Carlo experiments and real example, we examine sample sizes from 1,000 to 5,000.
We found that one did not need to examine more than 50 partitions; typically 10 to 20 intervals
were sucient.

Evaluating Expectations of the Outcome
Next, consider how one should choose the evaluation point within each interval for the desired
function of the outcome variable (i.e., the h (kjK )'s). For most applications, each interval will
4 One partition, from ;1 to +1, broken into R sub-intervals with equal probability is just a simple

multinomial density with all intervals having the same probability. So, the approach we use chooses the
number of intervals with the maximum gain in the likelihood function resulting from including covariates
as determinants of the interval probabilities (after adjusting the likelihood function value for the number of
intervals).

10

contain many observed values of the outcomes. In the Monte Carlo experiments and example
reported here, we evaluate the function h() at each observed value within the interval and take a
simple arithmetic average:
P
y2[yk;1 ;yk ) h(y )

h (kjK ) = P
(13)
1
y2[yk;1 ;yk )

It is important to note that this might be an extremely important assumption in small samples
for the approach that we use. In particular, consider the derivative of the expected value of the
function h(Y )
Q ;1
K
@ f(k; x) kj =1
[1 ; (j; x)]g
@ E~ (h(Y )jx) X

=
h (kjK )
(14)
@x
@x
k=1

given our assumption that h (kjK ) does not vary with x.

A better approximation might be to recognize that the average of the function h(Y ) within the
kth interval would vary with changes in the covariates; this would happen because the distribution
of y within the interval would vary with changes in x. The actual derivative of the conditional
expected value would be
Q ;1
K
X
@ f(k; x) kj =1
[1 ; (j; x)]g
@E (h(Y )jx)

=
h (kjK; x)
@x
@x
k=1

+

K @h (k jK; x)
X

k=1

@x

(k; x)

kY
;1
j =1

[1 ; (j; x)]

(15)

where h (kjK; x) is the average value of Y in the kth interval as a function of the explanatory
variables.
A comparison of Equations (14) and (15) reveals that the approach we use ignores the second
term in the formulation of the derivative. Note that one could run a regression of the outcomes
in each interval on the covariates and use that regression to calculate the average of the derivative
within each interval. For smooth and continuous functions h() with nite expected value, the
second term in the above derivative expression could be asymptotically negligible compared to the
rst term in the sum (i.e., as the number of partitions grows large, the limit of the ratio of the rst
term in the sum to the total sum is one), but we have not yet shown this for general cases. This
is clearly a topic that deserves additional attention. But note that the Monte Carlo experiments
presented here do indicate that ignoring the second term in this sum appears to introduce little
bias in the estimated derivatives.

11

Estimating the Conditional Multinomial Probabilities
Our nal speci cation of the approximation to the expected conditional value concerns the approximation to the density function p[yk;1  Y < yk jx]. We approximate this density using the hazard
rate decomposition discussed above. In particular, we specify a logit function for the probability of
an outcome falling in the kth interval given that it was not in one of the lower (k ; 1) intervals. In
practice, one could estimate a separate logit model for each \hazard" of falling within each interval.5
This, however, would introduce a large number of parameters in most realistic-sized problems. Instead, we estimate one logit probability using polynomials in functions of the covariates and the
interval number.
Suppose one chooses to use K partitions. By using partitions containing an equal number
of observations, the unconditional probability (not conditional on the x's) of an observation being
in the kth interval given that it was not in one of the lower (k ; 1) intervals is K ;(1k;1) . Let
k = ;ln(K ; k ) for k < K . Then,
k
logit( k ) = 1 +e e k = K ; (1k ; 1) :

(16)

If one estimated a single logit function for all of the (K ; 1) hazard rates with k as the only
covariate in the logit function, then the t of the unconditional discrete distribution function would
be \perfect;" the predicted probabilities of the outcome falling in each of the intervals is identical to
what one would obtain by estimating a logit hazard model with dummy variables for each interval,
or a separate logit model for each event of an observation falling into each of the intervals. By
using k as the only covariate in a logit formulation of the hazard function, we are guaranteed to
t exactly the discretized marginal distribution of y given the choice of K intervals.
In our estimation of the \hazard" functions that condition on covariates we follow a similar
strategy and estimate a single logit model for all hazard rates. We include polynomials in k in
addition to polynomials in the observed covariates as linear arguments to the logit function. We
also include interactions among the covariate polynomials and the k 's. This provides a exible
5 The fact that each outcome can contribute an \observation" to more than one \logit" and that outcomes

vary in the number of \observations" they contribute is a non-issue. One can always apply a \hazard"
decomposition to any conditional or unconditional distribution function and end up with exactly this type of
formulation. Every maximum likelihood estimation problem with continuous outcomes, then, can be thought
of as one where each observed outcome can contribute an \observation" to more than one interval.

12

way to smooth the hazard rate decomposition of the conditional density function. When we have
an outcome with substantively and quantitatively interesting point masses, as we do at zero expenditures in our analysis of health care expenses, we estimate a separate logit model with polynomials
in the covariates and without the k polynomials.6
We use downwards testing to guide the selection of the degree of the polynomial to use in the
logit model of the hazard functions. In particular, the most complex model we consider includes a
fourth degree polynomial in k and all fourth order terms in the covariates, their interactions, and
the covariate polynomials (including their interactions) interacted with the k polynomial. We then
reduce the order by one for the covariate polynomials, their interactions, and their interactions with
the shape parameter k , but retain fourth order polynomials in k . We test whether the additional
coecients as a group are signi cant with a Wald test at the ve percent level.7 If the higher order
terms are signi cant, then we keep the unrestricted speci cation. If not signi cant, we reduce
the polynomials and interactions by an additional order. We then use another Wald test at the
ve percent level to test whether the more detailed speci cation provides a better t than the
restricted model. If we do not nd a signi cant improvement with the higher order terms, we
reduce the speci cation further by eliminating all third order polynomials, third order interactions
of the covariates with themselves and with k , and fourth order polynomials in k . Again, we test
at the ve percent level whether the additional terms improve the goodness of t. The simplest
model we consider includes k , the square of k , and rst order terms in the covariates. In our
Monte Carlo work we nd that this procedure almost always selected the most complex set of
interactions in the logit hazard function.8
6 We found that polynomials in the logarithms of the covariates seemed to provide somewhat more stable
estimates than polynomials in the levels of the variables. Except for the dummy variables we use as explanatory variables, we add a constant to each covariate to ensure that the minimum value is positive and then
construct polynomials in the logarithms of the normalized covariates.
7 While the hazard formulation implies theoretically that there is independence between the events de ned
by the hazard rates, we recognize that the approximation we use may not be perfect. We use standard error
estimators (Eicher-Huber-White) that allow for correlation among the conditional events for each observed
outcome in the Wald tests.
8 Our estimation programs automatically drop linearly dependent variables and we take this into account
when testing. See Appendix Tables A3, A4, and A8 for a precise description of the polynomial terms we
include in the conditional density estimation for the Monte Carlo experiments and the Rand Health Insurance
Experiment data.

13

1.4 Calculating Derivatives
When calculating derivatives of the expectation of the function of the outcome of interest, we
hold constant the approximation to the function within each interval (the h (kjK )'s) as mentioned
above, di erentiate the approximating density function for each interval with respect to a set of
covariates, and then sum the products of the h (kjK )'s and the derivatives of the density function,
as described in Equation (14). To do this in practice we evaluate the conditional expected value
at various values of the explanatory variables and calculate the \arc" derivatives. Suppose we are
interested in calculating the derivatives of the expectation of health care expenses with respect
to the level of deductible in the health insurance plan, which we report in Table 1. One way of
calculating the average derivative (Average in the tables), is rst to calculate the expected value
of expenditures using the estimated distribution function for all observations. Next, deviate each
observation's deductible level and recalculate the expected values for all observations. Given the
polynomial approximations we use, it is advisable to ensure that the deductible levels are set to
values that are actually observed in the data; each observation could have a di erent deviation.
Then, take the di erence between these two expectations observation by observation and divide
the di erence by the nite di erence chosen for the covariate for each observation to obtain the
\derivative" for each observation. The population derivative is the average of these derivatives
across observations. This most closely corresponds to the average impact in the population of a
one unit change in a covariate9 In other instances, we evaluate the expected value of the function of
the outcome of interest for each observation with one particular covariate set to the same value for
all observations. We then deviate the covariate for each observation, recalculate the expectation,
take di erences, divide through by the change in the covariate, and average across observations.
This corresponds to the average derivative at a particular value of the chosen covariate, when all
of the other characteristics of individuals follow the joint (marginal) distribution observed in the
data. We also experimented with aggregating these values to construct di erent measures of the
overall \average" derivative of a covariate. These are reported as Min Variance, Equal Weights,
Weight 1, and Weight 2 in Table 1; these are de ned in detail in Appendix Table A2. Clearly, one
9 In our Monte Carlo experiments we randomly draw sets of explanatory variables from sets of covariates

for 1219 observations observed in the NMES data set. Rather than calculating derivatives for the estimation
sample, we calculate the derivatives for these 1219 sets of explanatory variables.

14

could chose a wide variety of ways to calculate derivatives of the expected value with respect to
particular covariates and how these derivatives vary with values of the other covariates.

1.5 Summary of the Estimation Procedure
First, split the sample into K intervals. Estimate the approximation to the conditional density function using all of the possible polynomial speci cations, and test downwards from the most complex
model to simpler models. Select that model that rst indicates that the additional coecients
are statistically signi cant. Repeat this procedure for a wide range of K values for the number
of intervals. Next select the value of K that maximizes the likelihood function value adjusted to
re ect the di erences in the number of intervals. This procedure yields the estimator of the density
function. We then calculate the derivatives using the nite di erence procedure described above.
When we examine the data from the Rand Health Insurance Experiment, we bootstrap this entire
procedure to obtain estimators of the standard errors. This means that the standard errors we
report control for all of the pre-testing we do with respect to the degree of the polynomial and the
selection of the number of intervals.

2 Speci cation of the Monte Carlo Experiments
In the Monte Carlo experiments we focus on ve speci cations of the data generating process. For
each model we use data from the National Medical Expenditure Survey (NMES) from 1987 to set
coecients and to de ne the joint distribution of the explanatory variables. For the most part,
we ran simple regressions of health care expenditures on age, household income, coinsurance rate,
deductible amount, and demographic controls to de ne the parameters determining the continuous
outcome in each data generating process (DGP). We used probit models, in which the dependent
variable is whether an individual had any medical expenditures in the NMES data, to calibrate
those DGPs that use a \two-part" approach. We used the same explanatory variables in the
probit equation as in the conditional expenditures equation along with an indicator of whether
an individual had a regular health care provider. For each replication within each DGP we draw
samples of the explanatory variables, with replacement, from a set of 1219 individuals in the NMES

15

data set. We examined sample sizes of 1000, 3000, and 5000, but we focus on sample size 5000 in
our discussion.
The rst DGP we examine is a single equation OLS model where the outcome is a simple
linear function of the covariates. This model has normal disturbances, and OLS is the best unbiased
estimator (ecient). We use this DGP to examine whether the complex estimation model we use
can replicate well a simple process and to uncover how much eciency might be lost because we
allow for extremely exible functional forms and distributions.
The second DGP we examine is a two-part model. In the rst part a probit model with
normal errors, calibrated with the NMES data, determines whether or not an individual has positive
expenditures. If the outcome generated by the DGP indicates that the individual had positive
expenditures, then a simple linear regression function with an independent normal error determines
the natural logarithm of the expenditure for the individual. With this DGP and the following three
DGPs, we use a \two-part" version of the conditional density estimation approach where we specify
a simple, separate logit for the rst stage (any expenditures) and a sequence of related logits to
de ne the conditional density function for positive expenditures.
The third DGP is quite similar to the second DGP. It only di ers by allowing the error variance in the second part to be proportional to the expected value of the logarithm of the dependent
variable. The fourth DGP adds additional heterogeneity and heteroscedasticity. In particular, it
speci es a random parameter model in the second stage regression function for the logarithmic
expenditures. The nal DGP we consider is a mixture model. Here, there is a distribution of
individuals, and each type has a di erent propensity to have positive expenditures and a di erent
expected level of logged expenditures given that they have some positive expenditures. The error
terms in the two parts are related, so a standard two-part model would su er from selection bias.
We compare the conditional density approximation estimators (CDE) of the derivatives of
expected expenditures to a variety of OLS estimators. Each OLS estimator regresses observed
expenditures (including the zero values) on a set of covariates; we do not use two-part models.10
Because we use level expenditures as the dependent variable in the OLS regressions, we need not
10 Since E (Y jx) = p(Y = 0jx)  0 + p(Y > 0jx)  E (Y jY > 0; x) = R(x), E (Y jx) is a function of x only. The
one-part models that we estimate are approximations to the expected value function R(x).

16

consider issues related to how one can translate from regressions of the outcome estimated in
logarithms to levels.11
The OLS estimators we consider are: 1) a simple OLS model with only linear covariates
[labeled OLS (levels, 1st order) in the tables];12 2) an OLS model that uses (up to) fourth order
polynomials in the levels of the explanatory variables where the forms of the polynomial interactions
are the same as those used in the conditional density estimation procedure except there is no need to
specify the k 's as this linear form is the conditional expectation [labeled OLS (levels, 4th order)];13
and 3) an OLS estimator identical to the second one, except that it uses polynomials in the logs
of the transformed explanatory variables rather than polynomials in the levels of the explanatory
variables [labeled OLS (logs, 4th order)]. A list of the full set of expansion terms used in estimation
are provided in Appendix Table A3. The frequency of selection of order of the polynomial expansion
is provided for each model for each data generating process in Appendix Table A4.
In Tables 1a through 1e we report the derivative of expected expenditures with respect to
the insurance deductible amount from several estimation models for each DGP in the Monte Carlo
experiments. The deductible is that amount of health expenditure dollars that a consumer pays
before the insurance company begins sharing the costs. Table 1a contains Monte Carlo evidence
when the DGP is a simple OLS model, and the DGPs for Tables 1b through 1e are described
in the table titles. We calculate the derivative by numerically di erentiating with respect to the
explanatory variable. When calculating this derivative, we hold constant the values of the error
terms for each observation and rely upon the averaging across observations to integrate out the
heterogeneity. Note that the simplest OLS model is the ecient estimator for the rst DGP. For
all other DGPs, all the empirical models are approximations to the true conditional expectations
11 We considered two-part models with logged expenditures conditional on any expenditures and the smear-

ing retransformation in our comparisons of di erent models. We found that these models, when estimated
with higher levels of polynomials whose coecients could not be deemed insigni cant, produced unreliable
estimates and extremely large standard errors. Given this nding, we did not explore modi cations of the
smearing/retransformation approach in our Monte Carlo experiments. Examples of this type of result are
found in our application to real data in the next section.
12 For the rst DGP this OLS estimator is the ecient estimator. In all others, the true DGP is considerably
more complex than a simple linear model.
13 We select the degree of the polynomial by a downwards testing approach using a similar Wald test at
the ve percent level for each Monte Carlo replication. We also calculate the derivatives of the expected
values in a fashion similar to that used with the conditional density estimator. We take nite di erences of
expectations by deviating one explanatory variable from the value it took on in the data set exactly as we
do for the conditional density estimator.

17

function. The tables report the numerical derivative at each chosen evaluation point and the average
derivative calculated by numerically di erentiating at every observed value in the data. The tables
report the \true" derivative, where we similarly numerically di erentiate the known DGP with
respect to each explanatory variable, and the derivatives from the OLS and CDE models. We
begin by demonstrating the ability of our quite non-linear conditional density estimation (CDE)
technique to uncover the true derivative according to the Monte Carlo experiment.
In Table 1a, using OLS to estimate derivatives provides the most ecient estimator. We
recover the true mean of -0.399 almost exactly and fairly accurately with a standard deviation is
0.057. Higher orders of level X 's and OLS also reproduce the true e ects becasue the rst order
model is always chosen by the Wald tests. However, higher orders of logged X 's do a relatively poor
job of tting the truth. The mean value of the average derivative is almost two (OLS 1st order)
standard derviations from the truth. The CDE technique with polynomials and interactions in the
logged X 's produces estimates with little bias (from the truth) but with somewhat larger standard
deviations. This larger variance is expected since OLS is ecient. However, the CDE procedure
does very well when the data are generated from a simple model. It has the ability, generally, to
capture the true constant derivative at di erent evaluation points.
The di erent DGPs examined in Tables 1b through 1e are intended to generate increasingly
more heterogeneity in the data generating process. Immediately we see that the simple rst order
OLS model does not do a good job of tting the data as the DGP becomes more complicated.
Allowing for higher order level polynomials in the OLS model provides a better t, but at a
loss of eciency. The best OLS model is one with polynomials and interactions in the logged
values of the transformed explanatory variables. The CDE technique produces little bias and has
standard deviations that are close to those provided by the one-part OLS models with fourth order
interactions of all the explanatory variables.
We also examined the impacts of age, income, and coinsurance rate in these Monte Carlo
experiments. The assessments of the various estimators for these alternative e ects are similar
to those for the deductible level examined in Table 1. The simple OLS model yields derivative
estimates that are quite far from the true average derivatives in models with any complexity. The
OLS estimators with fourth order terms and the CDE estimators all perform quite well in recovering
the average derivative as well as the non-constant derivative at speci c evaluation points. They

18

Table 1a: Average Deductible Derivatives
DGP: Yi = 0 Xi + i , iid normal errors, OLS

Derivative
Evaluation point

OLS

OLS

OLS

Truth

Levels
1st order

Levels
4th order

Logs
4th order

CDE

0

-0.399
( 0.000)

-0.396
( 0.057)

-0.396
( 0.057)

-0.014
( 0.883)

-0.190
( 1.050)

50

-0.399
( 0.000)

-0.396
( 0.057)

-0.396
( 0.057)

-0.807
( 0.261)

-0.488
( 0.567)

100

-0.399
( 0.000)

-0.396
( 0.057)

-0.396
( 0.057)

-0.591
( 0.200)

-0.404
( 0.183)

150

-0.399
( 0.000)

-0.396
( 0.057)

-0.396
( 0.057)

-0.473
( 0.165)

-0.396
( 0.123)

200

-0.399
( 0.000)

-0.396
( 0.057)

-0.396
( 0.057)

-0.398
( 0.142)

-0.398
( 0.106)

250

-0.399
( 0.000)

-0.396
( 0.057)

-0.396
( 0.057)

-0.346
( 0.126)

-0.400
( 0.097)

300

-0.399
( 0.000)

-0.396
( 0.057)

-0.396
( 0.057)

-0.267
( 0.101)

-0.397
( 0.095)

Average

-0.399
( 0.000)

-0.396
( 0.057)

-0.396
( 0.057)

-0.493
( 0.113)

-0.409
( 0.172)

Min Variance

-0.372
( 0.061)

Equal Weights

-0.382
( 0.130)

Weight 1

-0.382
( 0.121)

Weight 2

-0.391
( 0.110)

Standard deviations from the Monte Carlo experiments are in parentheses.
See Appendix Table A2 for measures of the average derivatives.

19

Table 1b: Average Deductible Derivatives

DGP: ln(Yi ) = 0 Xi + i , iid normal errors, 2-part
Derivative
Evaluation point

OLS

OLS

OLS

Truth

Levels
1st order

Levels
4th order

Logs
4th order

CDE

0

-2.632
( 0.000)

-0.279
( 0.064)

-1.173
( 0.532)

-2.752
( 0.947)

-2.543
( 1.288)

50

-0.412
( 0.000)

-0.279
( 0.064)

-0.823
( 0.290)

-0.435
( 0.296)

-0.368
( 0.584)

100

-0.219
( 0.000)

-0.279
( 0.064)

-0.536
( 0.164)

-0.262
( 0.146)

-0.227
( 0.243)

150

-0.166
( 0.000)

-0.279
( 0.064)

-0.307
( 0.158)

-0.188
( 0.112)

-0.152
( 0.180)

200

-0.131
( 0.000)

-0.279
( 0.064)

-0.133
( 0.193)

-0.146
( 0.098)

-0.112
( 0.144)

250

-0.094
( 0.000)

-0.279
( 0.064)

-0.008
( 0.223)

-0.119
( 0.090)

-0.088
( 0.123)

300

-0.070
( 0.000)

-0.279
( 0.064)

0.102
( 0.311)

-0.081
( 0.076)

-0.060
( 0.118)

Average

-0.513
( 0.000)

-0.279
( 0.064)

-0.518
( 0.141)

-0.531
( 0.117)

-0.533
( 0.184)

Min Variance

-0.472
( 0.128)

Equal Weights

-0.507
( 0.163)

Weight 1

-0.429
( 0.164)

Weight 2

-0.394
( 0.145)

Standard deviations from the Monte Carlo experiments are in parentheses.
See Appendix Table A2 for measures of the average derivatives.

20

Table 1c: Average Deductible Derivatives

DGP: ln(Yi ) = 0 Xi + i ; var()  E [ln(Y )], 2-part
Derivative
Evaluation point

OLS

OLS

OLS

Truth

Levels
1st order

Levels
4th order

Logs
4th order

CDE

0

-2.577
( 0.000)

-0.292
( 0.077)

-1.257
( 0.695)

-3.033
( 1.394)

-2.965
( 1.490)

50

-0.491
( 0.000)

-0.292
( 0.077)

-0.863
( 0.360)

-0.360
( 0.411)

-0.396
( 0.725)

100

-0.241
( 0.000)

-0.292
( 0.077)

-0.547
( 0.207)

-0.237
( 0.188)

-0.229
( 0.274)

150

-0.193
( 0.000)

-0.292
( 0.077)

-0.304
( 0.212)

-0.183
( 0.118)

-0.147
( 0.181)

200

-0.121
( 0.000)

-0.292
( 0.077)

-0.126
( 0.239)

-0.152
( 0.096)

-0.106
( 0.148)

250

-0.098
( 0.000)

-0.292
( 0.077)

-0.005
( 0.250)

-0.130
( 0.089)

-0.082
( 0.130)

300

-0.082
( 0.000)

-0.292
( 0.077)

0.073
( 0.393)

-0.100
( 0.089)

-0.055
( 0.120)

Average

-0.583
( 0.000)

-0.292
( 0.077)

-0.537
( 0.170)

-0.531
( 0.134)

-0.527
( 0.219)

Min Variance

-0.522
( 0.141)

Equal Weights

-0.568
( 0.169)

Weight 1

-0.473
( 0.152)

Weight 2

-0.432
( 0.145)

Standard deviations from the Monte Carlo experiments are in parentheses.
See Appendix Table A2 for measures of the average derivatives.

21

Table 1d: Average Deductible Derivatives

DGP: ln(Yi ) = i0 Xi + i = Xi + ( i ; )Xi + i ; random coecients model
Derivative
Evaluation point

OLS

OLS

OLS

Truth

Levels
1st order

Levels
4th order

Logs
4th order

CDE

0

-2.477
( 0.000)

-0.267
( 0.100)

-1.004
( 0.959)

-2.670
( 1.591)

-2.695
( 1.836)

50

-0.415
( 0.000)

-0.267
( 0.100)

-0.701
( 0.503)

-0.458
( 0.397)

-0.288
( 0.842)

100

-0.211
( 0.000)

-0.267
( 0.100)

-0.466
( 0.258)

-0.259
( 0.228)

-0.193
( 0.281)

150

-0.158
( 0.000)

-0.267
( 0.100)

-0.292
( 0.263)

-0.184
( 0.171)

-0.147
( 0.236)

200

-0.125
( 0.000)

-0.267
( 0.100)

-0.172
( 0.327)

-0.145
( 0.140)

-0.124
( 0.203)

250

-0.121
( 0.000)

-0.267
( 0.100)

-0.100
( 0.348)

-0.121
( 0.119)

-0.112
( 0.171)

300

-0.060
( 0.000)

-0.267
( 0.100)

-0.098
( 0.384)

-0.091
( 0.090)

-0.101
( 0.134)

Average

-0.481
( 0.000)

-0.267
( 0.100)

-0.464
( 0.235)

-0.531
( 0.184)

-0.509
( 0.213)

Min Variance

-0.458
( 0.173)

Equal Weights

-0.523
( 0.256)

Weight 1

-0.433
( 0.256)

Weight 2

-0.394
( 0.214)

Standard deviations from the Monte Carlo experiments are in parentheses.
See Appendix Table A2 for measures of the average derivatives.

22

Table 1e: Average Deductible Derivatives

DGP: Mixture model where type depends on unobserved health state, 2-part
Derivative
Evaluation point

OLS

OLS

OLS

Truth

Levels
1st order

Levels
4th order

Logs
4th order

CDE

0

-5.814
( 0.000)

-0.551
( 0.090)

-2.982
( 1.058)

-5.487
( 1.865)

-4.149
( 1.581)

50

-1.117
( 0.000)

-0.551
( 0.090)

-1.805
( 0.518)

-0.908
( 0.809)

-1.272
( 0.845)

100

-0.714
( 0.000)

-0.551
( 0.090)

-0.977
( 0.260)

-0.604
( 0.264)

-0.618
( 0.275)

150

-0.407
( 0.000)

-0.551
( 0.090)

-0.454
( 0.260)

-0.461
( 0.142)

-0.398
( 0.201)

200

-0.538
( 0.000)

-0.551
( 0.090)

-0.188
( 0.274)

-0.374
( 0.112)

-0.304
( 0.167)

250

-0.388
( 0.000)

-0.551
( 0.090)

-0.135
( 0.239)

-0.315
( 0.109)

-0.251
( 0.153)

300

-0.221
( 0.000)

-0.551
( 0.090)

-0.665
( 0.483)

-0.230
( 0.125)

-0.176
( 0.167)

Average

-1.155
( 0.000)

-0.551
( 0.090)

-1.016
( 0.233)

-0.848
( 0.233)

-0.990
( 0.236)

Min Variance

-0.985
( 0.182)

Equal Weights

-1.024
( 0.220)

Weight 1

-0.884
( 0.219)

Weight 2

-0.851
( 0.192)

Standard deviations from the Monte Carlo experiments are in parentheses.
See Appendix Table A2 for measures of the average derivatives.

23

exhibit little bias and have roughly comparable standard errors. Comparisons of these estimated
e ects across the various estimation approaches for the other variables are provided in Appendix
Tables A5 through A7.

3 An Application: Annual Medical Expenses
To demonstrate the exibility and comparative advantages of the conditional density estimation
procedure we use data from the Rand Health Insurance Experiment (RHIE) to explain annual
medical expenses. The RHIE randomly assigned health insurance to participating individuals with
the hope of overcoming adverse selection issues associated with the purchase of health insurance
when examining the impacts of health insurance on medical care expenditures. While the data were
collected some time ago (between 1974 and 1981), this data set is useful for our purposes because
1) these data have recently become available for public use, 2) results from the Experiment are
widely known among health economists, and 3) the data exhibit features that presumably require
special econometric treatment in estimation or prediction.
Individuals from six sites in di erent regions of the country participated in the RHIE which
randomly assigned households to one of 19 di erent health insurance plans. Because dental and
mental health expenses were compensated di erently by many plans we restrict our attention to
physician and hospital expenses. Similarly, we analyze expenses of individuals randomized to
plans with free care or a coinsurance rate and a maximum deductible amount only. We do not
consider Health Maintenance Organization (HMO) plans or plans with a deductible. We restrict
our attention to individuals between the ages of 14 and 62. We drop individuals in Dayton, Ohio
because it was a site that was atypical with regard to the Experiment. We consider the expenses
of each individual in every full year of participation (for a total of 1 to 5 years) unless attrition was
the result of death. In this case, we retain the part year observation because expenditures prior to
death are likely to be in uenced by health insurance. In order to keep the sample size as large as
possible we impute values of missing variables such as income, general health index, and number
of diseases using data on individuals with complete records. All dollar values are in 1999 dollars.

24

Table 2 lists summary statistics and de nitions for variables used in our analysis.14 A list of the
full set of expansion terms used in estimation are provided in Appendix Table A8.

Table 2: Summary Statistics from Rand HIE | All person years (8039)
Continuous Variables
Annual medical expenses ($1999)
Annual family income in thousands ($1999)
Annual participation incentive ($1999)
Index of general health at enrollment
Number of disease conditions at enrollment
Maximum deductible amount ($1999)
Coinsurance rate (%)
Age in years
Annual family size
Dummy Variables

Mean

Std.Dev.

Min

Max

947.25
31.75
994.04
70.34
10.33
876.02
30.14
32.76
3.53

3052.48
13.13
866.28
14.15
8.04
943.09
37.13
13.13
1.85

0
0
0
5.7
0
0
0
14
1

79455.11
98.93
2955.65
100.00
58.60
2437.95
95
61
14

Percent

Seattle (omitted category)
Fitchburg
Franklin County
Charleston
Georgetown County
Female
Non-white

27.37
16.15
18.97
16.73
20.79
53.14
18.36

Distribution of person-year observations by year

Percent

1976
1977
1978
1979
1980
1981

5.22
20.32
20.35
24.54
15.66
13.89

The conditional density estimation procedure, as the Monte Carlo experiments demonstrate,
produces reliable estimates of the e ects of covariates regardless of the functional form of the
dependent variable or the true, underlying regression framework. Thus, there is no need to concern
oneself with appropriate treatment of the error term when retransforming the predictions to levels.
14 A considerable amount of work went into preparation of the data set used in estimation in order to obtain

consistent observations on each eligible person-year within a family and to produce a set of explanatory
variables that most closely resembles that used in the published literature (Manning et al., 1987). SAS code
to replicate our research data le is available upon request.

25

Additionally, the procedure explores high order polynomials and interactions of the explanatory
variables and chooses the speci cation with the best t. Finally, the estimation technique allows
for variation in covariate e ects over particular ranges of the dependent variable. For example, the
e ect of a one thousand dollar increase in income might have very di erent e ects on expenditures
at low income levels than at high income levels. These di erential e ects are not simply a trivial
implication of a dependent variable transformation.
Table 3 reveals the varying derivatives for di erent values of selected explanatory variables.
We begin by discussing the derivative of expenditures with respect to income. Standard errors
for all estimation procedures come from the standard deviation of 50 bootstrap replications. All
derivatives are calculated by taking nite di erences as discussed above. For all estimation models,
upwards testing for the appropriate level of expansion overwhelmingly selected the fourth order
with these real data. In general, the CDE procedure reveals that $23 of an additional $1000 dollars
at low income levels ($10,000) will be spent on medical care. As income initially rises, individuals
spend more on medical care, but at a decreasing rate. As income continues to rise to higher levels,
there is little signi cant change in the amount spent on medical care. The second column of Table 3
reports results using the traditional two-part estimation technique and smearing to account for the
predicted errors in retransformation of the predicted log expenditures to produce level outcomes.
Here we use fourth order polynomials in the explanatory variables as we rejected the restrictions
implied by a third order polynomial model at the 5% level. The two-part model with smearing
yields qualitatively similar point estimates for the income e ects, but the bootstrapped standard
errors for this commonly used procedure are two to forty times larger than those of the CDE
model.15
The last two columns of Table 3 contain estimates from one-part models where those individuals with zero expenditures are included in the same OLS regression as those with positive
expenditures. Expenditures are measured in level real dollars, so there is no need to make ad hoc
15 Much of the original Rand work analyzing the HIE data attempted to account for potential heteroscedas-

ticity by using plan-speci c smearing retransformations, while we have used a single retransformation
correction using all observations with positive outcomes. Neither approach, however, can account for the full
range of variation in the x's that might be the source of heteroscedasticity. When we tried to estimate more
complex forms of heteroscedasticity, the excessively large standard errors often became even more absurd.

26

27

Mean Std.Error

Mean

0
25
50
avg

Coinsurance Rate

10
15
20
25
30
35
40
45
50
avg
-10.076
4.021
-4.698
-6.202

22.923
5.687
-1.861
-4.458
-4.671
-3.770
-2.380
-0.811
0.790
-0.008
(3.450)
(6.845)
(4.058)
(2.085)

(13.866)
(6.942)
(5.062)
(4.323)
(3.616)
(3.024)
(2.771)
(2.943)
(3.430)
(0.008)

(57.120)
(14.448)
(13.771)
(20.910)
(33.364)
(52.397)
(80.257)
(120.163)
(176.511)
(0.013)

111.435 (7.65 107 )
-114.300 (7.09 107 )
-7.038 (3.23 1012 )
83.067 (5.55 107 )

13.727
0.055
-4.491
-4.978
-3.825
-2.064
-0.115
1.869
3.846
-0.010

Std.Error

Two-part, ln(Y ),
Smearing, 4th order

Household Income (1000s 1999$, mean: 32.7, sd: 16.9)

Evaluation Point

CDE
log X 's, 4th order

-6.347
-0.428
-4.846
-4.918

21.932
6.199
-0.925
-4.009
-5.102
-5.170
-4.703
-3.958
-3.079
-0.005
(5.320)
(9.452)
(5.004)
(2.267)

(17.631)
(10.004)
(7.243)
(5.546)
(4.283)
(3.584)
(3.629)
(4.259)
(5.158)
(0.010)

Mean Std.Error

One-part, OLS Y ,
log X 's, 4th order

Table 3: Selected Covariate Derivatives Using Alternative Models

-10.783
2.950
-4.709
-7.445

18.039
9.568
3.407
-0.859
-3.645
-5.367
-6.439
-7.275
-8.291
0.003

(5.254)
(10.251)
(4.900)
(2.296)

(15.390)
(9.254)
(7.581)
(7.134)
(6.186)
(5.138)
(5.387)
(7.128)
(9.128)
(0.004)

Mean Std.Error

One-part, OLS Y ,
level X 's, 4th order

28

Mean Std.Error

Mean

Std.Error

Two-part, ln(Y ),
Smearing, 4th order

388.258

Female Indicator

(63.397)

(30.583)
(12.935)
(5.325)
(3.800)
(3.180)
(4.629)
(2.445)

Non-white Indicator -193.209 (123.959)

-12.847
-20.213
-19.080
-14.504
-9.333
-4.623
-11.354

30
40
50
60
70
80
avg
(63.504)

(83.355)
(16.188)
(6.226)
(3.700)
(2.319)
(4.028)
(30.022)

-273.867 (2753.129)

435.579

-58.472
-39.185
-25.090
-15.186
-8.245
-3.084
-17.366

General Health Index (higher is better health, mean: 70.3, sd: 14.2)

Evaluation Point

CDE
log X 's, 4th order

(93.917)

(41.129)
(16.839)
(8.988)
(7.531)
(4.319)
(5.937)
(3.361)
-307.955 (157.995)

361.629

-18.766
-27.653
-26.683
-20.540
-12.008
-2.574
-14.244

Mean Std.Error

One-part, OLS Y ,
log X 's, 4th order

337.893

-36.987
-35.839
-26.234
-14.337
-6.309
-8.316
-15.537

(89.007)

(30.129)
(16.387)
(9.793)
(6.572)
(6.619)
(6.531)
(3.286)

Mean Std.Error

One-part, OLS Y ,
level X 's, 4th order

-288.725 (159.226)

Table 3: Selected Covariate Derivatives Using Alternative Models | continued

assumptions to transform the estimated e ects to level expenditures. The third column uses polynomials in the levels of the explanatory variables, while the last column uses polynomials in the
logarithms of the adjusted explantory variables. As in the Monte Carlo experiments, these one-part
models perform almost as well as the CDE model. They yield point estimates quite similar to those
of the CDE model, but their bootstrapped standard errors are almost always larger than those from
the CDE approach.
Similar comparisons are found when we examine derivatives with respect to other variables.
Consider the e ects of the coinsurance rate, or the percent paid out-of-pocket by the individual,
on health expenditures. In the RHIE data this variable is not continuous, as it takes on only the
values 0, 25, 50, and 95%. The free plan (0% coinsurance rate) also has associated with it a $0
maximum deductible amount (MDE); the MDE is that level of out-of-pocket expenditures after
which additional medical care is free. In calculation of the impact on expenditures of changes in
the coinsurance rate, we have to move individuals from the free plan to a plan with some out-ofpocket responsibility. Such a move requires that we assign an MDE at the evaluation of a non-zero
coinsurance rate. We set the new MDE to 10% of family income or $2200 (1999 dollars), whichever
is less.16 This reassignment of originally free plans to paying plans is considerably di erent from
simply increasing the percentage paid by the individual who faced some out-of-pocket responsibility
originally. The CDE technique signi cantly predicts that movement from a free plan to a 25% plan
results in a $10 reduction in total health care expenditures per coinsurance percentage point increase
(i.e., a $250 decrease in expenditures with movement from a free plan to the 25% plan). Changes
in behavior associated with movement from a 25% plan to a 50% plan are less precise (across all
models) because few individuals in the RHIE were randomized to the 50% plan (about 5% of our
sample). On average, across all coinsurance rates, a one percentage point increase in out-of-pocket
responsibility results in a $6 decrease in expenditures.
The estimates of the coinsurance e ects from the two-part smearing model are disturbing. In
several of the bootstrap replications, a small fraction of the sample had absurdly large predicted
medical expenditures. This appears to happen because, for some combinations of the explanatory
variables, changing the coinsurance rate to evaluate the e ect yields a set of explanatory variables
16 The RHIE assigned MDE's as 5, 10 and 15% of income or $1000 (current year dollars), whichever was

less. Note that this way of setting the MDE in the RHIE is inconsistent with the true experimental design.

29

that is not well represented in the estimation sample. While the predictions of log expenditures
in these instances are not too extreme, once one antilogs the predicted level expenditures become
huge. This sensitivity to slightly out of sample predictions only seems to a ect substantially the
two-part smearing model. Both of the one-part level outcome models, also with fourth degree
polynomials in the explanatory variables, yield estimates of the coinsurance e ects close to those
from the CDE model. As for the income e ects discussed above, these two OLS models do have
larger bootstrapped standard errors than the CDE approach.
The e ect on health expenditures, as measured by the derivative with respect to the general
health index, reveals that better health leads to lower medical expenditures. In terms of this
health index, a one unit increase in health has a larger reduction in expenditures at low levels of
health than at levels at or above the mean level of the health index. Again, the two-part smearing
model provides imprecise estimates. The two OLS models predict somewhat larger responses than
the CDE model, and, as above, they uniformly have larger bootstrapped standard errors. The
di erences in mean expenditures between men and women and between whites and non-whites are
quite similar across estimation procedures. As above, the CDE model has the smallest bootstrapped
standard errors of all procedures.
We next explore how some of the average e ects described in Table 3 vary across subsets of
individuals. To do this, we take each person-year in the RHIE dataset, change two or three characteristics of the explanatory variables at a time, and examine how predicted health expenditures
vary for each characteristic. The changes correspond directly to some of those in Table 3, except
that the impacts can vary by health and demographic characteristics. Because all the evidence from
the Monte Carlo experiments and from Table 3 indicate that the CDE model provides accruate
estimates, we only present these multidimensional derivatives as calculated from the CDE model.
Bootstrapped standard errors are after the derivatives at each point and are in parentheses.
The rst panel in Table 4 displays how age e ects vary by gender. At age 20, for example,
men appear to increase health expenditures by $4.37 for each year they age. By age 30, health
expenditures of men increase by $12.06 for every year they get older, and at age 45 and later expenditures are increasing, on average, by more than $16.00 per year. Expenditures of women follow
a much di erent pattern. During their teens and twenties, young womens' health expenditures, on
average, rise rapidly. This is due to pregnany and childbirth costs. Linear interpolation of the age

30

31
18.300
1.674
-5.246
-7.296
-7.107
-5.962
-4.475
-2.928
-1.440
-0.006
-4.618
-2.485
-5.171
-4.425

Coinsurance = 0%
Coinsurance = 25%
Coinsurance = 50%
Average

(4.248)
(7.720)
(4.284)
(2.392)

(14.953)
(8.316)
(6.859)
(6.033)
(5.038)
(4.074)
(3.361)
(3.026)
(3.074)
(0.007)

White Male

0.579
4.368
8.667
12.057
14.485
15.979
16.563
16.312
12.388

(21.791)
(10.076)
(7.906)
(7.570)
(7.201)
(6.585)
(7.518)
(11.087)
(4.401)

Std.Error

Male

Mean

Income = 10K
Income = 15K
Income = 20K
Income = 25K
Income = 30K
Income = 35K
Income = 40K
Income = 45K
Income = 50K
Average

By Gender and Race

Age = 15
Age = 20
Age = 25
Age = 30
Age = 35
Age = 40
Age = 45
Age = 50
Average

By Gender

Evaluation Point

-1.490
-12.127
8.436
-0.840

11.447
6.084
3.795
3.237
3.588
4.423
5.527
6.789
8.150
0.006

(7.157)
(5.734)
(4.219)
(3.639)

(10.523)
(5.593)
(5.594)
(6.304)
(6.867)
(7.386)
(7.958)
(8.626)
(9.405)
(0.008)

Non-white Male

71.456
40.661
14.646
-1.499
-10.803
-15.706
-17.689
-17.778
15.055

(20.878)
(15.009)
(12.091)
(10.133)
(8.560)
(7.584)
(9.029)
(11.684)
(4.967)

Std.Error

Female

Mean

Std.Error

-15.850
12.402
-9.436
-9.836

29.914
8.006
-1.724
-5.296
-5.891
-5.070
-3.609
-1.897
-0.128
-0.005

(5.154)
(8.702)
(5.848)
(2.831)

(17.294)
(9.229)
(6.706)
(5.560)
(4.581)
(3.800)
(3.412)
(3.482)
(3.903)
(0.010)

White Female

Mean

Table 4: Derivative E ects by Group Using the Conditional Density Estimation Technique
Std.Error

-10.769
-8.189
12.868
-4.198

18.372
10.970
7.704
6.880
7.372
8.575
10.169
11.981
13.909
0.007

(10.641)
(8.408)
(6.082)
(5.996)

(14.230)
(7.912)
(7.665)
(8.408)
(9.052)
(9.625)
(10.233)
(10.926)
(11.720)
(0.009)

Non-white Female

Mean

32

Female Indicator

By Race

Coinsurance = 0%
Coinsurance = 25%
Coinsurance = 50%
Average

(33.713)
(15.113)
(7.108)
(6.176)
(6.435)
(7.591)
(5.070)

(9.675)
(10.483)
(5.053)
(5.093)

393.183

White

-10.992
11.726
-8.182
-6.484
(73.822)

(6.045)
(10.938)
(7.198)
(3.189)

GHI = 50

-25.290
-27.572
-22.704
-16.007
-9.806
-4.649
-13.382

GHI = 30
GHI = 40
GHI = 50
GHI = 60
GHI = 70
GHI = 80
Average

By General Health Index

-4.455
-6.546
-3.625
-2.792

Coinsurance = 0%
Coinsurance = 25%
Coinsurance = 50%
Average

Income = 10K

By Income

Std.Error

Mean

Evaluation Point

Std.Error

(34.047)
(14.959)
(7.133)
(5.443)
(4.848)
(5.821)
(4.331)

(6.087)
(8.174)
(3.985)
(3.326)

(4.647)
(8.084)
(5.199)
(2.546)
384.401

(173.283)

Non-white

-9.083
7.193
-5.879
-5.440

GHI = 60

-25.001
-30.776
-26.732
-19.660
-12.745
-6.938
-16.078

-14.294
-1.423
-2.973
-9.695

Income = 20K

Mean

Std.Error

(32.687)
(13.846)
(6.154)
(4.490)
(3.706)
(4.825)
(3.249)

(4.651)
(7.369)
(4.178)
(2.806)

-8.981
3.408
-4.142
-5.544

(3.929)
(6.733)
(3.919)
(2.187)

GHI = 70

-17.386
-25.116
-23.042
-17.420
-11.460
-6.248
-13.876

-13.515
3.986
-4.132
-8.770

Income = 30K

Mean

Table 4: Derivative E ects by Group Using the Conditional Density Estimation Technique | continued

e ects implies that womens' average health expenditures do not return to their average age 20 level
until they are 45 years old.
The second panel of Table 4 explores how the income e ects vary by race and gender. For
each of the four groups, additional income has the largest impact on health expenditures at the
lowest income levels. At income level $10,000, for example, an additional thousand dollars in income increases health expenditures by $11.45 for non-white males and by $29.91 for white females.
For non-whites, the point estimates indicate that additional income always increases health expenditures at higher income levels. But these point estimates for both whites and non-whites are
relatively small and not signi cantly di erent from zero.
The second panel in Table 4 also contains how the e ects of changing the coinsurance rate
vary by race and gender. Except for non-white males, the largest reduction in health expenditures
occurs when the coinsurance rate is raised from zero. Presumably, even a small copayment can
reduce substantively average health expenditures.
The third panel of Table 4 examines the coinsurance and health e ects on expenditures as a
function on income level. Somewhat surprisingly, a rise in the coinsurance rate from zero reduces
health expenditures more for those with average incomes ($30K) than for those with quite low
incomes ($10K). Given the low levels of expenditures at very low incomes, this might simply re ect
the fact that the poor have very little in the way of \discretionary" health expenditures.
The nal three sets of results indicate that the CDE models can easily estimate constant
e ects across levels of characteristics. The bottom of the third panel in Table 4 indicates that
the impact of health status, as measured by the general health index, does not vary by income
level. Likewise, the fourth panel in Table 4 indicates that the e ect of the coinsurance rate on
expenditures does not vary across health levels. The nal panel of this table shows that there is
almost no di erence by race in the male-female expenditure di erential.

4 Conclusion
This paper explores the performance of a new approach for estimating how expected derivatives
of an outcome vary with covariate values when the distribution of the outcome is characterized
by a point mass at zero and large positive skews. Such types of outcomes are often encountered

33

in health economics, where a signi cant fraction of people have no health expenditures and a few
have extremely high expenditures. In Monte Carlo work we calibrated our experimental design
to National Medical Expenditure Survey data and compared the performance of the approximate
conditional density estimator to a simple ordinary least squares model and to more complex ordinary
least squares models that use as explanatory variables polynomials in the explanatory variables used
in the simple OLS models. Overall, we found that the approximate conditional density estimator
that we propose provided accurate and precise estimates of derivatives of expected outcomes for
a wide range of types of explanatory variables. The simple OLS models performed quite poorly,
while the OLS models including the higher order polynomials in the explanatory variables performed
nearly as well as the conditional density estimation approach.
Using the CDE model we reexamine the Rand Health Insurance Experiment data and uncover
several new empirical results. We nd that the largest increases in health expenditures due to
increases in income happen at the lowest levels of the income distribution. We also nd that
increases in the coinsurance rate from free health care to low levels of copayment reduce health
care expenditures more for those with average incomes than for those with well-below average
incomes. It might be the case that those with very low incomes have few discretionary health
expenditures. The third most important result from our examination of the Rand Health Insurance
Experiment data is that increases in health expenditures due to declines in health do not vary by
income level. On average, the poor increase their health expenditures by the same amount as those
with average incomes when their health, as measured by Rand's general health index, declines. We
also recon rm other researchers' results that the largest impacts of increases in coinsurace rates on
health expenditures take place when one raises the coinsurance rate from zero (Newhouse, 1993).
It is important to note that these e ects are based on estimates from the Rand Health Insurance
Experiment where even the poorest individuals in the analysis sample do have health insurance.
We also examined brie y the performance of the commonly used two-part model, where one
estimates whether or not there are positive outcomes with a logit model in the rst part and a
simple OLS model relating the logarithm of the positive outcomes to explanatory variables in a
second part of the statistical model. In order to calculate how the expected outcome changes with
covariates in this framework, it is necessary to exponentiate the predicted log-outcome and adjust
multiplicatively for the expectation of the antilog of the disturbance term. In our preliminary Monte

34

Carlo work we found that this approach yielded imprecise and often absurd estimates. The worst
performances happened in those models where the true data generating process di ered from the
exact statistical speci cation used to de ne the two-part model with logarithmic outcomes. When
we tested for whether one could use a simple speci cation of the explanatory variables in the linearin-logarithm part of the model instead of including higher order polynomial terms, we often rejected
the simpler model because it did not t the data well. Once higher order terms were introduced into
this continuous, logarithmic part of the model, the estimation and approximation errors interacted
with the exponentiation of the expected outcome to yield quite inaccurate predictions of the level
outcomes. The corrections for the expectation of the antilog of the disturbance did not introduce
anywhere near as much noise into the estimates, unless we attempted to model and estimate the
heteroscedasticy of the error terms when applying a \smearing" type correction. We ended up not
using the two-part models with predicted logarithmic expenditures in our Monte Carlo experiments,
as the preliminary evidence suggested that this approach was dominated by the other estimators
we examined. Such extreme inaccuracies were not important for the conditional density estimators
or for the OLS models with level dependent variables and polynomials in the explanatory variables.
Our examination of the Rand Health Insurance Experiment data does provide an illustration of
the poor performance of the two-part model approach used with logarithmic positive expenditures
and smearing.
The implications from our analysis, however, are quite encouraging. They indicate that
researchers who wish to estimate the impact of exogenous changes in covariates such as income,
coinsurance rate, insurance deductible, and health status on expected health expenditures need
only estimate standard ordinary least squares models that combine zero expenditures along with
the level of positive expenditures. The Monte Carlo work also indicates that it is imperative to use
generously speci ed functions of and interactions among the explanatory variables in these OLS
models. The simplest OLS models we explore in the Monte Carlo experiments, i.e., those with level
outcomes and regressors and no higher order terms or interactions, almost always fail to measure
anything resembling a population average derivative in even moderately complex models.
The only drawback to using the OLS and CDE models with polynomials and interactions of
the explanatory variables is the seemingly low precision of the estimates. The standard deviation
for the CDE estimator of the deductible derivative in Table 1a, for example, is three times larger

35

than the standard deviation of the OLS estimator (0.172 vs. 0.057); these standard deviations
indicate the magnitude of the standard errors of the estimates from these estimators. By using
the exible CDE model with the simple linear model DGP in Table 1a (and also Tables A5a, A6a,
and A7a, all of which have the same DGP), calculated t-statistics will be about three times smaller
for the CDE than for the simple OLS estimator. This \lack of precision," however, is due to the
fact that the CDE model allows for the possibility that the e ect of insurance deductible can vary
with the level of the deductible and with the levels of the other covariates. The OLS model imposes
the true restriction, for this DGP, that the deductible e ect is constant across all dimensions.
To put the CDE model onto a more level playing eld with the OLS estimator for this DGP,
consider imposing the restriction that the CDE estimated deductible derivatives are estimating the
same quantity at each level of the deductible that we examined in Table 1a. We do not impose
the restriction that these derivative levels are also constant across all values of all of the other
covariates, as is imposed by the simple OLS estimator. We impose these restrictions ex post by
calculating the covariance matrix for the CDE estimators of the derivative at the seven deductible
levels displayed in this table and solving for that weighted average of the seven point derivatives
that yields the smallest variance. This result is the evaluation point labeled \Min Variance" in
Table 1a and the other tables of Monte Carlo results. We nd that by imposing this restriction
ex post, the standard error of the CDE estimator of the deductible e ect is only 7% higher than
that of the OLS estimator. If one is willing to impose this additional information on the empirical
model, the CDE approach can do nearly as well as the ecient OLS estimator.
Looking across the tables for all of the other DGPs, i.e., those where the classical regression
model is not a true representation of the DGP (Tables 1b-1e, A5b-A5e, A6b-A6e, A7b-A7e), it is
clear that in almost all cases that the simple OLS estimator has the largest bias of all of the four
approaches we examine. It rarely has an average e ect that is closer to the true e ect than any of
the other approaches, and often the bias exceeds 50% of the true average derivative. Simple OLS
still retains the feature that it has the smallest standard deviation of all of the estimators, but for
these DGPs this \precision gain" is more than o set by the misleading information conveyed by
the OLS point estimate of the derivative. This result highlights the fact that relying upon simple
regression speci cations can lead to quite misleading implications. These Monte Carlo experiments
demonstrate that is not the case that a mis-speci ed model is correct on average. Simple and

36

mis-speci ed models can exhibit signi cant biases, and tests based upon estimates from these
approaches will provide misleading information. The exible approaches that we use in the Monte
Carlo experiments and in the examination of the RHIE data do not have this drawback. They do
exhibit larger standard errors than the simple OLS models, but these larger standard errors merely
re ect the fact that the researcher is, truthfully, often unsure about the precise form of the true
regression speci cation. The apparent precision for the simple OLS estimator is ctional and only
comes from the fact that one estimates many fewer parameters than are needed to t the data well.
These CDE models allow one to model more directly the impact of covariates on outcomes.
One could, for example, model exactly how the budget constraint and structure of coinsurance
rates and deductible levels impact health expenditures at various points in the health expenditure
distribution. To do this well would require that one address issues of unobserved endogeneity, and
the CDE approach allows one to use the economic structure of the budget constraint to provide
important restrictions to help achieve identi cation. A nal advantage of the CDE approach is that
in most real world situations researchers will not have experimental data with random assignment
of the features of the health insurance programs that individuals face. Examination of such data
requires that one model endogeneity and address sample selection issues. Accurate estimation will
often entail the use of maximum likelihood models that t the data well, and that is precisely what
the conditional density estimation models can do.

37

References
Allison, P. (1984). Event History Analysis : Regression for Longitudinal Event Data. Beverly Hills,
Calif. : Sage Publications.
Angrist, J. (2000). \Estimation of Limited-Dependent Variable Models with Binary Endogenous
Regressors: Simple Strategies for Empirical Practice," Journal of Business and Economic Statistics,
forthcoming.
Cameron, A. and P. Trivedi (1998). Regression Analysis of Count Data, Cambridge: Cambridge
University Press.
Donald, S., D. Green, and H. Paarsch (2000). \Di erences in Wage Distributions between Canada
and the United States: An Application of a Flexible Estimator of Distribution Functions in the
Presence of Covariates," Review of Economic Studies, forthcoming.
Eastwood, B. and R. Gallant (1991). \Adaptive Rules for Seminonparametric Estimators that
Achieve Asymptotic Normality," Econometric Theory 3, 307-340.
Efron, B. (1988). \Logistic Regression, Survival Analysis, and the Kaplan-Meier Curve," Journal
of the American Statistical Association 83, 414-425.
Hahn, J., P. Todd, and W. Van der Klaauw (2000). \Identi cation and Estimation of Treatment
E ects with a Regression-Discontinuity Design," Econometrica, forthcoming.
Heckman, J. and B. Honore (1990). \The Empirical Content of the Roy Model," Econometrica 58,
1121-49.
Heckman, J. and B. Singer (1984). \A Method for Minimizing the Impact of Distributional Assumptions in Econometric Models for Duration Data," Econometrica 52, 271-320.
Manning, W. (1998). \The Logged Dependent Variable, Heteroscedasticity, and the Retransformation Problem," Journal of Health Economics 17, 283-295.
Manning, W. and J. Mullahy. (2000). \Estimating Log Models: To Transform or Not to Transform," working paper.

38

Manning, W., J. Newhouse, N. Duan, E. Keeler, A. Leibowitz, and M. Marquis (1987). \Health
Insurance and the Demand for Medical Care: Evidence from a Randomized Experiment," American
Economic Review 77, 251-277.
Maddala, G. (1983). \A Survey of the literature on Selectivity Bias as it Pertains to Health Care
Markets," in Scheer, R. and L. Rossiter (eds.) Advances in Health Economics and Health Services
Research 6, London: JAI Press.
Meyer, B. (1990). \Unemployment Insurance and Unemployment Spells," Econometrica 58, 757782.
Mullahy, J. (1998). \Much Ado About Two: Reconsidering the Retransformation and the Two-part
Model in Health Economics," Journal of Health Economics 17, 247-281.
Mroz, T. (1999). \Discrete Factor Approximation in Simultaneous Equation Models: Estimating
the Impact of a Dummy Endogenous Variable on a Continuous Outcome," Journal of Econometrics
92, 233-274.
Mroz, T. and D. Guilkey (1992). \Discrete Factor Approximations for Use in Simultaneous Equation Models with Both Continuous and Discrete Endogenous Variables," manuscript, University of
North Carolina at Chapel Hill.
Mroz, T. and D. Weir (1990). \Structural Change in Life Cycle Fertitly during the Fertility
Transition: France before and after the Revolution of 1789," Population Studies 44, 61-87.
Newhouse, J. (1993). Free for All? Lessons from the RAND Health Insurance Experiment, Cambridge: Harvard University Press.

39

Table A1: Summary Statistics from Rand HIE | First year of each person (2479)
Continuous Variables
Annual medical expenses ($1999)
Annual family income in thousands ($1999)
Annual participation incentive ($1999)
Index of general health at enrollment
Number of disease conditions at enrollment
Maximum deductible amount ($1999)
Coinsurance rate (%)
Age in years
Annual family size
Dummy Variables

Mean

Std.Dev.

Min

Max

783.52
31.79
995.46
70.34
10.31
876.84
30.87
31.10
3.71

2592.95
13.56
864.89
13.93
7.97
937.53
37.50
13.56
1.91

0
0
0
5.7
0
0
0
14
1

79455.11
98.93
2955.65
100.00
58.60
2437.95
95
61
13

Percent

Seattle (omitted category)
Fitchburg
Franklin County
Charleston
Georgetown County
Female
Non-white

27.43
15.69
19.00
16.54
21.34
52.84
18.96

Distribution of First Year Observed

Percent

1976
1977
1978
1979
1980
1981

16.94
49.70
1.98
27.71
2.38
1.29

40

Table A2: Average Derivative De nitions
Derivative

De nition

Let the evaluation points for calculation of the numerical derivative with respect to variable k
be denoted ejk ; j = 1; : : : ; J (k). We approximate the derivative by nite di erences.
Let the sample size at each evaluation point for variable k be denoted njk and the cuto points
be denoted ckj where njk is the number of observations observed to have the value of
variable k fall in the interval [cjk ; cj+1;k ).
Average

For each observed value of Xk , evaluate the function at Xk  2
where  is either the exact distance between adjacent evaluation points
(i.e.,  = ej+1;k ; ejk ) or thePaverage of the distances between the
evaluation points (i.e.,  = ( j ejk )=J (k)). The choice of  depends on the
nature of the observed data (continuous or discrete). Calculate the di erence
between values of the function at each deviated point.

Min Variance

In the calculations of the derivatives for variable k, nd the covariance matrix
of the J (k) derivatives. Find the weighted sum that minimizes the sum of the
squared errors.

Equal Weights Calculate a simple average of the J (k) derivatives at each evaluation point.
This measure accounts for neither the sample size at di erent evaluation points
nor the variances or covariances of the J (k) derivatives.
Weight 1

Weight 2

Calculate the weighted average of the derivatives where the weight is de ned
as the sample size about the evaluation point (njk ). This measure accounts for
the sample size at di erent evaluation points but not the variances or covariances
of the J (k) derivatives.
Calculate the weighted average of the derivatives where the weight is de ned as

wjk = 1=((1=njk ) + (1=nj+1;k )) for each derivative evaluated at a speci c evaluation

point. This measure accounts for sample size at di erent evaluation points.
In part, it accounts for the variances because it accounts for the sample sizes
about the points at where the derivatives are calculated.

41

Table A3: List of Explanatory Variables used in Monte Carlo Experiments
Order of
Polynomial
Expansion
First
Order

List of Variables
ded
age
inc
coi
fem
nwh
hsg
hsf
k

2

k

Second
Order












ded*ded

k

3

insurance deductible level
age
income
coinsurance rate (%)
female indicator
non-white indicator
good health status indicator
fair/poor health status indicator
function of cell indicator used only in CDE model
squared used only in CDE model
ded*coi
coi*coi

ded*inc
coi*inc
inc*inc

ded*age
coi*age
inc*age
age*age

*(all 1st order variables)

ded*fem
coi*fem
inc*fem
age*fem

ded*nwh
coi*nwh
inc*nwh
age*nwh
fem*nwh

ded*hsg ded*hsf
coi*hsg coi*hsf
inc*hsg inc*hsf
age*hsg age*hsf
fem*hsg fem*hsf
nwh*hsg nwh*hsf

k

Third
Order

ded2 *ded
coi2*ded
inc2 *ded
age2*ded
k

ded2 *coi
coi2 *coi
inc2 *coi
age2*coi

ded2 *inc ded2 *age ded2 *fem ded2 *nwh ded2 *hsg ded2 *hsf
coi2 *inc coi2 *age coi2 *fem coi2 *nwh coi2 *hsg coi2*hsf
inc2 *inc inc2 *age inc2 *fem inc2 *nwh inc2 *hsg inc2 *hsf
age2*inc age2 *age age2*fem age2*nwh age2 *hsg age2*hsf

*(all 2nd order variables)

2 *(all 1st order variables)
k
4
k

Fourth
Order

ded3 *ded ded3 *coi ded3 *inc ded3 *age ded3 *fem ded3 *nwh ded3 *hsg ded3 *hsf
coi3*ded coi3 *coi
coi3 *inc coi3 *age coi3 *fem coi3 *nwh coi3 *hsg coi3*hsf
age3*ded age3*coi age3*inc age3 *age age3*fem age3*nwh age3 *hsg age3*hsf
inc3 *ded inc3 *coi
inc3 *inc inc3 *age inc3 *fem inc3 *nwh inc3 *hsg inc3 *hsf
ded2 *coi2 ded2 *inc2 ded2 *age2 coi2*inc2 coi2*age2 inc2 *age2
k

*(all 3rd order variables)

3 *(all 1st order variables)
k

The rst part of all two-part speci cations allows for di erent e ects of the explantory variables
and does not include the shape parameters or its interactions in the CDE model.

42

Table A4: Frequency of Selection of Order of Polynomial Expansion
for each Data Generating Process

Model

Order of Polynomial Expansion
First

Second

Third

Fourth

Total

DGP: Yi = 0 Xi + i , iid normal errors, OLS
OLS levels
OLS logs
CDE

50
7
0

0
42
0

0
1
0

0
0
50

50
50
50

11
2
50

50
50
50

8
1
50

50
50
50

10
2
50

50
50
50

46
17
50

50
50
50

DGP: ln(Yi ) = 0 Xi + i , iid normal errors, 2-part
OLS levels
OLS logs
CDE

0
0
0

8
44
0

31
4
0

DGP: ln(Yi ) = 0 Xi + i ; var()  E [ln(Y )], 2-part
OLS levels
OLS logs
CDE

0
0
0

11
41
0

31
8
0

DGP : ln(Yi ) = i0 Xi + i = Xi + ( i ; )Xi + i ;
random coecients model
OLS levels
OLS logs
CDE

0
0
0

30
41
0

10
7
0

DGP : Mixture model where type depends on
unobserved health state, 2-part
OLS levels
OLS logs
CDE

0
0
0

0
10
0

43

4
23
0

Table A5a: Average Age Derivatives

DGP: Yi = 0 Xi + i , iid normal errors, OLS
Derivative
Evaluation point

OLS

OLS

OLS

Truth

Levels
1st order

Levels
4th order

Logs
4th order

CDE

30

7.504
( 0.000)

7.356
( 0.597)

7.356
( 0.597)

7.841
( 1.733)

7.369
( 2.272)

35

7.504
( 0.000)

7.356
( 0.597)

7.356
( 0.597)

7.549
( 0.748)

7.149
( 1.720)

40

7.504
( 0.000)

7.356
( 0.597)

7.356
( 0.597)

7.253
( 0.752)

7.230
( 1.733)

45

7.504
( 0.000)

7.356
( 0.597)

7.356
( 0.597)

6.967
( 1.172)

7.323
( 1.613)

50

7.504
( 0.000)

7.356
( 0.597)

7.356
( 0.597)

6.697
( 1.539)

7.375
( 1.763)

55

7.504
( 0.000)

7.356
( 0.597)

7.356
( 0.597)

6.446
( 1.822)

7.423
( 2.904)

Average

7.504
( 0.000)

7.356
( 0.597)

7.356
( 0.597)

7.400
( 0.949)

7.586
( 1.481)

Min Variance

7.371
( 0.672)

Equal Weights

7.311
( 0.780)

Weight 1

7.314
( 0.899)

Weight 2

7.313
( 0.749)

Standard deviations from the Monte Carlo experiments are in parentheses.
See Appendix Table A2 for measures of the average derivatives.

44

Table A5b: Average Age Derivatives

DGP: ln(Yi ) = 0 Xi + i , iid normal errors, 2-part
Derivative
Evaluation point

OLS

OLS

OLS

Truth

Levels
1st order

Levels
4th order

Logs
4th order

CDE

30

11.274
( 0.000)

15.324
( 1.031)

13.010
( 2.152)

12.809
( 1.742)

11.472
( 2.267)

35

11.650
( 0.000)

15.324
( 1.031)

13.537
( 2.209)

14.528
( 1.411)

12.265
( 2.067)

40

13.939
( 0.000)

15.324
( 1.031)

14.148
( 2.354)

15.496
( 1.408)

13.588
( 2.356)

45

13.594
( 0.000)

15.324
( 1.031)

15.144
( 2.489)

16.051
( 1.603)

15.006
( 2.301)

50

15.749
( 0.000)

15.324
( 1.031)

16.821
( 2.859)

16.364
( 1.917)

16.179
( 2.522)

55

15.782
( 0.000)

15.324
( 1.031)

19.480
( 5.542)

16.534
( 2.350)

16.654
( 4.044)

Average

12.759
( 0.000)

15.324
( 1.031)

15.042
( 1.908)

13.504
( 1.165)

13.477
( 1.713)

Min Variance

13.871
( 1.047)

Equal Weights

14.194
( 1.195)

Weight 1

13.160
( 1.024)

Weight 2

13.591
( 0.998)

Standard deviations from the Monte Carlo experiments are in parentheses.
See Appendix Table A2 for measures of the average derivatives.

45

Table A5c: Average Age Derivatives
DGP: ln(Yi ) = 0 Xi + i ; var()  E [ln(Y )], 2-part
Derivative
Evaluation point

OLS

OLS

OLS

Truth

Levels
1st order

Levels
4th order

Logs
4th order

CDE

30

13.339
( 0.000)

16.165
( 0.956)

14.457
( 2.595)

14.165
( 2.238)

12.912
( 2.634)

35

12.580
( 0.000)

16.165
( 0.956)

13.978
( 2.641)

15.070
( 1.817)

13.333
( 2.502)

40

13.872
( 0.000)

16.165
( 0.956)

14.449
( 2.443)

15.833
( 1.785)

14.000
( 2.383)

45

15.288
( 0.000)

16.165
( 0.956)

15.686
( 2.756)

16.372
( 1.860)

14.904
( 2.164)

50

16.130
( 0.000)

16.165
( 0.956)

17.504
( 3.063)

16.696
( 2.087)

15.738
( 2.565)

55

16.573
( 0.000)

16.165
( 0.956)

19.717
( 5.237)

16.837
( 2.733)

15.986
( 4.537)

Average

14.389
( 0.000)

16.165
( 0.956)

16.182
( 1.815)

14.732
( 1.466)

13.823
( 1.819)

Min Variance

14.354
( 1.056)

Equal Weights

14.479
( 1.190)

Weight 1

13.876
( 1.239)

Weight 2

14.128
( 1.107)

Standard deviations from the Monte Carlo experiments are in parentheses.
See Appendix Table A2 for measures of the average derivatives.

46

Table A5d: Average Age Derivatives

DGP: ln(Yi ) = i0 Xi + i = Xi + ( i ; )Xi + i ; random coecients model
Derivative
Evaluation point

OLS

OLS

OLS

Truth

Levels
1st order

Levels
4th order

Logs
4th order

CDE

30

12.963
( 0.000)

18.157
( 1.646)

13.669
( 3.171)

13.881
( 2.519)

14.528
( 2.537)

35

13.464
( 0.000)

18.157
( 1.646)

14.794
( 2.871)

16.352
( 2.446)

16.231
( 2.389)

40

16.153
( 0.000)

18.157
( 1.646)

16.733
( 2.832)

17.996
( 2.542)

17.347
( 2.860)

45

18.340
( 0.000)

18.157
( 1.646)

19.103
( 3.947)

19.217
( 2.589)

17.795
( 2.947)

50

20.627
( 0.000)

18.157
( 1.646)

21.526
( 4.730)

20.199
( 3.540)

17.318
( 3.932)

55

22.756
( 0.000)

18.157
( 1.646)

23.618
( 8.008)

21.036
( 5.866)

15.277
( 7.665)

Average

16.067
( 0.000)

18.157
( 1.646)

17.162
( 2.031)

15.524
( 1.730)

14.422
( 1.905)

Min Variance

16.196
( 1.547)

Equal Weights

16.416
( 2.081)

Weight 1

15.837
( 1.602)

Weight 2

16.042
( 1.739)

Standard deviations from the Monte Carlo experiments are in parentheses.
See Appendix Table A2 for measures of the average derivatives.

47

Table A5e: Average Age Derivatives

DGP: Mixture model where type depends on unobserved health state, 2-part
Derivative
Evaluation point

OLS

OLS

OLS

Truth

Levels
1st order

Levels
4th order

Logs
4th order

CDE

30

12.291
( 0.000)

16.489
( 1.257)

15.396
( 3.626)

14.635
( 3.469)

13.706
( 3.367)

35

13.134
( 0.000)

16.489
( 1.257)

15.691
( 3.797)

15.140
( 2.836)

14.108
( 2.539)

40

13.041
( 0.000)

16.489
( 1.257)

14.968
( 2.566)

15.570
( 2.409)

14.933
( 2.759)

45

15.615
( 0.000)

16.489
( 1.257)

14.868
( 3.314)

16.229
( 2.430)

15.790
( 2.423)

50

16.841
( 0.000)

16.489
( 1.257)

17.035
( 3.786)

17.149
( 2.724)

16.585
( 2.406)

55

17.258
( 0.000)

16.489
( 1.257)

23.110
( 5.742)

18.295
( 5.061)

17.389
( 4.410)

Average

14.135
( 0.000)

16.489
( 1.257)

15.801
( 2.249)

14.644
( 2.145)

14.169
( 2.332)

Min Variance

15.357
( 1.249)

Equal Weights

15.419
( 1.281)

Weight 1

14.757
( 1.532)

Weight 2

15.040
( 1.323)

Standard deviations from the Monte Carlo experiments are in parentheses.
See Appendix Table A2 for measures of the average derivatives.

48

Table A6a: Average Income Derivatives

DGP: Yi = 0 Xi + i , iid normal errors, OLS
Derivative
Evaluation point

OLS

OLS

OLS

Truth

Levels
1st order

Levels
4th order

Logs
4th order

CDE

5

4.391
( 0.000)

4.408
( 0.453)

4.408
( 0.453)

5.400
( 2.908)

4.964
( 3.562)

10

4.391
( 0.000)

4.408
( 0.453)

4.408
( 0.453)

5.596
( 0.915)

4.356
( 1.539)

15

4.391
( 0.000)

4.408
( 0.453)

4.408
( 0.453)

5.156
( 0.649)

4.292
( 1.239)

20

4.391
( 0.000)

4.408
( 0.453)

4.408
( 0.453)

4.701
( 0.714)

4.286
( 1.079)

25

4.391
( 0.000)

4.408
( 0.453)

4.408
( 0.453)

4.305
( 0.770)

4.266
( 0.931)

30

4.391
( 0.000)

4.408
( 0.453)

4.408
( 0.453)

3.969
( 0.798)

4.226
( 0.887)

35

4.391
( 0.000)

4.408
( 0.453)

4.408
( 0.453)

3.684
( 0.806)

4.169
( 0.974)

40

4.391
( 0.000)

4.408
( 0.453)

4.408
( 0.453)

3.441
( 0.804)

4.099
( 1.143)

45

4.391
( 0.000)

4.408
( 0.453)

4.408
( 0.453)

3.230
( 0.795)

4.018
( 1.341)

Average

4.391
( 0.000)

4.408
( 0.453)

4.408
( 0.453)

4.310
( 1.592)

4.411
( 1.849)

Min Variance

4.217
( 0.623)

Equal Weights

4.297
( 0.708)

Weight 1

4.388
( 0.877)

Weight 2

4.420
( 0.984)

Standard deviations from the Monte Carlo experiments are in parentheses.
See Appendix Table A2 for measures of the average derivatives.

49

Table A6b: Average Income Derivatives

DGP: ln(Yi ) = 0 Xi + i , iid normal errors, 2-part
Derivative
Evaluation point

OLS

OLS

OLS

Truth

Levels
1st order

Levels
4th order

Logs
4th order

CDE

5

32.353
( 0.000)

13.406
( 0.857)

32.388
( 5.360)

36.985
( 3.233)

33.601
( 4.648)

10

22.130
( 0.000)

13.406
( 0.857)

26.066
( 2.241)

23.892
( 1.485)

23.326
( 1.881)

15

16.872
( 0.000)

13.406
( 0.857)

20.709
( 1.717)

17.770
( 1.252)

17.802
( 2.023)

20

14.227
( 0.000)

13.406
( 0.857)

16.229
( 2.580)

14.205
( 1.288)

14.252
( 2.078)

25

11.406
( 0.000)

13.406
( 0.857)

12.537
( 3.087)

11.868
( 1.319)

11.710
( 1.938)

30

11.673
( 0.000)

13.406
( 0.857)

9.545
( 3.271)

10.215
( 1.326)

9.763
( 1.825)

35

8.512
( 0.000)

13.406
( 0.857)

7.166
( 3.497)

8.984
( 1.322)

8.210
( 1.867)

40

8.840
( 0.000)

13.406
( 0.857)

5.310
( 4.118)

8.030
( 1.312)

6.933
( 2.084)

45

7.353
( 0.000)

13.406
( 0.857)

3.889
( 5.198)

7.270
( 1.302)

5.854
( 2.426)

Average

20.164
( 0.000)

13.406
( 0.857)

22.683
( 1.609)

25.220
( 1.322)

22.529
( 1.811)

Min Variance

14.653
( 0.785)

Equal Weights

14.606
( 0.904)

Weight 1

18.861
( 0.871)

Weight 2

20.004
( 0.892)

Standard deviations from the Monte Carlo experiments are in parentheses.
See Appendix Table A2 for measures of the average derivatives.

50

Table A6c: Average Income Derivatives
DGP: ln(Yi ) = 0 Xi + i ; var()  E [ln(Y )], 2-part
Derivative
Evaluation point

OLS

OLS

OLS

Truth

Levels
1st order

Levels
4th order

Logs
4th order

CDE

5

30.522
( 0.000)

13.862
( 0.912)

31.142
( 4.823)

36.797
( 2.315)

34.075
( 3.872)

10

24.562
( 0.000)

13.862
( 0.912)

25.751
( 2.258)

24.294
( 1.294)

23.400
( 2.046)

15

17.096
( 0.000)

13.862
( 0.912)

21.095
( 1.635)

18.359
( 1.213)

17.883
( 1.889)

20

14.553
( 0.000)

13.862
( 0.912)

17.121
( 2.189)

14.860
( 1.184)

14.445
( 1.696)

25

12.383
( 0.000)

13.862
( 0.912)

13.774
( 2.577)

12.540
( 1.190)

12.059
( 1.459)

30

10.243
( 0.000)

13.862
( 0.912)

11.002
( 2.773)

10.885
( 1.230)

10.290
( 1.472)

35

10.686
( 0.000)

13.862
( 0.912)

8.750
( 3.164)

9.642
( 1.293)

8.921
( 1.811)

40

8.625
( 0.000)

13.862
( 0.912)

6.965
( 4.121)

8.672
( 1.367)

7.827
( 2.318)

45

7.520
( 0.000)

13.862
( 0.912)

5.592
( 5.688)

7.894
( 1.444)

6.929
( 2.868)

Average

23.489
( 0.000)

13.862
( 0.912)

22.700
( 1.833)

25.628
( 1.536)

22.871
( 2.205)

Min Variance

15.102
( 0.990)

Equal Weights

15.092
( 1.209)

Weight 1

19.135
( 1.177)

Weight 2

20.283
( 1.244)

Standard deviations from the Monte Carlo experiments are in parentheses.
See Appendix Table A2 for measures of the average derivatives.

51

Table A6d: Average Income Derivatives

DGP: ln(Yi ) = i0 Xi + i = Xi + ( i ; )Xi + i ; random coecients model
Derivative
Evaluation point

OLS

OLS

OLS

Truth

Levels
1st order

Levels
4th order

Logs
4th order

CDE

5

28.395
( 0.000)

11.573
( 1.236)

22.747
( 5.416)

28.427
( 3.934)

27.908
( 4.824)

10

19.444
( 0.000)

11.573
( 1.236)

19.666
( 2.767)

19.763
( 1.494)

18.553
( 2.142)

15

14.883
( 0.000)

11.573
( 1.236)

17.002
( 1.693)

15.392
( 1.424)

14.285
( 1.888)

20

12.681
( 0.000)

11.573
( 1.236)

14.725
( 2.045)

12.729
( 1.558)

11.942
( 2.003)

25

11.092
( 0.000)

11.573
( 1.236)

12.803
( 2.539)

10.925
( 1.760)

10.456
( 1.898)

30

10.219
( 0.000)

11.573
( 1.236)

11.208
( 2.893)

9.616
( 2.026)

9.382
( 1.783)

35

8.816
( 0.000)

11.573
( 1.236)

9.908
( 3.329)

8.619
( 2.324)

8.518
( 1.845)

40

9.702
( 0.000)

11.573
( 1.236)

8.873
( 4.144)

7.833
( 2.621)

7.765
( 2.122)

45

7.666
( 0.000)

11.573
( 1.236)

8.074
( 5.477)

7.196
( 2.904)

7.076
( 2.538)

Average

21.139
( 0.000)

11.573
( 1.236)

17.709
( 2.211)

20.200
( 1.881)

18.865
( 2.244)

Min Variance

12.914
( 1.171)

Equal Weights

12.876
( 1.254)

Weight 1

15.703
( 1.323)

Weight 2

16.605
( 1.423)

Standard deviations from the Monte Carlo experiments are in parentheses.
See Appendix Table A2 for measures of the average derivatives.

52

Table A6e: Average Income Derivatives

DGP: Mixture model where type depends on unobserved health state, 2-part
Derivative
Evaluation point

OLS

OLS

OLS

Truth

Levels
1st order

Levels
4th order

Logs
4th order

CDE

5

37.375
( 0.000)

15.628
( 0.984)

39.450
( 4.452)

39.784
( 4.527)

40.267
( 4.931)

10

27.317
( 0.000)

15.628
( 0.984)

30.468
( 1.975)

27.726
( 2.024)

28.573
( 2.656)

15

21.204
( 0.000)

15.628
( 0.984)

23.459
( 2.082)

22.122
( 1.624)

22.068
( 1.832)

20

19.742
( 0.000)

15.628
( 0.984)

18.292
( 2.755)

18.894
( 2.004)

17.901
( 1.903)

25

16.285
( 0.000)

15.628
( 0.984)

14.834
( 2.967)

16.784
( 2.491)

15.048
( 2.214)

30

13.597
( 0.000)

15.628
( 0.984)

12.954
( 3.225)

15.289
( 2.960)

13.000
( 2.530)

35

12.681
( 0.000)

15.628
( 0.984)

12.521
( 4.598)

14.166
( 3.388)

11.474
( 2.843)

40

12.177
( 0.000)

15.628
( 0.984)

13.401
( 7.461)

13.286
( 3.771)

10.310
( 3.155)

45

10.595
( 0.000)

15.628
( 0.984)

15.465
( 11.597)

12.572
( 4.111)

9.409
( 3.491)

Average

29.559
( 0.000)

15.628
( 0.984)

28.424
( 2.083)

29.753
( 2.292)

27.355
( 2.595)

Min Variance

18.736
( 1.180)

Equal Weights

18.672
( 1.477)

Weight 1

23.371
( 1.313)

Weight 2

24.694
( 1.450)

Standard deviations from the Monte Carlo experiments are in parentheses.
See Appendix Table A2 for measures of the average derivatives.

53

Table A7a: Average Coinsurance Derivatives
DGP: Yi = 0 Xi + i , iid normal errors, OLS

Derivative
Evaluation point

OLS

OLS

OLS

Truth

Levels
1st order

Levels
4th order

Logs
4th order

CDE

0

-5.000
( 0.000)

-4.985
( 0.955)

-4.985
( 0.955)

-4.801
( 4.017)

-4.644
( 5.101)

10

-5.000
( 0.000)

-4.985
( 0.955)

-4.985
( 0.955)

-4.585
( 2.881)

-4.621
( 3.247)

20

-5.000
( 0.000)

-4.985
( 0.955)

-4.985
( 0.955)

-3.590
( 2.350)

-4.695
( 6.294)

Average

-5.000
( 0.000)

-4.985
( 0.955)

-4.985
( 0.955)

-4.184
( 1.871)

-4.621
( 3.054)

Min Variance

-4.633
( 1.484)

Equal Weights

-4.653
( 2.390)

Weight 1

-4.683
( 5.119)

Weight 2

-4.634
( 1.500)

Standard deviations from the Monte Carlo experiments are in parentheses.
See Appendix Table A2 for measures of the average derivatives.

54

Table A7b: Average Coinsurance Derivatives

DGP: ln(Yi ) = 0 Xi + i , iid normal errors, 2-part
Derivative
Evaluation point

OLS

OLS

OLS

Truth

Levels
1st order

Levels
4th order

Logs
4th order

CDE

0

-5.565
( 0.000)

-9.393
( 1.530)

-5.977
( 4.899)

-4.528
( 4.566)

-5.206
( 5.429)

10

-7.270
( 0.000)

-9.393
( 1.530)

-7.810
( 3.228)

-8.155
( 3.316)

-7.082
( 3.386)

20

-6.637
( 0.000)

-9.393
( 1.530)

-8.103
( 10.263)

-7.027
( 4.088)

-8.057
( 9.418)

Average

-6.212
( 0.000)

-9.393
( 1.530)

-7.668
( 4.501)

-7.235
( 2.338)

-7.395
( 4.043)

Min Variance

-6.626
( 2.120)

Equal Weights

-6.781
( 3.663)

Weight 1

-7.708
( 7.696)

Weight 2

-6.558
( 2.136)

Standard deviations from the Monte Carlo experiments are in parentheses.
See Appendix Table A2 for measures of the average derivatives.

55

Table A7c: Average Coinsurance Derivatives

DGP: ln(Yi ) = 0 Xi + i ; var()  E [ln(Y )], 2-part
Derivative
Evaluation point

OLS

OLS

OLS

Truth

Levels
1st order

Levels
4th order

Logs
4th order

CDE

0

-7.450
( 0.000)

-9.791
( 1.592)

-6.754
( 6.809)

-4.172
( 6.586)

-5.698
( 6.733)

10

-7.468
( 0.000)

-9.791
( 1.592)

-8.145
( 3.789)

-8.984
( 3.500)

-7.472
( 3.826)

20

-7.101
( 0.000)

-9.791
( 1.592)

-8.547
( 8.204)

-7.496
( 3.792)

-8.243
( 7.828)

Average

-7.122
( 0.000)

-9.791
( 1.592)

-8.198
( 3.756)

-7.755
( 2.473)

-7.645
( 3.349)

Min Variance

-7.064
( 1.892)

Equal Weights

-7.138
( 2.912)

Weight 1

-7.942
( 6.298)

Weight 2

-6.965
( 1.934)

Standard deviations from the Monte Carlo experiments are in parentheses.
See Appendix Table A2 for measures of the average derivatives.

56

Table A7d: Average Coinsurance Derivatives

DGP: ln(Yi ) = i0 Xi + i = Xi + ( i ; )Xi + i ; random coecients model
Derivative
Evaluation point

OLS

OLS

OLS

Truth

Levels
1st order

Levels
4th order

Logs
4th order

CDE

0

-5.791
( 0.000)

-9.430
( 1.961)

-8.905
( 5.742)

-3.995
( 8.117)

-3.988
( 7.898)

10

-7.656
( 0.000)

-9.430
( 1.961)

-7.420
( 4.146)

-9.230
( 4.465)

-8.573
( 4.046)

20

-8.829
( 0.000)

-9.430
( 1.961)

-8.459
( 12.778)

-7.374
( 5.252)

-9.017
( 11.922)

Average

-8.092
( 0.000)

-9.430
( 1.961)

-8.012
( 5.527)

-7.771
( 3.423)

-8.048
( 5.444)

Min Variance

-7.186
( 2.088)

Equal Weights

-7.192
( 4.190)

Weight 1

-8.527
( 9.641)

Weight 2

-7.140
( 2.157)

Standard deviations from the Monte Carlo experiments are in parentheses.
See Appendix Table A2 for measures of the average derivatives.

57

Table A7e: Average Coinsurance Derivatives

DGP: Mixture model where type depends on unobserved health state, 2-part
Derivative
Evaluation point

OLS

OLS

OLS

Truth

Levels
1st order

Levels
4th order

Logs
4th order

CDE

0

-16.186
( 0.000)

-16.352
( 1.904)

-13.445
( 8.236)

-12.729
( 7.427)

-10.509
( 8.116)

10

-12.461
( 0.000)

-16.352
( 1.904)

-12.808
( 5.133)

-11.821
( 4.542)

-16.380
( 4.764)

20

-8.644
( 0.000)

-16.352
( 1.904)

-12.567
( 21.886)

-12.757
( 8.804)

-14.362
( 9.012)

Average

-11.443
( 0.000)

-16.352
( 1.904)

-13.514
( 8.118)

-13.011
( 4.436)

-15.211
( 4.403)

Min Variance

-14.250
( 2.704)

Equal Weights

-13.750
( 3.701)

Weight 1

-14.217
( 7.336)

Weight 2

-14.341
( 2.695)

Standard deviations from the Monte Carlo experiments are in parentheses.
See Appendix Table A2 for measures of the average derivatives.

58

59

Second
Order

First
Order

Order of
Polynomial
Expansion

k

3

maximum deductible amount
coinsurance rate
income
age
general health index
number of diseases
family size
female indicator
non-white indicator

t
fra
cha
geo
yr2
yr3
yr4
yr5
yr6

 function of cell indicator used only in CDE model
 squared used only in CDE model





















Fitchburg-Leominster, MA
Franklin Co., MA
Charleston, SC
Georgetown Co., SC
1977 indicator
1978 indicator
1979 indicator
1980 indicator
1981 indicator

mde*mde mde*coi mde*inc mde*age mde*ghi mde*dis mde*fam mde*fem mde*nwh
coi*coi coi*inc coi*age coi*ghi coi*dis coi*fam coi*fem coi*nwh
inc*inc inc*age inc*ghi inc*dis inc*fam inc*fem inc*nwh
age*age age*ghi age*dis age*fam age*fem age*nwh
ghi*ghi ghi*dis ghi*fam ghi*fem ghi*nwh
dis*dis dis*fam dis*fem dis*nwh
fam*fam fam*fem fam*nwh
fem*nwh
k *(all 1st order variables)

k

2

k

mde
coi
inc
age
ghi
dis
fam
fem
nwh

List of Variables

Table A8: List of Explanatory Variables used in HIE Application

60

*(all 2nd order variables)

inc3 *inc

*(all 3rd order variables)

coi3 *coi

k

3 *(all 1st order variables)

k

mde3 *mde

k

2 *(all 1st order variables)
k
4

k

age3*age

ghi3 *ghi

dis3 *dis fam3 *fam

mde2 *mde mde2 *coi mde2 *inc mde2 *age mde2 *ghi mde2 *dis mde2 *fam mde2 *fem mde2 *nwh
coi2 *mde coi2 *coi coi2 *inc coi2*age coi2 *ghi coi2*dis coi2 *fam coi2*fem coi2*nwh
inc2 *mde inc2 *coi inc2 *inc inc2 *age inc2 *ghi inc2 *dis inc2 *fam inc2 *fem inc2 *nwh
age2*mde age2*coi age2*inc age2*age age2*ghi age2*dis age2*fam age2*fem age2*nwh
ghi2 *mde ghi2 *coi ghi2 *inc ghi2*age ghi2 *ghi ghi2 *dis ghi2 *fam ghi2 *fem ghi2*nwh
dis2 *mde dis2 *coi dis2 *inc dis2 *age dis2 *ghi dis2 *dis dis2 *fam dis2 *fem dis2 *nwh
fam2 *mde fam2 *coi fam2 *inc fam2 *age fam2 *ghi fam2 *dis fam2 *fam fam2 *fem fam2 *nwh

List of Variables

The rst part of all two-part speci cations allows for di erent e ects of the explantory variables
and does not include the shape parameters or its interactions in the CDE model.

Fourth
Order

Third
Order

Order of
Polynomial
Expansion

Table A8: List of Explanatory Variables used in HIE Application | continued

